id,node_id,name,full_name,private,owner,html_url,description,fork,created_at,updated_at,pushed_at,homepage,size,stargazers_count,watchers_count,language,has_issues,has_projects,has_downloads,has_wiki,has_pages,has_discussions,forks_count,archived,disabled,open_issues_count,license,allow_forking,is_template,web_commit_signoff_required,visibility,forks,open_issues,watchers,default_branch,score,organization,readme,contributors,manual_label,prediction,release_downloads,code_of_conduct,contributing,security_policy,issue_templates,pull_request_template,subscribers_count,,,Groups/Clubs,Organizations
275949739,MDEwOlJlcG9zaXRvcnkyNzU5NDk3Mzk=,UCSD,aaronkplatt/UCSD,0,aaronkplatt,https://github.com/aaronkplatt/UCSD,Bootcamp,0,2020-06-29 23:39:09+00:00,2020-07-01 00:44:38+00:00,2020-07-01 00:44:36+00:00,,1,0,0,HTML,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['aaronkplatt'],1,0.76,0,,,,,,1,,,,
748879042,R_kgDOLKL8wg,Java-OOP,AbdullahGoma/Java-OOP,0,AbdullahGoma,https://github.com/AbdullahGoma/Java-OOP,Object Oriented Programming in Java,0,2024-01-26 23:51:45+00:00,2024-01-26 23:55:58+00:00,2024-01-26 23:54:09+00:00,,8893,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,main,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)




",['AbdullahGoma'],1,0.76,0,,,,,,1,,,,
54360903,MDEwOlJlcG9zaXRvcnk1NDM2MDkwMw==,MachineLearning,abgrg30/MachineLearning,0,abgrg30,https://github.com/abgrg30/MachineLearning,"CSE250B - University of California, San Diego",0,2016-03-21 04:56:13+00:00,2016-06-16 19:12:19+00:00,2016-03-21 11:07:40+00:00,,1579,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# MachineLearning

",['abgrg30'],1,0.76,0,,,,,,1,,,,
277016265,MDEwOlJlcG9zaXRvcnkyNzcwMTYyNjU=,AlgoToolbox,achyuth-ms/AlgoToolbox,0,achyuth-ms,https://github.com/achyuth-ms/AlgoToolbox,Algorithm Toolbox - UCSD,0,2020-07-04 01:22:48+00:00,2020-07-04 01:40:53+00:00,2020-07-04 01:40:51+00:00,,11,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Algorithm Toolbox - UCSD
Contains codes of Assignments of Algorthim Toolbox course by University of California San Diego.
",['achyuth-ms'],1,0.69,0,,,,,,1,,,,
644679109,R_kgDOJm0FxQ,sdctf-2023,acmucsd/sdctf-2023,0,acmucsd,https://github.com/acmucsd/sdctf-2023,The official challenges and deployment source code files used in San Diego CTF 2023.,0,2023-05-24 03:07:02+00:00,2024-11-15 14:09:07+00:00,2024-04-12 01:32:32+00:00,,1158,4,4,Jupyter Notebook,1,1,1,0,0,0,0,0,0,0,mit,1,0,0,public,0,0,4,main,1,1,"# SDCTF 2023

Here is the challenge and infrastructure files of [San Diego CTF 2023](https://sdc.tf).
Challenge files include source code that implement the challenge ideas.

This CTF was deployed on [Google Cloud Platform](https://cloud.google.com/) using the brilliant [kCTF](https://github.com/google/kctf) framework. Please check them out.

### Disclaimer

**San Diego CTF** is managed by the [ACM chapter at UC San Diego's](https://acmucsd.com/) Cyber community.
We're a bunch of college students and SDCTF 2023 is over, so ***no support will be provided*** for the building, deploying, and managing of these challenges.
This repository is published as a courtesy in the hopes that it will be educational to those interested in cybersecurity.


## Contents

Each challenge is in its own subdirectory with its build files (Ex. Makefiles), generation scripts, and deploy files (Ex. Dockerfiles, challenge.yaml).
`README.md` inside those folders are summaries of the challenge, information about CTF performance, internal specifications (if available), and links to writeups (if provided).

## Build and Deploy Instructions

First time setup for deployment: do the following in the given order

1. Setup [`kctf` environment](https://google.github.io/kctf/) (lol don't underestimate this)
2. Run command `kctf chal start` in every directory containing `challenge.yaml` (Tip: List them using `find . -name challenge.yaml`)
You can also currently run challenges locally (without deploying to a running cluster) with `kctf chal debug docker`.
See [the official docs](https://google.github.io/kctf/local-testing.html) for more information.

After updating the source code of any challenge(s), remember to run `kctf chal start` on the updated challenges to update the deployment.

We recommend building/running everything in [Google Cloud Shell](https://cloud.google.com/shell), which has a lot of tools (Ex. `gcc`) already built in.

## Google Cloud Shell

It is recommended to add the following to [`~/.customize_environment` in Google Cloud Shell](https://cloud.google.com/shell/docs/configuring-cloud-shell#environment_customization_script) so you have all the packages necessary to build or test the CTF.

```bash
#! /bin/bash
# Netcat/socat is useful when testing broken challenges. It is not necessary for building challenges
# Nasm is necessary to build some pwn challenges written in assembly
apt-get update -y && apt-get -y install netcat-openbsd socat nasm
```
",['nick-ls'],1,0.83,0,,,,,,1,,,,
37036996,MDEwOlJlcG9zaXRvcnkzNzAzNjk5Ng==,tritonbattles,Alex827/tritonbattles,0,Alex827,https://github.com/Alex827/tritonbattles,Flashcard app for UCSD,0,2015-06-07 23:52:06+00:00,2015-07-17 23:26:18+00:00,2015-06-10 08:27:52+00:00,,25716,0,0,HTML,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,"['Alex827', 'denthos']",1,0.65,0,,,,,,1,,,,
199931408,MDEwOlJlcG9zaXRvcnkxOTk5MzE0MDg=,SigProfilerMatrixGeneratorR,AlexandrovLab/SigProfilerMatrixGeneratorR,0,AlexandrovLab,https://github.com/AlexandrovLab/SigProfilerMatrixGeneratorR,R wrapper for utilizing the SigProfilerMatrixGenerator framework,0,2019-07-31 21:27:57+00:00,2023-07-11 01:14:37+00:00,2023-01-14 03:26:43+00:00,,1491,20,20,R,1,1,1,1,0,0,4,0,0,0,bsd-2-clause,1,0,0,public,4,0,20,master,1,1,"[![Docs](https://img.shields.io/badge/docs-latest-blue.svg)](https://osf.io/s93d5/wiki/home/) [![License](https://img.shields.io/badge/License-BSD\%202--Clause-orange.svg)](https://opensource.org/licenses/BSD-2-Clause) [![Build Status](https://travis-ci.com/AlexandrovLab/SigProfilerMatrixGeneratorR.svg?branch=master)](https://travis-ci.com/AlexandrovLab/SigProfilerMatrixGeneratorR)

# SigProfilerMatrixGeneratorR
An R wrapper for running the SigProfilerMatrixGenerator (https://osf.io/s93d5/wiki/home/) framework.

**INTRODUCTION**

The purpose of this document is to provide a guide for using the SigProfilerMatrixGenerator framework to generate mutational matrices for a set of samples with associated mutational catalogues. An extensive Wiki page detailing the usage of this tool can be found at https://osf.io/s93d5/wiki/home/. For users that prefer working in a Python environment, the tool is written in Python and can be found and installed from: https://github.com/AlexandrovLab/SigProfilerMatrixGenerator

![schematic](schematic.png)

**PREREQUISITES**

devtools  (R)
```R
>> install.packages(""devtools"")
```

reticulate* (R)
```R
>> install.packages(""reticulate"")  
```

*Reticulate has a known bug of preventing python print statements from flushing to standard out. As a result, some of the typical progress messages are delayed.

Alternatively, you can set up a conda environment with all the prerequisites. You can download minicoda for your operating system [here](https://docs.conda.io/en/latest/miniconda.html) and follow the instructions below:

```
conda create --name spmg_r -y
conda activate spmg_r
conda install python=3.10 r-base r-devtools r-reticulate -c conda-forge -y
```

**QUICK START GUIDE**

This section will guide you through the minimum steps required to create mutational matrices:
1. First, install the python package using pip. The R wrapper still requires the python package:

```
pip install SigProfilerMatrixGenerator
```
2. Open an R session and ensure that your R interpreter recognizes the path to your python3 installation:
```R
$ R
>> library(reticulate)
>> use_python(""[path_to_your_python3]"") # if using conda the path will be [path_to_your_conda]/envs/spmg_r/bin/python
>> py_config()
python:         /anaconda3/bin/python3
libpython:      /anaconda3/lib/libpython3.6m.dylib
pythonhome:     /anaconda3:/anaconda3
version:        3.6.5 |Anaconda, Inc.| (default, Apr 26 2018, 08:42:37)  [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]
numpy:          /anaconda3/lib/python3.6/site-packages/numpy
numpy_version:  1.16.1
```

If you do not see your python3 path listed, restart your R session and rerun the above commands in order.

2. Install SigProfilerMatrixGeneratorR using devtools:
```R
>>library(devtools)
>>install_github(""AlexandrovLab/SigProfilerMatrixGeneratorR"")
```

3. Load the package in the same R session and install your desired reference genome as follows (available reference genomes are: GRCh37, GRCh38, mm9, and mm10):
```R
>> library(""SigProfilerMatrixGeneratorR"")
>> install('GRCh37', rsync=FALSE, bash=TRUE)
```

This will install the human 37 assembly as a reference genome.

4. Place your vcf files in your desired output folder. It is recommended that you name this folder based on your project's name

5. From within the same R session, you can now generate the matrices as follows:

****SBS/DBS/ID****
```R
>> library(""SigProfilerMatrixGeneratorR"")
>> matrices <- SigProfilerMatrixGeneratorR(""test_SBS"", ""GRCh37"", ""[path_to_repo]/test_data/SBS"", plot=T, exome=F, bed_file=NULL, chrom_based=F, tsb_stat=False, seqInfo=False, cushion=100)
```

  The layout of the required parameters are as follows:

```R
SigProfilerMatrixGeneratorFunc(project, reference_genome, path_to_input_files)
```

  where project, reference_genome, and path_to_input_files must be strings (surrounded by quotation marks, ex: ""test""). Optional parameters include:


      exome=FALSe:       [boolean] Downsamples mutational matrices to the exome regions of the genome
      bed_file=NULL      [string path to bed_file] Downsamples mutational matrices to custom regions of the genome. Requires the full path to the BED file.
      chrom_based=FALSE  [boolean] Outputs chromosome-based matrices
      plot=FALSE         [boolean] Integrates with SigProfilerPlotting to output all available visualizations for each matrix.
      tsb_stat=FALSE     [boolean] Outputs the results of a transcriptional strand bias test for the respective matrices.
      seqInfo=FALSE      [boolean] Ouputs original mutations into a text file that contains the SigProfilerMatrixGenerator classificaiton for each mutation.
      cushion=100        [integer] Adds an Xbp cushion to the exome/bed_file ranges for downsampling the mutations.


**INPUT FILE FORMAT**

This tool currently supports maf, vcf, simple text file, and ICGC formats. The user must provide variant data adhering to one of these four formats. If the userâ€™s files are in vcf format, each sample must be saved as a separate files.



**CNV & SV: Setting up R environment with conda**

```
conda create --name spmg_r_1.2.13 -y
conda activate spmg_r_1.2.13
conda install python=3.10 r-base r-devtools r-reticulate -c conda-forge -y
pip install SigProfilerMatrixGenerator
echo 'devtools::install_github(""AlexandrovLab/SigProfilerMatrixGeneratorR"")' | Rscript -

```

****Generating CNV matrices****
```R
>> library(""SigProfilerMatrixGeneratorR"")
>> matrix_cnv <- CNVMatrixGenerator(""BATTENBERG"", ""[path_to_repo]/test_data/CNV"", ""test_CNV"", ""output_dir_CNV"")
```

### CNV Function Arguments ###

These are the acceptable parameters that can be passed into the function call.<br>

**Required:**<br>
 - **file_type:** Segmentation/caller type. Currently supported callers are [""ASCAT"", ""ASCAT_NGS"", ""SEQUENZA"", ""ABSOLUTE"", ""BATTENBERG"", ""FACETS"", ""PURPLE"", ""TCGA""]. <br> *Type:* string <br> *Example:* ""BATTENBERG""


 - **input_file:** Path to directory containing SV bedpe files, one per sample. <br> *Type:* string <br> *Example:* ""./SigProfilerMatrixGenerator/references/SV/example_input/560-Breast""

 - **output_path:** Path to directory for output files. If this directory doesn't exist, a new one will created. <br> *Type:* string <br> *Example:* ""./SigProfilerMatrixGenerator/references/SV/example_output/""

 - **project:** Project name for this instance of matrix generation. <br> *Type:* string <br> *Example:* ""560-Breast""

****Generating SV Matrices****
```R
>> library(""SigProfilerMatrixGeneratorR"")
>> matrix_sv <- SVMatrixGenerator(""[path_to_repo]/test_data/SV"", ""test_SV"", ""output_dir_SV"")
```

### SV Function Arguments ###

These are the acceptable parameters that can be passed into the function call.<br>

**Required:**<br>
 - **project:** Project name for this instance of matrix generation. <br> *Type:* string <br> *Example:* ""560-Breast""

 - **input_dir:** Path to directory containing SV bedpe files, one per sample. <br> *Type:* string <br> *Example:* ""./SigProfilerMatrixGenerator/references/SV/example_input/560-Breast""

 - **output_dir:** Path to directory for output files. If this directory doesn't exist, a new one will created. <br> *Type:* string <br> *Example:* ""./SigProfilerMatrixGenerator/references/SV/example_output/""


**SUPPORTED GENOMES**


This tool currently supports the following genomes:

GRCh38.p12 [GRCh38] (Genome Reference Consortium Human Reference 38), INSDC
Assembly GCA_000001405.27, Dec 2013. Released July 2014. Last updated January 2018. This genome was downloaded from ENSEMBL database version 93.38.

GRCh37.p13 [GRCh37] (Genome Reference Consortium Human Reference 37), INSDC
Assembly GCA_000001405.14, Feb 2009. Released April 2011. Last updated September 2013. This genome was downloaded from ENSEMBL database version 93.37.

GRCm39 [mm39] (Genome Reference Consortium Mouse Reference 39), INSDC
Assembly GCA_000001635.9, Jun 2020. Last updated August 2020. This genome was downloaded from ENSEMBL database version 103.

GRCm38.p6 [mm10] (Genome Reference Consortium Mouse Reference 38), INDSDC
Assembly GCA_000001635.8, Jan 2012. Released July 2012. Last updated March 2018. This genome was downloaded from ENSEMBL database version 93.38.

GRCm37 [mm9] (Release 67, NCBIM37), INDSDC Assembly GCA_000001635.18.
Released Jan 2011. Last updated March 2012. This genome was downloaded from ENSEMBL database version release 67.

Rnor_6.0 [rn6] INSDC Assembly GCA_000001895.4, Jul 2014. Released Jun 2015. Last updated Jan 2017.
This genome was downloaded from ENSEMBL database version 96.6.

Epstein-Barr Virus [EBV] NC_007605.1, Nov 2005. Last updated Aug 2018. This genome was downloaded from the NCBI database: https://www.ncbi.nlm.nih.gov/nuccore/82503188/.

CanFam3.1 [dog] GCA_000002285.2, Sep 2011. Last updated Jun 2019. This genome was downloaded from ENSEMBL database version 100.

WBcel235 [c_elegans] GCA_000002985.3, Oct 2014. Last updated Jan 2019. This genome was downloaded from ENSEMBL database version 100.

*One can specify ""_havana"" to the end of the genome to include annotations in t-cell receptor genes and IG clusters (available for GRCh37, GRCh38, and mm10).


**LOG FILES**

All errors and progress checkpoints are saved into *sigProfilerMatrixGenerator_[project]_[genome].err* and *sigProfilerMatrixGenerator_[project]_[genome].out*, respectively.
For all errors, please email the error and progress log files to the primary contact under CONTACT INFORMATION.

**CITATION**

Bergstrom EN, Huang MN, Mahto U, Barnes M, Stratton MR, Rozen SG, Alexandrov LB: SigProfilerMatrixGenerator: a tool for visualizing and exploring patterns of small mutational events. BMC Genomics 2019, 20:685
https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6041-2



**COPYRIGHT**

Copyright (c) 2020, Erik Bergstrom [Alexandrov Lab] All rights reserved.

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.

Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

**CONTACT INFORMATION**

Please address any queries or bug reports for SBS/ID/DBS to Erik Bergstrom at ebergstr@eng.ucsd.edu
Please address any queries or bug reports for CNV/SV to Azhar Khandekar at akhandek@eng.ucsd.edu
","['marcos-diazg', 'azhark2']",1,0.51,0,,,,,,2,,,,
925859987,R_kgDONy-Akw,HardHack,AlexWoods1/HardHack,0,AlexWoods1,https://github.com/AlexWoods1/HardHack,HardHack2024 UCSD,0,2025-02-01 23:03:33+00:00,2025-02-02 16:12:58+00:00,2025-02-02 16:12:55+00:00,,21,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['AlexWoods1'],-1,0.78,0,,,,,,1,,,,
406379858,MDEwOlJlcG9zaXRvcnk0MDYzNzk4NTg=,AmirhoseinJavadi,Amirhosein-javadi/AmirhoseinJavadi,0,Amirhosein-javadi,https://github.com/Amirhosein-javadi/AmirhoseinJavadi,"Hi, Iâ€™m Amirhosein Javadi. I'm a student at Sharif University of Technology",0,2021-09-14 13:32:32+00:00,2024-09-15 03:00:16+00:00,2024-09-15 03:00:12+00:00,https://github.com/Amirhosein-javadi,942,1,1,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,,['Amirhosein-javadi'],1,0.72,0,,,,,,1,,,,
107894780,MDEwOlJlcG9zaXRvcnkxMDc4OTQ3ODA=,smartercapes.com,andportnoy/smartercapes.com,0,andportnoy,https://github.com/andportnoy/smartercapes.com,Report cards for courses at UCSD using simple statistical analysis.,0,2017-10-22 19:10:25+00:00,2023-03-08 20:07:11+00:00,2022-08-17 15:31:21+00:00,https://smartercapes.com,1524,14,14,CSS,1,1,1,1,0,0,3,0,0,7,,1,0,0,public,3,7,14,master,1,,,"['andportnoy', 'godwinpang']",-1,0.78,0,,,,,,2,,,,
51066365,MDEwOlJlcG9zaXRvcnk1MTA2NjM2NQ==,sugarfree,andrewbuss/sugarfree,0,andrewbuss,https://github.com/andrewbuss/sugarfree,Emulated Vanilla core for UCSD CSE 141L,0,2016-02-04 09:44:38+00:00,2016-02-04 23:13:44+00:00,2016-02-06 00:21:02+00:00,,7,2,2,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,2,master,1,,,['andrewbuss'],1,0.77,0,,,,,,1,,,guruucsd,ucsd-ets
397878309,MDEwOlJlcG9zaXRvcnkzOTc4NzgzMDk=,amazon-product-reviews-exploratory-data-analysis,arham-rumi/amazon-product-reviews-exploratory-data-analysis,0,arham-rumi,https://github.com/arham-rumi/amazon-product-reviews-exploratory-data-analysis,,0,2021-08-19 08:54:11+00:00,2024-04-27 13:11:44+00:00,2022-10-20 11:43:38+00:00,,28169,3,3,Jupyter Notebook,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,3,main,1,,"
# Amazon Product Reviews - Exploratory Data Analysis

In this project, I am going to perform Exploratory Data Analysis on Amazon Product Reviews that will lead stakeholders to the understanding of data distribution, solving problem statements and some other aspects of data. Explanation of results is given in this [Medium Article](https://medium.com/@arhamrumi/amazon-reviews-eda-662c485ec00c).

_This project will remain in progress for better analysis_

## Acknowledgements

_WE DON NOT OWN ANY DATA_

_Our Datasets Resource for this Project is_

 - [ucsd.edu (JSON-Raw Data)](http://deepyeti.ucsd.edu/jianmo/amazon/index.html)
 - [Amazon Reviews (CSV-Cleaned Data)](https://www.kaggle.com/arhamrumi/amazon-reviews-eda-20012018)

  
## Technologies used

Following are the main technologies, used in this project

- Python
- Jupyter Lab

    Install it using the following pip command in CMD
    ```
    pip install jupyterlab
    ```

  
## Contributing

Contributions are always welcome!

For major changes, please open an issue first to discuss what you would like to change.

  
## Support

For support, email arhamrumi007@gmail.com


  
## Connection Links ðŸ”—
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://arham-rumi.netlify.app/)
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/arham-rumi-94769b180/)
","['arham-rumi', 'deepsourcebot']",0,0.7,0,,,,,,2,,,,
99174119,MDEwOlJlcG9zaXRvcnk5OTE3NDExOQ==,course-reviews-scraper,ArronJLinton/course-reviews-scraper,0,ArronJLinton,https://github.com/ArronJLinton/course-reviews-scraper,,0,2017-08-03 00:52:04+00:00,2023-03-08 21:38:25+00:00,2018-06-11 19:24:39+00:00,,167671,2,2,JavaScript,1,1,1,1,0,0,5,0,0,1,,1,0,0,public,5,1,2,master,1,,,"['jsorannotrilogy', 'afhaque', 'ArronJLinton']",0,0.66,0,,,,,,2,,,,
293320210,MDEwOlJlcG9zaXRvcnkyOTMzMjAyMTA=,Data-Structure-UC-San-Diego,Arsh77/Data-Structure-UC-San-Diego,0,Arsh77,https://github.com/Arsh77/Data-Structure-UC-San-Diego,Coursera UC San Diego course solution,0,2020-09-06 16:47:05+00:00,2020-09-06 16:53:09+00:00,2020-09-06 16:53:06+00:00,,1040,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Data-Structure-UC-San-Diego
Coursera UC San Diego course solution
",['Arsh77'],1,0.7,0,,,,,,1,,,,
370505793,MDEwOlJlcG9zaXRvcnkzNzA1MDU3OTM=,Mjolnir_kit,ArthurDassier/Mjolnir_kit,0,ArthurDassier,https://github.com/ArthurDassier/Mjolnir_kit,,0,2021-05-24 23:02:11+00:00,2025-01-11 11:32:21+00:00,2021-12-04 21:14:17+00:00,,4285,18,18,Python,1,1,1,1,0,0,4,0,0,0,,1,0,0,public,4,0,18,master,1,,,"['djnighti', 'ArthurDassier', 'fadli0029', 'Ayilay', 'degulati']",1,0.66,0,,,,,,2,,,vibansal,
151766222,MDEwOlJlcG9zaXRvcnkxNTE3NjYyMjI=,Big-Data-Specialization,Aryann-rajnish/Big-Data-Specialization,0,Aryann-rajnish,https://github.com/Aryann-rajnish/Big-Data-Specialization,coursera (Created by:  University of California San Diego),0,2018-10-05 19:06:09+00:00,2018-10-05 21:02:02+00:00,2018-10-05 21:02:00+00:00,,1766,0,0,Jupyter Notebook,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,"# Big-Data-Specialization
",['Aryann-rajnish'],1,0.59,0,,,,,,0,,,,
49069147,MDEwOlJlcG9zaXRvcnk0OTA2OTE0Nw==,UCSD2,athkou/UCSD2,0,athkou,https://github.com/athkou/UCSD2,Project for Course 2 in the UCSD Specialization,0,2016-01-05 13:57:36+00:00,2016-02-04 13:56:38+00:00,2016-02-04 13:52:31+00:00,,2202,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['athkou'],1,0.67,0,,,,,,1,,,,
288828132,MDEwOlJlcG9zaXRvcnkyODg4MjgxMzI=,DATA-STRUCTURES-AND-ALGORITHMS-SPECIALIZATION,Baasant/DATA-STRUCTURES-AND-ALGORITHMS-SPECIALIZATION,0,Baasant,https://github.com/Baasant/DATA-STRUCTURES-AND-ALGORITHMS-SPECIALIZATION,,0,2020-08-19 20:15:01+00:00,2020-10-04 02:19:49+00:00,2020-10-04 02:19:47+00:00,,1105,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['Baasant'],1,0.69,0,,,,,,1,,,,
441948607,R_kgDOGleZvw,lajolla_public,BachiLi/lajolla_public,0,BachiLi,https://github.com/BachiLi/lajolla_public,UCSD CSE 272 renderer,0,2021-12-26 17:36:31+00:00,2025-02-23 20:52:03+00:00,2025-01-06 18:38:37+00:00,,169787,88,88,C++,1,1,1,1,0,0,53,0,0,2,mit,1,0,0,public,53,2,88,main,1,,,"['BachiLi', 'AlstonXiao', 'jf514', 'ken2576', 'WeichenLiu', 'TH3CHARLie', 'TonyZYT2000', 'arthur-x', 'Cjkkkk', 'yashbelhe']",1,0.78,0,,,,,,5,,,,
206792473,MDEwOlJlcG9zaXRvcnkyMDY3OTI0NzM=,UnfoldingMaps,Basem-Gaber/UnfoldingMaps,0,Basem-Gaber,https://github.com/Basem-Gaber/UnfoldingMaps,Unfolding Maps project in Java using starter code from a UCSD course on coursera,0,2019-09-06 12:47:53+00:00,2019-09-06 13:08:54+00:00,2019-09-06 13:08:51+00:00,,11659,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)




",['Basem-Gaber'],1,0.76,0,,,,,,1,,,,
830654298,R_kgDOMYLHWg,rendercv,bchester102/rendercv,0,bchester102,https://github.com/bchester102/rendercv,,0,2024-07-18 17:41:19+00:00,2024-12-13 22:47:28+00:00,2024-12-13 22:47:24+00:00,,878,0,0,TeX,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,,['bchester102'],1,0.8,0,,,,,,1,,,,
181343507,MDEwOlJlcG9zaXRvcnkxODEzNDM1MDc=,UCSDUnfoldingMaps,Bealfan/UCSDUnfoldingMaps,0,Bealfan,https://github.com/Bealfan/UCSDUnfoldingMaps,UCSD,0,2019-04-14 17:18:39+00:00,2019-04-14 17:18:57+00:00,2019-04-14 17:18:54+00:00,,11711,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,[],1,0.74,0,,,,,,1,,,,
567410502,R_kgDOIdH_Rg,bimm143,bel008/bimm143,0,bel008,https://github.com/bel008/bimm143,UCSD Bioinformatics Lab - FA22,0,2022-11-17 18:23:53+00:00,2022-12-01 19:31:23+00:00,2022-12-01 23:27:32+00:00,,6362,0,0,HTML,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['bel008'],1,0.71,0,,,,,,1,,,,
118879974,MDEwOlJlcG9zaXRvcnkxMTg4Nzk5NzQ=,UCSDUnfoldingMaps,bhavna04/UCSDUnfoldingMaps,0,bhavna04,https://github.com/bhavna04/UCSDUnfoldingMaps,"Project in Certification Course: Object Oriented Programming in Java by University of California, San Diego.",0,2018-01-25 07:44:49+00:00,2018-01-25 07:44:49+00:00,2018-01-25 07:44:50+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],1,0.75,0,,,,,,1,,,,
84460480,MDEwOlJlcG9zaXRvcnk4NDQ2MDQ4MA==,ucsd-bioinformatics-1,Bioinformanics/ucsd-bioinformatics-1,0,Bioinformanics,https://github.com/Bioinformanics/ucsd-bioinformatics-1,"Finding Hidden Messages in DNA (Bioinformatics I) by University of California, San Diego (https://www.coursera.org/learn/dna-analysis/home/welcome)",0,2017-03-09 15:55:11+00:00,2023-10-05 14:18:36+00:00,2017-04-01 08:19:58+00:00,,3881,7,7,Python,1,1,1,1,0,0,6,0,0,0,gpl-3.0,1,0,0,public,6,0,7,master,1,1,"# ucsd-bioinformatics-1
Finding Hidden Messages in DNA (Bioinformatics I) by University of California, San Diego (https://www.coursera.org/learn/dna-analysis/home/welcome)
",['karlzf'],1,0.65,0,,,,,,1,,,,
833393479,R_kgDOMayTRw,ucsdcssa-app-frontend,bothermeQAQ/ucsdcssa-app-frontend,0,bothermeQAQ,https://github.com/bothermeQAQ/ucsdcssa-app-frontend,,0,2024-07-25 00:53:19+00:00,2025-01-14 00:24:47+00:00,2024-08-28 15:40:53+00:00,,60,0,0,JavaScript,1,1,1,1,0,0,3,0,0,1,,1,0,0,public,3,1,0,main,1,,,"['bothermeQAQ', 'francisgan']",1,0.81,0,,,,,,1,,,,
802696854,R_kgDOL9gulg,ucsdWebsite,Cardi16/ucsdWebsite,0,Cardi16,https://github.com/Cardi16/ucsdWebsite,my ucsd website.... @ https://acsweb.ucsd.edu/~jeacovera/index.html,0,2024-05-19 02:32:26+00:00,2024-06-14 01:18:21+00:00,2024-06-14 01:18:18+00:00,,11153,0,0,HTML,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['Cardi16'],1,0.78,0,,,,,,1,,,,
221542179,MDEwOlJlcG9zaXRvcnkyMjE1NDIxNzk=,ucsd-mobile-site,chorta/ucsd-mobile-site,0,chorta,https://github.com/chorta/ucsd-mobile-site,UCSD mobile site redesign,0,2019-11-13 20:07:01+00:00,2020-05-06 16:47:16+00:00,2020-05-06 22:13:30+00:00,,3347,0,0,HTML,1,1,1,1,1,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,,"['chorta', 'cindyhuynh']",1,0.7,0,,,,,,1,,,,
28250214,MDEwOlJlcG9zaXRvcnkyODI1MDIxNA==,Bioinformatics-Algorithms,chrisgarcia001/Bioinformatics-Algorithms,0,chrisgarcia001,https://github.com/chrisgarcia001/Bioinformatics-Algorithms,Programming exercises - bioinformatics algorithms,0,2014-12-19 23:19:44+00:00,2015-04-26 22:05:35+00:00,2015-04-26 22:05:35+00:00,,6208,1,1,Ruby,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"Bioinformatics Algorithms
=========================

Programming exercises (in Ruby) - bioinformatics algorithms from UC San Diego (F2013) course.
",['chrisgarcia001'],1,0.64,0,,,,,,1,,,,
314351480,MDEwOlJlcG9zaXRvcnkzMTQzNTE0ODA=,Christina2021,Christina2021/Christina2021,0,Christina2021,https://github.com/Christina2021/Christina2021,,0,2020-11-19 19:37:04+00:00,2021-03-03 23:48:16+00:00,2021-03-03 23:48:14+00:00,,679,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['Christina2021'],1,0.65,0,,,,,,1,,,,
12654113,MDEwOlJlcG9zaXRvcnkxMjY1NDExMw==,hackromatics,chuyaguo/hackromatics,0,chuyaguo,https://github.com/chuyaguo/hackromatics,Client wrapper api for syncromatics transit systems,0,2013-09-06 20:41:56+00:00,2016-11-01 07:24:50+00:00,2013-09-06 20:35:05+00:00,,85,5,5,Python,0,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,5,master,1,,"hackromatics
============
Client wrapper api for Syncromatics (http://www.syncromatics.com/) transit system.

install
=======
Requires `requests` (https://github.com/kennethreitz/requests).

how to use
==========
```python
import hackromatics

# connect the the server
api = hackromatics.API('http://ladotbus.com')

# get the transit regions
regions = api.regions()

# print out some info about the regions
for region in regions:
    print region.Name
```

sample sites
============
Here is an incomplete list of Syncromatics hosted transit sites: 
- UPenn Transit System ('http://pennrides.com')
- Los Angeles Department of Transportation ('http://ladotbus.com')
- keywest ('http://kwtransit.com') 
- UC San Diego ('http://www.ucsdbus.com/') 
- University of South Florida ('http://www.usfbullrunner.com')
- SF Presidio ('http://www.presidiobus.com/')
- CSU Long Beach ('http://csulbshuttle.com')
- Mississippi State ('http://transit.msstate.edu/')
- CSU Pomona ('http://broncoshuttle.com/')
- University of Delaware ('http://udshuttle.com')
- University of San Diego ('http://usdtram.com')
- National Institute of Health ('http://wttsshuttle.com/')
- UC San Francisco ('http://ucsfshuttles.com')
",['bgilb'],0,0.76,0,,,,,,2,,,,
115585297,MDEwOlJlcG9zaXRvcnkxMTU1ODUyOTc=,CognitiveCanvas-Mapping,CognitiveCanvas/CognitiveCanvas-Mapping,0,CognitiveCanvas,https://github.com/CognitiveCanvas/CognitiveCanvas-Mapping,Collaborative concept map build on webstrates.,0,2017-12-28 04:36:16+00:00,2024-01-25 17:48:09+00:00,2018-10-08 23:38:20+00:00,,909,8,8,JavaScript,1,1,1,1,0,0,3,0,0,3,,1,0,0,public,3,3,8,master,1,1,,"['XavierXinweiWang', 'GaParmar', 'stezh', 'mt3p', 'meicheng', 'IsaacFehr']",1,0.82,0,,,,,,6,,,,
197059490,MDEwOlJlcG9zaXRvcnkxOTcwNTk0OTA=,corundum,corundum/corundum,0,corundum,https://github.com/corundum/corundum,Open source FPGA-based NIC and platform for in-network compute,0,2019-07-15 19:27:33+00:00,2025-03-08 06:11:48+00:00,2024-07-05 08:24:12+00:00,https://corundum.io/,20398,1826,1826,Verilog,1,1,1,1,0,1,434,0,0,115,other,1,0,0,public,434,115,1826,master,1,1,"# Corundum Readme

[![Build Status](https://github.com/corundum/corundum/workflows/Regression%20Tests/badge.svg?branch=master)](https://github.com/corundum/corundum/actions/)

GitHub repository: https://github.com/corundum/corundum

Documentation: https://docs.corundum.io/

GitHub wiki: https://github.com/corundum/corundum/wiki

Google group: https://groups.google.com/d/forum/corundum-nic

Zulip: https://corundum.zulipchat.com/

## Introduction

Corundum is an open-source, high-performance FPGA-based NIC and platform for in-network compute.  Features include a high performance datapath, 10G/25G/100G Ethernet, PCI express gen 3, a custom, high performance, tightly-integrated PCIe DMA engine, many (1000+) transmit, receive, completion, and event queues, scatter/gather DMA, MSI interrupts, multiple interfaces, multiple ports per interface, per-port transmit scheduling including high precision TDMA, flow hashing, RSS, checksum offloading, and native IEEE 1588 PTP timestamping.  A Linux driver is included that integrates with the Linux networking stack.  Development and debugging is facilitated by an extensive simulation framework that covers the entire system from a simulation model of the driver and PCI express interface on one side to the Ethernet interfaces on the other side.

Corundum has several unique architectural features.  First, transmit, receive, completion, and event queue states are stored efficiently in block RAM or ultra RAM, enabling support for thousands of individually-controllable queues.  These queues are associated with interfaces, and each interface can have multiple ports, each with its own independent scheduler.  This enables extremely fine-grained control over packet transmission.  Coupled with PTP time synchronization, this enables high precision TDMA.

Corundum also provides an application section for implementing custom logic.  The application section has a dedicated PCIe BAR for control and a number of interfaces that provide access to the core datapath and DMA infrastructure.

Corundum currently supports devices from both Xilinx and Intel, on boards from several different manufacturers.  Designs are included for the following FPGA boards:

*  Alpha Data ADM-PCIE-9V3 (Xilinx Virtex UltraScale+ XCVU3P)
*  Dini Group DNPCIe_40G_KU_LL_2QSFP (Xilinx Kintex UltraScale XCKU040)
*  Cisco Nexus K35-S (Xilinx Kintex UltraScale XCKU035)
*  Cisco Nexus K3P-S (Xilinx Kintex UltraScale+ XCKU3P)
*  Cisco Nexus K3P-Q (Xilinx Kintex UltraScale+ XCKU3P)
*  Silicom fb2CG@KU15P (Xilinx Kintex UltraScale+ XCKU15P)
*  NetFPGA SUME (Xilinx Virtex 7 XC7V690T)
*  BittWare 250-SoC (Xilinx Zynq UltraScale+ XCZU19EG)
*  BittWare XUSP3S (Xilinx Virtex UltraScale XCVU095)
*  BittWare XUP-P3R (Xilinx Virtex UltraScale+ XCVU9P)
*  BittWare IA-420F (Intel Agilex F 014)
*  Intel Stratix 10 MX dev kit (Intel Stratix 10 MX 2100)
*  Intel Stratix 10 DX dev kit (Intel Stratix 10 DX 2800)
*  Intel Agilex F dev kit (Intel Agilex F 014)
*  Terasic DE10-Agilex (Intel Agilex F 014)
*  Xilinx Alveo U50 (Xilinx Virtex UltraScale+ XCU50)
*  Xilinx Alveo U55N/Varium C1100 (Xilinx Virtex UltraScale+ XCU55N)
*  Xilinx Alveo U200 (Xilinx Virtex UltraScale+ XCU200)
*  Xilinx Alveo U250 (Xilinx Virtex UltraScale+ XCU250)
*  Xilinx Alveo U280 (Xilinx Virtex UltraScale+ XCU280)
*  Xilinx Kria KR260 (Xilinx Zynq UltraScale+ XCK26)
*  Xilinx VCU108 (Xilinx Virtex UltraScale XCVU095)
*  Xilinx VCU118 (Xilinx Virtex UltraScale+ XCVU9P)
*  Xilinx VCU1525 (Xilinx Virtex UltraScale+ XCVU9P)
*  Xilinx ZCU102 (Xilinx Zynq UltraScale+ XCZU9EG)
*  Xilinx ZCU106 (Xilinx Zynq UltraScale+ XCZU7EV)

For operation at 10G and 25G, Corundum uses the open source 10G/25G MAC and PHY modules from the verilog-ethernet repository, no extra licenses are required.  However, it is possible to use other MAC and/or PHY modules.

Operation at 100G on Xilinx UltraScale+ devices currently requires using the Xilinx CMAC core with RS-FEC enabled, which is covered by the free CMAC license.

## Documentation

For detailed documentation, see https://docs.corundum.io/

### Block Diagram

![Corundum block diagram](docs/source/diagrams/svg/corundum_block.svg)

Block diagram of the Corundum NIC. PCIe HIP: PCIe hard IP core; AXIL M: AXI lite master; DMA IF: DMA interface; AXI M: AXI master; PHC: PTP hardware clock; TXQ: transmit queue manager; TXCQ: transmit completion queue manager; RXQ: receive queue manager; RXCQ: receive completion queue manager; EQ: event queue manager; MAC + PHY: Ethernet media access controller (MAC) and physical interface layer (PHY).

### Modules

#### `cmac_pad` module

Frame pad module for 512 bit 100G CMAC TX interface.  Zero pads transmit frames to minimum 64 bytes.

#### `cpl_op_mux` module

Completion operation multiplexer module.  Merges completion write operations from different sources to enable sharing a single `cpl_write` module instance.

#### `cpl_queue_manager` module

Completion queue manager module.  Stores device to host queue state in block RAM or ultra RAM.

#### `cpl_write` module

Completion write module.  Responsible for enqueuing completion and event records into the completion queue managers and writing records into host memory via DMA.

#### `desc_fetch` module

Descriptor fetch module.  Responsible for dequeuing descriptors from the queue managers and reading descriptors from host memory via DMA.

#### `desc_op_mux` module

Descriptor operation multiplexer module.  Merges descriptor fetch operations from different sources to enable sharing a single `desc_fetch` module instance.

#### `event_mux` module

Event mux module.  Enables multiple event sources to feed the same event queue.

#### `mqnic_core` module

Core module.  Contains the interfaces, asynchronous FIFOs, PTP subsystem, statistics collection subsystem, and application block.

#### `mqnic_core_pcie` module

Core module for a PCIe host interface.  Wraps `mqnic_core` along with generic PCIe interface components, including DMA engine and AXI lite masters.

#### `mqnic_core_pcie_us` module

Core module for a PCIe host interface on Xilinx 7-series, UltraScale, and UltraScale+.  Wraps `mqnic_core_pcie` along with FPGA-specific interface logic.

#### `mqnic_interface` module

Interface module.  Contains the event queues, interface queues, and ports.

#### `mqnic_port` module

Port module.  Contains the transmit and receive datapath components, including transmit and receive engines and checksum and hash offloading.

#### `mqnic_ptp` module

PTP subsystem.  Contains one `mqnic_ptp_clock` instance and a parametrizable number of `mqnic_ptp_perout` instances.

#### `mqnic_ptp_clock` module

PTP clock module.  Contains an instance of `ptp_clock` with a register interface.

#### `mqnic_ptp_perout` module

PTP period output module.  Contains an instance of `ptp_perout` with a register interface.

#### `mqnic_tx_scheduler_block_rr` module

Transmit scheduler block with round-robin transmit scheduler and register interface.

#### `mqnic_tx_scheduler_block_rr_tdma` module

Transmit scheduler block with round-robin transmit scheduler, TDMA scheduler, TDMA scheduler controller, and register interface.

#### `queue_manager` module

Queue manager module.  Stores host to device queue state in block RAM or ultra RAM.

#### `rx_checksum` module

Receive checksum computation module.  Computes 16 bit checksum of Ethernet frame payload to aid in IP checksum offloading.

#### `rx_engine` module

Receive engine.  Manages receive datapath operations including descriptor dequeue and fetch via DMA, packet reception, data writeback via DMA, and completion enqueue and writeback via DMA.  Handles PTP timestamps for inclusion in completion records.

#### `rx_hash` module

Receive hash computation module.  Extracts IP addresses and ports from packet headers and computes 32 bit Toeplitz flow hash.

#### `stats_collect` module

Statistics collector module.  Parametrizable number of increment inputs, single AXI stream output for accumulated counts.

#### `stats_counter` module

Statistics counter module.  Receives increments over AXI stream and accumulates them in block RAM, which is accessible via AXI lite.

#### `stats_dma_if_pcie` module

Collects DMA-related statistics for `dma_if_pcie` module, including operation latency.

#### `stats_dma_if_latency` module

DMA latency measurement module.

#### `stats_pcie_if` module

Collects TLP-level statistics for the generic PCIe interface.

#### `stats_pcie_tlp` module

Extracts TLP-level statistics for the generic PCIe interface (single channel).

#### `tdma_ber_ch` module

TDMA bit error ratio (BER) test channel module.  Controls PRBS logic in Ethernet PHY and accumulates bit errors.  Can be configured to bin error counts by TDMA timeslot.

#### `tdma_ber` module

TDMA bit error ratio (BER) test module.  Wrapper for a tdma_scheduler and multiple instances of `tdma_ber_ch`.

#### `tdma_scheduler` module

TDMA scheduler module.  Generates TDMA timeslot index and timing signals from PTP time.

#### `tx_checksum` module

Transmit checksum computation and insertion module.  Computes 16 bit checksum of frame data with specified start offset, then inserts computed checksum at the specified position.

#### `tx_engine` module

Transmit engine.  Manages transmit datapath operations including descriptor dequeue and fetch via DMA, packet data fetch via DMA, packet transmission, and completion enqueue and writeback via DMA.  Handles PTP timestamps for inclusion in completion records.

#### `tx_scheduler_ctrl_tdma` module

TDMA transmit scheduler control module.  Controls queues in a transmit scheduler based on PTP time, via a `tdma_scheduler` instance.

#### `tx_scheduler_rr` module

Round-robin transmit scheduler.  Determines which queues from which to send packets.

### Source Files

    cmac_pad.v                         : Pad frames to 64 bytes for CMAC TX
    cpl_op_mux.v                       : Completion operation mux
    cpl_queue_manager.v                : Completion queue manager
    cpl_write.v                        : Completion write module
    desc_fetch.v                       : Descriptor fetch module
    desc_op_mux.v                      : Descriptor operation mux
    event_mux.v                        : Event mux
    event_queue.v                      : Event queue
    mqnic_core.v                       : Core logic
    mqnic_core_pcie.v                  : Core logic for PCIe
    mqnic_core_pcie_us.v               : Core logic for PCIe (UltraScale)
    mqnic_interface.v                  : Interface
    mqnic_port.v                       : Port
    mqnic_ptp.v                        : PTP subsystem
    mqnic_ptp_clock.v                  : PTP clock wrapper
    mqnic_ptp_perout.v                 : PTP period output wrapper
    mqnic_tx_scheduler_block_rr.v      : Scheduler block (round-robin)
    mqnic_tx_scheduler_block_rr_tdma.v : Scheduler block (round-robin TDMA)
    queue_manager.v                    : Queue manager
    rx_checksum.v                      : Receive checksum offload
    rx_engine.v                        : Receive engine
    rx_hash.v                          : Receive hashing module
    stats_collect.v                    : Statistics collector
    stats_counter.v                    : Statistics counter
    stats_dma_if_pcie.v                : DMA interface statistics
    stats_dma_latency.v                : DMA latency measurement
    stats_pcie_if.v                    : PCIe interface statistics
    stats_pcie_tlp.v                   : PCIe TLP statistics
    tdma_ber_ch.v                      : TDMA BER channel
    tdma_ber.v                         : TDMA BER
    tdma_scheduler.v                   : TDMA scheduler
    tx_checksum.v                      : Transmit checksum offload
    tx_engine.v                        : Transmit engine
    tx_scheduler_ctrl_tdma.v           : TDMA transmit scheduler controller
    tx_scheduler_rr.v                  : Round robin transmit scheduler

## Testing

Running the included testbenches requires [cocotb](https://github.com/cocotb/cocotb), [cocotbext-axi](https://github.com/alexforencich/cocotbext-axi), [cocotbext-eth](https://github.com/alexforencich/cocotbext-eth), [cocotbext-pcie](https://github.com/alexforencich/cocotbext-pcie), [scapy](https://scapy.net/), and [Icarus Verilog](http://iverilog.icarus.com/).  The testbenches can be run with pytest directly (requires [cocotb-test](https://github.com/themperek/cocotb-test)), pytest via tox, or via cocotb makefiles.

## Publications

- A. Forencich, A. C. Snoeren, G. Porter, G. Papen, *Corundum: An Open-Source 100-Gbps NIC,* in FCCM'20. ([FCCM Paper](https://www.cse.ucsd.edu/~snoeren/papers/corundum-fccm20.pdf), [FCCM Presentation](https://www.fccm.org/past/2020/forums/topic/corundum-an-open-source-100-gbps-nic/))

- J. A. Forencich, *System-Level Considerations for Optical Switching in Data Center Networks*. ([Thesis](https://escholarship.org/uc/item/3mc9070t))

## Citation

If you use Corundum in your project, please cite one of the following papers
and/or link to the project on GitHub:

```
@inproceedings{forencich2020fccm,
    author = {Alex Forencich and Alex C. Snoeren and George Porter and George Papen},
    title = {Corundum: An Open-Source {100-Gbps} {NIC}},
    booktitle = {28th IEEE International Symposium on Field-Programmable Custom Computing Machines},
    year = {2020},
}

@phdthesis{forencich2020thesis,
    author = {John Alexander Forencich},
    title = {System-Level Considerations for Optical Switching in Data Center Networks},
    school = {UC San Diego},
    year = {2020},
    url = {https://escholarship.org/uc/item/3mc9070t},
}
```

## Dependencies

Corundum internally uses the following libraries:

*  https://github.com/alexforencich/verilog-axi
*  https://github.com/alexforencich/verilog-axis
*  https://github.com/alexforencich/verilog-ethernet
*  https://github.com/alexforencich/verilog-pcie
*  https://github.com/solemnwarning/timespec

","['alexforencich', 'joft-mle', 'Basseuph', 'andreasbraun90', 'minseongg', 'sessl3r', 'lomotos10', 'penberg', 'wnew', 'lastweek']",1,0.62,0,,,,,,87,,,,
867882833,R_kgDOM7rXUQ,TritonSpend,CSES-Open-Source/TritonSpend,0,CSES-Open-Source,https://github.com/CSES-Open-Source/TritonSpend,,0,2024-10-04 23:23:22+00:00,2025-03-07 20:10:18+00:00,2025-03-07 20:10:19+00:00,,2635,0,0,TypeScript,1,1,1,1,0,0,1,0,0,7,mit,1,0,0,public,1,7,0,main,1,1,"# CSES TritonSpend

TritonSpend is a finance app designed to help UC San Diego students manage their finances by tracking budgets, analyzing spending, and setting financial goals for better financial planning.

## Features

- Budget Tracking with Analytics: Monitor your spending and budget with detailed analytics to stay on top of your finances.
- Expense Categorization: Organize your expenses into categories for a clearer picture of where your money is going.
- Financial Goals and Alerts: Set financial goals and receive alerts when you exceed your budget limits.
- Spending Analysis and Visualizations: Gain insights into your spending habits through visualizations and reports.
- Personalized Virtual Financial Advisor: Get tailored financial advice based on your spending patterns and goals.

## Tech Stack

Front-End: React with Typescript  
Back-End: Node.js with Express.js  
Database: PostgreSQL  
Cloud: AWS

## License

This project is licensed under the MIT License.

## Contact

For any issues or questions, please contact Shree Venkatesh (s1venkatesh@ucsd.edu) or UC San Diego CSES (cses@ucsd.edu).
","['shree-venkatesh', 'qwer030413', 'kirustar14', 'VedantVardhaan', 'YashRavipati1', 'adontu06']",1,0.78,0,"# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, religion, or sexual identity and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our community include:

- Demonstrating empathy and kindness toward other people.
- Being respectful of differing opinions, viewpoints, and experiences.
- Giving and gracefully accepting constructive feedback.
- Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience.
- Focusing on what is best not just for us as individuals, but for the overall community.

Examples of unacceptable behavior include:

- The use of sexualized language or imagery, and sexual attention or advances of any kind.
- Trolling, insulting or derogatory comments, and personal or political attacks.
- Public or private harassment.
- Publishing othersâ€™ private information, such as a physical or email address, without their explicit permission.
- Other conduct which could reasonably be considered inappropriate in a professional setting.

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.

Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned with this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and it also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official email address, posting via an official social media account, or acting as an appointed representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at kgsun@ucsd.edu or cses@ucsd.edu. All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series of actions.

**Consequence**: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public communication with the community for a specified period. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant](https://www.contributor-covenant.org), version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.

For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq.
","# Contributing to CSES TritonSpend

First off, thank you for considering contributing to TritonSpend! ðŸŽ‰ We welcome all contributions and are excited to see what you'll bring to the project.

## Table of Contents

- [Code of Conduct](#code-of-conduct)
- [Getting Started](#getting-started)
  - [Setting Up the Environment](#setting-up-the-environment)
  - [Setting Up the Local Repository](#setting-up-the-local-repository)
  - [Installing Dependencies](#installing-dependencies)
  - [Setting Up the Local Development Database](#setting-up-local-development-database)
  - [Running the Frontend and Backend](#running-the-backend-and-frontend)
- [How to Contribute](#how-to-contribute)
  - [Reporting Bugs](#reporting-bugs)
  - [Suggesting Features](#suggesting-features)
  - [Improving Documentation](#improving-documentation)
  - [Submitting a Pull Request](#submitting-a-pull-request)
- [Development Guidelines](#development-guidelines)
  - [Code Style](#code-style)
  - [Commit Messages](#commit-messages)
- [Contact](#contact)

## Code of Conduct

By participating in this project, you agree to uphold the [Code of Conduct](CODE_OF_CONDUCT.md). Please read it to understand what actions will and will not be tolerated.

## Getting Started

### Setting Up the Environment

**Note**: You may have to restart terminal after installing each environment.

#### Downloading Git (and Git Bash)

1. Download git and git bash by following [this link](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).
2. Set up Git Bash as the shell for running command line prompts (in VSCode or directly openning Git Bash)
3. Run:
   ```bash
   git -v
   ```
   This should output something like this:
   ```bash
   git version 2.46.0.windows.1
   ```

#### Downloading Node.JS

1. Download **nvm (Node Version Manager)**. Follow the instructions on in [this link](https://www.freecodecamp.org/news/node-version-manager-nvm-install-guide/) for the details.
2. Run:
   ```bash
   nvm -v
   ```
   This should output the version of nvm you installed.
3. Install **Node.js v18.20.4**:
   ```bash
   nvm install v18.20.4**
   ```
4. Switch to the installed version:
   ```bash
   nvm use v18.20.4**
   ```
5. Run:
   ```bash
   node -v
   npm -v
   ```
   The results should be something like:
   ```bash
   v18.20.4
   10.7.0
   ```

### Setting Up the Local Repository

1. **Fork the repository** to your GitHub account.
2. **Clone** the origin repository locally:
   ```bash
   git clone https://github.com/CSES-Open-Source/TritonSpend.git
   ```
3. Create a **remote repository**:
   ```bash
   git remote add [your-username] https://github.com/[your-username]/TritonSpend.git
   ```
4. Run:
   ```bash
   git remote -v
   ```
   The output should be something like the following:
   ```bash
   [your-username]    https://github.com/[your-username]/TritonSpend.git (fetch)
   [your-username]    https://github.com/[your-username]/TritonSpend.git (push)
   origin  https://github.com/CSES-Open-Source/TritonSpend.git (fetch)
   origin  https://github.com/CSES-Open-Source/TritonSpend.git (push)
   ```

### Installing Dependencies

1. Open an instance of git bash and run:
   ```bash
   cd frontend
   ```
2. Install frontend libraries:
   ```bash
   npm install
   ```
3. Open another instance of git bash and run:
   ```bash
   cd backend
   ```
4. Install backend libraries:
   ```bash
   npm install
   ```

### Setting Up the Local Development Database

1. Go to [postgresql.org/download/](https://www.postgresql.org/download/) and download PostgreSQL for your OS.
2. Open the installer, and follow the on screeen instructions.

### Running the Backend and Frontend

1. Open an instance of git bash and run:
   ```bash
   cd frontend
   ```
2. Install frontend libraries:
   ```bash
   npm start
   ```
3. Open another instance of git bash and run:
   ```bash
   cd backend
   ```
4. Install backend libraries:
   ```bash
   npm start
   ```

### Phew... That was a lot of setting up. But you are good to go now!

## How to Contribute

### Reporting Bugs

1. Open the [CSES Opensource TritonSpend Github Repo](https://github.com/CSES-Open-Source/TritonSpend/).
2. Click on the **issues** tab (next to code).
3. Create a **new issue**.
4. Select **Bug report** as the type of issue.
5. Fill in the title and description and submit the issue.

### Suggesting Features

1. Open the [CSES Opensource TritonSpend Github Repo](https://github.com/CSES-Open-Source/TritonSpend/).
2. Click on the **issues** tab (next to code).
3. Create a **new issue**.
4. Select **Feature request** as the type of issue.
5. Fill in the title and description and submit the issue.

### Improving Documentation

### Submitting a Pull Request

1. Create a new branch for the current issue you are working on:
   ```bash
   git checkout -b origin/main [name-of-branch]
   ```
2. Make changes to the branch and **commit changes**. I would recomment using VSCode version control or GitHub Desktop for making commits.
3. Run lint in respective frontend and backend directories:
   ```bash
   npm run lint-check
   ```
   Make sure to fix all lint errors before pushing your code.
4. **Push** the commits to your forked repository:
   ```bash
   git push [your-username] HEAD
   ```
   `[your-username]` is whatever you chose to set the name of your remote repository as. To check this type:
   ```bash
   git remote -v
   ```
5. Go to your forked repository and make a **pull request** to the main branch of the original repository. Make sure to fill in the title and description of the pull request.

## Development Guidlines

### Code Style

Please follow these coding style guidelines:

- We recommend using Prettier to format on save, and then running ESLint before making a pull request.
- Indent with tabs and use a 2-space indentation.
- Use semicolons and the end of each line.
- Write clear, concise comments where necessary.
- Use meaningful variable and function names.

### Commit Messages

Please write a rough description for the changes made in each commits

## Contact

For any issues or questions, please contact Shree Venkatesh (s1venkatesh@ucsd.edu) or UC San Diego CSES (cses@ucsd.edu).
",,Directory exists,,0,,,,
345942094,MDEwOlJlcG9zaXRvcnkzNDU5NDIwOTQ=,CPR_CL,csm9493/CPR_CL,0,csm9493,https://github.com/csm9493/CPR_CL,The Official Code of CPR (ICLR 2021),0,2021-03-09 08:54:38+00:00,2024-12-11 14:25:48+00:00,2021-10-14 02:32:24+00:00,,588,14,14,Jupyter Notebook,1,1,1,1,0,0,6,0,0,1,,1,0,0,public,6,1,14,main,1,,"# CPR

The official code of CPR: Classifier-Projection Regularization for Continual Learning (ICLR 2021) [[arxiv]](https://arxiv.org/pdf/2006.07326.pdf)

## Quick Start

### 1. Requirements

```
$ pip install -r requirements.txt
$ mkdir weights data
```

### 2. Prepare Datasets

1) Download datasets (CIFAR[1], Omniglot[2] and CUB200[3]) from [[this google drive link]](https://drive.google.com/file/d/19UaTcjGYj8YUBlj69mPK7zcVvFUR8bso/view?usp=sharing)
2) Locate downloaded datasets to './data' directory

```
./data
      /Permuted_Omniglot_task50.pt
      /binary_split_cub200_new
      /binary_split_cifar100
      /binary_cifar10
      /binary_omniglot
```

### 3.  Run .sh file

#### 3-1) Train 'CIFAR' scenarios using \[EWC, SI, MAS, Rwalk, AGS-CL\] with and without CPR

```
$ ./train_cifar.sh
```

#### 3-2) Train 'Omniglot' scenario using \[EWC, SI, MAS, Rwalk, AGS-CL\] with and without CPR

```
$ ./train_omniglot.sh
```

#### 3-3) Train 'CUB200' scenario using \[EWC, SI, MAS, Rwalk, AGS-CL\] with and without CPR

```
$ ./train_cub200.sh
```

### 3.  Analyze experimental results

1) Check './result_analysis_code/'. There are example ipython files to anayze the experimental results of [EWC, MAS, SI, Rwalk, AGS-CL] with or without CPR in CIFAR100. Note that the analysis results are for experiments conducted on only single seed.

2) You can easily transform and use these files to analyze other results!


## QnA
### 1. How to apply CPR to another CL algorithm?

: The implementation for CPR is quite simple. As shown in Equation (3) of the paper, you can implement CPR by maximizing an entropy of a model's softmax output (in other words, minimizing KL divergence between the model's softmax output and uniform distribution). Note that a lambda (the hyperparameter for entropy maximization) should be selected carefully. As an example, check Line 222 at './approaches/ewc_cpr.py'.


## Citation

```
@inproceedings{
  cha2021cpr,
  title={{\{}CPR{\}}: Classifier-Projection Regularization for Continual Learning},
  author={Sungmin Cha and Hsiang Hsu and Taebaek Hwang and Flavio Calmon and Taesup Moon},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=F2v4aqEL6ze}
}
```

## Reference
[1] Krizhevsky, Alex, and Geoffrey Hinton. ""Learning multiple layers of features from tiny images."" (2009): 7.

[2] Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. ""Human-level concept learning through probabilistic program induction."" Science 350.6266 (2015): 1332-1338.

[3] Welinder, Peter, et al. ""Caltech-UCSD birds 200."" (2010).


","['yongbee', 'csm9493']",0,0.74,0,,,,,,1,,,,
144326145,MDEwOlJlcG9zaXRvcnkxNDQzMjYxNDU=,cy-jupyterlab,cytoscape/cy-jupyterlab,0,cytoscape,https://github.com/cytoscape/cy-jupyterlab,Jupyter lab widget for rendering graphs (networks),0,2018-08-10 19:44:21+00:00,2024-01-26 20:58:21+00:00,2022-10-18 19:05:28+00:00,,1722,24,24,Jupyter Notebook,1,1,1,1,0,0,4,0,0,7,,1,0,0,public,4,7,24,master,1,1,"# cy-jupyterlab

**A Jupyter Lab extension for interactive graph (network) data visualization**


![tab](https://user-images.githubusercontent.com/1568884/195467656-6db34de5-cca4-4f08-afc8-604b6f15bb7c.png)

## Introduction

*Cy-JupyterLab* is a Jupyter Lab *extension* for interactive graph visualization. Current version supports the following data types: 

* Cytoscape eXchange format ([.cx](http://www.home.ndexbio.org/data-model/))
* [Cytoscape.js](http://js.cytoscape.org/) JSON (.cyjs)

![cell](https://user-images.githubusercontent.com/1568884/195467711-f9ec19a8-8dd0-4ded-9de0-612badab9b53.png)

## Features

* Interactive network visualization in Panels.
* Supports visualization in Jupyter Notebook cells
* Full support for Cytoscape.js compatible *styles*
* Support for data from [NDEx](https://www.ndexbio.org/)) database.
* Automatic layouts

## Requirments

* JupyterLab - Tested on v3.4

### Optional

* ndex2 - this is a python library to import data from NDEx.  If you want to use NDEx data sets, this provides high-level API to access the data

## Installation

### v0.1.0

```bash
jupyter labextension install @iau/cy-jupyterlab
```

### v0.5.0 and later (Not released yet)

```bash
jupyter labextension install cy-jupyterlab
```

## For Developers

To build the extension from the source, please do the following in the cloned directory:

```bash
jlpm install
jlpm build
jupyter labextension link .
```

To rebuild the package and the JupyterLab app:

```bash
jlpm build
jupyter lab build
```

### Acknoowledgment

The prototype was developed by the following students as a summer project 2018:

* Hideki Akazawa (University of Osaka, Japan)
* Kaito Uemura (University of Osaka, Japan)

----
&copy; 2022 University of California, San Diego

[Trey Ideker Lab](https://medschool.ucsd.edu/som/medicine/research/labs/ideker/Pages/default.aspx)
","['tmsah', 'keiono', 'jingjingbic']",1,0.69,0,,,,,,5,,,,
102908069,MDEwOlJlcG9zaXRvcnkxMDI5MDgwNjk=,AutoComplete-Tries-BinarySearchTrees-Hashtables-,daniel-huang-1230/AutoComplete-Tries-BinarySearchTrees-Hashtables-,0,daniel-huang-1230,https://github.com/daniel-huang-1230/AutoComplete-Tries-BinarySearchTrees-Hashtables-,Data structure project from 2017 winter at UC San Diego. Course: CSE 100 Advanced Data Structure,0,2017-09-08 22:02:34+00:00,2018-08-28 01:36:22+00:00,2017-09-08 22:57:43+00:00,,2879,2,2,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,2,master,1,,"# Project Overview
This is my second personal assignment in the course **Advanced Data Structure** ( CSE 100 ) from **UC San Diego** 

What I learned: 

1.Implement either a **multi-way trie (MWT)** or **ternary search tree (TST)** data structure for strings ( I ended up using
  **MWT** in my implementation )

2.Implement auto-complete functionality seen in almost all text-based applications these days.

3.Compare the empirical running time of MWTs or TSTs , Balanced Binary Search Trees and Hash Tables to their 
    expected analytical running times 

4.Research and compare the performance of different hash functions for strings

**NOTE**: We were allowed to either team up with other students or try to complete the project alone. I chose to go **solo**.

# Language 
   The program is written in **C++**

# Instructions below are copied from the original [assignment page](https://sites.google.com/a/eng.ucsd.edu/cse-100-winter-2017/assignments/assignment-2-auto-complete) 


Set Up

Please follow the instructions provided in this PPT to get started with the set-up of this assignment. 

Provided files in repo : Makefile, DictionaryTrie.h/cpp, DictionaryBST.h/cpp, DictionaryHashtable.h/cpp,  util.h/cpp , test.cpp (more info)
Files provided in ieng6 :  dictionary:  freq1.txt, freq2.txt, freq3.txt(smaller dictionaries), shuffled_freq_dict.txt , shuffled_unique_freq_dict.txt, freq_dict.txt
autoCompleter_GUI: This contains code that generates a GUI (not required for use, but created for your benefit): Autocomplete.pro, main.cpp, mainwindow.h/cpp/ui, mylineedit.h/cpp, wordlist.h/cpp, Compile Guide.txt

NOTES (IMPORTANT): 

DO NOT CREATE ANY NEW FILES TO SUPPORT THE IMPLEMENTATION OF DictionaryTrie.  If you want to create new classes to support any of the Dictionary classes  (e.g. a TrieNode class), please place the class header and definition in the existing .h and .cpp files.
DO NOT add any dictionary to your repository. This may cause your repository to hang up unexpectedly and make your life (and ours) very difficult.
Don't add executables and the GUI files to your repository. 
Make sure you have room in your account before copying files. Combined, the files for this PA are roughly 200 MB in size (because of the dictionaries).
DO NOT edit any of the function signatures, or remove any of the provided code. However, you are free to create any member variables and member functions for the DictionaryTrie class to implement predictCompletions, provided that you adhere to good object oriented design, and specifically either use a multi-way trie or a ternary trie to store the dictionary. In addition, you are free to add and implement any classes and methods in the provided util.cpp/util.h or      DictionaryTrie.h/cpp. 


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Checkpoint Instructions
1. Implement a Dictionary ADT using three different data structures: a balanced BST, a Hash Table, and a Multi-way Trie or Ternary Search Tree 

DictionaryBST

This class must use a balanced binary search tree to store the words in the dictionary.  However, this should be easy, because the C++ STL set uses a balanced BST (a red-black tree, specifically) to store its elements. So all you need to do is use a C++ set to store the words in the dictionary.   If implementing this class feels too simple, you're probably doing it right.

Implementation Checklist:

Constructor
Destructor
find method (returns true if the word is in the dictionary and false otherwise)
insert method (puts a word into the dictionary)

You will find it helpful to look at the files DictionaryBST.h for more thorough descriptions. 

DictionaryHashtable

This class must use a hashtable data structure to store the words in the dictionary.  However, this should be be easy, because the C++ STL unordered_set uses a hashset (i.e. a set implemented with a hashtable) to store its elements. So all you need to do is use an  C++ unordered_set to store the words in the dictionary.  If implementing this class feels too simple, you're probably doing it right.

Implementation Checklist:

Constructor
Destructor
find method (returns true if the word is in the dictionary and false otherwise)
insert method (puts a word into the dictionary)

You will find it helpful to look at the files DictionaryHashtable.h for more thorough descriptions. 

DictionaryTrie

This class must use either a Multiway Trie or a Ternary Search Tree to store the words in the dictionary, and you must implement this data structure from scratch.  Implementing this class will not be as trivial as implementing the other two.   Note that you will likely need to implement additional classes and/or methods to support your Trie implementation (e.g. some kind of Node class). If you choose to do so, place their declarations and definitions in the existing .h and .cpp files.  You should not create any new files. If you add new files, your code will not work with the provided GUI and will fail the test cases on vocareum. 

Implementation Checklist:

Constructor
Destructor
find method (returns true if the word is in the dictionary and false otherwise: it does not care about the word's frequency. )
insert method (puts a word together with its frequency into the dictionary. If a duplicate word inserted has a different frequency, update the frequency to the larger frequency but return false)

You will find it helpful to look at the files DictionaryTrie.h for more thorough descriptions. Do not worry about implementing predictCompletions for the checkpoint. 


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


2. Test your implementations

Implementation Checklist:

Add more test cases in test.cpp and ensure that â€œmake testâ€ runs and works. Tip: test your code on shuffled dictionaries (which may change the structure of a DictionaryTrie implemented as a Ternary Search Trie).

We have provided two dictionary files  that you may use to test your implementation. (You much choose to not use them as well) : 

freq_dict.txt which contains about 4,000,000 English words and phrases (up to 5 words each) and their frequencies. Entries are limited to the lowercase letters a-z and the space character ' '. 
unique_freq_dict.txt which contains about 200,000 words and their frequencies.  Entries are limited to the lowercase letters a-z and the space character   ' '. 

Both dictionary files have the following format

freq_count_1 word_1

freq_count_2 word_2

...

freq_count_n word_n

In util.cpp, we have also provided a function named load_dict that load the words from the stream (with frequencies if it is a DictionaryTrie) into the Dictionary object. We recommend you to use it to load words from an open file. It is overloaded to take:

a reference to a Dictionary object (it is overloaded for all three Dictionaries)
an istream
(optionally) a number of words to read in


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Final Submission

1. Implement Auto-Complete by implementing the predictCompletions method in the DictionaryTrie class.

Implementation Checklist:

predictCompletions (returns a vector containing the num_completions most frequent legal completions of the prefix string ordered from most frequent to least frequent). See edge cases checklist, hint section, and DictionaryTrie.h for more details. 
 
An example of how predictCompletions works:

Suppose dictionary.txt contains:
step 510
step up 500
steward 200
steer 100
stealth 100

If prefix = â€œsteâ€ and num_completions = 4, predictCompletions can return either <""step"", ""step up"", ""steward"", â€œsteerâ€> or  <""step"", ""step up"", ""steward"", â€œstealthâ€>, depending upon how it decided to break ties for equivalent frequencies. 

Edge Cases Checklist: (Read Carefully)
Ties may be broken in arbitrary order. 
You may assume that no word in the dictionary will begin with, or end with, a space character. 
If the prefix itself is a valid word, it should be included in the list of returned words if its frequency is among the top num_completions most frequent legal completions. 
If the number of legal completions is less than that specified by num_completions, your function should return as many valid completions as possible.
If there are no legal completions, you should return an empty vector.
The empty prefix must return an empty vector.
Invalid inputs should print an error message that reads ""Invalid Input. Please retry with correct input"" and return an empty vector. Invalid inputs include the following: a prefix is an empty string, prefix is a string that contain non-dictionary characters (character not in the dictionary).
All legal completions must be words (or phrases) that appear in the loaded dictionary.
If a duplicate word inserted has a different frequency, update the frequency to the larger frequency 
Think of more edge cases yourself! 

Our Submission scripts use  shuffled_unique_freq_dict.txt FOR PredictCompletions. 
We have provided a small dictionary file smalldictionary.txt for you to test the corner cases. We strongly encourage and recommend you to come up with more such smaller dictionaries to test various corner cases. This will help in debugging as well. 

Hints on implementing predictCompletions (i.e., autocomplete):

Note: If you don't want spoilers, skip to the next section on testing your code :)

The autocomplete functionality requires two key steps:

Find the given prefix (this should be easy as it uses the same logic as the find function). This step allows you to progress up to some point in the trie. 
Search through the subtree rooted at the end of the prefix to find the num_completion most likely completions of the prefix.  

For step 2, an exhaustive search through the subtree is a simple approach.  One possible exhaustive search implementation would use the breadth first search algorithm. You'll need a queue, which you can produce by using the C++ STL's  std::queue data structure and always add nodes to the back (push_back) and remove them from the front (pop_front), and then keep track of the num_completion most frequent legal words you have seen along the way. This is a good starting point. While implementing exhaustive search is sufficient for this PA, brainstorming and thinking about techniques/algorithms that would prevent exhaustive search and return the completions faster is good food for thought.  Checkout the starpoint if you are interested in coming up with an algorithm that is much faster than the exhaustive search algorithm.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


2. Test your implementations

Implementation Checklist:


Add test cases in test.cpp and ensure that the autocomplete functionality works. You may use the same dictionary files and util functions as the checkpoint. 
Test your code with the provided GUI. This document has the instructions to test your program with the GUI. Note: We are NOT grading the GUI, or your ability to get the GUI working. The GUI is just for your benefit,  because we thought it would be cool to have so you can see your own algorithm in action. It is okay if you do not test your program with the GUI. 


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


3. Benchmark Dictionaries

Implementation Checklist:
Create the benchdict program (i.e., translate the purple text below into code).
Run benchdict on shuffled_freq_dict.txt. See below for details. 
Produce 1 graph (using google sheets, excel, gnuplot, etc) for each dictionary type. Use the most reliable run produced by the previous step. See below for details. 
Create a FinalReport.pdf that contains the three graphs and a discussion of the results. Answer the specific question in blue below. See below for details.  

3.1 Create a program named benchdict that does the following:

It should take four arguments as input:  ./benchdict min_size step_size num_iterations dictfile
min_size - The minimum size of the dictionary you want to test
step_size - The step size (how much to increase the dictionary size each iteration)
num_iterations - The number of iterations (e.g. how many times do you want to increase your dictionary size)
dictfile - The name of a dictionary file to use

Then it should run the following algorithm:
For each Dictionary class (DictionaryBST, DictionaryHashtable, DictionaryTrie):

    Print a message to standard out to indicate which dictionary class you are benchmarking.

    For i = 0 to num_iterations:

Create a new dictionary object of that class and load min_size + i*step_size words from the beginning of the dictionary file (you will need to reset the istream to the start of the dictionary file at the start of each iteration). Use the load_dict function from util.cpp!
Read the next 100 words from the dictionary file and then compute the time to find those 100 words in the dictionary object.  They will not be there.  Using the same 100 words, repeat the find process many times and take the average time of all the runs.  Be sure to time only the part when you are looking for the words in the dictionary.   
Print the dictsize and the running time you calculated in step two to standard out, separated by a tab (\t)

     Delete dictionary object (to avoid code to crash for lack of memory)

Edge Case Checklist:

 If there are fewer than min_size+i*step_size words in the file, benchdict should print a warning message. We will not test you on these corner cases as benchmarking does not make sense if there are no enough words.  However, you must handle these corner cases reasonably by printing some warning/error message. 

3.2 Run your program on the shuffled_freq_dict.txt dictionary
    Here is an example (the ### will be numbers representing the running time to find 100 words) where:
    min_size = 6000, step_size = 1000, and num_iterations = 5 (you'll want to use more iterations and possibly a larger step size or starting value):

    DictionaryTrie
    6000    ###
    7000    ###
    8000    ###
    9000    ###
    10000    ###

    DictionaryBST
    6000    ###
    7000    ###
    8000    ###
    9000    ###
    10000   ###

    DictionaryHashtable
    6000    ###
    7000    ###
    8000    ###
    9000    ###
    10000   ###

    At minimum, you are required to have at least 15 iterations, minimum min_size 5000, and minimum min_step_size 100. We recommend you experiment on which numbers you use: some sizes and steps will be more informative than others.  

    A timer class has been provided to you inside the util.h/cpp files. Simply call void begin_timer() to begin the timer and int end_timer()to end it. The end_timer() function will return the duration since begin_timer() was called, in nanoseconds.

    Note: The dictionary file freq_dict.txt is very large, so if you plan on testing on the entirety of that dictionary, we highly recommend that you allocate all DictionaryBST, DictionaryHashtable, and DictionaryTrie objects on the heap. If any more than one dictionary data structure is exists in memory simultaneously (even if both are allocated on the heap), your code is likely to crash due to a lack of memory.

3.3 Plot your results in a graph
Using the most reliable run of 3.2 Produce  a graph (using google sheets, excel, gnuplot, etc) for each dictionary type. Plots are between Dictionary Size and Run Time. 

3.4 Finally, create a file named FinalReport.pdf in which you reason about the running times for your three dictionary files.  Include your three graphs (one for each dictionary type) using the data you collected and reason about the curves you see.  Then, specifically answer the following question:
In class we saw that a Hashtable has expected case time to find of O(1), a BST worst case O(logN) and a MWT worst case O(K), where K is the length of the longest string.   We didn't look at the running time of the TST, though the book mentions that its average case time to find is O(logN) (and worst case O(N)).  Are your empirical results consistent with these analytical running time expectations?  If yes, justify how by making reference to your graphs.  If not, explain why not and also explain why you think you did not get the results you expected (also referencing your graphs).

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


4. Research and compare the performance of different hash functions for strings

Implementation Checklist:

Find two different hash functions for strings (online, in textbooks, etc) that are non-trivial (i.e., they donâ€™t just return the same value for every string). Note: It is OK if you find the implementation of the hash function, just make sure you understand what it is doing.
Implement the two hash functions in a file named benchhash.cpp and record the source of each hash function in a comment above the function. Note: The input to each function should be a string and a table size, and the output should be an unsigned int between 0 and the table size (not including table size).  
Test your two functions by calculating the expected hash values of several string by hand and then making sure that your functions return the expected output.  You will report these test cases in your writeup.  
Understand how to compare the performance of two hash functions. See below for details. 
Add actual code to benchhash.cpp to compare the performance of the two hash functions. See below for details. 
Add the following to the FinalReport.pdf:
Describe how each hash function works, and cite the source where you found this information.  Your description of how the hash function works should be in your own words. 
Describe how you verified the correctness of each hash function's implementation.  Describe at least 3 test cases you used, what value you expected for each hash function on each test case, and the process you used to verify that the functions gave this desired output.   
Run your benchhash program multiple times with different data and include a table that summarizes the results of several runs of each hash function.  Format the output nicely--don't just copy and paste from your program's output.  
Comment on which hash function is better, and why, based on your output.  Comment on whether this matched your expectation or not.    
Read the â€œNotes for FinalReport.pdfâ€ to make sure you followed all the guidelines.
That's it, you're done!!  You are now ready to submit your final solution. See the grading overview below. 


Mini lesson on how to compare the performance of two hash functions: 

You will do this by calculating the number of collisions each hash function produces. In other words, we will count the number of times each slot in the table was hashed to. Each time a slot is hashed to, we will say that that slot experienced a â€œhit.â€  From that information, you can construct a histogram showing how many slots received zero hits (no item ever hashed to that slot), one hit (1 item hashed to that slot and the slot never faced a collision), two hits (the slot faced 1 collision), and so forth. You can also calculate the average and maximum number of steps that a find would take. 

For example, given a table size of 2000, a collection of 1000 words in a dictionary, and a hash function that computes a nonnegative integer <2000 (table size) from a string, we might discover that 
    #hits    #slots receiving that #hits 
    0        1042
    1        932
    2        15
    3        7
    4        3 
    5        1   

Assume that the hash table uses separate-chaining for collision resolution. From that information, we would then calculate how many steps are required to find a certain amount of words. For example:
1 word would require 5 steps (1). 
The intuition behind this is that one hash table slot received 5 hits! That means that slot has a linked list of 5 elements and therefore there is 1 word in the back of that linked list that will require 5 steps (i.e., comparisons) to find it. 
 4 words  (3 + 1) would require 4 steps
The intuition behind this is that 3 slots received 4 hits! That means that the 3 slots have a linked list of 4 elements and each linked list therefore contains 1 word in that back that would require 4 steps  (i.e., comparisons) to find it. However, donâ€™t forget about the 1 slot that received 5 hits! There is also 1 word in that linked list that is the 4th element in that 5 element linked list. Thus, that word would also take 4 steps to find and thus we have a total of 3 + 1 words that would require 4 steps. 
11 words (7 + 3 + 1) would require 3 steps 
Same intuition as above. We must take into consideration the last elements in the 7 slots with 3 element linked lists, the 3rd elements in the slots with the 4 element linked lists, and the 3rd element in the slot with the 5 element linked list. 
 26 words (15 + 7 + 3 + 1)  would require 2 steps 
 958 words (932 + 15 + 7 + 3 + 1)  would require 1 step 

From that information, we would then calculate that the average number of steps in a search would be about 1.064, since 
(958*(1 step) + 26*(2 steps) + 11*(3 steps) + 4*(4 steps) + 1*(5 steps)) / (1000) =  1.064.

The worst case is the maximum number of steps that would be needed to find a word: 5 for the example above. 

How to actually add code to your benchhash.cpp file: 

Your benchhash function should take two arguments as input:  ./benchhash dictfile num_words
dictfile -- The name of a dictionary file to use (string)
num_words -- The number of words to be inserted from the dictionary in the hashtable (unsigned int)

We will then â€œsimulateâ€ the hash function by taking the following steps (i.e., we wonâ€™t actually need to create a hash table and insert strings into it!): 

Choose the size of the simulated hash table to be 2 * num_words.
Calculate the hash value for each string from a dictionary of size num_words. Keep track of the number of â€œhitsâ€ each slot receives by creatively using a vector.
For each hash function print:
The number of slots that received each number of hits, as described above
The average number of steps in a successful search
The max number of steps that would be needed to find a word in a hashtable 

 Here is an example (with totally made-up values) of what your output would look like if the number of words to be inserted from the dictionary in the hashtable is 1000:

./benchhash freq1.txt 1000
Printing the statistics for hashFunction1 with hash table size 2000
#hits    #slots receiving the #hits
0        1999
1000        1
The average number of steps for a successful search for hash function 1 would be 500.5
The worst case steps that would be needed to find a word is 1000
Printing the statistics for hashFunction2
#hits    #slots receiving the #hits
0        1042
1        932
2        15
3        7
4        3                   
5        1
The average number of steps for a successful search  for hash function 2 would be 1.064
The worst case steps that would be needed to find a word is 5

Notes for FinalReport.pdf: 

1) Changing the file extension of a file from .txt to .pdf does NOT convert the plain text file to a pdf file. You must create the .pdf document using one of the many word processors  available to you. If you're at a loss for what to use, I'd recommend using google docs, MS word, or LaTeX for all you fancy people out there. 
2) You will be required to create graphs to present your data. If you're at a loss for what to use, we recommend using google spreadsheets or excel to create graphs you can copy and paste, or hand-drawing really nicely and copying the image from MS paint (we won't judge)--whatever suits you. 
3) Naturally you must make sure that  your explanations are clear, your writing/typing is legible, and your graphs are neat, organized, and fitting. 
4) Please be kind to the graders and be as concise and organized in your answers as possible. We want you to articulate, but we aren't looking for a novel by Charles Dickens.


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


Grading Overview 

Checkpoint grading (5 points)
5 points for the correctness of insert and find functions of DictionaryBST, DictionaryHashtable, and DictionaryTrie 

Final Submission grading (25 points)
8 points for correctness of predictCompletions. It must return as many completions possible, up to num_completions, of the highest frequency completions in the DictionaryTrie, from highest frequency to lowest.  
2 points for the benchdict program 
3 points for the benchhash program
7 points for FinalReport.pdf
2 points for code that is free of memory leaks
3 points for Commenting,  style  and a good object-oriented design (see the minimal style guide)

Some caveats: 
IMPORTANT: Tables and graphs of experimental results, and transcripts in your FinalReport.pdf, must be genuine and not misleading.  It may happen that some of your code or algorithms do not work correctly.  In this case you must mention and explain this situation in documentation and reports. Faking data/ Copying somebody else's plot is a serious violation of the academic Integrity Policy of CSE 100. 
Code that does not compile will not receive credit.
Any code that does not compile, or segfaults, or does not create any objects will NOT receive credit for the memory leak test
You will receive 0 points for style, and FinalReport.pdf if you do not implement a ternary search tree or a multi-way trie as your DictionaryTrie.
Naturally, at this point, you will get a 0 for code that was not submitted.  REMEMBER TO SUBMIT YOUR CODE ON VOCAREUM WELL BEFORE THE DEADLINE.  

Required solution files:  Makefile, DictionaryTrie.h/cpp, DictionaryBST.h/cpp, DictionaryHashtable.h/cpp,  util.h/cpp, benchhash.cpp , test.cpp, benchdict.cpp, FinalReport.pdf

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Starpoint

If you're gotten here and you still want more, we're providing this ""star point"" option.  However, this is just a suggestion.  Any significant extension or project will be considered for a star point.  If you're interested, keep reading.

First, what is a ""star point""?  Star points are challenging, open-ended extensions designed to engage those who really want to learn more and go beyond the basic requirements.  However, these are not extra credit.  If you do ""enough"" starpoint and are ""close enough"" to the boundary, you may be moved up to the higher grade, but do these star point extensions because you are intellectually curious and want a challenge.  Not for the grade.  The course staff will not answer questions like ""If I do this, will I get a star point?"".  If you are doing the star point extension just to get the starpoint, then you're doing it for the wrong reason.  Only do it if you would be happy whether or not you get the point in the end.

We have two suggested star points for this assignment. You can choose to do one or both of these depending on your interest. 

1. Implement Efficient PredictCompletions that beats the reference solution

For implementing AutoComplete we have provided you with a reference solution  that implements this function using an exhaustive search technique. While doing an exhaustive search is good enough for finishing the PA, to earn the starpoint you need to design and implement an algorithm that consistently beats the running time by at least a factor of 10 on the specific test examples we provide, and others with similar tree structure.  What we mean by ""similar tree structure"" is that we will also test on similar-length prefixes that have subtrees of similar size to the examples we provide.  If you beat the reference by at least a factor of 10 on our examples and you haven't done anything tricky to hard-code for just these solutions you should be fine.

The file benchtrie.cpp implements a program that times your implementation of the predictCompletions method in DictionaryTrie.  You can use this program to see if your solution beats the reference solution.  However, more importantly, you must use this program as a template for benchmarking in general. 

To test the runtime of the reference solution, refbenchtrie has been provided to you. It will run 5 tests using our reference solution and output the times taken. The same 5 tests are already provided for you in the benchtrie main method. Note that the testers will take a long time to build the dictionary using the freq_dict.txt file.

In terms of timing, these are the cases we are definitely testing for:

- The first 10 completions of each letter of the alphabet: We expect your implementation to be at least 10 times faster than the reference implementation when searching for the first 10 completions of ANY letter of the alphabet. This includes letters with many completions (e.g. ""a"" and ""t""), and letters with relatively few completions (e.g. ""q"" and ""x"").
- The sum of the first 10 completions of every letter of the alphabet: We expect your implementation to be at least 100 times faster than the reference implementation when searching for the first 10 completions of ALL letters of the alphabet. What this means is if we looped from ""a"" to ""z"" and returned the first 10 completions of each of them, the total run-time should be 1/100th of the reference run-time. 
- If any test case takes longer than a minute to complete, you will likely lose some or all points for that case. 
- Note that this isn't an exhaustive list of what we will test for in terms of timing:  We may test for other prefixes. For timing purposes, we will not test on any prefixes longer than 5 characters (including spaces), and any prefix we test for timing purposes will be in the tree, and will have at least 100 completions. For example, if ""troll"" is not a prefix in the dictionary, or if it was but only has 2 completions, we will not test that prefix for timing. We expect such prefixes to beat the reference code by a factor of 2 when searching for the first 10 completions.

NOTE:  You cannot use caching (i.e) you cannot store multiple keys in a single node  in the dictionary via some data structure or create multiple copies of the dictionary/keys via other data structures during insert. Implementations that use caching will not receive the StarPoint. 
  In StarPoint.pdf explain the algorithm that you used for PredictCompletions with an example.  You will also submit all your Dictionaryclasses and implementation. 

2 Implement SpellCorrection 

Extend your DictionaryTrie class to support Spell Suggestions.  Your program spellCheck.cpp will allow the user to type in words to check the spelling of. If the word is spelled correctly (i.e. it was found in the trie), inform the user. If the word is misspelled, However, you should inform the user that they were incorrect, and provide a potential alternative. You must use the trie to come up with somesuggestion of the word they may have intended.  You can use the trie to come up with somesuggestion of the word they may have intended, by simply returning a word that was found somewhere on the path to the word they were typing (""yesterday"" might be a suggestion for the word ""yesterdayz"", for example). If no word exists on that path, you should inform the user that you have no suggestions for them.The suggestions being provided by the above method is fairly weak, and will probably not find suggestions for some common misspellings. However, this can be remedied by expanding the search in the tree. Instead of focusing on the path from the root to the last node, you can start looking down other branches.
To determine if a word is a good suggestion, you can use various metrics. One possible metric is the hamming distance, which simply computes the number of characters in each string are mismatched. This is a fairly weak metric for spell checking, but likely will produce slightly better results than the above. Another metric is the Levenshtein distance, which better handles strings of different lengths. Each of these metrics measure how different two strings are. Implement one of the above algorithms, and provide a handful of better suggestions by ranking them using the implemented metric.

 Spell Check a File: It is not very useful to have a stand alone program for spell checking. It would be better if you could specify a file to be spell checked, and perform this operation on that file. You must produce a new file, which is a spell checked version of the original file.This program should take, as a command line arguments, the dictionary file name AND a plain text file to spell check. Your program should build a trie as normal using the dictionary. It should then check each word sequentially in the file. For every misspelled word, you should provide suggestions and ask the user which suggestion should be used. For ease of use, one of the suggestions should be the ""incorrectly"" spelled word. After you have finished checking the specified file, you should write a new file with the string ""_checked"" appended to the end of the file name. This file will be essentially a copy of the original file, but with all of the spellings ""corrected"" by the users choices.

You will turn in a makefile that generates the executable spellcheckfile , spellcheck , starpoint.pdf and  your code as part of your submission.

In starpoint.pdf explain the algorithm you used to provide suggestions. Also explain how you tested your program. 




Sign in|Recent Site Activity|Report Abuse|Print Page|Powered By Google Sites



# GUI 
Special thanks to the Gui team: Galen Krulce, Huajie Ajax Wu, Becky Huayin Zhou, Raymond Shi

For without them, the GUI for this PA would not be possible. They have gone through long, hard nights and learned how to code in QT from scratch to produce this beautiful code in roughly a week. All the while they put up with spontaneous source file changes, my design suggestions and my lack of punctuality, and they made sure this GUI launched with the assignment. For any students who read this, please let any of the GUI team that you see know that they are awesome and are dripping with awesomesauce. --Jor-el



Dictionaries were extracted and processed from:

http://www.wordfrequency.info
http://www.ngrams.info/
https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists#Top_English_words_lists
http://www.becomeawordgameexpert.com/dictionary.htm

Because we need to cite them to not be sued.

# Author
 [@Daniel](https://www.linkedin.com/in/daniel-huang-443546115/)
",['daniel-huang-1230'],1,0.64,0,,,,,,2,,,,
102928178,MDEwOlJlcG9zaXRvcnkxMDI5MjgxNzg=,Palindrome-C-translated-to-Assembly,daniel-huang-1230/Palindrome-C-translated-to-Assembly,0,daniel-huang-1230,https://github.com/daniel-huang-1230/Palindrome-C-translated-to-Assembly,Project from 2016 summer at UC San Diego. Course: CSE 30 Computer Organization and Systems Programming,0,2017-09-09 04:59:09+00:00,2020-09-09 02:27:01+00:00,2017-09-09 05:10:49+00:00,,1150,0,0,C,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,"# Project Overview

 This project is a personal programming assignment from the course **Computer Organization and System Programming"""" at 
 **UC San Diego**. The goal of the course overall is to help us learn the basics of **x86 assembly** and along with some **C** 
 programming. The palindrome.c program is simple and straightforward, but the real challenge lies in where we, as students, had
 to translate the program from **C** to **assembly**. Today, assembly language is used primarily for direct hardware manipulation,
 access to specialized processor instructions, or to address critical performance issues. Typical uses are **device drivers**, 
 **low-level embedded systems**, and **real-time systems**.
 
 
 # Language
  This program consists of both **C** and **assembly** language




# Date: 07/25/2016




**What I did**:
1. This program would take in input, either from a file or from the keyboard, and 
   determine if it is a **palindrome**.
   Palindrome means a word reads forward the same as it reads backward.
   The program can act differently depending on how the user specify options.
   It can read the word as it is and it can also check the word on its bits level to 
   see if the byte patterns are palindromes.
   In the end, the program would print out the tracked number of total palindromes 	
   found to the terminal.

2. With the supplied **Makefile** from the public directory, just type in â€œ**make**â€ in the 
   command line to compile all source files.

3. To run the program, assuming the executable name is palindrome, type something as 
   the following:
	$./palindrome -s -f testfile1

   The above will set the option flag to treat input as string(char array) and read 
	in input from file named tesfile1

4.The normal output goes to stdout.
   ex: 
[cs30ubp@ieng9]:pa3:548$ ./palindrome -b 
r
""r"" is not a Binary palindrome
R
""R"" is not a Binary palindrome
B
""B"" is a Binary palindrome
RJ
""RJ"" is a Binary palindrome
T~*
""T~*"" is a Binary palindrome
<
""<"" is a Binary palindrome
.
""."" is not a Binary palindrome
404
""404"" is not a Binary palindrome
RBJ
""RBJ"" is a Binary palindrome
^D
5 palindromes were seen:
B
RJ
T~*
<
RBJ

5. Abnormal output goes to stderr.

ex:
[cs30ubp@ieng9]:pa3:559$ ./palindrome -b -f avsvv
avsvv: No such file or directory



6. First of all, I have to test for different option flags. 
   For example, I need to make sure only either one of -b or -s is specified,not  both. If both are specified, the program have to print out error message and return.
   When -f is specified, make sure to use perror to handle cases like invalid/non-existent file input.

   In addition to correctly outputting results for testfiles, I also have to test
   for the inputs from keyboard. All inputs must be recorded and checked by calling 
   my palindrome functions and print out the results when ctrl+D is typed in.

7. Make sure to compile all files on **SPARC** machines with the provided Makefile.


# Author 
[@Daniel](https://www.linkedin.com/in/daniel-huang-443546115/)
 
",['daniel-huang-1230'],1,0.59,0,,,,,,1,,,,
34025235,MDEwOlJlcG9zaXRvcnkzNDAyNTIzNQ==,StudyBuddy,darrenlin9/StudyBuddy,0,darrenlin9,https://github.com/darrenlin9/StudyBuddy,Team project for UCSD CSE 110.,0,2015-04-16 00:15:59+00:00,2015-04-16 00:15:59+00:00,2015-05-10 00:05:53+00:00,,88,0,0,,1,1,1,1,0,0,3,0,0,0,,1,0,0,public,3,0,0,master,1,,,['darrenlin9'],1,0.61,0,,,,,,3,,,,
382315241,MDEwOlJlcG9zaXRvcnkzODIzMTUyNDE=,ucsandiego_dsa_psets,dcvallejosjr/ucsandiego_dsa_psets,0,dcvallejosjr,https://github.com/dcvallejosjr/ucsandiego_dsa_psets,my answer to the pset/coding exercises from UC San Diego DSA course,0,2021-07-02 10:45:33+00:00,2021-08-17 16:44:20+00:00,2021-08-17 16:44:17+00:00,,127,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['dcvallejosjr'],1,0.79,0,,,,,,1,,,,
84863183,MDEwOlJlcG9zaXRvcnk4NDg2MzE4Mw==,UCSD-RoboFishy,dheideman/UCSD-RoboFishy,0,dheideman,https://github.com/dheideman/UCSD-RoboFishy,,0,2017-03-13 18:54:23+00:00,2017-05-07 02:00:25+00:00,2017-07-06 10:17:54+00:00,,5012,3,3,C++,1,1,1,1,0,0,2,0,0,0,mit,1,0,0,public,2,0,3,master,1,,,"['gmarcy07', 'justindho', 'dheideman', 'stusona', 'jtharvey']",0,0.75,0,,,,,,2,,,,
234709505,MDEwOlJlcG9zaXRvcnkyMzQ3MDk1MDU=,SEMal,dipta007/SEMal,0,dipta007,https://github.com/dipta007/SEMal,Predict Malonylation Sites from a protein sequence using both structural and evolutionary information,0,2020-01-18 09:15:26+00:00,2023-10-03 04:00:59+00:00,2023-10-03 04:01:45+00:00,,3442,0,0,Python,1,1,1,1,0,0,4,0,0,30,mit,1,0,0,public,4,30,0,master,1,,"## Official Implementation of [SEMal: Accurate Protein Malonylation Site Predictor Using Structural and Evolutionary Information](https://www.sciencedirect.com/science/article/abs/pii/S001048252030353X)

Predict Malonylation Sites from a protein sequence using both structural and evolutionary information

## Flowchart
![Flowchart](./flowchart.jpg)

## STEPS:  
    1. elm to .csv convert:
        Run ""1_elm_to_csv"" with proper function parameters (input is the .elm file downloaded from ""http://plmd.biocuckoo.org/download.php""

    2. .csv to mathematical sequence:
        Run ""2_mathematical_seq"" with proper function parameters (input is the output from previous step)
        0 = Non_sites
        1 = Sites
        2 = Others

    3. Get proteins in fasta format:
        Run ""3_fasta.py"" with proper function parameters (input is the output from previous step)

    4. CD_HIT to eliminate identical proteins:
        Run CDHIT (http://weizhong-lab.ucsd.edu/cdhit_suite/cgi-bin/index.cgi?cmd=cd-hit)

    5. Get Unique fastas in different files:
        Run ""4_unique_seq_different_file"" to get the fastas in different files for getting PSSM

    6. Get PSSM
        Run PSSM on the cloud using the scripts.sh folder commands

    7. Get SPD3
        Run SpiderLocal to get the SPD3 files

    8. Get Statistics
        Run ""5_how_many_sites.py"" to get number of sites and non-sites
",['dipta007'],0,0.58,0,,,,,,1,,,,
882916087,R_kgDONKA69w,object-oriented-programming-in-java-university-of-california-san-diego,don-maleesha/object-oriented-programming-in-java-university-of-california-san-diego,0,don-maleesha,https://github.com/don-maleesha/object-oriented-programming-in-java-university-of-california-san-diego,"This repository contains demos and assignments for the Object Oriented Programming (OOP) course in Java from the University of California, San Diego. It showcases practical examples, coding assignments, and projects that explore fundamental and advanced OOP concepts.",0,2024-11-04 03:18:50+00:00,2024-11-04 03:48:34+00:00,2024-11-04 03:48:30+00:00,,1,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['don-maleesha'],1,0.64,0,,,,,,1,,,,
79676224,MDEwOlJlcG9zaXRvcnk3OTY3NjIyNA==,models-legacy,DSE-capstone-sharknado/models-legacy,0,DSE-capstone-sharknado,https://github.com/DSE-capstone-sharknado/models-legacy,BPR-Based Recommender Systems for Amazon Dataset,0,2017-01-21 22:15:01+00:00,2019-11-22 01:36:18+00:00,2017-05-25 20:27:40+00:00,sharknado.eggie5.com,144,3,3,C++,1,1,1,1,0,0,4,0,0,0,,1,0,0,public,4,0,3,master,1,1,"# Amazon Dataset RecSys Models

Includes reference implementations for:

* BMR: https://arxiv.org/pdf/1205.2618.pdf
* VBMR: https://arxiv.org/pdf/1510.01784.pdf
* TVBMP: https://arxiv.org/pdf/1602.01585.pdf

recommender systems trained on an Amazon Reviews dataset:

Dataset: http://jmcauley.ucsd.edu/data/amazon/

Original Code: https://sites.google.com/a/eng.ucsd.edu/ruining-he/ ( Ruining He)

## Requirements

Traditional gcc tool-chain setup, i.e. not a mac (LLVM).  * See Docker notes below *

* compiler support for openmp (ubuntu: `sudo apt install libomp-dev`)
* armidillo lib (ubuntu: `sudo apt-get install libarmadillo-dev`)


## Preprocessing

### Transform

All the models need the reviews dataset in a simplified format (CSV), use the `convert_to_simple.py` util to do this:

```
python convert_to_simple.py reviews_Clothing_Shoes_and_Jewelry.json.gz reviews_simple.gz
```

It is now possible to train w/ this output file which is all reviews across all categories of clothing. It is often useful to segment across categories: 

### Segmentation

It is useful for evaluation to segment the clothing dataset into:

* women
* men
* boys
* girls
* baby 

using the `getClothingSubReviews` script.

For input it takes the gzipped simplified output from above and a meta data file which has some category mappings:

 https://storage.googleapis.com/sharknado-recsys-public/productMeta_simple.txt.gz

The command takes the simplified dataset file and the metadata as input:

```
 ./getClothingSubReviews ../data/clothing_full.gz ../data/productMeta_simple.txt
```

 This will generate these segmented review files (which you need to gzip to use in the training program):

```
reviews_Baby.txt
reviews_Boys.txt
reviews_Girls.txt
reviews_Men.txt
reviews_Women.txt
```



## Build Suite

To build the suite, run the `Makefile`, by typing `make` in the project directory. This will build a binary named `train`.


### Training

To train all the models, pass in the following args:

1. Review file path â€” the simplified dataset
2. Img feature path â€” the image features
3. Latent Feature Dim. (K) â€” hyperparameter
4. Visual Feature Dim. (K') â€” hyperparameter
5. alpha (for WRMF only) â€” hyperparameter
6. biasReg (regularizer for bias terms) â€” hyperparameter
7. lambda  (regularizer for general terms) â€” hyperparameter
8. lambda2 (regularizer for \""sparse\"" terms) â€” hyper-parameter
9. Epochs (number of epochs)
10. Max iterations
11. Corpus/Category name under \""Clothing Shoes & Jewelry\"" (e.g. Women)

Although some parameters don't apply to some of the models, they are just passed in bulk.

To start the training routine:

```
./train simple_out.gz image_feat.gz 20 k2 alpha 10 10 lambda2 epoch 10 ""Clothing/women""
```

Example Output:

```
{
  ""corpus"": ""simple_out.gz"",
  Loading votes from simple_out.gz, userMin = 5, itemMin = 0  ....

  Generating votes data
  ""nUsers"": 39387, ""nItems"": 23033, ""nVotes"": 278677

<<< BPR-MF__K_20_lambda_10.00_biasReg_10.00 >>>

Iter: 1, took 0.266870
Iter: 2, took 0.247799
Iter: 3, took 0.250260
Iter: 4, took 0.248863
Iter: 5, took 0.262415
[Valid AUC = 0.358993], Test AUC = 0.360745, Test Std = 0.305036
Iter: 6, took 0.245542
Iter: 7, took 0.245433
Iter: 8, took 0.236978
Iter: 9, took 0.236842
Iter: 10, took 0.234738
[Valid AUC = 0.610926], Test AUC = 0.611459, Test Std = 0.294283


 <<< BPR-MF >>> Test AUC = 0.611459, Test Std = 0.294283


 <<< BPR-MF >>> Cold Start: #Item = 11453, Test AUC = 0.554613, Test Std = 0.300705

Model saved to Clothing__BPR-MF__K_20_lambda_10.00_biasReg_10.00.txt.
}
```

### Computational Note

The training routine heavy make use of threading. In experimentation we have been able to utilize 15 cores during training. This is especially important during the expensive AUC calculation.

##Docker

To run the docker image:

```
docker run -v ~/Development/DSE/capstone/UpsDowns:/mnt/mac  -ti updowns /bin/bash
```

the `v` flag will mount the source repot to `/mnt/mac` in the container.


## Models

### BPR

On Amazon, regularization hyper-parameter lambda=10 works the best for BPR-MF, MM-MF and VBPR in most cases. 


### VBPR

```
../tools/getClothingSubImgFeatures _image_features_Clothing_Shoes_and_Jewelry.b productMeta_simple.txt.gz
```

```
./train data/reviews_Women.txt data/image_features_Women.b 10 10 na 1 1 1 na 10 ""women""
```
",['eggie5'],0,0.75,0,,,,,,5,,,,
252617562,MDEwOlJlcG9zaXRvcnkyNTI2MTc1NjI=,unfolding-maps,ducanhitz/unfolding-maps,0,ducanhitz,https://github.com/ducanhitz/unfolding-maps,Object oriented java coursera specialization,0,2020-04-03 02:50:18+00:00,2022-10-05 11:35:59+00:00,2015-09-17 17:56:30+00:00,,11760,0,0,,0,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)


",[],1,0.74,0,,,,,,0,,,,
205411462,MDEwOlJlcG9zaXRvcnkyMDU0MTE0NjI=,ECE-269-Linear-Algebra-and-Applications,e3u3/ECE-269-Linear-Algebra-and-Applications,0,e3u3,https://github.com/e3u3/ECE-269-Linear-Algebra-and-Applications,Final project from Fall 2017 semester at University of California San Diego ECE Linear Algebra and Applications,0,2019-08-30 15:42:41+00:00,2019-08-30 15:42:44+00:00,2019-06-01 03:37:26+00:00,,7184,0,0,MATLAB,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['Ag8833'],1,0.61,0,,,,,,0,,,,
563184399,R_kgDOIZGDDw,haskell-dino-run,Easonrust/haskell-dino-run,0,Easonrust,https://github.com/Easonrust/haskell-dino-run,,0,2022-11-08 04:29:54+00:00,2022-12-15 01:03:39+00:00,2022-12-07 01:28:41+00:00,,57,4,4,Haskell,1,1,1,1,0,0,0,0,0,0,apache-2.0,1,0,0,public,0,0,4,main,1,,"# DINO RUNNN!
We plan to develop an arcade game using brick library in Haskell named DINO RUNNN! DINO RUNNN! is an endless runner game  which is inpired by Chrome Dino developed by Google. In this game, our hero dino runs at full speed to avoid his predators. Players will be using keyboards to help the character avoid all obstacles and rush to the end. The dinosaur needs to jump over bushes and Cactaceae without getting hurt and it can reach some bonus food to get score bonus. It also needs to cope with other challenges on the road. The difficulty of this adventure will gradually increase along this journey. Watch out, before your fail the game by letting dino get hurt.
Once the game is finished(the player fails the game), the player will receive their scores and ranking.

## Goals
- [ ] Use the keyboard to control the dinosaur's vertical movement
- [ ] Automatically generate views, obstacles and bonus food along the road
- [ ] Gradually increase the game difficulty (speed, obstacle amount) over time
- [ ] Display scoreboard at the end

## Architecture

- Dino: Inspired by Samy's tutorial of the Snake. This component is designed to deal with all the events that occur in the game stage. Currently, the code file includes functions that deal with 3 major tasks: 
1. Check whether Dino dies or collides with the barrier. 
2. Determine the height and velocity of Dino. 
3. Generate bush/barriers during the game.
- UI: Built by Brick. Shows the game start/game over user interfaces, with a scoreboard indicating the player's score during the game.Contains the main logic of the game


## Challenges
1. Jumping Height 
Dino accidentally gets the ability to control jumping height. The group needs to deal with the surprise.
-> Sol1: Find out the code snippets that make this trouble and tackle this problem with a total prohibition of ""jumping in the air""
-> Sol2: We can use it as a special feature of the game, making it more fun for players to use this trick coping the challenges they met.

2. Avatar Size
Dino's avatar size is way too large for the display. It either takes up 1/4 of the screen or cannot be properly displayed in a small window.
->Sol1: Increase the resolution of the gaming window and enlarge the barrier to make them compatible with Dino
->Sol2: Modify the array that defines Dino's shape to make a smaller version of Dino.

3. Time Conflicts 
Most team members need to prepare for the final exams and interviews next 2 weeks. There are still a few issues that need to be discussed and settled.
-> Sol1: Confirm a time slot for future discussion. Survey each team member for their schedule in the next week. Meanwhile use WeChat to share ideas.


## Progress
- Successfully create the game start page and jump from it to the game playing page.
- Implemented the gravity function, and fixed a bug that allows Dino to start jumping in the air.
- Added UIs for the Start and End of this game.
- Implemented collision detection and death check functions.
- Implemented character/bushes animation.
- Refactored the Dino avatar with a pixel-style sketch of high quality.


## Team Members
- Shiting Ding (s1ding@ucsd.edu)
- Zhiyuan Chai (zhchai@ucsd.edu)
- Le Yang (ley004@ucsd.edu)
- Xinyu Zhou (xiz143@ucsd.edu)

## Reference
- https://en.wikipedia.org/wiki/Dinosaur_Game
- https://github.com/jtdaugherty/brick/
","['Easonrust', '181830014', 'NellyZhou', 'DDDSSSTTT']",1,0.7,0,,,,,,1,,,,
220064156,MDEwOlJlcG9zaXRvcnkyMjAwNjQxNTY=,Bioinformatics_Specialization,egeulgen/Bioinformatics_Specialization,0,egeulgen,https://github.com/egeulgen/Bioinformatics_Specialization,Solution implementations for the code challenges in the Bioinformatics Specialization by UCSD,0,2019-11-06 18:32:33+00:00,2024-12-13 12:34:32+00:00,2021-05-24 09:10:19+00:00,,5320,5,5,Python,1,1,1,1,0,0,1,0,0,0,mit,1,0,0,public,1,0,5,master,1,,,['egeulgen'],1,0.45,0,,,,,,1,,,,
173729412,MDEwOlJlcG9zaXRvcnkxNzM3Mjk0MTI=,unfolding_maps,elenakhas/unfolding_maps,0,elenakhas,https://github.com/elenakhas/unfolding_maps,"A project for the Object Oriented Programming in Java course (Coursera.org, UC San Diego, Duke University)",0,2019-03-04 11:07:58+00:00,2019-03-04 11:15:20+00:00,2019-03-04 11:15:18+00:00,,12220,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"# Unfolding_maps




The project for the course ""Object Oriented Programming in Java"".

The project uses the Processing library (https://processing.org/reference/libraries/) and is implemented as a PApplet.

Besides completing the required methods, two extensions were implemented:

1.  AIRPORTS WHERE I TRAVELED

![Airports](airportmap.jpg)

Airports Map:
The map shows the airports I traveled to. When you hover over an airport, its name, code, city and country are displayed. When you click on an airport, the routes and destination airports from this airport are displayed, everything else is hidden.


2. EARTHQUAKES THREATENING CITIES


![Earthquakes](earthquakes.jpg)

When you click on a city, a window with some earthquake related information about the city id displayed under the key, it includes: the name of the city, country, the number of earthquakes this city is in the threat circle of, the name and the place of the most recent earthquake close to this city, the average magnitude of all the earthquakes this city was affected by.

In EarthquakeCityMap class:

* implemented the display() method that sets the instructions on how to draw the information panel and what information to print for the lastClicked city marker: it calls getCity(), getCountry(), getPopulation(), numberOfEarthquakes(), mostRecentQuake(), averageMagnitude() methods to display information and processing library methods for modifying shapes and texts;
* added a call to display() in the draw() method;
* implemented  numberOfEarthquakes() method that counts all the earthquakes close to the city (according to the size of the threat circle);
* implemented  mostRecentQuake () method that compares the time of the earthquakes the clicked city in in the threat circle of, finds the most recent one and gets its name by calling getTitle() method. If there is not one, it returns a string ""No recent quake"";
* implemented averageMagnitude()  methods that calculates average magnitude of the quakes that affect the clicked city;
* implemented a compareTime() method that compares the year, month, day and time of an earthquake step by step and returns the most recent one.


__Additions__:

In ParseFeed class:

* modified parseEarthquake() method so that it parses the information about the time of the earthquake;

In EarthquakeMarker class:

* added getters getMonth(), getYear(), getDay(), getTime() to use in compareTime() method;

In AirportMap class:

* implemented data structures: List <String> MyCities containing cities read from a file, ArrayList <Marker> airportsTo containing destination airports from a clicked airport, erases after each click;
* implemented readMyAirports() method that reads a text file into a List of Strings MyCities;
* implemented modified methods mouseMoved(), selectMarkerIfHover(), mouseClicked(), unhideMarkers() similar to the ones in the previous assignments; 
* implemented checkAirportsForClick(), showDestinations(), displayRoutes() methods;  checkAirportsForClick() checks if an airport was clicked, calls showDestinations() method that hides markers that are not clicked and not destination airports for a clicked marker, displayRoutes() that unhides the route markers from a clicked airport;
* added getters and setters.
",['elenakhas'],1,0.75,0,,,,,,0,,,,
19714225,MDEwOlJlcG9zaXRvcnkxOTcxNDIyNQ==,talk-2014,ellisonbg/talk-2014,0,ellisonbg,https://github.com/ellisonbg/talk-2014,A series of talks that I gave about Jupyter/IPython during 2014,0,2014-05-12 20:28:11+00:00,2015-10-14 19:22:17+00:00,2014-10-30 21:21:21+00:00,,20634,4,4,Python,1,1,1,1,0,0,3,0,0,1,mit,1,0,0,public,3,1,4,master,1,,,['ellisonbg'],0,0.79,0,,,,,,3,,,,
146743975,MDEwOlJlcG9zaXRvcnkxNDY3NDM5NzU=,Data_Structures_and_Algorithms_Specialisation,engrravijain/Data_Structures_and_Algorithms_Specialisation,0,engrravijain,https://github.com/engrravijain/Data_Structures_and_Algorithms_Specialisation,Specialisation course by University of California San Diego and National Research University Higher School of Economics,0,2018-08-30 12:07:33+00:00,2018-08-30 12:12:36+00:00,2018-08-30 12:12:33+00:00,,4877,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,# Data_Structures_and_Algorithms_Specialisation,[],1,0.69,0,,,,,,0,,,,
308783124,MDEwOlJlcG9zaXRvcnkzMDg3ODMxMjQ=,UCSDUnfoldingMaps,Ericsong2333/UCSDUnfoldingMaps,0,Ericsong2333,https://github.com/Ericsong2333/UCSDUnfoldingMaps,,0,2020-10-31 01:50:56+00:00,2020-10-31 02:00:29+00:00,2020-10-31 02:00:25+00:00,,11706,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,main,1,,,['Ericsong2333'],1,0.75,0,,,,,,1,,,,
125433442,MDEwOlJlcG9zaXRvcnkxMjU0MzM0NDI=,DFT-leakage-phenomena,eriksandstroem/DFT-leakage-phenomena,0,eriksandstroem,https://github.com/eriksandstroem/DFT-leakage-phenomena,"Project in DSP studying the DFT leakage phenomena, ECE161B, University of California, San Diego",0,2018-03-15 22:30:12+00:00,2018-03-16 03:14:28+00:00,2018-03-16 03:14:27+00:00,,462,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# DFT-leakage-phenomena
The objective of this project is to study the phenomena usually referred to spectral leakage or DFT leakage. The phenomena is important to understand in order to analyze discrete time signals correctly. MatLab is used for implementation.
",['eriksandstroem'],1,0.53,0,,,,,,0,,,,
565717795,R_kgDOIbgrIw,Algorithms-toolbox-answers-CPP,Esraa-alii/Algorithms-toolbox-answers-CPP,0,Esraa-alii,https://github.com/Esraa-alii/Algorithms-toolbox-answers-CPP,This repository will contain my work from the Master Algorithmic Programming Techniques Specialization that was created by UC San Diego and delivered through Coursera. I will be implementing solutions in C++.,0,2022-11-14 07:13:21+00:00,2023-02-18 20:43:19+00:00,2023-01-28 16:17:15+00:00,,1058,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"<div align=""center"">
 
![Component 8](https://user-images.githubusercontent.com/40190772/83211365-3a474080-a15d-11ea-8064-3c1c5ce2ed57.png)


</div>






</div>

# ðŸŒŸ Algorithmic Toolbox

> This repository will contain my work from the [Master Algorithmic Programming Techniques Specialization](https://www.coursera.org/specializations/data-structures-algorithms) that was created by UC San Diego and delivered through Coursera. I will be implementing solutions in C++.



## About This Specialization

> The Specialization covers algorithmic techniques for solving problems arising in computer science applications. It is a mix of theory and practice: you will not only design algorithms and estimate their complexity, but you will get a deeper understanding of algorithms by implementing them in the programming language of your choice (C, C++, C#, Haskell, Java, JavaScript, Python2, Python3, Ruby, and Scala).

> This Specialization is unique, because it offers two real-world projects. Advanced Shortest Paths project is offered in the end of the Algorithms on Graphs course. In this project, you'll deal with road network analysis and social network analysis. You'll learn how to compute the fastest route between New York and Mountain View thousands of times faster than classic algorithms and close to those used in Google Maps.

> Through Genome Assembly culminating project at the end of the Specialization, you'll learn how to assemble genomes from millions of short pieces and how algorithms fuel recent developments in personalized medicine.


## ðŸ“ Table of Content
- [Week-1](/week1_programming_challenges)[ (pdf) ](/week1_programming_challenges/week1_programming_challenges.pdf)
  * [Sum of two Digits](/week1_programming_challenges/1_sum_of_two_digits)
  * [Maximum Pairwise Product](/week1_programming_challenges/2_maximum_pairwise_product)


- [Week-2](/week2_programming_challenges)[ (pdf) ](/week2_programming_challenges/week2_programming_challenges.pdf)
  * [Small Fibonacci Number](/week2_programming_challenges/1_fibonacci_number)
  * [The Last Digit of a Large Fibonacci Number](/week2_programming_challenges/2_last_digit_of_fibonacci_number)
  * [Greatest Common Divisor](/week2_programming_challenges/3_greatest_common_divisor)
  * [Least Common Multiple](/week2_programming_challenges/4_least_common_multiple)
  * [Huge Fibonacci Number modulo m](/week2_programming_challenges/5_fibonacci_number_again)
  * [Last Digit of a Sum of Fibonacci Numbers](/week2_programming_challenges/)
  * [Last Digit of a Partial Sum of Fibonacci Numbers](/week2_programming_challenges/)
  * [Last Digit of the Sum of Squares of Fibonacci Numbers](/week2_programming_challenges/)
  
  
- [Week-3](/week3_programming_challenges)[ (pdf) ](/week2_programming_challenges/week2_programming_challenges.pdf)
  * [Money Change](/week3_programming_challenges/1_money_change)
  * [Maximum Value of the Loot (Fractional Knapsack)](/week3_programming_challenges/2_maximum_value_of_the_loot)
  * [Maximum Advertisement Revenue (Maximum Dot Product)](/week3_programming_challenges/3_maximum_advertisement_revenue)
  * [Collecting Signatures (Covering Segments by Points)](/week3_programming_challenges/4_collecting_signatures)
  * [Maximum Number of Prizes (Different Summands)](/week3_programming_challenges/5_maximum_number_of_prizes)
  * [Maximum Salary (Largest Number)](/week3_programming_challenges/6_maximum_salary)


- [Week-4](/week4_programming_challenges)[ (pdf) ](/week4_programming_challenges/week4_divide_and_conquer.pdf)
  * [binary search](/week4_programming_challenges/1_binary_search)
  * [majority element](/week4_programming_challenges/2_majority_element)
  * [improving quicksort](/week4_programming_challenges/3_improving_quicksort)
  * [number of inversions](/week4_programming_challenges/4_number_of_inversions)
  * [organizing a lottery](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week4_programming_challenges/5_organizing%20a%20lottery/organizing%20a%20lottery.cpp)
  * [closest points](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week4_programming_challenges/6_Closest_Points/Closest_Points.cpp)
  
  
- [Week-5](/week5_programming_challenges)[ (pdf) ](/week5_programming_challenges/week5_dynamic_programming1.pdf)
  * [money change again](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week5_programming_challenges/1_money_change_again/change_dp.cpp)
  * [primitive calculator](/week4_programming_challenges/2_majority_element)
  * [edit distance](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week5_programming_challenges/3_edit_distance/edit_distance.cpp)
  * [longest common subsequence of two sequences](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week5_programming_challenges/4_longest_common_subsequence_of_two_sequences/lcs2.cpp)
  * [longest common subsequence of three sequences](https://github.com/AbdallahHemdan/Algorithmic-Toolbox-San-Diego/blob/master/week5_programming_challenges/5_longest_common_subsequence_of_three_sequences/lcs3.cpp)
  
  
- [Week-6](/week6_programming_challenges)[ (pdf) ](/week6_programming_challenges/week6_dynamic_programming1.pdf)
  * [maximum amount of gold](/week6_programming_challenges/1_maximum_amount_of_gold)
  * [partitioning souvenirs](/week6_programming_challenges/2_partitioning_souvenirs)
  * [maximum value of an arithmetic expression](/week6_programming_challenges/3_maximum_value_of_an_arithmetic_expression)
  



## ðŸŽ‰ Certificate
<img
  src=""Algorithmic Toolbox.png""
  alt=""Alt text""
  title=""Optional title""
  style=""display: inline-block; margin: 0 auto; max-width: 400px"">





",['Esraa-alii'],1,0.66,0,,,,,,1,,,,
87244618,MDEwOlJlcG9zaXRvcnk4NzI0NDYxOA==,Bioinformatics-UC.San.Diego,extwiii/Bioinformatics-UC.San.Diego,0,extwiii,https://github.com/extwiii/Bioinformatics-UC.San.Diego,Bioinformatics - Coursera,0,2017-04-04 23:28:15+00:00,2021-04-02 15:38:50+00:00,2017-04-09 00:57:06+00:00,,28,1,1,,1,1,1,1,0,0,0,0,0,0,apache-2.0,1,0,0,public,0,0,1,master,1,,"# Bioinformatics-UC.San.Diego
Master bioinformatics software and computational approaches in modern biology - Coursera

## Course I - Finding Hidden Messages in DNA
* Welcome!
  * [Where in the Genome Does DNA Replication Begin? I](http://bioinformaticsalgorithms.com/faqs/replication.html)
  * [Background of pseudocode](http://bioinformaticsalgorithms.com/excerpt/Pseudocode.pdf)
* Finding Replication Origins
  * [Where in the Genome Does DNA Replication Begin? II](http://bioinformaticsalgorithms.com/faqs/replication.html#week2)
* Hunting for Regulatory Motifs
  * [Which DNA Patterns Play the Role of Molecular Clocks? I](http://bioinformaticsalgorithms.com/faqs/motifs.html)
* How Rolling Dice Helps Us Find Regulatory Motifs
  * [Which DNA Patterns Play the Role of Molecular Clocks? II](http://bioinformaticsalgorithms.com/faqs/motifs.html#week4)
  
## Course II - Genome Sequencing
* Introduction to Genome Sequencing
  * [How Do We Assemble Genomes? I](http://bioinformaticsalgorithms.com/faqs/assembly.html#week1)
* Applying Euler's Theorem to Assemble Genomes
  * [How Do We Assemble Genomes? II](http://bioinformaticsalgorithms.com/faqs/assembly.html#week2)
* Sequencing Antibiotics
  * [How Do We Sequence Antibiotics? I](http://bioinformaticsalgorithms.com/faqs/antibiotics.html#week3)
* From Ideal to Real Spectra for Antibiotics Sequencing
  * [How Do We Sequence Antibiotics? II](http://bioinformaticsalgorithms.com/faqs/antibiotics.html#week4)

## Course III - Comparing Genes, Proteins, and Genomes
* Introduction to Sequence Alignment
  * [How Do We Compare Biological Sequences? I](http://bioinformaticsalgorithms.com/faqs/alignment.html#week1)
* From Finding a Longest Path to Aligning DNA Strings
  * [How Do We Compare Biological Sequences? II](http://bioinformaticsalgorithms.com/faqs/alignment.html#week2)
* Advanced Topics in Sequence Alignment
  * [How Do We Compare Biological Sequences? III](http://bioinformaticsalgorithms.com/faqs/alignment.html#week3)
* Genome Rearrangements and Fragility
  * [Are There Fragile Regions in the Human Genome? I](http://bioinformaticsalgorithms.com/faqs/rearrangements.html#week4)
* Applying Genome Rearrangement Analysis to Find Genome Fragility
  * [Are There Fragile Regions in the Human Genome? II](http://bioinformaticsalgorithms.com/faqs/rearrangements.html#week5)

## Course IV - Molecular Evolution
* Introduction to Evolutionary Tree Construction
  * [Which Animal Gave Us SARS? I](http://bioinformaticsalgorithms.com/faqs/evolution.html#week1)
* More Algorithms for Constructing Trees from Distance Matrices
  * [Which Animal Gave Us SARS? II](http://bioinformaticsalgorithms.com/faqs/evolution.html#week2)
* Constructing Evolutionary Trees from Characters
  * [Which Animal Gave Us SARS? III](http://bioinformaticsalgorithms.com/faqs/evolution.html#week3)

## Course V - Genomic Data Science and Clustering
* This course isn't available yet

## Course VI - Finding Mutations in DNA and Proteins 
* Introduction to Read Mapping
  * [How Do We Locate Disease-Causing Mutations? I](http://bioinformaticsalgorithms.com/faqs/bwt.html#week1)
* The Burrows-Wheeler Transform
  * [How Do We Locate Disease-Causing Mutations? II](http://bioinformaticsalgorithms.com/faqs/bwt.html#week2)
* Speeding Up Burrows-Wheeler Read Mapping
  * [How Do We Locate Disease-Causing Mutations? III](http://bioinformaticsalgorithms.com/faqs/bwt.html#week3)
* Introduction to Hidden Markov Models 
  * [Why Have Biologists Still Not Developed an HIV Vaccine? I](http://bioinformaticsalgorithms.com/faqs/hmm.html#week4)
* Profile HMMs for Sequence Alignment
  * [Why Have Biologists Still Not Developed an HIV Vaccine? II](http://bioinformaticsalgorithms.com/faqs/hmm.html#week5)

#### Taught by: 
#### Pavel Pevzner, Professor - Department of Computer Science and Engineering 
#### Phillip E. C. Compeau, Postdoctoral Researcher - Computer Science & Engineering, UC San Diego

### Rating :full_moon::full_moon::full_moon::full_moon::full_moon::full_moon::new_moon::new_moon::new_moon::new_moon:
### Difficulty :full_moon::full_moon::full_moon::full_moon::full_moon::full_moon::new_moon::new_moon::new_moon::new_moon:

### Created By Bilal Cagiran | [E-Mail](mailto:bcagiran@hotmail.com) | [Github](https://github.com/extwiii/) | [LinkedIn](https://linkedin.com/in/bilalcagiran) | [CodePen](http://codepen.io/extwiii/) | [Blog/Site](http://bilalcagiran.com) | [FreeCodeCamp](https://www.freecodecamp.com/extwiii) 
",['extwiii'],1,0.55,0,,,,,,2,,,,
128383516,MDEwOlJlcG9zaXRvcnkxMjgzODM1MTY=,MicroMasters-UC-San-Diego-Data-Science,faizalazman/MicroMasters-UC-San-Diego-Data-Science,0,faizalazman,https://github.com/faizalazman/MicroMasters-UC-San-Diego-Data-Science,MicroMasters Repo. Finished Python for Data Science and currently working on DSE 210x and DSE220x,0,2018-04-06 10:58:05+00:00,2023-05-23 00:32:19+00:00,2020-05-04 12:53:40+00:00,https://www.edx.org/course/python-for-data-science,20568,8,8,Jupyter Notebook,1,1,1,1,0,0,4,0,0,0,,1,0,0,public,4,0,8,master,1,,"# MicroMasters UC San Diego Data Science
![alt text](https://github.com/faizalazman/MicroMaster-UC-San-Diego-Data-Science/blob/master/DSE200x%20Python%20for%20Data%20Science/UCSD-logo.png)

# DSE200x Python for Data Science
# DSE210x Statistics and Probability in Data Science using Python
# DSE220x Fundamental of Machine Learning
# DSE230x Big Data Analytics using Spark
About this course
In the information age, data is all around us. Within this data are answers to compelling questions across many societal domains (politics, business, science, etc.). But if you had access to a large dataset, would you be able to find the answers you seek?

This course, part of the Data Science MicroMasters program, will introduce you to a collection of powerful, open-source, tools needed to analyze data and to conduct data science. Specifically, youâ€™ll learn how to use:

  - python
  - jupyter notebooks
  - pandas
  - numpy
  - matplotlib
  - git
and many other tools.
You will learn these tools all within the context of solving compelling data science problems.

After completing this course, youâ€™ll be able to find answers within large datasets by using python tools to import data, explore it, analyze it, learn from it, visualize it, and ultimately generate easily sharable reports.

By learning these skills, youâ€™ll also become a member of a world-wide community which seeks to build data science tools, explore public datasets, and discuss evidence-based findings. Last but not least, this course will provide you with the foundation you need to succeed in later courses in the Data Science MicroMasters program.

What you'll learn
  - Basic process of data science
  - Python and Jupyter notebooks
  - An applied understanding of how to manipulate and analyze uncurated datasets
  - Basic statistical analysis and machine learning methods
  - How to effectively visualize results
  

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/faizalazman/MicroMasters-UC-San-Diego-Data-Science/master?filepath=https%3A%2F%2Fgithub.com%2Ffaizalazman%2FMicroMasters-UC-San-Diego-Data-Science%2Fblob%2Fmaster%2FDSE200x%2520Python%2520for%2520Data%2520Science%2FWeek%25206%2520Mini%2520Projects%2FNotebook.ipynb)
",['faizalazman'],1,0.7,0,,,,,,,,,,
219826203,MDEwOlJlcG9zaXRvcnkyMTk4MjYyMDM=,UCSDCourse,FitzXu/UCSDCourse,0,FitzXu,https://github.com/FitzXu/UCSDCourse,UCSD CSE Courses,0,2019-11-05 18:45:01+00:00,2021-11-16 04:55:54+00:00,2019-06-21 17:13:04+00:00,,610630,1,1,,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,,[],1,0.74,0,,,,,,0,,,,
160988469,MDEwOlJlcG9zaXRvcnkxNjA5ODg0Njk=,flexflow-train,flexflow/flexflow-train,0,flexflow,https://github.com/flexflow/flexflow-train,Automatically Discovering Fast Parallelization Strategies for Distributed Deep Neural Network Training,0,2018-12-08 23:43:13+00:00,2025-03-07 02:01:20+00:00,2025-03-05 09:20:01+00:00,https://flexflow.ai,283983,1764,1764,C++,1,1,1,1,0,0,236,0,0,246,apache-2.0,1,0,0,public,236,246,1764,master,1,1,,"['jiazhihao', 'eddy16112', 'lockshaw', 'lambda7xx', 'wmdi', 'reyna-abhyankar', 'goliaro', 'KateUnger', 'Efrainq07', 'soumyac1999', 'awgu', 'msbaines', 'tnoyola', 'Bob-Chen222', 'Marsella8', 'williamberman', 'mandeeplearning', 'ferdiko', 'eric-zheng', 'xinhaoc', 'kadinlz', 'victorli2002', 'aquan9', 'facebook-github-bot', 'JHancox', 'stas00', 'dycz0fx', 'mengdiz97', 'daiyaanarfeen', 'caoshiyi', 'easyeasydev', 'dan-garvey', 'bhetherman', 'chenzhuofu', 'Flasew', 'thomasw21', 'rajasbansal', 'stelleg', 'oOTigger', 'powderluv']",1,0.69,0,"# Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to make participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment
include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or
advances
* Trolling, insulting/derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or electronic
address, without explicit permission
* Other conduct which could reasonably be considered inappropriate in a
professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.

## Scope

This Code of Conduct applies within all project spaces, and it also applies when
an individual is representing the project or its community in public spaces.
Examples of representing a project or community include using an official
project e-mail address, posting via an official social media account, or acting
as an appointed representative at an online or offline event. Representation of
a project may be further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at <opensource-conduct@fb.com>. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,
available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see
https://www.contributor-covenant.org/faq
","# Developers Guide

## Setup

> [!NOTE]
> If you are developing on Stanford's sapling cluster, instead see the instructions [here](./docs/SAPLING.md).
> If you don't know what this means, you're not using sapling so you should just continue reading.

1. FlexFlow Train uses [nix](https://nix.dev/manual/nix/2.24/) to manage dependencies and the development environment. 
   There exist a number of ways to install nix, but we recommend one of the following:

   1. If you have root permissions: [DeterminateSystems/nix-installer](https://github.com/DeterminateSystems/nix-installer)

   2. If you don't have root permissions: [DavHau/nix-portable](https://github.com/DavHau/nix-portable). 
      Note that nix-portable does not work particularly well if the nix store is in NFS[^1] or other distributed file systems, 
      so if you are running on an HPC cluster where the home directory is mounted via a distributed file system we recommend setting the 
      `NP_LOCATION` environment to `/tmp` or some other non-NFS location. 

      While you should at least skim nix-portable's setup instructions, you'll probably end up doing something like this:
      ```
      $ USERBIN=""${XDG_BIN_HOME:-$HOME/.local/bin}""
      $ wget 'https://github.com/DavHau/nix-portable/releases/download/v010/nix-portable' -O ""$USERBIN/nix-portable""
      ...
      $ chmod u+x ""$USERBIN/nix-portable""
      ...
      $ ln -sf ""$USERBIN/nix-portable"" ""$USERBIN/nix""
      ...
      $ echo 'export PATH=$USERBIN:$PATH' >> ~/.bashrc
      ...
      ```
      Now if everything is setup properly, you should be able to see something like the following (don't worry if the version number is slightly different) if you run `nix --version`:
      ```
      $ nix --version
      nix (Nix) 2.20.6
      ```

[^1]: [Network File System](https://en.wikipedia.org/wiki/Network_File_System)

2. Clone the FlexFlow Train repository (or, if you'd prefer, follow the alternative setup instructions in the [ff-dev](#ff-dev-optional) section)

```
$ FF_DIR=""$HOME/flexflow-train"" # or wherever else you want to put the repository
$ git clone --recursive git@github.com:flexflow/flexflow-train.git ""$FF_DIR""
...
```

3. Enter the nix-provided `default` development environment[^2]

[^2]: aka ""dev shell""

```
$ cd ""$FF_DIR""
$ nix develop --accept-flake-config
```

4. Build and run the non-GPU-required tests (systems that have access to CUDA GPUs can also run the GPU-mandatory tests by following the instructions [here](#gpu-setup))

```
(ff) $ proj cmake
...
(ff) $ proj test --skip-gpu-tests
...
```
If everything is correctly configured, you should see a bunch of build messages followed by something like
```
(ff) $ proj test --skip-gpu-tests
421/421 Test #441: get_transformer_computation_graph
100% tests passed, 0 tests failed out of 421

Label Time Summary:
compiler-tests                  =   6.13 sec*proc (19 tests)
local-execution-tests           =   0.13 sec*proc (3 tests)
models-tests                    =   0.05 sec*proc (4 tests)
op-attrs-tests                  =   0.48 sec*proc (59 tests)
pcg-tests                       =   0.33 sec*proc (33 tests)
substitution-generator-tests    =   0.06 sec*proc (2 tests)
substitutions-tests             =   0.10 sec*proc (9 tests)
utils-tests                     =   1.20 sec*proc (293 tests)

Total Test time (real) =   8.64 sec
```

If you don't, or if you see any tests failing, please double check that you have followed the instructions above. 
If you have and are still encountering an issue, please [contact us](#contact-us) with a detailed description of your platform and the commands you have run.

### GPU setup

If you are developing on a machine with one or more CUDA GPUs, you can also run the tests that require a GPU by entering the `gpu` devshell instead of the `default` devshell:
```
$ NIXPKGS_ALLOW_UNFREE=1 nix develop .#gpu --accept-flake-config --impure
```
and then running
```
(ff) $ proj test
...
```
You should see the additional GPU tests run. If you instead see a message like 

> `Error: ... Pass --skip-gpu-tests to skip running tests that require a GPU`

Double check that you are correctly in the `gpu` devshell, not the `default` devshell. 
If you've confirmed that you are in the correct devshell and are still encountering issues, [contact us](#contact-us) 
with a detailed description of your platform and the commands you have run.

### ff-dev (optional)

Many of the FlexFlow Train developers use an additional set of scripts called [ff-dev](https://github.com/lockshaw/ff-dev) 
to automate many common git operations associated with FlexFlow Train development. 

To setup ff-dev, run TODO (tracked in [#1573](https://github.com/flexflow/flexflow-train/issues/1573)).

<!--
To use ff-dev, instead of cloning the FlexFlow Train repo directly, you'll instead clone ff-dev to `~/ff`:

```console
$ git clone --recursive git@github.com:lockshaw/ff-dev.git ""$HOME/ff""
```

and then run the `ff-dev-init` command from within the nix environment provided by `ff-dev`:

```
$ cd ~/ff
$ nix develop . --accept-flake-config
...
$ ff-dev-init
...
```

> [!NOTE]
> The development environment provided by ff-dev is different than the environment provided 
> by FlexFlow Train. Whenever you are running any scripts from ff-dev, make sure that your 
> shell prompt begins with `(ff-dev)`. Whenever you are actually doing FlexFlow Train development,
> make sure that your shell prompt begins with `(ff)`.

As part of `ff-dev-init`, you'll likely need to add a github authentication token to allow `ff-dev` to
create and modify your fork of the FlexFlow Train repository. 
If this is necessary, you'll see a prompt saying something like 

```console
? What account do you want to log into?  [Use arrow keys to move, type to filter]
...
```
At this point, perform the following steps:

1. Select ""GitHub.com""
2. Select ""SSH""
3. Select ""Yes""
4. Select ""Paste an authentication token""
5. Now go to <https://github.com/settings/tokens> and click ""Generate new token"" in the top right-hand corner, in the dropdown that appears select ""Generate new token (classic)""
6. You should see a text field called ""Note"". Enter a brief name to remind yourself what this key is for.
7. Under ""Expiration"" select ""90 days""
8. Under ""Select scopes"" check the following check boxes: `repo`, `read:org`, and `admin:public_key`
9. Click ""Generate token""
10. You should now see a key beginning with `ghp_`. Copy this, save it somewhere to your computer safe (if you lose it, github won't show it to you again)
11. Copy the key beginning with `ghp_` into the prompt ""Paste your authentication token:"" and hit enter.
12. You should now see a message that says ""Logged in as \<your github username\>"", followed by a bunch of output from git as it clones the FlexFlow repository.

Once these steps are completed, you should be able to `cd ~/ff/master` and resume the standard setup instructions from step 3 (i.e., entering the nix-provided development environment).
You can find more instructions for how to use ff-dev [here]().
-->

### nix-direnv (optional)

If you installed nix system-wide (e.g., using [DeterminateSystems/nix-installer](https://github.com/DeterminateSystems/nix-installer)), 
you can use [direnv](https://direnv.net/) to automatically enter the FlexFlow Train development environment when you `cd` into the repository, rather
than having to manually run `nix develop`.
[direnv](https://direnv.net) will also automatically exit the environment when you `cd` out of the repository, and (if configured using [nix-direnv](https://github.com/nix-community/nix-direnv)) will even automatically reload the environment if the `flake.nix` file changes.
You can find the installation instructions for direnv [here](https://direnv.net/docs/installation.html), and if you would like automatic environment reloading you can also install nix-direnv using the instructions [here](https://github.com/nix-community/nix-direnv?tab=readme-ov-file#installation).

Once you have direnv (and optionally nix-direnv) installed, cd into the root of your cloned FlexFlow Train repository and run
```
$ echo 'use flake . --accept-flake-config' > .envrc
```
You should see a message that the `.envrc` file you just created is blocked. 
Run the command shown in the error message (i.e., `direnv allow`), and direnv should automatically place you in the environment.
For more information on using direnv with nix, see [here](https://github.com/direnv/direnv/wiki/Nix).

## Building, Testing, etc.

Most operations you'll want to perform while developing FlexFlow Train are provided through a small python utility called [proj](https://github.com/lockshaw/proj). 
`proj` is automatically pulled in by nix when you enter the dev shell, so you should be able to run 
```
(ff) $ proj -h
```
and see the full list of operations that `proj` supports.
`proj` commands can be run from anywhere in the repository (i.e., they do not have to be run from the root).
To help you get started, however, a list of common command invocations is included here:

- To build FlexFlow Train:
  ```
  (ff) $ proj build
  ```
- To build and run FlexFlow Train tests (without a GPU):
  ```
  (ff) $ proj test --skip-gpu-tests
  ```
- To build and run FlexFlow Train tests (with a GPU):
  ```
  (ff) $ proj test
  ```
- To regenerate CMake files (necessary anytime you switch branches or modify the CMake source. If you're ever running into weird build issues, try running this and see if it fixes things):
  ```
  (ff) $ proj cmake
  ```
- To format all of the FlexFlow Train sources files: 
  ```
  (ff) $ proj format
  ```
- To build the FlexFlow Train Doxygen docs:
  ```
  (ff) $ proj doxygen
  ```
  You can also add the `--browser` command to automatically open the built docs in your default browser if you are working on your local machine.

## Code Organization

The bulk of the FlexFlow source code is stored in the following folders:

1. `lib`: The C++ code that makes up FlexFlow's core, split up into a number of libraries. You can find a description of each library [here](./lib/README.md).
2. `bin`: Command-line interfaces for FlexFlow and associated tools (all in C++). Generally, these are just thin wrappers that parse command-line arguments and then call out to functions defined in `lib` for the actual processing/logic. You can find a description of each binary [here](./bin/README.md).
3. `bindings`: Python (or any additional languages added in the future) bindings for FlexFlow Train
4. `docs`: Config files for documentation generators and code for generating diagrams. The actual documentation itself is included in the source directories/files as either `.md` files or inline in the language's documentation syntax (i.e., [Doxygen](https://www.doxygen.nl/manual/index.html) for C++ and [Sphinx](https://www.sphinx-doc.org/en/master/) for Python).
5. `cmake`: CMake configuration for building FlexFlow Train. Note that unless you're modifying the build configuration (i.e., adding a library, additional dependencies, etc.), you generally should use [proj](#building-testing-etc) instead of interacting with CMake directly. 
6. `deps`: Third-party dependencies included as submodules. Note that since FlexFlow Train moved to [nix](https://nix.dev/manual/nix/2.24/) for managing dependencies many (but not all) of these are used in the default configuration.

## Continuous Integration

We currently implement CI testing using Github Workflows. Each workflow is defined by its corresponding YAML file in the [.github/workflows](.github/workflows) folder of the repo. We currently have the following workflows:

1. [`tests`](./.github/workflows/per-lib-check.yml): Builds and runs GPU and non-GPU unit tests for all of the code under `lib` and `bin`. Also uploads coverage numbers to [codecov.io](https://app.codecov.io/gh/flexflow/flexflow-train).
2. [`clang-format-check.yml`](./.github/workflows/clang-format-check.yml): ensures that the source code is properly formatted using `clang-format`. To format your code locally, run `proj format` (see [here](#building-testing-etc) for more information on `proj`).
4. [`shell-check.yml`](./.github/workflows/shell-check.yml): runs shellcheck on all bash scripts in the repo.

GPU machines for CI are managed using [runs-on](https://runs-on.com/).

## Contributing to FlexFlow

We actively welcome your pull requests. Note that we may already be working on the feature/fix you're looking for, so we suggest searching through the [open issues](https://github.com/flexflow/flexflow-train/issues), [open PRs](https://github.com/flexflow/flexflow-train/pulls), and [contacting us](#contact-us) to make sure you're not duplicating existing effort!

The steps for getting changes merged into FlexFlow are relatively standard:

1. [Fork the repo](https://github.com/flexflow/flexflow-train/fork) and either create a new branch based on `master`, or just modify `master` directly.
2. If you've added code that should be tested, add tests. The process for adding tests for code under `lib` is documented [here](./lib/README.md#tests). Adding tests for other parts of the code is currently undocumented, so you will [contact us](#contact-us) for information on how to do it.
3. Ensure the code builds (i.e., run `proj build`).
4. Ensure the test suite passes (i.e., run `proj test`).
5. Format the code (i.e., run `proj format`).
6. Create a new PR from your modified branch to the `master` branch in FlexFlow Train. 
   Provide a brief description of the changes you've made and link any related/closed issues.

Code review is done using [Reviewable](https://reviewable.io/).
If you haven't used Reviewable before, please read through (or at least skim) the [""Reviews"" section](https://docs.reviewable.io/reviews.html) of the Reviewable documentation.

## Contact Us

Either [create an issue](https://github.com/flexflow/flexflow-train/issues/new) or join the FlexFlow [Zulip](https://flexflow.zulipchat.com/join/mtiwtwttgggnivrkb6vlakbr/) instance. 
For any reported bugs, please ensure that your description clear and has sufficient information for us to reproduce the issue.

## License

By contributing to FlexFlow Train, you agree that your contributions will be licensed
under the [LICENSE](./LICENSE) file in the root directory of this source tree.
",,,"**Description of changes:**



**Related Issues:**

Linked Issues:
- Issue #

Issues closed by this PR:
- Closes #
",28,,,,
783121181,R_kgDOLq17HQ,sha-256,fqw1727252209/sha-256,0,fqw1727252209,https://github.com/fqw1727252209/sha-256,ucsd ece111 project3,0,2024-04-07 02:01:04+00:00,2024-04-09 13:07:23+00:00,2024-04-10 13:03:25+00:00,,42,0,0,SystemVerilog,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,"['Lucas-Fengqw', 'fqw1727252209']",1,0.67,0,,,,,,1,,,,
583826549,R_kgDOIsx8dQ,GVAED,fudanyliu/GVAED,0,fudanyliu,https://github.com/fudanyliu/GVAED,Generalized Video Anomaly Event Detection: Systematic Taxonomy and Comparison of Deep Models,0,2022-12-31 04:06:55+00:00,2025-02-28 08:53:22+00:00,2024-03-27 01:21:03+00:00,https://dl.acm.org/doi/abs/10.1145/3645101,745,42,42,,1,1,1,1,0,0,5,0,0,0,mit,1,0,0,public,5,0,42,main,1,,,['fudanyliu'],0,0.62,0,,,,,,1,,,,
256327784,MDEwOlJlcG9zaXRvcnkyNTYzMjc3ODQ=,COGS108_Repo,gh-tan/COGS108_Repo,0,gh-tan,https://github.com/gh-tan/COGS108_Repo,Repo for COGS108 UCSD,0,2020-04-16 20:55:27+00:00,2020-04-16 21:05:37+00:00,2020-04-16 21:05:34+00:00,,1,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['gh-tan'],1,0.7,0,,,,,,1,,,,
273385970,MDEwOlJlcG9zaXRvcnkyNzMzODU5NzA=,Biology-Meets-Programming,giuliafazzi/Biology-Meets-Programming,0,giuliafazzi,https://github.com/giuliafazzi/Biology-Meets-Programming,"Biology Meets Programming: Bioinformatics for Beginners, University of California San Diego",0,2020-06-19 02:27:21+00:00,2020-07-06 22:06:42+00:00,2020-07-06 22:06:39+00:00,,5,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['giuliafazzi'],1,0.68,0,,,,,,1,,,,
31440847,MDEwOlJlcG9zaXRvcnkzMTQ0MDg0Nw==,bio3d,Grantlab/bio3d,0,Grantlab,https://github.com/Grantlab/bio3d,A mirror of official bio3d development site at Bitbucket: https://bitbucket.org/Grantlab/bio3d. See also bio3d website:  http://thegrantlab.org/bio3d,0,2015-02-27 21:55:02+00:00,2025-01-18 10:15:29+00:00,2023-04-30 23:18:37+00:00,,192447,21,21,PostScript,0,1,1,0,0,0,6,0,0,0,,1,0,0,public,6,0,21,master,1,1,"# Bio3D Package for Biological Structure Analysis #

Utilities to analyze, process, organize and explore biomolecular structure, sequence and dynamics data.


## Features ##

Features include the ability to read and write structure, sequence and dynamic trajectory data, perform database searches, atom summaries, atom selection, re-orientation, superposition, rigid core identification, clustering, torsion analysis, distance matrix analysis, structure and sequence conservation analysis, normal mode analysis (NMA), correlation network analysis (CNA) and principal component analysis (PCA).  

In addition, various utility functions are provided to enable the statistical and graphical power of the R environment to work with biological sequence and structural data.  Please refer to the main [Bio3D website](http://thegrantlab.org/bio3d/) for more background information.


## Installing Bio3D ##

For the majority of users we recommend the use of the last stable release available from [CRAN](http://cran.r-project.org/web/packages/bio3d/) and the main [Bio3D website](http://thegrantlab.org/bio3d/). To install from within R issue the command:

```
#!r
install.packages(""bio3d"", dependencies=TRUE)
```

The development version is available from our bitbucket repository and typically contains new functions and bug fixes that have not yet been incorporated into the latest stable release. The simplest method for development version installation is to use the R function install_bitbucket() from the devtools package:


```
#!r
install.packages(""devtools"")
library(devtools)
install_bitbucket(""Grantlab/bio3d"", subdir = ""ver_devel/bio3d/"")
```

Alternative installation methods and additional instructions are posted to the [wiki section](https://bitbucket.org/Grantlab/bio3d/wiki/Home) of our bitbucket repository. 

## Installing the bio3d.core package of the Bio3D family ##

Since 2020, we have started a new way to develop and implement Bio3D: Instead of maintaining a single R package (bio3d), we put main modules into separate packages. The **bio3d.core** package provides functionality for data processing and basic sequence, structure and dynamics analyses. This package is required for other packages of the Bio3D family (See below). To install it, use the `install_bitbucket()` function from the **devtools** package:

```
#!r
library(devtools)
install_bitbucket(""Grantlab/bio3d/bio3d-core"", ""core"")
```

## Other packages in the Bio3D family ##

With growing functionality in Bio3D we have decided to implement larger Bio3D modules into separate packages:

* [Bio3D-web](https://bitbucket.org/Grantlab/bio3d-web/) for online interactive analysis of protein structure ensembles
* [Bio3D-nma](https://bitbucket.org/Grantlab/bio3d-nma/) for Normal Mode Analysis (NMA) of protein structures and ensembles
* [Bio3D-cna](https://bitbucket.org/Grantlab/bio3d-cna/) for Correlation Network Analysis (CNA) for protein structure ensembles
* [Bio3D-eddm](https://bitbucket.org/Grantlab/bio3d-eddm/) for Distances matrix analysis for the identification of significant conformational changes underling functional processes
* [Bio3D-gesostas](https://bitbucket.org/Grantlab/bio3d-geostas/) for the identification of geometrically stable domains in biomolecules
* [Bio3D-view](https://bitbucket.org/Grantlab/bio3d-view/) for interactive visualization of structures in R

Current ongoing projects entails:

* [Bio3D-mmtf](https://bitbucket.org/Grantlab/bio3d-mmtf/) [In development]
* [Bio3D-amber](https://bitbucket.org/Grantlab/bio3d-amber/) [In development]
* [Bio3D-muscle](https://bitbucket.org/Grantlab/bio3d-muscle/) [In development]
* [Bio3D-cheminf](https://bitbucket.org/larsss/cheminf/src/master/) 
* [Bio3D-dcna](https://bitbucket.org/xinqyao/dcna)

## Contributing to Bio3D ##

We are always interested in adding additional functionality to Bio3D. If you have ideas, suggestions or code that you would like to distribute as part of this package, please contact us (see below). You are also encouraged to contribute your code or issues directly to [this repository](https://bitbucket.org/Grantlab/bio3d/) for incorporation into the development version of the package. For details on how to do this please see the [developer wiki](https://bitbucket.org/Grantlab/bio3d/wiki/Home).  

  
## Contact ##

You are welcome to:

* Submit suggestions and bug-reports at: https://bitbucket.org/Grantlab/bio3d/issues
* Send a pull request on: https://bitbucket.org/Grantlab/bio3d/pull-requests
* Compose a friendly e-mail to: bjgrant@ucsd.edu
","['xinqyao', 'larssk', 'bioboot', 'julienide', 'jariwalask', 'Hongyang449', 'exeResearch', 'ajkal', 'emilioxavier']",1,0.61,0,,,,,,4,,,,
214350708,MDEwOlJlcG9zaXRvcnkyMTQzNTA3MDg=,CSE221_project,guptarohit994/CSE221_project,0,guptarohit994,https://github.com/guptarohit994/CSE221_project,FA19 CSE 221 Operating Systems UCSD Course Project,0,2019-10-11 05:28:33+00:00,2023-12-12 09:19:48+00:00,2019-12-22 06:46:15+00:00,,3091,5,5,C,1,1,1,1,0,0,2,0,0,0,cc0-1.0,1,0,0,public,2,0,5,master,1,,,"['guptarohit994', 'gigaflw', 'Kien085']",1,0.71,0,,,,,,2,,,,
217582902,MDEwOlJlcG9zaXRvcnkyMTc1ODI5MDI=,Coursera-Algorithm-Toolbox,hanihashemi/Coursera-Algorithm-Toolbox,0,hanihashemi,https://github.com/hanihashemi/Coursera-Algorithm-Toolbox,Algorithmic Toolbox by University of California San Diego & National Research University Higher School of Economics,0,2019-10-25 17:24:53+00:00,2019-10-25 17:24:57+00:00,2019-10-25 17:24:54+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Coursera-Algorithm-Toolbox
Algorithmic Toolbox by University of California San Diego &amp; National Research University Higher School of Economics
",['hanihashemi'],1,0.76,0,,,,,,0,,,,
784439855,R_kgDOLsGaLw,UC-San-Diego-Applied-Mathematics,hayashady/UC-San-Diego-Applied-Mathematics,0,hayashady,https://github.com/hayashady/UC-San-Diego-Applied-Mathematics,,0,2024-04-09 21:22:56+00:00,2024-04-09 21:22:56+00:00,2024-04-09 21:22:56+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,[],1,0.74,0,,,,,,1,,,,
678292251,R_kgDOKG3rGw,MMSR,HoldenHu/MMSR,0,HoldenHu,https://github.com/HoldenHu/MMSR,,0,2023-08-14 08:02:14+00:00,2025-02-24 10:00:32+00:00,2024-08-05 12:08:42+00:00,,13178,33,33,Jupyter Notebook,1,1,1,1,0,0,3,0,0,3,,1,0,0,public,3,3,33,main,1,,,"['HoldenHu', 'mirrorssssssss']",0,0.62,0,,,,,,2,,,,
210275486,MDEwOlJlcG9zaXRvcnkyMTAyNzU0ODY=,code,ianeisenman/code,0,ianeisenman,https://github.com/ianeisenman/code,"Ian Eisenman, UCSD",0,2019-09-23 05:58:09+00:00,2019-09-23 06:15:54+00:00,2019-09-23 06:15:52+00:00,,1,0,0,,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['ianeisenman'],0,0.67,0,,,,,,1,,,,
22523459,MDEwOlJlcG9zaXRvcnkyMjUyMzQ1OQ==,cy-rest-R,idekerlab/cy-rest-R,0,idekerlab,https://github.com/idekerlab/cy-rest-R,Example R script to use Cytoscape via RESTful API module.,0,2014-08-01 18:51:44+00:00,2024-09-19 12:43:37+00:00,2019-04-22 22:07:11+00:00,,4496,28,28,HTML,1,1,1,1,1,0,13,0,0,3,mit,1,0,0,public,13,3,28,develop,1,1,,"['keiono', 'thomaskelder']",1,0.79,0,,,,,,18,,,,
59869984,MDEwOlJlcG9zaXRvcnk1OTg2OTk4NA==,ndex-valet-electron,idekerlab/ndex-valet-electron,0,idekerlab,https://github.com/idekerlab/ndex-valet-electron,NDEx Valet Electron app,0,2016-05-28 00:26:16+00:00,2016-06-15 20:10:13+00:00,2016-08-24 01:37:14+00:00,,1848,1,1,JavaScript,1,1,1,1,0,0,2,0,0,1,mit,1,0,0,public,2,1,1,master,1,1,"# NDEx Valet Electron App

## Introduction
This is an experimental application to use [Electron](http://electron.atom.io/) as a new front-end for Cytoscape app.

**This Electron app is designed to work as a part of Cytoscape app,** and not a stand-alone application for browsing NDEx.

## Project Structure

### Files
- `package.json` - Points to the app's main file and lists its details and dependencies.
- `main.js` - Starts the app and creates a browser window to render HTML. This is the app's **main process**.
- `render.js` - JavaScript code for the page renderer.

## Run
You **cannot** test complete application only with this project, but you can test the some of the features, such as searching NDEx database.

```bash
npm install && npm start
```

## Build the Application


## License:
* Source Code: [MIT License](https://opensource.org/licenses/MIT)
* Documentation: [CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/)

----
The Cytoscape Consortium

&copy; 2016 Keiichiro Ono (University of California, San Diego)
","['keiono', 'jlord', 'kevinsawicki', 'tcyrus', 'zeke', 'izuzak', 'laiso', 'icoxfog417', 'fscherwi', 'bokuweb', 'zanesterling', 'louis993546', 'phanect', 'IonicaBizau', 'posva', 'clemens-tolboom', 'galeksandrp']",1,0.78,0,,,,,,4,,,,
49069885,MDEwOlJlcG9zaXRvcnk0OTA2OTg4NQ==,UCSDUnfoldingMaps,IlkyazA/UCSDUnfoldingMaps,0,IlkyazA,https://github.com/IlkyazA/UCSDUnfoldingMaps,,0,2016-01-05 14:10:47+00:00,2016-03-12 13:22:48+00:00,2016-03-17 11:38:25+00:00,,2,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['IlkyazA'],0,0.7,0,,,,,,0,,,UCSD-SASLab,
271539370,MDEwOlJlcG9zaXRvcnkyNzE1MzkzNzA=,spec2vec_gnps_data_analysis,iomega/spec2vec_gnps_data_analysis,0,iomega,https://github.com/iomega/spec2vec_gnps_data_analysis,Analysis and benchmarking of mass spectra similarity measures using gnps data set.,0,2020-06-11 12:22:33+00:00,2025-02-10 03:20:25+00:00,2021-08-13 08:47:06+00:00,,21769,24,24,Jupyter Notebook,1,1,1,1,0,0,11,0,0,2,apache-2.0,1,0,0,public,11,2,24,master,1,1,,['florian-huber'],0,0.62,0,,,,,,5,,,,
558680904,R_kgDOIUzLSA,Bootcamp-Project-1,IsaacAGonzalez/Bootcamp-Project-1,0,IsaacAGonzalez,https://github.com/IsaacAGonzalez/Bootcamp-Project-1,The first collaborative project for UCSD coding bootcamp,0,2022-10-28 03:44:03+00:00,2022-11-11 04:02:18+00:00,2022-11-15 02:23:31+00:00,,3981,0,0,HTML,1,1,1,1,1,0,2,0,0,0,mit,1,0,0,public,2,0,0,main,1,,"# So-Cal Brew Hopper

UCSD Full Stack Flex Bootcamp - Project 1

University of California San Diego Cohort 2022

## Project Description:

As a user, I want to search for breweries using names and locations to create a bucketlist with my desired destinations. I want my bucketlist attached to the same application with selected brewery names and be able to remove breweries from my list after my destination visit.  I want to see my saved bucketlist when I revisit the application at a later date.

We present, So-Cal Brew Hopper. brew Hopper is an interactive tool that allows our user to search for desired breweries in the San Diego area and turn their destination into a custom user bucket list at the top of the site using a toggle button. This will allow the user to actively track which breweries they have yet to visit, as well as remove them once their visit is completed. If the user is looking to stay in for the night, the app also provides a featured cocktail recipe.

Modal on load of page
![Screenshot of application](./assets/images/Screenshots/Modal.png)
Home Page
![Screenshot of application](./assets/images/Screenshots/Landing.png)
Search Results
![Screenshot of application](./assets/images/Screenshots/Table.png)
Bucketlist (Shopping Cart)
![Screenshot of application](./assets/images/Screenshots/Bucketlist.png)

## User Instruction:

This application is still in it's developmental phase and requires CORS access. Please be sure to visit [CORS Anywhere](https://cors-anywhere.herokuapp.com/corsdemo) to unlock temporary access before entering [So-Cal Brew Hopper](https://isaacagonzalez.github.io/Bootcamp-Project-1/).

## Project Requirements:

Using agile project management, we were instructed to create an application with the following requirements:

* Custom CSS style pages and Bootstrap

* Deployed to GitHub Pages

* Interactive and responds to user input

* Uses two server-side APIs

* Uses modals

* Uses local storage to save selected brewery

* Responsive

* Polished UI

* Clean repository with proper file structure, labels, comments, etc...

* Detailed README

## Tech/framework used:

HTML, CSS, [Canva](https://www.canva.com/), JavaScript, [JQuery](https://releases.jquery.com/jquery/), [Bootstrap](https://getbootstrap.com/), [Postman](https://www.postman.com/)

## APIs:

* [The Cocktail DB](https://www.thecocktaildb.com/) - An open, crowd-sourced database of drinks and cocktails.

* [Yelp Fusion](https://api.yelp.com/) - Delivers current local data using various restaurant attributes.

## Group 9 Team Members: 

* Isaac Gonzalez ([@IsaacAGonzalez](https://github.com/IsaacAGonzalez))

* Christen Lorber ([@cmarielorber](https://github.com/cmarielorber))

* Louis Yoon ([@louyoon89](https://github.com/louyoon89))

## Successes:

Worked as a communicative and supportive team to create a responsive application.
## Links:

[So-Cal Brew Hopper](https://isaacagonzalez.github.io/Bootcamp-Project-1/)

[So-Cal Brew Hopper Presentation](https://docs.google.com/presentation/d/1AG9MXBHcwNv7QvGwzCMGrs-qU3t_gmbevpuajOwpsOE/edit?usp=sharing)

","['cmarielorber', 'IsaacAGonzalez', 'louyoon89']",1,0.74,0,,,,,,1,,,,
185886876,MDEwOlJlcG9zaXRvcnkxODU4ODY4NzY=,DS-Project,j5jun/DS-Project,0,j5jun,https://github.com/j5jun/DS-Project,Repository for COGS 108: Data Science in Practice (@UC San Diego) Group Project,0,2019-05-09 23:45:04+00:00,2019-06-13 06:22:22+00:00,2019-06-13 06:22:21+00:00,,4191,0,0,Jupyter Notebook,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,0,master,1,,"### Project repository for Data Science in Practice @ UC San Diego
#### Course Description: COGS 108 (Spring, 2019) Taught by Professor Shannon Ellis. 

**Project Objective:** Determining the association between state crime rate and the majority party affiliation using data science techniques

**Relevant skills:** Python, Jupyter Notebook, Git, Python libraries (i.e. Pandas, Numpy, Matplotlib, Seaborn)
","['j5jun', 'sxl002', 'wsc012']",1,0.71,0,,,,,,0,,,,
444259077,R_kgDOGnrbBQ,JacobGlennAyers,JacobGlennAyers/JacobGlennAyers,0,JacobGlennAyers,https://github.com/JacobGlennAyers/JacobGlennAyers,Github Profile Readme,0,2022-01-04 02:19:04+00:00,2025-01-19 10:09:46+00:00,2025-01-19 10:09:44+00:00,,5,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"Education - 

Associate's Degree of Science from Santa Barbara City College (2019)

Bachelor's Degree from UC San Diego in Electrical Engineering with an emphasis in Machine Learning and Digital Signal Processing (2022)

Master's Degree from UC San Diego in Machine Learning and Data Science from the Electrical and Computer Engineering Department (2024)

Ph.D in the D-ITET Department of ETH Zurich at the Institute of Neuroinformatics (exp. 2028)

Languages - 

Python, C, C++, Java, Matlab, BASH

Work Experience - 

I lead a research team for [Engineers for Exploration](http://e4e.ucsd.edu/) on the [Automated Acoustic Species Identification](https://www.youtube.com/watch?v=QnObobMEaZE&t=32s&ab_channel=UCSanDiegoEngineersforExploration) project.

Autonomous Systems Intern at Nokia Bell Labs
",['JacobGlennAyers'],1,0.64,0,,,,,,1,,,,
413230158,R_kgDOGKFkTg,Object-Oriented-Java-Programming,JayM6669/Object-Oriented-Java-Programming,0,JayM6669,https://github.com/JayM6669/Object-Oriented-Java-Programming,"Object Oriented Java Programming: Data Structures and Beyond by the University of California, San Diego",0,2021-10-04 00:28:55+00:00,2021-10-04 00:28:57+00:00,2021-10-04 00:35:11+00:00,,29174,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Object Oriented Java Programming: Data Structures and Beyond by the University of California, San Diego, offered at Coursera.

This is the first course in a five course specialization.

I am taking this course to learn Java coming from a background of mainly C++ and Python.

The course utilizes the UnfoldingMaps and Processing libraries to build an interactive map applet.

The project taught how to implement an interactive map with the UnfoldingMaps library using the processing library. The map shows cities, earthquakes (both land and ocean quakes) and airports using data
from a websites or CSV files with such information.

The following features have been added by me:
* Markers show additional information on mouseover (e.g. population of a city or magnitude of an earthquake)
* Clicks on cities hide all other cities and earthquakes that did not affect this city.
* Clicks on earthquakes will hide all other earthquakes and all cities were not affected by this earthquake. If an ocean quake was clicked, it will additionally draw lines to affected cites.
* In both above cases, airports will be hidden.
* Clicks on airports hide all other markers except for airports that are directly connected to this airport via flight routes. The flight route data may be incomplete.
* All markers can be revealed again by clicking onto a free space.

Notes:
* A threat circle of an earthquake was calculated using an approximate formula.
* The incompleteness of flight data can be solved by using more flight data. This programming assignment mainly aimed on the technical aspect of implementation rather than completeness of data.
",[],1,0.67,0,,,,,,0,,,,
120688465,MDEwOlJlcG9zaXRvcnkxMjA2ODg0NjU=,ixdMobileWebApp,jcrich1469/ixdMobileWebApp,0,jcrich1469,https://github.com/jcrich1469/ixdMobileWebApp,For UCSD ixd assignments,0,2018-02-08 00:13:35+00:00,2018-02-09 07:22:30+00:00,2018-02-24 16:56:05+00:00,,11416,0,0,HTML,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,,,['jcrich1469'],1,0.73,0,,,,,,1,,,,
96783478,MDEwOlJlcG9zaXRvcnk5Njc4MzQ3OA==,UCSanDiegoX-DSE200x-Python-for-Data-Science,jjw244/UCSanDiegoX-DSE200x-Python-for-Data-Science,0,jjw244,https://github.com/jjw244/UCSanDiegoX-DSE200x-Python-for-Data-Science,UCSandDiego Micro Masters Program,0,2017-07-10 13:55:31+00:00,2025-03-05 19:37:23+00:00,2017-12-15 17:55:00+00:00,,19638,34,34,Jupyter Notebook,1,1,1,1,0,0,43,0,0,0,,1,0,0,public,43,0,34,master,1,,"# Python for Data Science!

This 10-week self-paced course is part of the Data Science MicroMasters program and will introduce you to a collection of powerful, open-source, tools needed to analyze data and to conduct data science. Specifically, youâ€™ll learn how to use:
- python
- jupyter notebooks
- pandas
- numpy
- matplotlib
- git
- scikit-learn
- nltk
- And many other tools

You will learn these tools all within the context of solving compelling data science problems.

After completing this course, youâ€™ll be able to find answers within large datasets by using python tools to import data, explore it, analyze it, learn from it, visualize it, and ultimately generate easily sharable reports. You'll also be introduced to Machine Learning techniques and Natural Language Processing tools to expand your data analysis abilities (e.g., being able to analyze twitter data for user sentiments).

By learning these skills, youâ€™ll also become a member of a world-wide community which seeks to build data science tools, explore public datasets, and discuss evidence-based findings. Last but not least, this course will provide you with the foundation you need to succeed in later courses in the Data Science MicroMasters program.

## Your Instructors

_Ilkay Altintas_ is the chief data science officer at the San Diego Supercomputer Center (SDSC), UC San Diego, where she is also the founder and director for the Workflows for Data Science Center of Excellence. She received her Ph.D. degree from the University of Amsterdam in the Netherlands with an emphasis on provenance of workflow-driven collaborative science and she is currently an assistant research scientist at UCSD.

_Leo Porter_ is an Assistant Teaching Professor at the Department of Computer Science and Engineering at the University of California, San Diego. He received his Ph.D. in Computer Science, specifically computer architecture, from UC San Diego in 2011.

## Earning a Certificate
Verification - Becoming a verified learner allows you access to additional videos, exercise notebooks, and the instructional team to make your experience feel more like it would if you took the course in person at UC San Diego. In addition, earning a verified certificate puts you on the path to a Data Science MicroMasters and possible course credit (see details in the course). Lastly, we know from the data on online courses that registered learners complete courses at a much higher rate than those who do not. As such, we strongly encourage you to register for a verified certificate!

## Getting Help
To get help with the course, please click the Discussion tab and post a question. To get help with a technical problem, check the [edX Help Center>](https://support.edx.org/hc/en-us), the [edX Learner's Guide](http://edx.readthedocs.io/projects/edx-guide-for-students/en/latest/), or contact the edX general support team by clicking on the ""Support"" tab on the left-hand side of the screen. New to EdX? Please spend as little as 10 minutes to make your learning more successful by enrolling in the [EdX DemoX course](https://www.edx.org/course/demox-edx-demox-1-0).

##Honor Code
By enrolling in an edX course, I agree that I will: Complete all tests and assignments on my own, unless collaboration on an assignment is explicitly permitted. Maintain only one user account and not let anyone else use my username and/or password. Not engage in any activity that would dishonestly improve my results, or improve or hurt the results of others. Not post answers to problems that are being used to assess student performance.

## Get Started!
To get started, click on the â€œCourseâ€ tab at the top of the page!
",['jjw244'],1,0.77,0,,,,,,0,,,,
381492170,MDEwOlJlcG9zaXRvcnkzODE0OTIxNzA=,joelfishbein,joelfishbein/joelfishbein,0,joelfishbein,https://github.com/joelfishbein/joelfishbein,Config files for my GitHub profile.,0,2021-06-29 20:44:06+00:00,2023-11-01 22:28:16+00:00,2023-11-01 22:32:31+00:00,https://github.com/joelfishbein,6,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['joelfishbein'],1,0.76,0,,,,,,1,,,,
16415101,MDEwOlJlcG9zaXRvcnkxNjQxNTEwMQ==,BXA,JohannesBuchner/BXA,0,JohannesBuchner,https://github.com/JohannesBuchner/BXA,Bayesian X-ray analysis (nested sampling for Xspec and Sherpa),0,2014-01-31 17:32:17+00:00,2025-01-07 15:22:46+00:00,2024-11-13 09:35:51+00:00,https://johannesbuchner.github.io/BXA/,83916,59,59,Python,1,1,1,1,1,0,20,0,0,10,gpl-3.0,1,0,0,public,20,10,59,master,1,,,"['JohannesBuchner', 'amasini', 'brefsdal', 'ferrigno', 'lewtonstein', 'ruizca']",0,0.65,0,,,,,,6,,,mlpc-ucsd,
672671540,R_kgDOKBgnNA,TTSM_Workshop_Symbolic_Music_Generation,Jovie-Liu/TTSM_Workshop_Symbolic_Music_Generation,0,Jovie-Liu,https://github.com/Jovie-Liu/TTSM_Workshop_Symbolic_Music_Generation,Course Materials for TTSM Workshop I: Symbolic Music Data Processing and Generation,0,2023-07-30 21:39:38+00:00,2024-10-16 09:40:26+00:00,2024-08-04 19:44:28+00:00,https://ttsm.link/more2023,5845,2,2,Jupyter Notebook,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,2,main,1,,,['Jovie-Liu'],1,0.65,0,,,,,,1,,,,
66747488,MDEwOlJlcG9zaXRvcnk2Njc0NzQ4OA==,UCSDUnfoldingMaps,jrottersman/UCSDUnfoldingMaps,0,jrottersman,https://github.com/jrottersman/UCSDUnfoldingMaps,,0,2016-08-28 03:29:25+00:00,2016-08-28 03:30:20+00:00,2016-08-28 03:30:16+00:00,,11689,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,['jrottersman'],1,0.75,0,,,,,,1,,,,
127539986,MDEwOlJlcG9zaXRvcnkxMjc1Mzk5ODY=,UCSD,jwarlop/UCSD,0,jwarlop,https://github.com/jwarlop/UCSD,,0,2018-03-31 14:36:40+00:00,2018-06-18 17:51:17+00:00,2018-06-18 17:51:16+00:00,,63250,1,1,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,,['jwarlop'],1,0.74,0,,,,,,2,,,,
116420582,MDEwOlJlcG9zaXRvcnkxMTY0MjA1ODI=,UCSDUnfoldingMaps,kartik-chandna/UCSDUnfoldingMaps,0,kartik-chandna,https://github.com/kartik-chandna/UCSDUnfoldingMaps,Earthquake visualization using Unfolding map library,0,2018-01-05 19:42:14+00:00,2022-04-17 20:39:38+00:00,2018-01-05 20:14:23+00:00,,3098,3,3,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,3,master,1,,,['kartik-chandna'],1,0.68,0,,,,,,0,,,,
905117111,R_kgDONfL9tw,KTPortfolio.github.io,kat1001/KTPortfolio.github.io,0,kat1001,https://github.com/kat1001/KTPortfolio.github.io,,0,2024-12-18 07:40:17+00:00,2024-12-18 08:33:56+00:00,2024-12-18 08:33:53+00:00,,25,0,0,,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# KTPortfolio.github.io

### Education
UC San Diego
- BS
- MAS


### Work Experience


### Research/Projects


### Creative 
",['kat1001'],1,0.79,0,,,,,,1,,,,
195496791,MDEwOlJlcG9zaXRvcnkxOTU0OTY3OTE=,UCSDx-ALGS201x,KennethSee/UCSDx-ALGS201x,0,KennethSee,https://github.com/KennethSee/UCSDx-ALGS201x,My solutions to University of California San Diego's Data Structure Fundamentals' programming assignments,0,2019-07-06 04:20:25+00:00,2023-02-20 07:26:28+00:00,2019-07-31 04:36:43+00:00,,103,2,2,Python,1,1,1,1,0,0,5,0,0,0,,1,0,0,public,5,0,2,master,1,,"# UCSDx - ALGS201x
My solutions to University of California San Diego's Data Structure Fundamentals' programming assignments

## Programming Assignments

### 1. [Check brackets in code](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/check_brackets.py)

#### Problem Introduction
In this problem you will implement a feature for a text editor to find errors in the usage of brackets in the code.

#### Problem Description
**Task.** Your friend is making a text editor for programmers. He is currently working on a feature that will find errors in the usage of different types of brackets. Code can contain any brackets from the set []{}(), where the opening brackets are [,{, and ( and the closing brackets corresponding to them are ],}, and ).
For convenience, the text editor should not only inform the user that there is an error in the usage of brackets, but also point to the exact place in the code with the problematic bracket. First priority is to find the first unmatched closing bracket which either doesnâ€™t have an opening bracket before it, like ] in ](), or closes the wrong opening bracket, like } in ()[}. If there are no such mistakes, then it should find the first unmatched opening bracket without the corresponding closing bracket after it, like ( in {}([]. If there are no mistakes, text editor should inform the user that the usage of brackets is correct.

Apart from the brackets, code can contain big and small latin letters, digits and punctuation marks. More formally, all brackets in the code should be divided into pairs of matching brackets, such that in each pair the opening bracket goes before the closing bracket, and for any two pairs of brackets either one of them is nested inside another one as in (foo[bar]) or they are separate as in f(a,b)-g[c]. The bracket [ corresponds to the bracket ], { corresponds to }, and ( corresponds to ).

**Input Format.** Input contains one string ð‘† which consists of big and small latin letters, digits, punctuation marks and brackets from the set []{}(). Constraints. The length of ð‘† is at least 1 and at most 105.

**Output Format.** If the code in ð‘† uses brackets correctly, output â€œSuccess"" (without the quotes). Otherwise, output the 1-based index of the first unmatched closing bracket, and if there are no unmatched closing brackets, output the 1-based index of the first unmatched opening bracket.

**Memory Limit.** 512MB

### 2. [Compute tree height](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/tree_height.py)

#### Problem Introduction
Trees are used to manipulate hierarchical data such as hierarchy of categories of a retailer or the directory structure on your computer. They are also used in data analysis and machine learning both for hierarchical clustering and building complex predictive models, including some of the best-performing in practice algorithms like Gradient Boosting over Decision Trees and Random Forests. In the later modules of this course, we will introduce balanced binary search trees (BST) â€” a special kind of trees that allows to very efficiently store, manipulate and retrieve data. Balanced BSTs are thus used in databases for efficient storage and actually in virtually any non-trivial programs, typically via built-in data structures of the programming language at hand.

In this problem, your goal is to get used to trees. You will need to read a description of a tree from the input, implement the tree data structure, store the tree and compute its height.

#### Problem Description
**Task.** You are given a description of a rooted tree. Your task is to compute and output its height. Recall that the height of a (rooted) tree is the maximum depth of a node, or the maximum distance from a leaf to the root. You are given an arbitrary tree, not necessarily a binary tree.

**Input Format.** The first line contains the number of nodes ð‘›. The second line contains ð‘› integer numbers from âˆ’1 to ð‘› âˆ’ 1 â€” parents of nodes. If the ð‘–-th one of them (0 â‰¤ ð‘– â‰¤ ð‘› âˆ’ 1) is âˆ’1, node ð‘– is the root, otherwise itâ€™s 0-based index of the parent of ð‘–-th node. It is guaranteed that there is exactly one root. It is guaranteed that the input represents a tree. Constraints. 1 â‰¤ ð‘› â‰¤ 105.

**Output Format.** Output the height of the tree.

**Memory Limit.** 512MB

### 3. [Convert array into heap](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/build_heap.py)

#### Problem Introduction
In this problem you will convert an array of integers into a heap. This is the crucial step of the sorting algorithm called HeapSort. It has guaranteed worst-case running time of ð‘‚(ð‘› log ð‘›) as opposed to QuickSortâ€™s average running time of ð‘‚(ð‘› log ð‘›). QuickSort is usually used in practice, because typically it is faster, but HeapSort is used for external sort when you need to sort huge files that donâ€™t fit into memory of your computer.

#### Problem Description
**Task.** The first step of the HeapSort algorithm is to create a heap from the array you want to sort. By the way, did you know that algorithms based on Heaps are widely used for external sort, when you need to sort huge files that donâ€™t fit into memory of a computer?
Your task is to implement this first step and convert a given array of integers into a heap. You will do that by applying a certain number of swaps to the array. Swap is an operation which exchanges elements ð‘Žð‘– and ð‘Žð‘— of the array ð‘Ž for some ð‘– and ð‘—. You will need to convert the array into a heap using only ð‘‚(ð‘›) swaps, as was described in the lectures. Note that you will need to use a min-heap instead of a max-heap in this problem.

**Input Format.** The first line of the input contains single integer ð‘›. The next line contains ð‘› space-separated integers ð‘Žð‘–.

**Constraints.** 1 â‰¤ ð‘› â‰¤ 100 000; 0 â‰¤ ð‘–, ð‘— â‰¤ ð‘› âˆ’ 1; 0 â‰¤ ð‘Ž0, ð‘Ž1, . . . , ð‘Žð‘›âˆ’1 â‰¤ 109. All ð‘Žð‘– are distinct.

**Output Format.** The first line of the output should contain single integer ð‘š â€” the total number of swaps. ð‘š must satisfy conditions 0 â‰¤ ð‘š â‰¤ 4ð‘›. The next ð‘š lines should contain the swap operations used to convert the array ð‘Ž into a heap. Each swap is described by a pair of integers ð‘–, ð‘— â€” the 0-based indices of the elements to be swapped. After applying all the swaps in the specified order the array must become a heap, that is, for each ð‘– where 0 â‰¤ ð‘– â‰¤ ð‘› âˆ’ 1 the following conditions must be true:

1. If 2ð‘– + 1 â‰¤ ð‘› âˆ’ 1, then ð‘Žð‘– < ð‘Ž2ð‘–+1.
2. If 2ð‘– + 2 â‰¤ ð‘› âˆ’ 1, then ð‘Žð‘– < ð‘Ž2ð‘–+2.

Note that all the elements of the input array are distinct. Note that any sequence of swaps that has length at most 4ð‘› and after which your initial array becomes a correct heap will be graded as correct.

**Memory Limit.** 512MB.

### 4. [Parallel processing](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/job_queue.py)

#### Problem Introduction
In this problem you will simulate a program that processes a list of jobs in parallel. Operating systems such as Linux, MacOS or Windows all have special programs in them called schedulers which do exactly this with the programs on your computer.

#### Problem Description
**Task.** You have a program which is parallelized and uses ð‘› independent threads to process the given list of ð‘š jobs. Threads take jobs in the order they are given in the input. If there is a free thread, it immediately takes the next job from the list. If a thread has started processing a job, it doesnâ€™t interrupt or stop until it finishes processing the job. If several threads try to take jobs from the list simultaneously, the thread with smaller index takes the job. For each job you know exactly how long will it take any thread to process this job, and this time is the same for all the threads. You need to determine for each job which thread will process it and when will it start processing.

**Input Format.** The first line of the input contains integers ð‘› and ð‘š. The second line contains ð‘š integers ð‘¡ð‘– â€” the times in seconds it takes any thread to process ð‘–-th job. The times are given in the same order as they are in the list from which threads take jobs. Threads are indexed starting from 0.

**Constraints.** 1 â‰¤ ð‘› â‰¤ 105; 1 â‰¤ ð‘š â‰¤ 105; 0 â‰¤ ð‘¡ð‘– â‰¤ 109.

**Output Format.** Output exactly ð‘š lines. ð‘–-th line (0-based index is used) should contain two spaceseparated integers â€” the 0-based index of the thread which will process the ð‘–-th job and the time in seconds when it will start processing that job.

**Memory Limit.** 512MB.

### 5. [Phone Book](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/phone_book.py)

#### Problem Introduction
In this problem you will implement a simple phone book manager.

#### Problem Description
**Task.** In this task your goal is to implement a simple phone book manager. It should be able to process the following types of userâ€™s queries:
<p>âˆ™ <i>add number name</i>. It means that the user adds a person with name name and phone number number to the phone book. If there exists a user with such number already, then your manager has to overwrite the corresponding name.</p>
<p>âˆ™ <i>del number</i>. It means that the manager should erase a person with number number from the phone book. If there is no such person, then it should just ignore the query.</p>
<p>âˆ™ <i>find number</i>. It means that the user looks for a person with phone number number. The manager should reply with the appropriate name, or with string â€œnot found"" (without quotes) if there is no such person in the book.</p>

**Input Format.** There is a single integer ð‘ in the first line â€” the number of queries. Itâ€™s followed by ð‘ lines, each of them contains one query in the format described above.

**Constraints.** 1 â‰¤ ð‘ â‰¤ 10<sup>5</sup>. All phone numbers consist of decimal digits, they donâ€™t have leading zeros, and each of them has no more than 7 digits. All names are non-empty strings of latin letters, and each of them has length at most 15. Itâ€™s guaranteed that there is no person with name â€œnot found"".

**Output Format.** Print the result of each find query â€” the name corresponding to the phone number or â€œnot found"" (without quotes) if there is no person in the phone book with such phone number. Output one result per line in the same order as the find queries are given in the input.

**Memory Limit.** 512MB.

### 6. [Hashing with chains](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/hash_chains.py)

#### Problem Introduction
In this problem you will implement a hash table using the chaining scheme. Chaining is one of the most popular ways of implementing hash tables in practice. The hash table you will implement can be used to implement a phone book on your phone or to store the password table of your computer or web service (but donâ€™t forget to store hashes of passwords instead of the passwords themselves, or you will get hacked!).

#### Problem Description
**Task.** In this task your goal is to implement a hash table with lists chaining. You are already given the number of buckets ð‘š and the hash function. It is a polynomial hash function
<p><blockquote class=""imgur-embed-pub"" lang=""en"" data-id=""3QPBxvj""><a href=""https://imgur.com/3QPBxvj"">Polynomial hash function</a></blockquote></p>
where ð‘†[ð‘–] is the ASCII code of the ð‘–-th symbol of ð‘†, ð‘ = 1 000 000 007 and ð‘¥ = 263. Your program should support the following kinds of queries:
<p>âˆ™ <i>add string</i> â€” insert string into the table. If there is already such string in the hash table, then just ignore the query.</p>
<p>âˆ™ <i>del string</i> â€” remove string from the table. If there is no such string in the hash table, then just ignore the query.</p>
<p>âˆ™ <i>find string</i> â€” output â€œyes"" or â€œno"" (without quotes) depending on whether the table contains string or not.</p>
<p>âˆ™ <i>check ð‘–</i> â€” output the content of the ð‘–<sup>th</sup> list in the table. Use spaces to separate the elements of the list. If ð‘–<sup>th</sup> list is empty, output a blank line.</p>

When inserting a new string into a hash chain, you must insert it in the beginning of the chain. Input Format. There is a single integer ð‘š in the first line â€” the number of buckets you should have. The next line contains the number of queries ð‘. Itâ€™s followed by ð‘ lines, each of them contains one query in the format described above.

**Constraints.** 1 â‰¤ ð‘ â‰¤ 10<sub>5</sub>; ð‘/5 â‰¤ ð‘š â‰¤ ð‘. All the strings consist of latin letters. Each of them is non-empty and has length at most 15.

**Output Format.** Print the result of each of the find and check queries, one result per line, in the same order as these queries are given in the input.

**Memory Limit.** 512MB.

### 7. [Binary tree traversals](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/tree_orders.py)

#### Problem Introduction
In this problem you will implement in-order, pre-order and post-order traversals of a binary tree. These traversals were defined in the week 1 lecture on tree traversals, but it is very useful to practice implementing them to understand binary search trees better.

#### Problem Description
**Task.** You are given a rooted binary tree. Build and output its in-order, pre-order and post-order traversals.

**Input Format.** The first line contains the number of vertices ð‘›. The vertices of the tree are numbered from 0 to ð‘› âˆ’ 1. Vertex 0 is the root. The next ð‘› lines contain information about vertices 0, 1, ..., ð‘›âˆ’1 in order. Each of these lines contains three integers ð‘˜ð‘’ð‘¦<sub>ð‘–</sub>, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â€” ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> is the key of the ð‘–<sup>th</sup> vertex, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> is the index of the left child of the ð‘–<sup>th</sup> vertex, and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> is the index of the right child of the ð‘–<sup>th</sup> vertex. If ð‘– doesnâ€™t have left or right child (or both), the corresponding ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> or ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> (or both) will be equal to âˆ’1.

**Constraints.** 1 â‰¤ ð‘› â‰¤ 105; 0 â‰¤ ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> â‰¤ 109; âˆ’1 â‰¤ ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub>, ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â‰¤ ð‘› âˆ’ 1. It is guaranteed that the input represents a valid binary tree. In particular, if ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> != âˆ’1 and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> != âˆ’1, then ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> != ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub>. Also, a vertex cannot be a child of two different vertices. Also, each vertex is a descendant of the root vertex.

**Output Format.** Print three lines. The first line should contain the keys of the vertices in the in-order traversal of the tree. The second line should contain the keys of the vertices in the pre-order traversal of the tree. The third line should contain the keys of the vertices in the post-order traversal of the tree.

**Memory Limit.** 512MB.

### 8. [Is it a binary search tree?](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/is_bst.py)

#### Problem Introduction
In this problem you are going to test whether a binary search tree data structure from some programming language library was implemented correctly. There is already a program that plays with this data structure by inserting, removing, searching integers in the data structure and outputs the state of the internal binary tree after each operation. Now you need to test whether the given binary tree is indeed a correct binary search tree. In other words, you want to ensure that you can search for integers in this binary tree using binary search through the tree, and you will always get correct result: if the integer is in the tree, you will find it, otherwise you will not.

#### Problem Description
**Task.** You are given a binary tree with integers as its keys. You need to test whether it is a correct binary search tree. The definition of the binary search tree is the following: for any node of the tree, if its key is ð‘¥, then for any node in its left subtree its key must be strictly less than ð‘¥, and for any node in its right subtree its key must be strictly greater than ð‘¥. In other words, smaller elements are to the left, and bigger elements are to the right. You need to check whether the given binary tree structure satisfies this condition. You are guaranteed that the input contains a valid binary tree. That is, it is a tree, and each node has at most two children.

**Input Format.** The first line contains the number of vertices ð‘›. The vertices of the tree are numbered from 0 to ð‘› âˆ’ 1. Vertex 0 is the root. The next ð‘› lines contain information about vertices 0, 1, ..., ð‘›âˆ’1 in order. Each of these lines contains three integers ð‘˜ð‘’ð‘¦<sub>ð‘–</sub>, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â€” ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> is the key of the ð‘–<sup>th</sup> vertex, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> is the index of the left child of the ð‘–<sup>th</sup> vertex, and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> is the index of the right child of the ð‘–<sup>th</sup> vertex. If ð‘– doesnâ€™t have left or right child (or both), the corresponding ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> or ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> (or both) will be equal to âˆ’1.

**Constraints.** 0 â‰¤ ð‘› â‰¤ 105; âˆ’2<sup>31</sup> < ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> < 2<sup>31</sup> âˆ’ 1; âˆ’1 â‰¤ ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub>, ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â‰¤ ð‘› âˆ’ 1. It is guaranteed that the input represents a valid binary tree. In particular, if ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> != âˆ’1 and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> != âˆ’1, then ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> != ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub>. Also, a vertex cannot be a child of two different vertices. Also, each vertex is a descendant of the root vertex. All keys in the input will be different.

**Output Format.** If the given binary tree is a correct binary search tree (see the definition in the problem description), output one word â€œCORRECTâ€ (without quotes). Otherwise, output one word â€œINCORRECTâ€ (without quotes).

**Memory Limit.** 512MB.

### 9. [Is it a binary search tree? Hard version.](https://github.com/KennethSee/UCSDx---ALGS201x/blob/master/is_bst_hard.py)

#### Problem Introduction
In this problem you are going to solve the same problem as the previous one, but for a more general case, when binary search tree may contain equal keys.

#### Problem Description
**Task.** You are given a binary tree with integers as its keys. You need to test whether it is a correct binary search tree. Note that there can be duplicate integers in the tree, and this is allowed. The definition of the binary search tree in such case is the following: for any node of the tree, if its key is ð‘¥, then for any node in its left subtree its key must be strictly less than ð‘¥, and for any node in its right subtree its key must be greater than or equal to ð‘¥. In other words, smaller elements are to the left, bigger elements are to the right, and duplicates are always to the right. You need to check whether the given binary tree structure satisfies this condition. You are guaranteed that the input contains a valid binary tree. That is, it is a tree, and each node has at most two children.

**Input Format.** The first line contains the number of vertices ð‘›. The vertices of the tree are numbered
from 0 to ð‘› âˆ’ 1. Vertex 0 is the root. The next ð‘› lines contain information about vertices 0, 1, ..., ð‘›âˆ’1 in order. Each of these lines contains three integers ð‘˜ð‘’ð‘¦<sub>ð‘–</sub>, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â€” ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> is the key of the ð‘–<sup>th</sup> vertex, ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> is the index of the left child of the ð‘–<sup>th</sup> vertex, and ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> is the index of the right child of the ð‘–<sup>th</sup> vertex. If ð‘– doesnâ€™t have left or right child (or both), the corresponding ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub> or ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> (or both) will be equal to âˆ’1.

**Constraints.** 0 â‰¤ ð‘› â‰¤ 105; âˆ’2<sup>31</sup> â‰¤ ð‘˜ð‘’ð‘¦<sub>ð‘–</sub> â‰¤ 2<sup>31</sup> âˆ’ 1; âˆ’1 â‰¤ ð‘™ð‘’ð‘“ð‘¡<sub>ð‘–</sub>, ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub> â‰¤ ð‘› âˆ’ 1. It is guaranteed that the input represents a valid binary tree. In particular, if ð‘™ð‘’ð‘“ ð‘¡ð‘– Ì¸= âˆ’1 and ð‘Ÿð‘–ð‘”â„Žð‘¡ð‘– Ì¸= âˆ’1, then ð‘™ð‘’ð‘“ ð‘¡ð‘– Ì¸= ð‘Ÿð‘–ð‘”â„Žð‘¡<sub>ð‘–</sub>. Also, a vertex cannot be a child of two different vertices. Also, each vertex is a descendant of the root vertex. Note that the minimum and the maximum possible values of the 32-bit integer type are allowed to be keys in the tree â€” beware of integer overflow!

**Output Format.** If the given binary tree is a correct binary search tree (see the definition in the problem description), output one word â€œCORRECTâ€ (without quotes). Otherwise, output one word â€œINCORRECTâ€ (without quotes).

**Memory Limit.** 512MB.
",['KennethSee'],1,0.69,0,,,,,,0,,,foundation-interface,UCSD-Historical-Enrollment-Data
710969128,R_kgDOKmCHKA,ucsd.edu-optimization,keran-w/ucsd.edu-optimization,0,keran-w,https://github.com/keran-w/ucsd.edu-optimization,,0,2023-10-27 21:05:02+00:00,2023-11-09 19:02:50+00:00,2023-10-30 20:25:43+00:00,,25245,0,0,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# UCSD-Site-Clone

Creating a static clone of UCSD website and optimizing for performance and accessibility

Original homepage: [https://ucsd.edu/](https://ucsd.edu/)

New homepage deployed on [netlify](https://phenomenal-sopapillas-1546c3.netlify.app/)

## Lighthouse Reports

[Original homepage Lighthouse Report](
https://googlechrome.github.io/lighthouse/viewer/?psiurl=https%3A%2F%2Fucsd.edu%2F&strategy=desktop&category=performance&category=accessibility&category=best-practices&category=seo&category=pwa&utm_source=lh-chrome-ext)

[New homepage Lighthouse Report](
https://googlechrome.github.io/lighthouse/viewer/?psiurl=https%3A%2F%2Fphenomenal-sopapillas-1546c3.netlify.app%2F&strategy=desktop&category=performance&category=accessibility&category=best-practices&category=seo&category=pwa&utm_source=lh-chrome-ext)

## Metrics

- Performance score: 39 -> 54
- First Contentful Paint: 3.3 s -> 2.0 s
- Largest Contentful Paint: 7.3 s -> 2.9 s
- Cumulative Layout Shift: 0.411 -> 0.41
- Speed Index: 3.3 s -> 2.0 s

## Fixes

- Compress all images with [tinypng](https://tinypng.com/)
- Remove document.write
- Remove some unused CSS files
- Update links to static resources if the file is available
- Compress large CSS files [cssminifier](https://www.toptal.com/developers/cssminifier)
",['keran-w'],1,0.83,0,,,,,,1,,,,
225257187,MDEwOlJlcG9zaXRvcnkyMjUyNTcxODc=,NBA_statistics_pred,keyitotallyojbk/NBA_statistics_pred,0,keyitotallyojbk,https://github.com/keyitotallyojbk/NBA_statistics_pred,This is the final project of ECE225 in UC San Diego,0,2019-12-02 01:11:32+00:00,2020-12-07 01:07:31+00:00,2020-12-07 01:07:28+00:00,,5437,1,1,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"# NBA_statistics_pred
This is the final project of ECE225 in UC San Diego
",['keyitotallyojbk'],1,0.75,0,,,,,,2,,,/mlpc-ucsd,ucsdlib
437287498,R_kgDOGhB6Sg,algorithmic-toolbox,kiro-boiko/algorithmic-toolbox,0,kiro-boiko,https://github.com/kiro-boiko/algorithmic-toolbox,Content notes and Java source code to the Algorithmic Toolbox course taught by University of California San Diego and HSE University.,0,2021-12-11 13:18:48+00:00,2021-12-30 12:23:21+00:00,2021-12-30 12:23:18+00:00,,13386,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Algorithmic Toolbox #


## What is it?

This repository is designed to aid those currently learning algorithms as well as to track
my own learning process.
Specifically, it is aimed at providing content notes and my solutions source code to the [Algorithmic Toolbox Course](https://www.udemy.com/course/java-the-complete-java-developer-course/) as part of the broaded [Data Structures and Algorithms Specialization](https://www.coursera.org/specializations/data-structures-algorithms) offered by University of California San Diego and
HSE University on Coursera.
The course main focus is on practicing algorithms implementations, standard and stress testing of programs, and performance comparison of fast and slow programs.


## What topics does it cover?
 - [x] Week 1: Introduction
    - Naive and Efficient Implementations
    - Simple Functional Testing
    - Stress Testing
    - Debugging
    - Algorithms covered:
      - _Sum of Two Digits_
      - _Maximum Pairwise Product_ 
 - [x] Week 2: Algorithmic Warm-Up
    - Computing Runtimes
    - Asymptotic Notations
    - Logarithms
    - Algorithms covered:
      - _Greatest Common Divisor_
      - _Least Common Multiple_
      - _Fibonacci Number_
      - _Last Digit of a Fibonacci Number_
      - _Fibonacci Number Modulo M_
      - _Last Digit of the Sum of Fibonacci Numbers_
      - _Last Digit of the Partial Sum of Fibonacci Numbers_
      - _Last Digit of the Sum of Squares of Fibonacci Numbers_  
 - [x] Week 3: Greedy Algorithms 
    - Generic Greedy Algorithm Strategy
    - Main Ingredients of Greedy Algorithms
    - Algorithms covered:
      - _Money Change_
      - _Maximum Value of the Loot / Fractional Knapsack_
      - _Car Fueling_
      - _Maximum Ad Revenue / Maximum Dot Product_
      - _Collecting Signatures / Covering Segments by Points_
      - _Maximum Number of Prizes / Different Summands_
      - _Maximum Salary / Largest Number_   
 - [ ] Week 4: Divide-and-Conquer Algorithms
 - [ ] Week 5: Dynamic Programming 1
 - [ ] Week 6: Dynamic Programming 2 
---
",['kiro-boiko'],1,0.65,0,,,,,,1,,,,
232172228,MDEwOlJlcG9zaXRvcnkyMzIxNzIyMjg=,ucsd,Klye-1002/ucsd,0,Klye-1002,https://github.com/Klye-1002/ucsd,,0,2020-01-06 19:41:28+00:00,2020-01-06 19:41:28+00:00,2020-01-06 19:41:29+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],-1,0.77,0,,,,,,1,,,ucsd-ccbb,UCSD-SUMS
125726629,MDEwOlJlcG9zaXRvcnkxMjU3MjY2Mjk=,ucsd,krishna23444/ucsd,0,krishna23444,https://github.com/krishna23444/ucsd,,0,2018-03-18 13:15:03+00:00,2018-03-19 16:36:53+00:00,2017-05-14 02:34:54+00:00,,41722,0,0,HTML,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['nitay'],-1,0.73,0,,,,,,0,,,,
25718667,MDEwOlJlcG9zaXRvcnkyNTcxODY2Nw==,Bioinformatics-Algorithms-part-I-,lanttern/Bioinformatics-Algorithms-part-I-,0,lanttern,https://github.com/lanttern/Bioinformatics-Algorithms-part-I-,"Projects from bioinformatics algorithms part I (Cousera, UCSD)",0,2014-10-25 03:28:33+00:00,2022-02-01 17:20:35+00:00,2014-10-25 03:34:55+00:00,,7220,6,6,Python,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,6,master,1,,,['lanttern'],1,0.64,0,,,,,,1,,,,
433911146,R_kgDOGdz1ag,Facial-Recognition-w-Names---LBPH,lcbueno/Facial-Recognition-w-Names---LBPH,0,lcbueno,https://github.com/lcbueno/Facial-Recognition-w-Names---LBPH,"Context This database of faces was downloaded from YALE University in the United States.  Content The Yale Face Database (size 6.4MB) contains 165 grayscale images in GIF format of 15 individuals. There are 11 images per subject, one per different facial expression or configuration: center-light, w/glasses, happy, left-light, w/no glasses, normal, right-light, sad, sleepy, surprised, and wink.  Acknowledgements http://vision.ucsd.edu/content/yale-face-database",0,2021-12-01 16:54:49+00:00,2021-12-01 17:02:48+00:00,2021-12-01 17:02:45+00:00,,28384,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['lcbueno'],0,0.64,0,,,,,,1,,,,
885050451,R_kgDONMDMUw,BlisLab-GEMM-Optimization,leowubj/BlisLab-GEMM-Optimization,0,leowubj,https://github.com/leowubj/BlisLab-GEMM-Optimization,,0,2024-11-07 21:34:38+00:00,2024-11-07 21:42:31+00:00,2024-11-07 21:42:27+00:00,,1333,0,0,C,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-24ddc0f5d75046c5622901739e7c5dd533143b0c8e959d652212380cedb1ea36.svg)](https://classroom.github.com/a/CfDgC9eg)
# pa1-starter<br />
pa1 assignment<br />
Starter Code for the Matrix Multiplication assignment<br />
Original code provided by Jim Demmel<br />
http://www.cs.berkeley.edu/~knight/cs267/hw1.html<br />
with some modifications by Scott B. Baden at UC San Diego<br />
with some modifications by Bryan Chin at UC San Diego<br />

## Usage

Build the executables
```bash
make
```
Generate test data and run the performance tests (You might need to modify the permission)
```bash
./genDATA.sh
```
Display the test results
```bash
cat data.txt
```
Remove all files generated from compilation
```bash
make clean
```",['leowubj'],1,0.74,0,,,,,,1,,,,
114667198,MDEwOlJlcG9zaXRvcnkxMTQ2NjcxOTg=,UCSD-Campus-Marketing,liebscher/UCSD-Campus-Marketing,0,liebscher,https://github.com/liebscher/UCSD-Campus-Marketing,Marketing on the UC San Diego Campus,0,2017-12-18 17:08:56+00:00,2017-12-23 01:02:48+00:00,2017-12-23 03:06:13+00:00,,23,0,0,JavaScript,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['liebscher'],1,0.78,0,,,,,,1,,,UCSD-PL,
456306928,R_kgDOGzKw8A,RegexPlus,limpa105/RegexPlus,0,limpa105,https://github.com/limpa105/RegexPlus,,0,2022-02-07 00:12:37+00:00,2024-01-13 11:56:40+00:00,2023-10-12 16:02:46+00:00,,22470,6,6,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,6,main,1,,"## Regex\+ 
### Regex\+ is a novel regular expression synthesizer that is able to synthesize regular expressions from just a few positive examples! 

## To use our tool:
1. run ` python synthesis.py`
2. provide a couple of examples conveying the regular expression you desire
<br> (For best results provide varied examples)


## To learn more about how our tool works:
Checkout our paper [Regex\+: Synthesizing Regular Expressions from Positive Examples](https://github.com/limpa105/RegexPlus/blob/main/Regex%2B:%20Synthesizing%20Regular%20Expressions%20from%20Positive%20Examples.pdf) that we had the amazing opportunity to present at [SYNT2022](https://www.cs.technion.ac.il/~shaull/SYNT2022/)


## Contributors 
This project was created by Elizaveta Pertseva, Mark Barbone, Joey Rudek and Nadia Polikarpova


#### For any questions please email epertsev@ucsd.edu
","['limpa105', 'mb64', 'jrdek']",1,0.6,0,,,,,,2,,,,
773768356,R_kgDOLh7EpA,pointrix,liuxinren456852/pointrix,0,liuxinren456852,https://github.com/liuxinren456852/pointrix,Pointrix: a differentiable point-based rendering libraries,0,2024-03-18 11:14:06+00:00,2024-08-16 09:30:37+00:00,2024-03-18 08:56:55+00:00,,4816,5,5,,0,1,1,0,0,0,9,0,0,0,apache-2.0,1,0,0,public,9,0,5,main,1,,"<div align=""center"">
  <p align=""center"">
      <picture>
      <img alt=""Pointrix"" src=""https://github.com/pointrix-project/pointrix/assets/32637882/e0bd7ce3-fbf3-40f3-889c-7c882f3eed20"" width=""80%"">
      </picture>
  </p>
  <p align=""center"">
    A differentiable point-based rendering library.
    <br />
    <a href=""https://pointrix-project.github.io/pointrix/"">
    <strong>DocumentðŸ  | </strong></a>
    <a href=""https://countermaker.github.io/pointrix.io/"">
    <strong>PaperðŸ“„ (Comming soon) | </strong></a>
    <a href=""https://github.com/pointrix-project/dptr"">
    <strong>DPRT BackendðŸŒ </strong></a>
    <br />
    <br />
    <!-- <a href=""https://github.com/othneildrew/Best-README-Template"">View Demo</a>
    Â·
    <a href=""https://github.com/othneildrew/Best-README-Template/issues"">Report Bug</a>
    Â·
    <a href=""https://github.com/othneildrew/Best-README-Template/issues"">Request Feature</a> -->
  </p>
</div>

[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fpointrix-project%2Fpointrix&count_bg=%2396114C&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=visitors&edge_flat=false)](https://hits.seeyoufarm.com)
![Hits](https://img.shields.io/github/stars/pointrix-project/pointrix)
![Static Badge](https://img.shields.io/badge/Pointrix_document-Pointrix_document?color=hsl&link=https%3A%2F%2Fpointrix-project.github.io%2Fpointrix)




Pointrix is a differentiable point-based rendering library which has following properties:
- **Powerful Backend**:
  - Support **""Render Anything""**(depth, normal, optical flow, anything you want)  and **""Backward Anything""** (Intrinsics & Extrinsics).
  - Modular design and easy to modify, support open-gl and opencv camera.
- **Rich Feature**:
  - Static Scene Reconstruction: 
    - **[Vanilla 3DGS](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_high.pdf) (2023 Siggraph Best Paper)**
  - Dynamic Scene Reconstruction: 
    - **[Deformable 3DGS](https://arxiv.org/abs/2309.13101) (2024 CVPR)**
    - **[Gaussian-Flow](https://arxiv.org/abs/2312.03431) (2024 CVPR)**
  - Text to 3D generation: 
    - [MVDream](https://arxiv.org/abs/2308.16512) (2023 Arxiv)
      
- **Highly Extensible and Designed for Research**:
  - Pointrix adopts a modular design, with clear structure and easy extensibility. 
  - Only few codes need to be modified if you want to add a new method. 


<div style=""display:flex;"">
  <img src=""https://github.com/pointrix-project/pointrix/assets/32637882/61795e5a-f91a-4a2a-b6ce-9a341a16145e"" width=""30%"" />
  <img src=""https://github.com/pointrix-project/pointrix/assets/32637882/616b7af8-3a8a-455a-ac1e-a62e9dc146d2"" width=""30%"" />
  <img src=""https://github.com/pointrix-project/pointrix/assets/32637882/928a142e-38cb-48e6-847b-1c6d4b95f7a3"" width=""30%"" />
</div>

## contributors
<a href=""https://github.com/pointrix-project/pointrix/graphs/contributors"">
  <img src=""https://contrib.rocks/image?repo=pointrix-project/pointrix"" />
</a>

Made with [contrib.rocks](https://contrib.rocks).

## Prerequisites

### Installations
1. Install the following package:

First,create a new conda environment and activate it:

```bash
conda create -n pointrix python=3.9
conda activate pointrix
```

Then, you need to install pytorch
```bash
conda install pytorch==2.1.1 torchvision==0.16.1 pytorch-cuda=12.1 -c pytorch -c nvidia
```
Other dependencies:

```
pip install -r requirements.txt
```

Finally, install our DPTR rendering kernel:

```bash
# Install official diff-gaussian-rasterization
# clone the code from github
git clone https://github.com/pointrix-project/dptr.git --recursive
cd dptr
# install dptr
pip install .
```
```bash
# Install simple knn
git clone https://gitlab.inria.fr/bkerbl/simple-knn.git
cd simple-knn
python setup.py install
pip install .
```

Note: we support both gaussian original kernel and DPTR kernel.

## Running our example
### 1. Lego
1. Download the lego data and put it in your folder:

```bash
wget http://cseweb.ucsd.edu/\~viscomp/projects/LF/papers/ECCV20/nerf/nerf_example_data.zip
```

2. Run the following command to train the model (...data path in the config file...):

```bash
cd Pointrix
pip install -e .
cd projects/gaussian_splatting
python launch.py --config ./configs/nerf_dptr.yaml

# you can also run this if you have installed gaussian original kernel
python launch.py --config ./configs/nerf.yaml
```

### 2. Mip-nerf 360 or other colmap dataset
1. Download the data and put it in your folder:

http://storage.googleapis.com/gresearch/refraw360/360_v2.zip

2. Run the following command to train the model (...data path in the config file...):

```bash
cd Pointrix
pip install -e .
cd projects/gaussian_splatting
python launch.py --config ./configs/colmap_dptr.yaml

# you can also run this if you have install gaussian original kernel
python launch.py --config ./configs/colmap.yaml
```

## Try other methods

### 1. Dynamic Gaussian
1. Download the iphone dataset and put it in your folder:
https://drive.google.com/drive/folders/1cBw3CUKu2sWQfc_1LbFZGbpdQyTFzDEX

2. Run the following command to train the model:

**you need to modify the data path in the config file to the path of the data you downloaded.**

```bash
cd Pointrix
pip install -e .
cd projects/deformable_gaussian
python launch.py --config deform.yaml
```

### 2. Generation (WIP)


# WIP
- [ ] Introduction video
- [ ] **Add GUI for visualization (this week).**
- [ ] **Implementataion of Gaussian-Flow (CVPR 2024) (this week).**
- [ ] Implementataion of MVDream (this week).
- [ ] Implementataion of Relightable Gaussian (arXiv 2023).
- [ ] **Support camera optimization  (this week).**

Welcome to join us or submit PR if you have any idea or methods.




","['LinZhuoChen', 'Linyou', 'briocheKJ', 'yGaoJiany']",0,0.76,0,,,,,,0,,,,
97325737,MDEwOlJlcG9zaXRvcnk5NzMyNTczNw==,UCSDUnfMaps,lowen-heart/UCSDUnfMaps,0,lowen-heart,https://github.com/lowen-heart/UCSDUnfMaps,,0,2017-07-15 15:46:42+00:00,2017-07-15 15:55:19+00:00,2017-07-15 15:55:17+00:00,,12430,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,[],1,0.74,0,,,,,,1,,,,
146698813,MDEwOlJlcG9zaXRvcnkxNDY2OTg4MTM=,algorithms_UCSD,maco668/algorithms_UCSD,0,maco668,https://github.com/maco668/algorithms_UCSD,,0,2018-08-30 05:14:10+00:00,2020-09-26 13:04:19+00:00,2018-09-02 16:28:12+00:00,,18090,1,1,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"# algorithms_UCSD

course1 (Java): â€œAlgorithmic Toolboxâ€ (by University of California, San Diego & National Research University Higher School of Economics on Coursera. Certificate earned at Monday, May 9, 2016 7:25 AM GMT)
Certificate: https://www.coursera.org/account/accomplishments/certificate/B74M62ZA86KR
Analysis of algorithm, big-O notation, greedy algorithms, recursion, divide-and-conquer, sorting algorithms. Passed coding assignments in Java: 1) Fractional knapsack, 2) changing money, 3) minimum dot product, 4) covering segments by points, 5) binary search, 6) majority element, 7) primitive calculator, 8) discrete knapsack without repetitions, 9) compute edit distance between two strings, 10) maximize value of an arithmetic expression.     

course2 (Java): â€œData Structuresâ€ (by University of California, San Diego & National Research University Higher School of Economics on Coursera. Certificate earned at Monday, June 27, 2016 1:24 AM GMT) 
Certificate: https://www.coursera.org/account/accomplishments/certificate/KJDSC9PGZ9AB
Stacks and queues, Linked lists, dynamic arrays, tree traversal methods, binary heap, priority queues, disjoint sets, hashing algorithms, binary search trees.      
Passed coding assignments in Java): 1) check brackets in code, 2) compute tree height, 3) convert array into heap, 4) job queueing of parallel processing, 5) phone book, 6) hashing with chains, 7) binary tree traversals, 8) set with range sums using splay tree. 

course3 (Java): â€œAlgorithms on Graphsâ€ (by University of California, San Diego & National Research University Higher School of Economics on Coursera. Certificate earned at Sunday, September 18, 2016 3:08 AM GMT) 
Certificate: https://www.coursera.org/account/accomplishments/certificate/5KVZALTJDMW5
Depth-first-search, direct acyclic graphs, topological sort, strongly connected components, breath-first-search, Dijkstraâ€™s algorithm for fastest route, Bellman-Ford algorithm for currency exchange, minimum spanning trees.
Passed coding assignments in Java: 1) finding an exit from a maze, 2) connected components, 3) checking consistency of CS curriculum, 4) determining an order of courses, 5) checking reachability of an intersection from any other, 6) computing the minimum number of flight segments, 7) checking whether a graph is bipartite, 8) computing the minimum cost of a flight, 9) detecting anomalies in currency exchange rates, 10) building roads to connect cities.

course4 (C++): â€œAlgorithms on Stringsâ€ (by University of California, San Diego & National Research University Higher School of Economics on Coursera. Certificate earned at Tuesday, August 15, 2017 12:01 PM GMT) 
Certificate: https://www.coursera.org/account/accomplishments/certificate/8LAAP5JU3YCE
Suffix trees, Burrows-Wheeler transform, suffix arrays, Knuth-Morris-Pratt algorithm for exact pattern matching, suffix array construction, constructing suffix tree from suffix array. 
Passed coding assignments in C++: 1) implementing trie matching, 2) extending trie matching, 3) construct suffix tree of a string, 4) construct Burrows-Wheeler transform of a string, 5) reconstruct a string from its Burrows-Wheeler transform, 5) finding all occurrences of a pattern in a string, 6) construct the suffix array of a long string.  

course5 (C++): â€œAdvanced Algorithms and Complexityâ€ (by University of California, San Diego & National Research University Higher School of Economics on Coursera. Certificate earned at Saturday, October 28, 2017 12:54 AM GMT)
Certificate: https://www.coursera.org/account/accomplishments/certificate/SJZU4CNM9MKE
Flows in networks, Edmonds-Karp algorithm, bipartite matching, linear programming, simplex method, NP-complete problems and reduction, NP-complete special cases, approximate, and exact algorithms.  
Passed coding assignments in C++): 1) evacuating people, 2) assigning airline crews to flights, 3) Gaussian elimination, 4) optimal diet problem, 5) assign frequencies to cells of a GSM network, 6) cleaning the apartment
(Hamiltonian path problem), 7) integrated circuit design (reduced to 2-satisfiability problem), 8) plan a fun party (maximum weighted independent set in trees).
",['maco668'],1,0.7,0,,,,,,0,,,,
494440103,R_kgDOHXiOpw,UCSD-course,Magos-Dominus/UCSD-course,0,Magos-Dominus,https://github.com/Magos-Dominus/UCSD-course,Course work from Coursera,0,2022-05-20 11:38:03+00:00,2022-05-20 11:41:36+00:00,2022-05-25 17:46:06+00:00,,11742,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,main,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

The solutions to the required coursework are located in the src folder and 
are further divided into folders for each module
",['Magos-Dominus'],1,0.72,0,,,,,,1,,,,
82821413,MDEwOlJlcG9zaXRvcnk4MjgyMTQxMw==,UCSDUnfoldingMaps,mahendrathapa/UCSDUnfoldingMaps,0,mahendrathapa,https://github.com/mahendrathapa/UCSDUnfoldingMaps,,0,2017-02-22 15:38:00+00:00,2017-02-22 15:38:48+00:00,2017-04-12 11:52:46+00:00,,16513,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['mahendrathapa'],1,0.7,0,,,,,,1,,,,
24459026,MDEwOlJlcG9zaXRvcnkyNDQ1OTAyNg==,struck,mani-monaj/struck,0,mani-monaj,https://github.com/mani-monaj/struck,"Enhancements to build system of ""Struck: Structured Output Tracking with Kernels v4.0"" (http://www.samhare.net/research/struck)",0,2014-09-25 13:27:14+00:00,2016-05-15 14:04:08+00:00,2014-09-25 14:34:25+00:00,,192,1,1,C++,1,1,1,1,0,0,4,0,0,0,gpl-3.0,1,0,0,public,4,0,1,master,1,,"Enhancements to build system of 
""Struck: Structured Output Tracking with Kernels v4.0"" 
(http://www.samhare.net/research/struck)

- CMake based build
- Standalone library (libstruck)

$ sudo apt-get install libopencv-dev libcv-dev libhighgui-dev libeigen2-dev cmake build-essential
$ mkdir build
$ cd build
$ cmake .. -DCMAKE_BUILD_TYPE=Release 
$ make
$ ./demo ../examples/config.txt

Original README:

Struck: Structured Output Tracking with Kernels

Code to accompany the paper:
  Struck: Structured Output Tracking with Kernels
  Sam Hare, Amir Saffari, Philip H. S. Torr
  International Conference on Computer Vision (ICCV), 2011

Copyright (C) 2011 Sam Hare, Oxford Brookes University, Oxford, UK

Contact: Sam Hare <sam.hare@brookes.ac.uk>

------------
Requirements
------------

OpenCV: http://opencv.willowgarage.com/
Eigen: http://eigen.tuxfamily.org/

This code has been developed and tested using 
OpenCV v2.1 and Eigen v2.0.15

-----
Usage
-----

> struck [config-file-path]

If no path is given the application will attempt to
use ./config.txt.

Please see config.txt for configuration options.

---------
Sequences
---------

Sequences are assumed to be of the format of those 
available from:

http://vision.ucsd.edu/~bbabenko/project_miltrack.shtml

----------------
Acknowledgements
----------------

This code uses the OpenCV graphing utilities provided
by Shervin Emami: http://www.shervinemami.co.cc/graphs.html
",['mani-monaj'],0,0.61,0,,,,,,1,,,gmtsar,
88223675,MDEwOlJlcG9zaXRvcnk4ODIyMzY3NQ==,COGS108_Repo,marissahing/COGS108_Repo,0,marissahing,https://github.com/marissahing/COGS108_Repo,For COGS 108 UCSD,0,2017-04-14 02:12:17+00:00,2017-04-14 02:12:17+00:00,2017-04-14 02:12:18+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],1,0.67,0,,,,,,0,,,,
471463622,R_kgDOHBn2xg,bioinformatics_course,Martinus1/bioinformatics_course,0,Martinus1,https://github.com/Martinus1/bioinformatics_course,UCSD Coursera Bioinformatics Course,0,2022-03-18 17:45:53+00:00,2022-03-18 17:50:53+00:00,2022-03-19 17:25:47+00:00,,2,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['Martinus1'],1,0.57,0,,,,,,1,,,,
104000091,MDEwOlJlcG9zaXRvcnkxMDQwMDAwOTE=,Flashcard-Generator,mattcarr09/Flashcard-Generator,0,mattcarr09,https://github.com/mattcarr09/Flashcard-Generator,"UC San Diego Coding BootCamp - Week 6, Homework 2",0,2017-09-18 22:54:56+00:00,2017-09-19 05:51:52+00:00,2017-09-19 05:51:49+00:00,,1512,0,0,JavaScript,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Flashcard-Generator
The backend for a basic flashcard application. The backend will essentially constitute an API that allows users to create two types of flashcards. 

1.) Basic flashcards, which have a front (""Who was the first president of the United States?""), and a back (""George Washington""). <br>
2.) Cloze-Deleted flashcards, which present partial text (""... was the first president of the United States.""), and the full text when the user requests it (""George Washington was the first president of the United States."")<br>


<strong>Cloze Deletions:</strong> A cloze deletion is simply a sentence that has had some of its text removed. For example, given the sentence: ""George Washington was the first president of the United States."" ...We can create a ""cloze deletion"" by removing the words ""George Washington"": ""... was the first president of the United States."" This is useful for building flash card applications that forces users to remember the important part of a sentence, and is a common device in educational applications. A flash card built this way has three parts: The full text. This is the entire sentence users need to remember: ""George Washington was the first president of the United States."" The cloze deletion. This is the text we've chosen to remove: ""George Washington"". The partial text. This is what we get if we remove the cloze deletion from the full text: ""... was the first president of the United States.
",['mattcarr09'],1,0.65,0,,,,,,0,,,nbcrrolls,
446251371,R_kgDOGplBaw,max-wild,max-wild/max-wild,0,max-wild,https://github.com/max-wild/max-wild,Config files for my GitHub profile.,0,2022-01-10 02:01:16+00:00,2022-01-10 02:02:28+00:00,2023-12-18 09:13:37+00:00,https://github.com/max-wild,33,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['max-wild'],1,0.79,0,,,,,,1,,,,
403754488,MDEwOlJlcG9zaXRvcnk0MDM3NTQ0ODg=,DeGroot_1974_consensus,MCHatcher/DeGroot_1974_consensus,0,MCHatcher,https://github.com/MCHatcher/DeGroot_1974_consensus,This repository provides a simple code for simulating the model of opinion dynamics in DeGroot (1974).,0,2021-09-06 20:46:17+00:00,2024-10-30 11:30:21+00:00,2021-09-07 06:58:53+00:00,,4,6,6,MATLAB,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,6,main,1,,"# DeGroot_1974_consensus
This repository provides a simple code that simulates the opinion dynamics model in DeGroot (1974, JASA), Reaching a Consensus. 
See:
- https://www.tandfonline.com/doi/abs/10.1080/01621459.1974.10480137
- https://pages.ucsd.edu/~aronatas/project/academic/degroot%20consensus.pdf
",['MCHatcher'],0,0.72,0,,,,,,1,,,,
758316354,R_kgDOLTL9Qg,mdang2077,mdang2077/mdang2077,0,mdang2077,https://github.com/mdang2077/mdang2077,Config files for my GitHub profile.,0,2024-02-16 03:44:32+00:00,2024-02-16 03:44:32+00:00,2024-02-16 03:46:27+00:00,https://github.com/mdang2077,1,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['mdang2077'],1,0.71,0,,,,,,1,,,,
251300919,MDEwOlJlcG9zaXRvcnkyNTEzMDA5MTk=,AlgorithmicToolbox,miaseoud/AlgorithmicToolbox,0,miaseoud,https://github.com/miaseoud/AlgorithmicToolbox,This repository contains my work from the Algorithmic Toolbox course which is part of the Data Structures and Algorithms Specialization that was created by UC San Diego and delivered through Coursera.,0,2020-03-30 12:41:51+00:00,2020-03-30 13:28:13+00:00,2020-03-30 13:28:11+00:00,https://www.coursera.org/learn/algorithmic-toolbox/,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,# AlgorithmicToolbox,['miaseoud'],1,0.68,0,,,,,,1,,,,
373159118,MDEwOlJlcG9zaXRvcnkzNzMxNTkxMTg=,uc-san-diego-data-structures-and-algorithms,MichaelHeinecke/uc-san-diego-data-structures-and-algorithms,0,MichaelHeinecke,https://github.com/MichaelHeinecke/uc-san-diego-data-structures-and-algorithms,Code for Data Structures and Algoritms course by UC San Diego,0,2021-06-02 12:25:50+00:00,2021-10-28 14:52:00+00:00,2023-04-04 12:13:38+00:00,,1968,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['MichaelHeinecke'],1,0.62,0,,,,,,1,,,,
67179420,MDEwOlJlcG9zaXRvcnk2NzE3OTQyMA==,UCSDGraphsCourse,michaeloverman/UCSDGraphsCourse,0,michaeloverman,https://github.com/michaeloverman/UCSDGraphsCourse,mapping application from UCSD on Coursera Advanced Algorithms Course,0,2016-09-02 01:29:01+00:00,2016-09-02 01:29:59+00:00,2016-09-02 01:34:25+00:00,,790,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,['michaeloverman'],1,0.72,0,,,,,,2,,,,
89988218,MDEwOlJlcG9zaXRvcnk4OTk4ODIxOA==,remylist,mightyminh/remylist,0,mightyminh,https://github.com/mightyminh/remylist,UC San Diego Project 2: Full-Stack application that allows users to share and borrow items for free.,0,2017-05-02 03:35:24+00:00,2020-08-12 19:44:19+00:00,2017-07-11 00:42:59+00:00,http://remyslist.herokuapp.com,13318,3,3,HTML,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,3,master,1,,"# Remy's List

This application allows users to lend and borrow items for free. Lenders upload items which borrowers can browse and request for a certain amount of time. Non-users can also browse items before deciding if they would like to join.


## Table of Contents

- [Website](#website)
- [Technologies used](#technologies-used)
- [Dependencies](#dependencies)
- [Developers](#developers)
- [To Install on local machine](#to-install-on-local-machine)
- [Screenshots](#screenshots)
- [Acknowledgements](#acknowledgements)

## Website
[http://remyslist.herokuapp.com/](http://remyslist.herokuapp.com/)


## Technologies used
* NodeJs
* CSS3
* Javascript
* jQuery
* Handlebars
* MySQL
* NPM packages

## Dependencies
NPM packages

1. `body-parser` (Node.js body parsing middleware)
1. `express` (Web framework)
1. `mysql` (A node.js driver for mysql)
1. `sequelize` (Multi dialect ORM for Node.JS)
1. `express-handlebars` (Handlebars view engine for Express)
1. `passport` (Authentication for Node.js.)
1. `passport-local` (Local username and password authentication strategy for Passport.)
1. `connect-flash` (Flash messages for Express)
1. `express-session` (Simple session middleware for Express)
1. `nodemailer` ( Sending e-mail from  Node.js app)


## Developers

### Front-end
[Minhtuyen Mai](https://github.com/mightyminh), 
[Yousra Elbana](https://github.com/Yousrat)

### Back-end
[Radhika Sivarajan](https://github.com/radhika-sivarajan), 
[Erin Glabe](https://github.com/eglabe)

## To Install on local machine

* Git Clone the repository to your local machine.
* Go to the config directory and change development environment properties.
* Navigate to the folder where the repository in Terminal.
* Run the command `npm install` to download the required dependencies.
* Then type `node server.js` in terminal inside the directory.
* Then run below address on browser.
	
	localhost:8080

## Screen recording

![Remy's List](/public/assets/img/RemysList.gif)

## Acknowledgements

We would like to thank our instructors: George and Brandon, for their guidance and knowledge. As well as our TAs: Felipe and Travis for their assistance.
","['radhika-sivarajan', 'mightyminh', 'eglabe', 'Yousrat']",1,0.72,0,,,,,,2,,,,
212385659,MDEwOlJlcG9zaXRvcnkyMTIzODU2NTk=,friendsfinder,mike-4040/friendsfinder,0,mike-4040,https://github.com/mike-4040/friendsfinder,UCSD Homework Project,0,2019-10-02 16:12:29+00:00,2020-06-05 16:10:43+00:00,2022-12-11 08:07:24+00:00,,36,0,0,HTML,1,1,1,1,0,0,0,0,0,2,,1,0,0,public,0,2,0,master,1,,,['mike-4040'],1,0.78,0,,,,,,1,,,,
704323196,R_kgDOKfsefA,MasQCLIP,mlpc-ucsd/MasQCLIP,0,mlpc-ucsd,https://github.com/mlpc-ucsd/MasQCLIP,(ICCV 2023) MasQCLIP for Open-Vocabulary Universal Image Segmentation,0,2023-10-13 02:43:53+00:00,2025-01-20 10:13:14+00:00,2023-10-18 20:19:05+00:00,,504,37,37,Python,1,1,1,0,0,0,2,0,0,4,other,1,0,0,public,2,4,37,main,1,1,,"['xuxalan', 'tyxiong23', 'zh-ding']",1,0.78,0,,,,,,1,,,,
351261695,MDEwOlJlcG9zaXRvcnkzNTEyNjE2OTU=,PRTR,mlpc-ucsd/PRTR,0,mlpc-ucsd,https://github.com/mlpc-ucsd/PRTR,(CVPR 2021) PRTR: Pose Recognition with Cascade Transformers,0,2021-03-25 00:26:46+00:00,2024-08-15 19:58:06+00:00,2021-06-21 04:23:02+00:00,,5806,141,141,Jupyter Notebook,1,1,1,1,0,0,29,0,0,4,apache-2.0,1,0,0,public,29,4,141,main,1,1,,"['zx1239856', 'yix081']",1,0.71,0,,,,,,11,,,,
726957287,R_kgDOK1R85w,TokenCompose,mlpc-ucsd/TokenCompose,0,mlpc-ucsd,https://github.com/mlpc-ucsd/TokenCompose,(CVPR 2024) ðŸ§© TokenCompose: Text-to-Image Diffusion with Token-level Supervision,0,2023-12-03 21:43:01+00:00,2025-02-17 02:24:30+00:00,2024-12-21 14:23:09+00:00,https://mlpc-ucsd.github.io/TokenCompose/,218835,120,120,Jupyter Notebook,1,1,1,0,1,1,4,0,0,0,apache-2.0,1,0,0,public,4,0,120,main,1,1,,"['JamesSand', 'zwcolin']",1,0.81,0,,,,,,3,,,,
164145198,MDEwOlJlcG9zaXRvcnkxNjQxNDUxOTg=,Big_Data,msmsk05/Big_Data,0,msmsk05,https://github.com/msmsk05/Big_Data,,0,2019-01-04 19:09:54+00:00,2021-03-10 10:50:25+00:00,2019-01-04 19:30:53+00:00,,472242,2,2,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,2,master,1,,"# coursera-Big-Data-specialization
Repo for coursera specialization Big Data by UC San Diego
","['MaxPoon', 'kunall17', 'msmsk05']",1,0.68,0,,,,,,0,,,,
172785299,MDEwOlJlcG9zaXRvcnkxNzI3ODUyOTk=,Bioinformatics-Specialisation-UC,mtleis/Bioinformatics-Specialisation-UC,0,mtleis,https://github.com/mtleis/Bioinformatics-Specialisation-UC,Code implemented while studying for the Bioinformatics Specialisation at Courseera:UC-San Diego,0,2019-02-26 20:28:24+00:00,2019-05-28 07:32:20+00:00,2019-05-28 07:32:17+00:00,,5201,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],1,0.62,0,,,,,,1,,,,
101533424,MDEwOlJlcG9zaXRvcnkxMDE1MzM0MjQ=,UCSDUnfoldingMapsWeek4,muhammad83/UCSDUnfoldingMapsWeek4,0,muhammad83,https://github.com/muhammad83/UCSDUnfoldingMapsWeek4,,0,2017-08-27 06:06:45+00:00,2017-08-27 06:07:09+00:00,2017-08-27 06:07:07+00:00,,11707,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)




",[],1,0.73,0,,,,,,1,,,,
48257104,MDEwOlJlcG9zaXRvcnk0ODI1NzEwNA==,MPC-Meshing_Point_Clouds,NadineAB/MPC-Meshing_Point_Clouds,0,NadineAB,https://github.com/NadineAB/MPC-Meshing_Point_Clouds,"3D scanners produce sets of 3D data points, sampled from the surface of a 3D object. These points are frequently unorganized, and to use them in 3D applications requires computing a polygon (usually triangular) mesh which best approximates the sampled surface. This means associating a connectivity structure with the point set  This project addresses the problem of meshing point clouds using spherical parameterization presented in Gotsman's paper here http://graphics.ucsd.edu/~matthias/Papers/MeshingUsingSphericalParameterization.pdf  library used in the porject:      Boost, Qt",0,2015-12-18 21:22:57+00:00,2023-12-19 14:28:40+00:00,2021-12-26 06:42:25+00:00,,312032,22,22,C++,1,1,1,1,0,0,7,0,0,0,,1,0,0,public,7,0,22,master,1,,"Meshing Point Clouds using spherical parameterization
=====================================================
3D scanners produce sets of 3D data points, sampled  from  the  surface  of  a  3D  object.  These  points are  frequently  unorganized,  and  to  use  them  in  3D  applications  requires  computing a polygon  (usually  triangular) mesh  which  best  approximates  the  sampled  surface.  This means associating a connectivity structure with the point set.

This project addresses the problem of meshing point clouds using spherical parameterization method presented in Gotsman's paper here http://www.cs.technion.ac.il/~gotsman/AmendedPubl/Matthias/meshing.pdf.

Our approach relies on the automatic finding of the correspondences between the landmarks on the input laser scan and a template face mesh. Once we find the set of correspondences, we define a morphing function and apply it to the template mesh. As a result, the template mesh is morphed and represents the same facial features captured from the laser scan. Our method is completely automatic and does not rely neither on:

1) any prior anatomical knowledge about the position of the landmarks
or on
2) the morphology of the input face.


Usage
=====
library used in the porject:
- Boost, Qt
- OpenMesh
- CGAL Lib
- Profiler 
- Qhull
- Eigen 3.0
- visual studio 

![Screenshot](https://github.com/NadineAB/MPC-Meshing_Point_Clouds/blob/master/Screen%20Shot%202018-08-07%20at%2000.22.54.png)
",['NadineAB'],0,0.69,0,,,,,,0,,,,
850149149,R_kgDOMqw_HQ,Experiences-of-Non-Native-English-Speakers-Learning-Computer-Science-in-a-US-University,NayeliGuzman/Experiences-of-Non-Native-English-Speakers-Learning-Computer-Science-in-a-US-University,0,NayeliGuzman,https://github.com/NayeliGuzman/Experiences-of-Non-Native-English-Speakers-Learning-Computer-Science-in-a-US-University,"Carmen Nayeli Guzman, Anne Xu, and Adalbert Gerald Soosai Raj. 2021. Experiences of Non-Native English Speakers Learning Computer Science in a US University. In Proceedings of the 52nd ACM Technical Symposium on Computer Science Education (SIGCSE '21). Association for Computing Machinery, New York, NY, USA, 633â€“639. https://doi.org/10.1145/3408877.",0,2024-08-31 01:57:28+00:00,2024-08-31 04:10:19+00:00,2024-08-31 04:02:17+00:00,,1022,0,0,Jupyter Notebook,1,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"This project was created through the Computing Education Research Lab at the University of California, San Diego. 
The Jupyter Notebook cleans and processes survey data obtained from undergraduate computer science 
courses at UCSD. 
",['NayeliGuzman'],1,0.74,0,,,,,,1,,,,
8447881,MDEwOlJlcG9zaXRvcnk4NDQ3ODgx,opaltoolkit,nbcrrolls/opaltoolkit,0,nbcrrolls,https://github.com/nbcrrolls/opaltoolkit,Wrapping scientific applications as Web services,0,2013-02-27 03:25:33+00:00,2019-10-16 08:49:53+00:00,2015-02-19 23:15:15+00:00,http://nbcr.ucsd.edu/data/docs/opal/,121865,5,5,JavaScript,1,1,1,1,0,0,3,0,0,1,,1,0,0,public,3,1,5,master,1,1,,"['sriramkrishnan', 'lclementi', 'nadyawilliams']",1,0.8,0,,,,,,3,,,,
675867920,R_kgDOKEjtEA,Psychedelics_and_Depression,nehasharma732/Psychedelics_and_Depression,0,nehasharma732,https://github.com/nehasharma732/Psychedelics_and_Depression,COGS 108: Data Science in Practice (UC San Diego Summer 2023),0,2023-08-07 23:24:48+00:00,2024-03-14 20:14:03+00:00,2023-12-07 22:59:33+00:00,,21231,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Psychedelics & Depression

Team Members: [Neha Sharma](https://github.com/nehasharma732), [Vartan Pashayan](https://github.com/VartanPashayan), [Alexander Levine](https://github.com/alexlevine1220), [Sohaib Khan](https://github.com/SKhan141), [Sneha Sairam](https://github.com/sneha530)

Final Write-up: [Psychedelics_and_Depression](https://github.com/nehasharma732/Psychedelics_and_Depression/blob/main/FinalProject_writeup.ipynb)

## Overview

The intriguing realm of Psilocybin Mushrooms, commonly known as Psychedelic Mushrooms, has captivated the interest of popculture and academics alike. These unique fungi contain Psilocybin, a psychedelic compound categorized as a classic hallucinogen. Its influence extends to various serotonin receptors across different brain regions including the cerebral cortex and thalamus (Daniel and Haberman, 2018), and throughout the body. 

In recent times, a noticeable trend has emerged - a growing curiosity about the potential therapeutic applications of non- conventional drugs, particularly in the context of depression and other medical conditions. This shift has led individuals to explore the possibility of using Psilocybin as a potential remedy for their health issues.

This project aims unveil potential links between depression among users of psychedelic substances and the co-occurrence of other ailments through exploratory data analysis.
",['nehasharma732'],1,0.77,0,,,,,,1,,,,
292359021,MDEwOlJlcG9zaXRvcnkyOTIzNTkwMjE=,Bootcamp2020,NGP-Bootcamp/Bootcamp2020,0,NGP-Bootcamp,https://github.com/NGP-Bootcamp/Bootcamp2020,"Materials for NGP Bootcamp, September 2020",0,2020-09-02 18:10:58+00:00,2022-09-16 04:40:58+00:00,2022-09-16 04:42:17+00:00,,30194,1,1,Jupyter Notebook,1,1,1,1,0,0,3,0,0,1,,1,0,0,public,3,1,1,master,1,1,"![](https://pbs.twimg.com/profile_banners/121204594/1531763557/1500x500)
# NGP Bootcamp 2020
Materials for the UC San Diego Neurosciences Bootcamp, September 2020.  To open DataHub and sync with this repository, click [here](https://datahub.ucsd.edu/hub/user-redirect/git-sync?repo=https://github.com/NGP-Bootcamp/Bootcamp2020).

## Roadmap
### Sep 11: Linear Algebra + Python Introduction *(Optional)*
- **Linear Algebra** [[Slides](https://github.com/NGP-Bootcamp/Bootcamp2020/blob/master/LinearAlgebra.pdf)]
- **00-IntroPython Notebooks** [[Slides](https://github.com/NGP-Bootcamp/Bootcamp2020/blob/master/00-IntroPython/Introduction%20to%20Python%20%26%20Jupyter%20Notebooks.pdf)]
     - 01: Expressions, Variables, Strings [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/00-IntroPython/01-SyntaxExpressionsVariables.ipynb)
     - 02: Data Structures [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/00-IntroPython/02-DataStructures.ipynb)
     - 03: Booleans, Conditionals, Loops [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/00-IntroPython/03-BooleansConditionalsLoops.ipynb)
     - 04: Object-Oriented Programming [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/00-IntroPython/04-OOP.ipynb)

*Before Monday, regardless of whether you attend on Friday, please complete NMA-Tutorial1.ipynb and NMA-Tutorial2.ipynb. We'll discuss on Monday!*


### Sep 14: Introduction to Electrophysiology + Amplifier technologies + RC Circuits + Analysis of Allen data
- **RC Circuit Lab** [[PDF](https://github.com/NGP-Bootcamp/Bootcamp2020/blob/master/RC_Circuitry_Simulation.pdf)][[Supplementary Google Doc](https://docs.google.com/document/d/1oSgRBj__LDzU_g0R2NHaBLZ0HfWBfU_FsPk_-9gjj-0/edit?usp=sharing)]
- **01-CellTypes Notebook**
     - Cell Types Notebook [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/01-CellTypes/CellTypesNotebook.ipynb)

### Sep 15: Computational model types, modeling practice, model fitting
- **Introduction to modeling** [[Slides](https://github.com/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/IntroModeling.pdf)]
- **02-IntroModeling Notebooks**
     - 01: Model Fitting: Linear regression with MSE [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/01-LinearRegressionMSE.ipynb)
     - 02: Model Fitting: Linear regression with MLE [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/02-LinearRegressionMLE.ipynb)
     - 03: Model Fitting: Confidence intervals and bootstrapping *(Optional)* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/03-Uncertainty.ipynb)
     - 04: Model Fitting: Multiple linear regression and polynomial regression [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/04-MultipleLinearRegression.ipynb)
     - 05: Model Selection: Bias-variance trade-off [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/05-BiasVariance.ipynb)
     - 06: Model Selection: Cross-validation *(Optional)* [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/02-IntroModeling/06-CrossValidation.ipynb)

<hr>

### Sep 16: Generalized linear models
- **Machine Learning Notebooks**
- 01: Generalized Linear Models: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/03-GLM/01-GLM.ipynb)
- 02: Logistic Regression [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/03-GLM/02-LogisticRegression.ipynb)
     
### Sep 17: Dimensionality reduction
- 01: Introduction to PCA: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/04-DimReduction/01-Intro.ipynb)
- 02: PCA in 2D [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/04-DimReduction/02-PCA.ipynb)
- 03: PCA and clustering with k-means: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/04-DimReduction/03-PCAandClustering.ipynb)
- 04: Data reconstruction and classification:  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/04-DimReduction/04-PCANeuralData.ipynb)

### Sep 18: Bayesian stats
- 01: Regularization in Machine learning: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/05-Bayes/01-Regularization.ipynb)
- 02: Bayes Rule with Gaussians [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/05-Bayes/02-BayesRule.ipynb)
- 03: Causal inference with mixture of Gaussians: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/05-Bayes/03-GaussianMixture.ipynb)
- 04: Data fitting: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NGP-Bootcamp/Bootcamp2020/blob/master/05-Bayes/04-DataFitting.ipynb)

*Coming soon...*

### Sep 21 & 22: Modeling neurons and networks

### Sep 23: Synaptic plasticity and dynamic networks

### Sept 24: Deep learning
","['ajuavinett', 'gmishne', 'mattarlab', 'jing8wang', 'mikioaoi', 'aljdf']",1,0.65,0,,,,,,2,,,,
134140052,MDEwOlJlcG9zaXRvcnkxMzQxNDAwNTI=,data-structures,nishchayp/data-structures,0,nishchayp,https://github.com/nishchayp/data-structures," Contains my code submission for Data Structures course as offered by University of California, San Diego & National Research University Higher School of Economics on Coursera. ",0,2018-05-20 10:15:20+00:00,2018-06-20 01:09:26+00:00,2018-05-20 10:28:17+00:00,,1085,1,1,C++,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,1,master,1,,"# data-structures
Contains my code submission for <b>Data Structures</b> course as offered by <b>University of California, San Diego &amp; National Research University Higher School of Economics</b> on <b>Coursera</b>.</br>
https://www.coursera.org/learn/data-structures</br></br>
<i>Note: The purpose of this repository is to preserve my submissions for future reference and is not inteded to help other students in any form of plagirism. That being said I'll be more than happy to help with and discuss any problem related to the course.
Feel free to message me on Gitter(https://gitter.im/nishchayp).</i>
",['nishchayp'],1,0.68,0,,,,,,1,,,,
182439539,MDEwOlJlcG9zaXRvcnkxODI0Mzk1Mzk=,ucsd-d3-2019,notcome/ucsd-d3-2019,0,notcome,https://github.com/notcome/ucsd-d3-2019,UCSD D3 Datathon,0,2019-04-20 18:11:44+00:00,2019-07-16 01:03:07+00:00,2019-07-16 01:03:06+00:00,,55,0,0,Python,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,,['notcome'],1,0.78,0,,,,,,2,,,,
690813987,R_kgDOKSz8Iw,conditional-restir-prototype,NVlabs/conditional-restir-prototype,0,NVlabs,https://github.com/NVlabs/conditional-restir-prototype,,0,2023-09-12 23:59:00+00:00,2025-02-21 12:16:16+00:00,2024-01-18 01:17:26+00:00,,17488,112,112,C++,1,1,1,1,0,0,5,0,0,2,other,1,0,0,public,5,2,112,main,1,1,"# Conditional ReSTIR Prototype
![](teaser.png)

## Introduction
- This repo includes source code for the following [SIGGRAPH Asia 2023 paper](https://research.nvidia.com/labs/rtr/publication/kettunen2023conditional/)

> **[Conditional Resampled Importance Sampling and ReSTIR](https://research.nvidia.com/labs/rtr/publication/kettunen2023conditional/)**<br>
> Markus Kettunen* (NVIDIA), Daqi Lin* (NVIDIA), Ravi Ramamoorthi (NVIDIA and UC San Diego), Thomas Bashford-Rogers (University of Warwick),  Chris Wyman (NVIDIA)<br>
> (*Joint first authors) <br>

This prototype application of conditional ReSTIR defers ReSTIR-based path reuse by one or more bounces. It is based on conditional resampled importance sampling (CRIS) theory, an extension of GRIS [[Lin et al. 2022]](https://research.nvidia.com/publication/2022-07_generalized-resampled-importance-sampling-foundations-restir) to conditional path spaces that enables reusing subpaths from unidirectional-sampled paths with correct unbiased contribution weights. Our conditional ReSTIR prototype modifies ReSTIR PT [[Lin et al. 2022]](https://github.com/DQLin/ReSTIR_PT) with a final gather pass. As in photon mapping, such a final gather reduces blotchy artifacts from sample correlation.

- The method is implemented as a rendering component called ""ConditionalReSTIR"" (`Source/Falcor/Rendering/ConditionalReSTIR`) in Falcor 5.2.
See [README-Falcor.md](README-Falcor.md) for the original README file provided by Falcor.
- A script `runConditionalReSTIRDemo.bat` is provided to show how the method works VeachAjar scene (from [Benedikt Bitterli's rendering resources](https://benedikt-bitterli.me/resources/)) which is contained in the repo.
- Before running the scripts, you need to compile the program and download the scene files following the instruction below.

## Licensing

The new conditional resampling code in this repository is [licensed](LICENSE.md) under the NVIDIA Source Code License.  Included NVIDIA dependencies remain licensed under their existing licenses, including:  [Falcor](https://github.com/NVIDIAGameWorks/Falcor/blob/master/LICENSE.md), [DLSS](https://github.com/NVIDIA/DLSS/blob/main/LICENSE.txt), [RTXGI](https://github.com/NVIDIAGameWorks/RTXGI/blob/main/License.txt), [RTXDI](https://github.com/NVIDIAGameWorks/RTXDI/blob/main/LICENSE.txt), and [NRD](https://github.com/NVIDIAGameWorks/RayTracingDenoiser/blob/master/LICENSE.txt).  

Falcor also downloads various 3rd party dependencies as git submodules; these have their own licenses.

## Prerequisites
- Windows 10 version 20H2 or newer
- Visual Studio 2022
- [Windows 10 SDK version 10.0.19041.1 Or Newer](https://developer.microsoft.com/en-us/windows/downloads/sdk-archive)
- We relied on NVIDIA drivers 530.xx and above 
        * Though our baseline Falcor only requires NVIDIA driver 466.11 or later
- A GPU supporting DirectX Raytracing 
        * Conditional ReSTIR is very costly; we recommend a NVIDIA GeForce RTX 4090 if planning to play with settings much

## How to compile
IMPORTANT:  We use git submodules to download dependencies!  Downloading the git repository as a .zip (rather than using `git clone`) will ensure you lack required dependencies, and the build scripts will fail.

After cloning the repository:
- Run `setup_vs2022.bat`
- Open `build/windows-vs2022/Falcor.sln` and the `Build Solution` in the `Release` configuration 

## Run the demo
- Execute `runConditionalReSTIRDemo.bat`
- The GUI contains self-explanatory settings for parameter tweaking under ""Rendering Presets"".  
- Not all exposed options under other, more advanced, menus work together in all configurations (e.g., at least Falcor's existing path tracing ""Russian roulette"" toggle is known buggy).

## Testing with more scenes
To run our code more generally requires:
- Running the executable `build/windows-vs2022/bin/Release/Mogwai.exe`
- Loading the conditional ReSTIR render script `scripts/ConditionalReSTIR.py`.  Options include:
        * Drag and drop the script into a running Mogwai instance 
        * Load via a Mogwai menu (File -> Load Script), or 
        * Pass to Mogwai as an command line parameter (as in `runConditionalReSTIRDemo.bat`)
- Loading a scene:
        * The last line of the `ConditionalReSTIR.py` script already does this
        * Modify this line, if desired, or delete it and load the scene explicity via drag-and-drop or the Mogwai menus.

Mogwai can load a variety of [scene types](docs/usage/scene-formats.md):
- Falcor's native `.pyscene` format ([more details](docs/usage/scene-formats.md)). 
- Some simplistic `.usd` files (support is largely experimental).
- FBX files and GLTF files via the included [Assimp](https://github.com/assimp/assimp) module.
        * Many of these lack emissive light surfaces, which are important for ReSTIR renderers.
        * Often we wrap these in a .pyscene file so we can modify material emissive properites via Python on load.
- Many PBRT v4 files:
        * E.g., from [Benedikt's resources](https://benedikt-bitterli.me/resources/) page
        * Though not all materials match with PBRT.


",['DQLin'],1,0.6,0,,,,,,8,,,,
762193211,R_kgDOLW4lOw,VILA,NVlabs/VILA,0,NVlabs,https://github.com/NVlabs/VILA,"VILA is a family of state-of-the-art vision language models (VLMs) for diverse multimodal AI tasks across the edge, data center, and cloud.",0,2024-02-23 09:19:16+00:00,2025-03-07 05:10:49+00:00,2025-03-07 05:10:46+00:00,,72255,2989,2989,Python,1,1,1,0,1,0,241,0,0,69,apache-2.0,1,0,0,public,241,69,2989,main,1,1,"

# VILA: Optimized Vision Language Models

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](CODE_LICENSE)
[![Model License](https://img.shields.io/badge/MODEL%20License-CC%20By%20NC%204.0-red.svg)](MODEL_LICENSE)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/release/python-3100/)

[arXiv](https://arxiv.org/abs/2412.04468) / [Demo](https://vila.mit.edu/) / [Models](https://huggingface.co/collections/Efficient-Large-Model/nvila-674f8163543890b35a91b428) / [Subscribe](https://forms.gle/6nf1QdPYdvC2vgxM8)

## ðŸ’¡ Introduction

VILA is a family of open VLMs designed to optimize both efficiency and accuracy for efficient video understanding and multi-image understanding. 

## ðŸ’¡ News

- \[2025/1\] As of January 6, 2025 VILA is now part of the new Cosmos Nemotron vision language models.
- \[2024/12\] We release [NVILA](https://arxiv.org/abs/2412.04468) (a.k.a VILA2.0) that explores the full stack efficiency of multi-modal design, achieving cheaper training, faster deployment and better performance.
- \[2024/12\] We release [LongVILA](./longvila/README.md) that supports long video understanding, with long-context VLM with more than 1M context length and multi-modal sequence parallel system.
- \[2024/10\] VILA-M3, a SOTA medical VLM finetuned on VILA1.5 is released! VILA-M3 significantly outperforms Llava-Med and on par w/ Med-Gemini and is fully opensourced! [code](https://github.com/Project-MONAI/VLM#-news) [model](https://huggingface.co/MONAI)
- \[2024/10\] We release [VILA-U](https://github.com/mit-han-lab/vila-u): a Unified foundation model that integrates Video, Image, Language understanding and generation.
- \[2024/07\] VILA1.5 also ranks 1st place (OSS model) on [MLVU test leaderboard](https://github.com/JUNJIE99/MLVU).
- \[2024/06\] VILA1.5 is now the best open sourced VLM on [MMMU leaderboard](https://mmmu-benchmark.github.io/#leaderboard) and [Video-MME](https://video-mme.github.io/home_page.html#leaderboard) leaderboard!
- \[2024/05\] We release VILA-1.5, which offers **video understanding capability**. VILA-1.5 comes with four model sizes: 3B/8B/13B/40B.

<details>
<summary>Click to show more news</summary>

- \[2024/05\] We release [AWQ](https://arxiv.org/pdf/2306.00978.pdf)-quantized 4bit VILA-1.5 models. VILA-1.5 is efficiently deployable on diverse NVIDIA GPUs (A100, 4090, 4070 Laptop, Orin, Orin Nano) by [TinyChat](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat) and [TensorRT-LLM](demo_trt_llm) backends.
- \[2024/03\] VILA has been accepted by CVPR 2024!
- \[2024/02\] We release [AWQ](https://arxiv.org/pdf/2306.00978.pdf)-quantized 4bit VILA models, deployable on Jetson Orin and laptops through [TinyChat](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat) and [TinyChatEngine](https://github.com/mit-han-lab/TinyChatEngine).
- \[2024/02\] VILA is released. We propose interleaved image-text pretraining that enables **multi-image** VLM. VILA comes with impressive in-context learning capabilities. We open source everything: including training code, evaluation code, datasets, model ckpts.
- \[2023/12\] [Paper](https://arxiv.org/abs/2312.07533) is on Arxiv!

</details>

## Performance

## Image Benchmarks

![](https://nvlabs.github.io/VILA/asset/image_results.png)

### Video  Benchmarks

![](https://nvlabs.github.io/VILA/asset/video_results.png)

### Efficient Deployments

![](https://nvlabs.github.io/VILA/asset/deployment_viz.png)

<sup>NOTE: Measured using the [TinyChat](https://github.com/mit-han-lab/llm-awq/tinychat) backend at batch size = 1.</sup>

### Inference Performance

#### Decoding Throughput ( Token/sec )

| $~~~~~~$                    |  A100  | 4090  | Orin |
| --------------------------- |  ----- | ----- | ---- |
| NVILA-3B-Baseline           |  140.6 | 190.5 | 42.7 |
| NVILA-3B-TinyChat           |  184.3 | 230.5 | 45.0 |
| NVILA-Lite-3B-Baseline      |  142.3 | 190.0 | 41.3 |
| NVILA-Lite-3B-TinyChat      |  186.0 | 233.9 | 44.9 |
| NVILA-8B-Baseline           |  82.1  | 61.9  | 11.6 |
| NVILA-8B-TinyChat           |  186.8 | 162.7 | 28.1 |
| NVILA-Lite-8B-Baseline      |  84.0  | 62.0  | 11.6 |
| NVILA-Lite-8B-TinyChat      |  181.8 | 167.5 | 32.8 |
| NVILA-Video-8B-Baseline *   |  73.2  | 58.4  | 10.9 |
| NVILA-Video-8B-TinyChat *   |  151.8 | 145.0 | 32.3 |

#### TTFT (Time-To-First-Token) ( Sec )

| $~~~~~~$                    |   A100  |  4090  |  Orin  |
| --------------------------- |  ------ | ------ | ------ |
| NVILA-3B-Baseline           |  0.0329 | 0.0269 | 0.1173 |
| NVILA-3B-TinyChat           |  0.0260 | 0.0188 | 0.1359 |
| NVILA-Lite-3B-Baseline      |  0.0318 | 0.0274 | 0.1195 |
| NVILA-Lite-3B-TinyChat      |  0.0314 | 0.0191 | 0.1241 |
| NVILA-8B-Baseline           |  0.0434 | 0.0573 | 0.4222 |
| NVILA-8B-TinyChat           |  0.0452 | 0.0356 | 0.2748 |
| NVILA-Lite-8B-Baseline      |  0.0446 | 0.0458 | 0.2507 |
| NVILA-Lite-8B-TinyChat      |  0.0391 | 0.0297 | 0.2097 |
| NVILA-Video-8B-Baseline *   |  0.7190 | 0.8840 | 5.8236 |
| NVILA-Video-8B-TinyChat *   |  0.6692 | 0.6815 | 5.8425 |

<sup>NOTE: Measured using the [TinyChat](https://github.com/mit-han-lab/llm-awq/tinychat) backend at batch size = 1, dynamic_s2 disabled, and num_video_frames = 64. We use W4A16 LLM and W8A8 Vision Tower for Tinychat and the baseline precision is FP16.</sup>
<sup>\*: Measured with video captioning task. Otherwise, measured with image captioning task.</sup>

## VILA Examples

### Video captioning

https://github.com/Efficient-Large-Model/VILA/assets/156256291/c9520943-2478-4f97-bc95-121d625018a6

Prompt: Elaborate on the visual and narrative elements of the video in detail.

Caption: The video shows a person's hands working on a white surface. They are folding a piece of fabric with a checkered pattern in shades of blue and white. The fabric is being folded into a smaller, more compact shape. The person's fingernails are painted red, and they are wearing a black and red garment. There are also a ruler and a pencil on the surface, suggesting that measurements and precision are involved in the process.

### In context learning

<img src=""demo_images/demo_img_1.png"" height=""239"">
<img src=""demo_images/demo_img_2.png"" height=""250"">

### Multi-image reasoning

<img src=""demo_images/demo_img_3.png"" height=""193"">

### VILA on Jetson Orin

https://github.com/Efficient-Large-Model/VILA/assets/7783214/6079374c-0787-4bc4-b9c6-e1524b4c9dc4

### VILA on RTX 4090

https://github.com/Efficient-Large-Model/VILA/assets/7783214/80c47742-e873-4080-ad7d-d17c4700539f

## Installation

1.  Install [Anaconda Distribution](https://www.anaconda.com/download).
2.  Install the necessary Python packages in the environment.

    ```bash
    ./environment_setup.sh vila
    ```

3.  (Optional) If you are an NVIDIA employee with a wandb account, install
    onelogger and enable it by setting `training_args.use_one_logger` to `True`
    in `llava/train/args.py`.

    ```bash
    pip install --index-url=https://sc-hw-artf.nvidia.com/artifactory/api/pypi/hwinf-mlwfo-pypi/simple --upgrade one-logger-utils
    ```

4.  Activate a conda environment.

    ```bash
    conda activate vila
    ```

## Training

VILA training contains three steps, for specific hyperparameters, please check out the [scripts/v1_5](scripts/v1_5) folder:

### Step-1: Alignment

We utilize LLaVA-CC3M-Pretrain-595K dataset to align the textual and visual modalities.

The stage 1 script takes in two parameters and it can run on a single 8xA100 node.

```bash
bash scripts/NVILA-Lite/align.sh Efficient-Large-Model/Qwen2-VL-7B-Instruct <alias to data>
```

and the trained models will be saved to `runs/train/nvila-8b-align`.

### Step-1.5:

```bash
bash scripts/NVILA-Lite/stage15.sh runs/train/nvila-8b-align/model <alias to data>
```

and the trained models will be saved to `runs/train/nvila-8b-align-1.5`.

### Step-2: Pretraining

We use MMC4 and Coyo dataset to train VLM with interleaved image-text pairs.

```bash
bash scripts/NVILA-Lite/pretrain.sh runs/train/nvila-8b-align-1.5 <alias to data>
```

and the trained models will be saved to `runs/train/nvila-8b-pretraining`.

### Step-3: Supervised fine-tuning

This is the last stage of VILA training, in which we tune the model to follow multimodal instructions on a subset of M3IT, FLAN and ShareGPT4V. This stage runs on a 8xA100 node.

```bash
bash scripts/NVILA-Lite/sft.sh runs/train/nvila-8b-pretraining <alias to data>
```

and the trained models will be saved to `runs/train/nvila-8b-SFT`.

## Evaluations

We have introduce `vila-eval` command to simplify the evaluation. Once the data is prepared, the evaluation can be launched via

```bash
MODEL_NAME=NVILA-15B
MODEL_ID=Efficient-Large-Model/$MODEL_NAME
huggingface-cli download $MODEL_ID

vila-eval \
    --model-name $MODEL_NAME \
    --model-path $MODEL_ID \
    --conv-mode auto \
    --tags-include local
```

it will launch all evaluations and return a summarized result.

## Inference

We provide `vila-infer` for quick inference with user prompts and images.

```bash
# image description
vila-infer \
    --model-path Efficient-Large-Model/NVILA-15B \
    --conv-mode auto \
    --text ""Please describe the image"" \
    --media demo_images/demo_img.png

# video description
vila-infer \
    --model-path Efficient-Large-Model/NVILA-15B \
    --conv-mode auto \
    --text ""Please describe the video"" \
    --media https://huggingface.co/datasets/Efficient-Large-Model/VILA-inference-demos/resolve/main/OAI-sora-tokyo-walk.mp4
```

`vila-infer` is also compatible with VILA-1.5 models. For example:

```bash
vila-infer \
    --model-path Efficient-Large-Model/VILA1.5-3b \
    --conv-mode vicuna_v1 \
    --text ""Please describe the image"" \
    --media demo_images/demo_img.png

vila-infer \
    --model-path Efficient-Large-Model/VILA1.5-3b \
    --conv-mode vicuna_v1 \
    --text ""Please describe the video"" \
    --media https://huggingface.co/datasets/Efficient-Large-Model/VILA-inference-demos/resolve/main/OAI-sora-tokyo-walk.mp4


vila-infer \
    --model-path Efficient-Large-Model/NVILA-15B \
    --conv-mode auto \
    --text ""Please describe the video"" \
    --media https://huggingface.co/datasets/Efficient-Large-Model/VILA-inference-demos/resolve/main/OAI-sora-tokyo-walk.mp4
```

## Quantization and Deployment

Our VILA models are quantized by [AWQ](https://arxiv.org/abs/2306.00978) into 4 bits for efficient inference on the edge. We provide a push-the-button [script](https://github.com/mit-han-lab/llm-awq/blob/main/scripts/nvila_example.sh) to quantize VILA with AWQ.

### Running VILA on desktop GPUs and edge GPUs

We support AWQ-quantized 4bit VILA on GPU platforms via [TinyChat](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat). We provide a [tutorial](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat#support-vlm-models-vila--llava) to run the model with TinyChat after quantization. We also provide an [instruction](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat/serve) to launch a Gradio server (powered by TinyChat and AWQ) to serve 4-bit quantized VILA models.

### Running VILA on laptops

We further support our AWQ-quantized 4bit VILA models on various CPU platforms with both x86 and ARM architectures with our [TinyChatEngine](https://github.com/mit-han-lab/TinyChatEngine). We also provide a detailed [tutorial](https://github.com/mit-han-lab/TinyChatEngine/tree/main?tab=readme-ov-file#deploy-vision-language-model-vlm-chatbot-with-tinychatengine) to help the users deploy VILA on different CPUs.

### Running VILA API server

A simple API server has been provided to serve VILA models. The server is built on top of [FastAPI](https://fastapi.tiangolo.com/) and [Huggingface Transformers](https://huggingface.co/transformers/). The server can be run with the following command:

#### With CLI

```bash
python -W ignore server.py \
    --port 8000 \
    --model-path Efficient-Large-Model/NVILA-15B \
    --conv-mode auto
```

#### With Docker

```bash
docker build -t vila-server:latest .
docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
    -v ./hub:/root/.cache/huggingface/hub \
    -it --rm -p 8000:8000 \
    -e VILA_MODEL_PATH=Efficient-Large-Model/NVILA-15B \
    -e VILA_CONV_MODE=auto \
    vila-server:latest
```

Then you can call the endpoint with the OpenAI SDK as follows:

```python
from openai import OpenAI

client = OpenAI(
    base_url=""http://localhost:8000"",
    api_key=""fake-key"",
)
response = client.chat.completions.create(
    messages=[
        {
            ""role"": ""user"",
            ""content"": [
                {""type"": ""text"", ""text"": ""Whatâ€™s in this image?""},
                {
                    ""type"": ""image_url"",
                    ""image_url"": {
                        ""url"": ""https://blog.logomyway.com/wp-content/uploads/2022/01/NVIDIA-logo.jpg"",
                        # Or you can pass in a base64 encoded image
                        # ""url"": ""data:image/png;base64,<base64_encoded_image>"",
                    },
                },
            ],
        }
    ],
    model=""NVILA-15B"",
)
print(response.choices[0].message.content)
```

<sup>NOTE: This API server is intended for evaluation purposes only and has not been optimized for production use. SGLang support is coming on the way.</sup>

## Checkpoints

We release the following models:

- NVILA-8B / NVILA-8B-Lite
- NVILA-15B / NVILA-15B-Lite

## ðŸ”’ License

- The code is released under the Apache 2.0 license as found in the [LICENSE](./LICENSE) file.
- The pretrained weights are released under the [CC-BY-NC-SA-4.0 license](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en).
- The service is a research preview intended for non-commercial use only, and is subject to the following licenses and terms:
  - [Model License](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) of LLaMA. For LLAMA3-VILA checkpoints terms of use, please refer to the [LLAMA3 License](https://llama.meta.com/llama3/license/) for additional details.
  - [Terms of Use](https://openai.com/policies/terms-of-use) of the data generated by OpenAI
  - [Dataset Licenses](./data_prepare/LICENSE) for each one used during training.

## Team

NVILA Core contributors: [Zhijian Liu](https://zhijianliu.com), [Ligeng Zhu](https://lzhu.me/), [Baifeng Shi](https://bfshi.github.io/), [Zhuoyang Zhang](https://openreview.net/profile?id=~Zhuoyang_Zhang1), [Yuming Lou](<>), [Shang Yang](https://ys-2020.github.io/), [Haocheng Xi](<>), [Shiyi Cao](<>), [Yuxian Gu](<>), [Dacheng Li](<>), [Xiuyu Li](<>), [Yunhao Fang](https://seerkfang.github.io/), [Yukang Chen](https://yukangchen.com/), [Cheng-Yu Hsieh](<>), [De-An Huang](<>), [An-Chieh Cheng](<>), [Vishwesh Nath](<>), [Jinyi Hu](<>), [Sifei Liu](<>), [Ranjay Krishna](<>), [Daguang Xu](<>), [Xiaolong Wang](<>), [Pavlo Molchanov](https://www.pmolchanov.com/), [Jan Kautz](https://jankautz.com/), [Hongxu Yin](https://hongxu-yin.github.io/), [Song Han](http://songhan.mit.edu/), [Yao Lu](https://scholar.google.com/citations?user=OI7zFmwAAAAJ&hl=en)

LongVILA contributors: [Yukang Chen](https://yukangchen.com/), [Fuzhao Xue](https://xuefuzhao.github.io/), [Dacheng Li](<https://dachengli1.github.io>), [Qinghao Hu](<https://tonyhao.xyz>), [Ligeng Zhu](https://lzhu.me/), [Xiuyu Li](<https://xiuyuli.com>), [Yunhao Fang](https://seerkfang.github.io/), [Haotian Tang](http://kentang.net/), [Shang Yang](https://ys-2020.github.io/), [Zhijian Liu](https://zhijianliu.com), [Ethan He](<>), [Hongxu Yin](https://hongxu-yin.github.io/), [Pavlo Molchanov](https://www.pmolchanov.com/), [Jan Kautz](<https://jankautz.com>), [Linxi Fan](<https://jimfan.me>), [Yuke Zhu](<https://yukezhu.me>), [Yao Lu](https://scholar.google.com/citations?user=OI7zFmwAAAAJ&hl=en), [Song Han](http://songhan.mit.edu/)

<details>
<summary> VILA-1.5 contributors </summary>

[\*Yao Lu](https://scholar.google.com/citations?user=OI7zFmwAAAAJ&hl=en): Nvidia, [\*Hongxu Yin](https://hongxu-yin.github.io/): Nvidia, [\*Ji Lin](https://www.linji.me/): OpenAI (work done at Nvidia and MIT), [Wei Ping](https://scholar.google.com/citations?user=6gKEYRgAAAAJ&hl=en): Nvidia, [Pavlo Molchanov](https://www.pmolchanov.com/): Nvidia, [Andrew Tao](https://scholar.google.com/citations?user=Wel9l1wAAAAJ&hl=en): Nvidia, [Haotian Tang](http://kentang.net/): MIT, [Shang Yang](https://ys-2020.github.io/): MIT, [Ligeng Zhu](https://lzhu.me/): Nvidia, MIT, [Wei-Chen Wang](https://weichenwang.me/): MIT, [Fuzhao Xue](https://xuefuzhao.github.io/): Nvidia, NUS, [Yunhao Fang](https://seerkfang.github.io/): Nvidia, UCSD, [Yukang Chen](https://yukangchen.com/): Nvidia, [Zhuoyang Zhang](https://openreview.net/profile?id=~Zhuoyang_Zhang1): Nvidia, [Yue Shen](https://www.linkedin.com/in/yue-james-shen/): Nvidia, [Wei-Ming Chen](https://scholar.google.com/citations?user=6xFvyJwAAAAJ&hl=en): Nvidia, [Huizi Mao](https://scholar.google.com/citations?user=r5WezOYAAAAJ&hl=zh-CN): Nvidia, [Baifeng Shi](https://bfshi.github.io/): Nvidia, UC Berkeley, [Jan Kautz](https://jankautz.com/): Nvidia, [Mohammad Shoeybi](https://scholar.google.com/citations?user=62ElavIAAAAJ&hl=en): Nvidia, [Song Han](http://songhan.mit.edu/): Nvidia, MIT

</details>

## Citations

```
@misc{liu2024nvila,
      title={NVILA: Efficient Frontier Visual Language Models},
      author={Zhijian Liu and Ligeng Zhu and Baifeng Shi and Zhuoyang Zhang and Yuming Lou and Shang Yang and Haocheng Xi and Shiyi Cao and Yuxian Gu and Dacheng Li and Xiuyu Li and Yunhao Fang and Yukang Chen and Cheng-Yu Hsieh and De-An Huang and An-Chieh Cheng and Vishwesh Nath and Jinyi Hu and Sifei Liu and Ranjay Krishna and Daguang Xu and Xiaolong Wang and Pavlo Molchanov and Jan Kautz and Hongxu Yin and Song Han and Yao Lu},
      year={2024},
      eprint={2412.04468},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.04468},
}
```

```
@misc{chen2024longvila,
      title={LongVILA: Scaling Long-Context Visual Language Models for Long Videos},
      author={Yukang Chen and Fuzhao Xue and Dacheng Li and Qinghao Hu and Ligeng Zhu and Xiuyu Li and Yunhao Fang and Haotian Tang and Shang Yang and Zhijian Liu and Ethan He and Hongxu Yin and Pavlo Molchanov and Jan Kautz and Linxi Fan and Yuke Zhu and Yao Lu and Song Han},
      year={2024},
      eprint={2408.10188},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

```
@misc{lin2023vila,
      title={VILA: On Pre-training for Visual Language Models},
      author={Ji Lin and Hongxu Yin and Wei Ping and Yao Lu and Pavlo Molchanov and Andrew Tao and Huizi Mao and Jan Kautz and Mohammad Shoeybi and Song Han},
      year={2023},
      eprint={2312.07533},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

# Acknowledgement

- [LLaVA](https://github.com/haotian-liu/LLaVA): the codebase we built upon. Thanks for their wonderful work.
- [InternVL](https://github.com/OpenGVLab/InternVL): for open-sourcing InternViT (used in VILA1.5-40b) and the [InternVL-SFT](https://github.com/OpenGVLab/InternVL/tree/main/internvl_chat#prepare-training-datasets) data blend (inspired by LLaVA-1.6) used in all VILA1.5 models.
- [Vicuna](https://github.com/lm-sys/FastChat): the amazing open-sourced large language model!
- [Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT): we borrowed video evaluation script from this repository.
- [MMC4](https://github.com/allenai/mmc4), [COYO-700M](https://github.com/kakaobrain/coyo-dataset), [M3IT](https://huggingface.co/datasets/MMInstruction/M3IT), [OpenORCA/FLAN](https://huggingface.co/datasets/Open-Orca/FLAN), [ShareGPT4V](https://github.com/InternLM/InternLM-XComposer/tree/main/projects/ShareGPT4V), [WIT](google-research-datasets/wit), [GSM8K-ScRel](https://github.com/OFA-Sys/gsm8k-ScRel/blob/main/data/train_use.jsonl), [VisualGenome](https://visualgenome.org/api/v0/api_home.html), [VCR](https://visualcommonsense.com/download/), [ScienceQA](https://huggingface.co/datasets/derek-thomas/ScienceQA), [Shot2Story](https://github.com/bytedance/Shot2Story/blob/master/DATA.md), [Youcook2](http://youcook2.eecs.umich.edu/), [Vatex](https://eric-xw.github.io/vatex-website/download.html), [ShareGPT-Video](https://huggingface.co/datasets/ShareGPTVideo/train_video_and_instruction) for providing datasets used in this research.
","['yaolug', 'Lyken17', 'zhijian-liu', 'yukang2017', 'Efficient-Large-Language-Model', 'Qinghao-Hu', 'hongxuyin', 'yichenxu99', 'Louym', 'Ubospica', 'Xiuyu-Li', 'meenchen', 'songhan', 'ys-2020', 'AaronNZH', 'eltociear', 'DachengLi1', 'bfshi']",1,0.78,0,,,,,,39,,,,
905484191,R_kgDONfiXnw,HermiteFD-ROM,opaliss/HermiteFD-ROM,0,opaliss,https://github.com/opaliss/HermiteFD-ROM,AW Hermite + central finite difference POD/ROM,0,2024-12-18 23:27:48+00:00,2025-01-24 20:48:01+00:00,2025-01-24 20:47:57+00:00,,42620,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['opaliss'],1,0.72,0,,,,,,1,,,,
248229145,MDEwOlJlcG9zaXRvcnkyNDgyMjkxNDU=,UCSanDiego_MicroMasters_DataScience-BigDataAnalyticsUsingSpark,PeterSchuld/UCSanDiego_MicroMasters_DataScience-BigDataAnalyticsUsingSpark,0,PeterSchuld,https://github.com/PeterSchuld/UCSanDiego_MicroMasters_DataScience-BigDataAnalyticsUsingSpark,"The University of California, San Diego, course DSE230x ""Big Data Analytics Using Spark"" (Summer 2019): Learn how to analyze large datasets using Jupyter notebooks, MapReduce and Spark as a platform. Part 4 of the Â»Data ScienceÂ« MicroMastersÂ® Program on edX.  Instructor: Yoav Freund, Professor of CS and Engineering, University of California San Diego. ",0,2020-03-18 12:44:47+00:00,2021-02-11 15:52:15+00:00,2020-03-25 14:01:17+00:00,https://mas-dse.github.io/DSE230/class_information_cse255/,6422,1,1,,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,1,master,1,,"# UC San Diego MicroMasters Data Science ""Big Data Analytics Using Spark""
DES230 ""Big Data Analytics Using Spark"" by Yoav Freund, Professor of Computer Science and Engineering UC San Diego. Learn how to analyze large datasets using Jupyter notebooks, MapReduce and Spark as a platform. Part 4 of Data Science MicroMastersÂ® Program on edX. 

#### About this course ####

In data science, data is called ""big"" if it cannot fit into the memory of a single standard laptop or workstation. The analysis of big datasets requires using a cluster of tens, hundreds or thousands of computers. Effectively using such clusters requires the use of distributed files systems, such as the Hadoop Distributed File System (HDFS) and corresponding computational models, such as Hadoop, MapReduce and Spark. In this course, part of the Data Science MicroMasters program, we will learn what the bottlenecks are in massive parallel computation and how to use spark to minimize these bottlenecks. We will learn how to perform supervised and unsupervised machine learning on massive datasets using the Machine Learning Library (MLlib).

In this course, as in the other ones in this MicroMasters program, we will gain hands-on experience using PySpark within the Jupyter notebooks environment.

#### Topics ####


    Programming Spark using Pyspark
    Identifying the computational tradeoffs in a Spark application
    Performing data loading and cleaning using Spark and Parquet
    Modeling data through statistical and machine learning methods
    
#### Course Outline ####
This is a ten-week course.

    (1) Memory Hierarchy, latency vs. throughput.
    (2) Spark Basics
    (3) Dataframes and SQL
    (4) PCA and weather analysis
    (5) K-means and intrinsic dimensions
    (6) Decision trees, boosting, and random forests
    (7) Neural Networks and TensorFlow    
",['PeterSchuld'],1,0.73,0,,,,,,1,,,,
108029105,MDEwOlJlcG9zaXRvcnkxMDgwMjkxMDU=,ucsd-graphs,pmadhukar/ucsd-graphs,0,pmadhukar,https://github.com/pmadhukar/ucsd-graphs,,0,2017-10-23 19:25:16+00:00,2017-10-23 19:27:19+00:00,2017-10-23 19:27:17+00:00,,11728,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"Original instructions in starter code provided by UC San Diego instructors:

unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)
",['pmadhukar'],1,0.73,0,,,,,,1,,,,
233121521,MDEwOlJlcG9zaXRvcnkyMzMxMjE1MjE=,html-kitchen-sink,ProfPowell/html-kitchen-sink,0,ProfPowell,https://github.com/ProfPowell/html-kitchen-sink,All of HTML5 in one big kitchen sink demo.,0,2020-01-10 20:02:35+00:00,2023-10-25 16:36:37+00:00,2022-03-01 17:39:38+00:00,,315,4,4,HTML,1,1,1,1,0,0,5,0,0,0,mit,1,0,0,public,5,0,4,main,1,,"# html-kitchen-sink

The all of HTML5 in one big kitchen sink demo! 

Provide simple examples of all the HTML tags with content that describes the purposes of the tags or constructs where possible.  The page is not meant to be realistic rather to provide a rapid yet complete overview of what is available in HTML.  While the demo is complete in basic coverage, for detailed coverage links are provided to associated specifications or element specific demos.

**Note**: This page is not meant to show proper usage, though it generally does not abuse HTML do not confuse syntax awareness with correct employment as they are two very different topics and the later is very contextual, subjective and will likely take significant effort to master.

This is parimarily a teaching repository in support of classes at UC San Diego including CSE110, CSE 112, CSE134B, CSE135 and any other classes where web technologies may be employed.  However, anyone interested in contributing or modifying content should create a pull request or speak to me tpowell2ucsd.edu about proposed changes.  

Planned Improvements
- [ ] More a11y emphasis
- [ ] Better demo for data-* attributes to promote use
- [ ] i18n content
- [ ] Encourage an initial translation to Mandarin for student support

","['ProfPowell', 'CamdynR', 'tpowell']",1,0.76,0,,,,,,1,,,,
271874428,MDEwOlJlcG9zaXRvcnkyNzE4NzQ0Mjg=,EarthQuake-Data-Visualization,psambalkar/EarthQuake-Data-Visualization,0,psambalkar,https://github.com/psambalkar/EarthQuake-Data-Visualization,,0,2020-06-12 19:24:09+00:00,2020-07-02 11:03:22+00:00,2020-07-02 11:03:18+00:00,,11653,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)




",['psambalkar'],1,0.75,0,,,,,,1,,,,
609800615,R_kgDOJFjRpw,Overview,pterameta/Overview,0,pterameta,https://github.com/pterameta/Overview,"Overview and map of the organization, for the UC San Diego course COGS138: Neural Data Science",0,2023-03-05 09:24:28+00:00,2023-12-20 20:48:54+00:00,2022-02-06 00:51:57+00:00,,1160,0,0,,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Overview

COGS 138 - Neural Data Science - is a class offered by the Cognitive Science Department of UC San Diego, taught by Professor Bradley Voytek and co-developed with Professor Ashley Juavinett. Here is an overview and map of the COGS 138 Organization, which hosts materials and assignments for the class.

## Syllabus

The most recent iteration of this class is the upcoming winter quarter 2022, the [**syllabus**](COGS138_Wi22.pdf) for which is in progress.

## Lectures

Slides and materials will be organized by week. Links to lecture slides and notebooks will be included here.

## Tutorials

We've begun to put together basic tutorials for core concepts [here](https://github.com/NeuralDataScience/Tutorials)

## Assignments

Assignments will (probably) be completed on [datahub.ucsd.edu](http://datahub.ucsd.edu).

## Readings

Suggested readings can be found on the [readings page](https://github.com/NeuralDataScience/Readings).

## Final Projects

A core component of the class is completing a final group project. You can see the past project from the Winter 2021 version of the class [here](https://github.com/NeuralDataScience/Projects/tree/main/Wi2021).

---

## A reminder about time:

These assignments are intermingled with your project proposal and final project (due finals week). This is an assignment-heavy course load to get you as much practice as possible. This will require good time management and planning on your part. Start planning ahead now to avoid late submissions and issues later in the quarter.
",['voytek'],1,0.82,0,,,,,,0,,,,
55026711,MDEwOlJlcG9zaXRvcnk1NTAyNjcxMQ==,cse110sp16,purag/cse110sp16,0,purag,https://github.com/purag/cse110sp16,"Our project for CSE 110, Spring 2016, UC San Diego",0,2016-03-30 02:41:56+00:00,2016-10-02 00:17:21+00:00,2016-06-05 08:32:48+00:00,,10440,2,2,Java,1,1,1,1,0,0,1,0,0,5,gpl-3.0,1,0,0,public,1,5,2,master,1,,"# cse110sp16
Our project for CSE 110, Spring 2016, UC San Diego
","['purag', 'LizIzhikevich', 'ProgrammingIncluded', 's1powers', 'nadahf', 'anjaliverma1']",1,0.69,0,,,,,,11,,,,
883563960,R_kgDONKoduA,qwer030413,qwer030413/qwer030413,0,qwer030413,https://github.com/qwer030413/qwer030413,My personal repo,0,2024-11-05 07:28:51+00:00,2024-11-05 07:32:13+00:00,2024-11-05 07:32:09+00:00,,3,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"## ðŸš€ About Me
Junior at the University of California, San Diego majoring in computer science.

<!--
**qwer030413/qwer030413** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working on ...
- ðŸŒ± Iâ€™m currently learning ...
- ðŸ‘¯ Iâ€™m looking to collaborate on ...
- ðŸ¤” Iâ€™m looking for help with ...
- ðŸ’¬ Ask me about ...
- ðŸ“« How to reach me: ...
- ðŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
",['qwer030413'],1,0.78,0,,,,,,1,,,,
284192499,MDEwOlJlcG9zaXRvcnkyODQxOTI0OTk=,UCSDGraph1,raghavgarg8376/UCSDGraph1,0,raghavgarg8376,https://github.com/raghavgarg8376/UCSDGraph1,,0,2020-08-01 05:18:16+00:00,2020-08-01 05:18:29+00:00,2020-08-01 05:18:26+00:00,,523,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,['raghavgarg8376'],1,0.68,0,,,,,,1,,,,
436041341,R_kgDOGf12fQ,roboflo,rekumar/roboflo,0,rekumar,https://github.com/rekumar/roboflo,Task scheduler for robotic systems that juggle many tasks in parallel across multiple stations.,0,2021-12-07 22:16:59+00:00,2024-08-11 10:01:36+00:00,2024-01-29 18:43:51+00:00,,693,8,8,Python,1,1,1,0,0,0,1,0,0,1,gpl-3.0,1,0,0,public,1,1,8,master,1,,"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/rekumar/roboflo/HEAD?labpath=.%2FExamples%2Fbasic%20usage.ipynb)
[![PyPI version](https://badge.fury.io/py/roboflo.svg)](https://badge.fury.io/py/roboflo)
[![codecov](https://codecov.io/gh/rekumar/roboflo/branch/master/graph/badge.svg?token=V3LPNLOJOG)](https://codecov.io/gh/rekumar/roboflo)

![roboflo](/docs/roboflo.png)

`pip install roboflo`

Task scheduler for any system with coordinated workers. The original use case is for the Perovskite Automated Spin-Coating Assembly Line (PASCAL) in the Fenning Lab at UC San Diego, where a robotic arm moves small glass slides between stations to perform experiments. 

`roboflo` assumes that you have a set of `Worker`'s that act (independently or in unison) to perform `Task`'s of set duration. Furthermore, one or more `Worker`'s can function to transition between `Task`'s (eg my robot moves a sample from the hotplate to a camera, or my mom moves me from school to soccer practice). These transition moves constitute a special case of `Task`'s , called `Transition`'s. The total set of `Worker`'s and `Transition`'s define your `System`. Sets of `Task`'s are consolidated into `Protocol`'s (eg the same process for five samples or five kids), which are then scheduled (using the `Scheduler` on your `System`) to minimize the total working time. An example schedule is shown below. 

Happy robot-ing!

![Example Schedule](/docs/exampleschedule.jpg)

PS - shoutout to [Taskpacker](https://github.com/Edinburgh-Genome-Foundry/Taskpacker), from which I drew heavy inspiration. `roboflo` carries much of the design philosophy from `Taskpacker`, but uses only Python packages (the backend is Google ORTools as opposed to Numberjack, which can be difficult to install especially on Windows). `roboflo` also introduces `Transitions`, which define a finite state machine, as a critical component in the workflow under the assumption that many robotic platforms involve workers whose specific jobs are to move things between other workers.

",['rekumar'],1,0.59,0,,,,,,1,,,,
57801379,MDEwOlJlcG9zaXRvcnk1NzgwMTM3OQ==,UCSDUnfoldingMaps,rohituppalapati/UCSDUnfoldingMaps,0,rohituppalapati,https://github.com/rohituppalapati/UCSDUnfoldingMaps,,0,2016-05-01 20:23:58+00:00,2016-05-01 20:24:14+00:00,2016-05-01 20:24:12+00:00,,11688,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,,['rohituppalapati'],1,0.66,0,,,,,,1,,,,
215650137,MDEwOlJlcG9zaXRvcnkyMTU2NTAxMzc=,UCSD-CSE202-Algorithms,Rshcaroline/UCSD-CSE202-Algorithms,0,Rshcaroline,https://github.com/Rshcaroline/UCSD-CSE202-Algorithms,,0,2019-10-16 21:45:57+00:00,2024-12-19 23:51:01+00:00,2019-12-10 16:54:52+00:00,http://algorithms.eng.ucsd.edu/cse202,13951,9,9,TeX,1,1,1,1,0,0,5,0,0,0,,1,0,0,public,5,0,9,master,1,,,['Rshcaroline'],1,0.74,0,,,,,,1,,,,
17991431,MDEwOlJlcG9zaXRvcnkxNzk5MTQzMQ==,R_functions,ruicarsa/R_functions,0,ruicarsa,https://github.com/ruicarsa/R_functions,PIL R,0,2014-03-21 19:21:00+00:00,2015-09-10 22:26:05+00:00,2014-08-25 21:57:20+00:00,,172,0,0,R,1,1,1,1,0,0,0,0,0,0,gpl-3.0,1,0,0,public,0,0,0,master,1,,,['ruicarsa'],1,0.74,0,,,,,,2,,,,
49956813,MDEwOlJlcG9zaXRvcnk0OTk1NjgxMw==,EarthquakeMap,s-leroux/EarthquakeMap,0,s-leroux,https://github.com/s-leroux/EarthquakeMap,"My project for ""Object Oriented Programming in Java"" by UCSD on Coursera ",0,2016-01-19 14:08:35+00:00,2016-01-19 14:11:39+00:00,2016-01-19 14:11:36+00:00,,11671,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)


",['s-leroux'],1,0.72,0,,,,,,1,,,,
329496882,MDEwOlJlcG9zaXRvcnkzMjk0OTY4ODI=,arranger,salu133445/arranger,0,salu133445,https://github.com/salu133445/arranger,"Official Implementation of ""Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music"" (ISMIR 2021)",0,2021-01-14 03:28:25+00:00,2025-01-01 11:14:38+00:00,2023-06-26 07:40:36+00:00,https://salu133445.github.io/arranger/,202668,58,58,Python,1,0,1,0,1,1,8,0,0,1,mit,1,0,0,public,8,1,58,main,1,,"# Arranger

This repository contains the official implementation of ""Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music"" (ISMIR 2021).

__Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music__<br>
Hao-Wen Dong, Chris Donahue, Taylor Berg-Kirkpatrick and Julian McAuley<br>
_Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)_, 2021<br>
[[homepage](https://salu133445.github.io/arranger/)]
[[paper](https://arxiv.org/pdf/2107.05916.pdf)]
[[video](https://youtu.be/-KncOGouAh8)]
[[slides](https://salu133445.github.io/arranger/pdf/arranger-ismir2021-slides.pdf)]
[[video (long)](https://youtu.be/RMhzOuHJ5UI)]
[[slides (long)](https://salu133445.github.io/arranger/pdf/arranger-research-exam-slides.pdf)]
[[code](https://github.com/salu133445/arranger)]

## Content

- [Content](#content)
- [Prerequisites](#prerequisites)
- [Directory structure](#directory-structure)
- [Data Collection](#data-collection)
- [Data Preprocessing](#data-preprocessing)
- [Models](#models)
- [Baseline algorithms](#baseline-algorithms)
- [Configuration](#configuration)
- [Citation](#citation)


## Prerequisites

You can install the dependencies by running `pipenv install` (recommended) or `python3 setup.py install -e .`. Python>3.6 is required.

## Directory structure

```text
â”œâ”€ analysis         Notebooks for analysis
â”œâ”€ scripts          Scripts for running experiments
â”œâ”€ models           Pretrained models
â””â”€ arranger         Main Python module
   â”œâ”€ config.yaml   Configuration file
   â”œâ”€ data          Code for collecting and processing data
   â”œâ”€ common        Most-common algorithm
   â”œâ”€ zone          Zone-based algorithm
   â”œâ”€ closest       Closest-pitch algorithm
   â”œâ”€ lstm          LSTM model
   â””â”€ transformer   Transformer model
```

## Data Collection

### Bach Chorales

```python
# Collect Bach chorales from the music21 corpus
import shutil
import music21.corpus

for path in music21.corpus.getComposer(""bach""):
    if path.suffix in ("".mxl"", "".xml""):
        shutil.copyfile(path, ""data/bach/raw/"" + path.name)
```

### MusicNet

```sh
# Download the metadata
wget -O data/musicnet https://homes.cs.washington.edu/~thickstn/media/musicnet_metadata.csv
```

### NES Music Database

```sh
# Download the dataset
wget -O data/nes http://deepyeti.ucsd.edu/cdonahue/nesmdb/nesmdb_midi.tar.gz

# Extract the archive
tar zxf data/nes/nesmdb_midi.tar.gz

# Rename the folder for consistency
mv nesmdb_midi/ raw/
```

### Lakh MIDI Dataset (LMD)

```sh
# Download the dataset
wget -O data/lmd http://hog.ee.columbia.edu/craffel/lmd/lmd_matched.tar.gz

# Extract the archive
tar zxf data/lmd/lmd_matched.tar.gz

# Rename the folder for consistency
mv lmd_matched/ raw/

# Download the filenames
wget -O data/lmd http://hog.ee.columbia.edu/craffel/lmd/md5_to_paths.json
```

## Data Preprocessing

> The following commands assume Bach chorales. You might want to replace the dataset identifier `bach` with identifiers of other datasets (`musicnet` for MusicNet, `nes` for NES Music Database and `lmd` for Lakh MIDI Dataset).

```sh
# Preprocess the data
python3 arranger/data/collect_bach.py -i data/bach/raw/ -o data/bach/json/ -j 1

# Collect training data
python3 arranger/data/collect.py -i data/bach/json/ -o data/bach/s_500_m_10/ -d bach -s 500 -m 10 -j 1
```

## Models

- LSTM model
  - `arranger/lstm/train.py`: Train the LSTM model
  - `arranger/lstm/infer.py`: Infer with the LSTM model
- Transformer model
  - `arranger/transformer/train.py`: Train the Transformer model
  - `arranger/transformer/infer.py`: Infer with the Transformer model

## Pretrained Models

Pretrained models can be found in the `models/` directory.

To run a pretrained model, please pass the corresponding command line options to the `infer.py` scripts. You may want to follow the commands used in the experiment scripts provided in `scripts/infer_*.sh`.

For example, use the following command to run the pretrained BiLSTM model with embeddings.

```sh
# Assuming we are at the root of the repository
cp models/bach/lstm/bidirectional_embedding/best_models.hdf5 OUTPUT_DIRECTORY
python3 arranger/lstm/infer.py \
  -i {INPUT_DIRECTORY} -o {OUTPUT_DIRECTORY} \
  -d bach -g 0 -bi -pe -bp -be -fi
```

The input directory (`INPUT_DIRECTORY`) contains the input JSON files, which can be generated by `muspy.save()`. The output directory (`OUTPUT_DIRECTORY`) should contain the pretrained model and will contain the output files. The `-d bach` option indicates that we are using the Bach chorale dataset. The `-g 0` option will run the model on the first GPU. The `-bi -pe -bp -be -fi` specifies the model options (run `python3 arranger/lstm/infer.py -h` for more information).

## Baseline algorithms

- Most-common algorithm
  - `arranger/common/learn.py`: Learn the most common label
  - `arranger/common/infer.py`: Infer with the most-common algorithm
- Zone-based algorithm
  - `arranger/zone/learn.py`: Learn the optimal zone setting
  - `arranger/zone/infer.py`: Infer with the zone-based algorithm
- Closest-pitch algorithm
  - `arranger/closest/infer.py`: Infer with the closest-pitch algorithm
- MLP model
  - `arranger/mlp/train.py`: Train the MLP model
  - `arranger/mlp/infer.py`: Infer with the MLP model

## Configuration

In `arranger/config.yaml`, you can configure the MIDI program numbers used for each track in the sample files generated. You can also configure the color of the generated sample piano roll visualization.

## Citation

Please cite the following paper if you use the code provided in this repository.

> Hao-Wen Dong, Chris Donahue, Taylor Berg-Kirkpatrick and Julian McAuley, ""Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music,"" _Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)_, 2021.

```bibtex
@inproceedings{dong2021arranger,
    author = {Hao-Wen Dong and Chris Donahue and Taylor Berg-Kirkpatrick and Julian McAuley},
    title = {Towards Automatic Instrumentation by Learning to Separate Parts in Symbolic Multitrack Music},
    booktitle = {Proceedings of the International Society for Music Information Retrieval Conference (ISMIR)},
    year = 2021,
}
```
",['salu133445'],1,0.64,0,,,,,,3,,,,
48147710,MDEwOlJlcG9zaXRvcnk0ODE0NzcxMA==,Kinematics-Laplacian-3D,sechaparroc/Kinematics-Laplacian-3D,0,sechaparroc,https://github.com/sechaparroc/Kinematics-Laplacian-3D,Kinematics 3D with Laplacian Deformation,0,2015-12-17 02:32:53+00:00,2023-07-30 19:08:07+00:00,2016-05-07 00:00:23+00:00,,30055,2,2,Java,1,1,1,1,0,0,3,0,0,1,,1,0,0,public,3,1,2,master,1,,,['sechaparroc'],0,0.61,0,,,,,,1,,,,
944267340,R_kgDOOEhgTA,sevendunn.github.io,sevendunn/sevendunn.github.io,0,sevendunn,https://github.com/sevendunn/sevendunn.github.io,,0,2025-03-07 04:01:18+00:00,2025-03-07 04:50:53+00:00,2025-03-07 04:50:50+00:00,,5,0,0,,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Seven Dunn
### Undergraduate - BS Physics (Specialization in Astrophysics)
### University of California, San Diego


#### Contact
###### Email: sevendastro[at]gmail.com

",['sevendunn'],1,0.72,0,,,,,,1,,,,
90966138,MDEwOlJlcG9zaXRvcnk5MDk2NjEzOA==,medical-imaging-datasets,sfikas/medical-imaging-datasets,0,sfikas,https://github.com/sfikas/medical-imaging-datasets,A list of Medical imaging datasets.,0,2017-05-11 10:14:19+00:00,2025-03-06 10:10:39+00:00,2024-09-12 13:11:08+00:00,,47,2350,2350,,1,1,1,1,0,0,422,0,0,1,,1,0,0,public,422,1,2350,master,1,,,"['sfikas', 'camlloyd', 'federikovi', 'super233', 'FMCalisto', 'fedorov', 'gabrielziegler3', 'Borda', 'radroof22', 'SantJay']",0,0.75,0,,,,,,60,,,,
820998751,R_kgDOMO9yXw,LLM-Inference-Acceleration,shishishu/LLM-Inference-Acceleration,0,shishishu,https://github.com/shishishu/LLM-Inference-Acceleration,LLM Inference with Deep Learning Accelerator.,0,2024-06-27 15:45:57+00:00,2025-02-28 02:57:52+00:00,2025-01-23 16:28:52+00:00,,5084,31,31,,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,31,main,1,,"# LLM-Inference-Acceleration

## Table of Contents

 - [About This Project](#about-this-project)
 - [Listing of Papers by Topics](#listing-of-papers-by-topics)
   - [Review](#review)
   - [Attention Mechanism](#attention-mechanism)
   - [Quantization](#quantization)
   - [KV Cache](#kv-cache)
   - [Continuous Batching](#continuous-batching)
   - [HW/SW Co-design](#hwsw-co-design)
   - [Framework/System/Architecture](#frameworksystemarchitecture)
   - [More](#more)

## About This Project
This project is dedicated to collecting and curating research papers focused on Large Language Model (LLM) inference acceleration. I hope to summarize and share the knowledge I gain during my self-learning journey.

It will be updated regularly. Contributions are welcome, so feel free to star or submit a pull request.

## Listing of Papers By Topics

Design Rule:
- Keywords: frequent academic terms for paper search.
- <mark>**Paper intro**: core idea/image with useful extensions are included for quick start. See example [[intro of SmoothQuant](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/smoothquant--accurate-and-efficient-post-training-quantization-for-large-language-models/README.md)].</mark>
- Citation: data for the papers is sourced from Google Scholar.

## Review
Last update of citation was on 28th July, 2024.

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|LLM Inference|**Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems**|[[pdf](https://arxiv.org/abs/2312.15234)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/review/towards-efficient-generative-large-language-model-serving--a-survey-from-algorithms-to-systems/README.md)]|CMU|2023.12|36|
|LLM Inference|**A survey on efficient inference for large language models**|[[pdf](https://arxiv.org/abs/2404.14294)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/review/a-survey-on-efficient-inference-for-large-language-models/README.md)]|THU,  Infinigence-AI, SJTU etc|2024.04|14|

## Attention Mechanism
Last update of citation was on 23rd Jan, 2025.

Upcoming topics include: FlashDecoding, QLoRA

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|MQA|**Fast Transformer Decoding: One Write-Head is All You Need**|[[pdf](https://arxiv.org/abs/1911.02150v1)]|Google|2019.11|340|
|GQA|**GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints** [EMNLP 2023]|[[pdf](https://arxiv.org/abs/2305.13245)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/gqa--training-generalized-multi-query-transformer-models-from-multi-head-checkpoints/README.md)]|Google|2023.05|489|
|ALiBi|**Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation** [ICLR 2022]|[[pdf](https://arxiv.org/abs/2108.12409)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/train-short--test-long--attention-with-linear-biases-enables-input-length-extrapolation/README.md)]|UW, Facebook, Allen Institute|2021.08|605|
|RoPE|**RoFormer: Enhanced Transformer with Rotary Position Embedding** [Neurocomputing 2024]|[[pdf](https://arxiv.org/abs/2104.09864)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/roformer--enhanced-transformer-with-rotary-position-embedding/README.md)]|Zhuiyi Technology|2021.04|1743|
|CoPE|**Contextual Position Encoding: Learning to Count What's Important**|[[pdf](https://arxiv.org/abs/2405.18719)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/contextual-position-encoding--learning-to-count-what-s-important/README.md)]|Meta|2024.05|20|
|FlashAttention|**FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness** [NeurIPS 2022]|[[pdf](https://arxiv.org/abs/2205.14135)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/flashattention--fast-and-memory-efficient-exact-attention-with-io-awareness/README.md)]|Stanford, University at Buffalo|2022.05|1658|
|FlashAttention2|**FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning**|[[pdf](https://arxiv.org/abs/2307.08691)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/flashattention-2--faster-attention-with-better-parallelism-and-work-partitioning/README.md)]|Princeton, Stanford|2023.07|706|
|Longformer|**Longformer: The Long-Document Transformer**|[[pdf](https://arxiv.org/abs/2004.05150)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/longformer--the-long-document-transformer/README.md)]|Allen Institute|2020.04|4577|
|Mistral|**Mistral 7B**|[[pdf](https://arxiv.org/abs/2310.06825)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/mistral-7b/README.md)]|Mistral|2023.10|1151|
|StreamingLLM, Attention Sinks|**Efficient Streaming Language Models with Attention Sinks** [ICLR 2024]|[[pdf](https://arxiv.org/abs/2309.17453)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/efficient-streaming-language-models-with-attention-sinks/README.md)]|MIT, Meta, CMU etc|2023.09|386|
|LoRA|**LoRA: Low-Rank Adaptation of Large Language Models** [ICLR 2022]|[[pdf](https://arxiv.org/abs/2106.09685)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/lora--low-rank-adaptation-of-large-language-models/README.md)]|Microsoft|2021.06|10000|
|LISA|**LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning**|[[pdf](https://arxiv.org/abs/2403.17919)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/lisa--layerwise-importance-sampling-for-memory-efficient-large-language-model-fine-tuning/README.md)]|HKUST, UIUC|2024.03|16|
|HydraLoRA|**HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning** [NIPS 2024]|[[pdf](https://arxiv.org/abs/2404.19245)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/hydralora--an-asymmetric-lora-architecture-for-efficient-fine-tuning/README.md)]|University of Macau, University of Texas at Austin, Cambridge|2024.04|8|
|MLA|**DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model**|[[pdf](https://arxiv.org/abs/2405.04434)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/deepseek-v2--a-strong--economical--and-efficient-mixture-of-experts-language-model/README.md)]| DeepSeek|2024.05|77|
|MFA|**Multi-matrix Factorization Attention**|[[pdf](https://arxiv.org/abs/2412.19255)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/multi-matrix-factorization-attention/README.md)]|StepFun, THU, FDU etc|2024.12|0|
|TPA|**Tensor Product Attention Is All You Need**|[[pdf](https://arxiv.org/abs/2501.06425)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/attention-mechanism/tensor-product-attention-is-all-you-need/README.md)]|THU|2025.01|0|

## Quantization
Last update of citation was on 5th July, 2024.

Upcoming topics include: QLoRA

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|LLM.int8|**LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale** [NeurIPS 2022]|[[pdf](https://arxiv.org/abs/2208.07339)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/llm.int8----8-bit-matrix-multiplication-for-transformers-at-scale/README.md)]|UW, Facebook, Hugging Face etc|2022.08|554|
|SmoothQuant|**SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models** [ICML 2023]|[[pdf](https://arxiv.org/abs/2211.10438)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/smoothquant--accurate-and-efficient-post-training-quantization-for-large-language-models/README.md)]|MIT, NVIDIA|2022.11|382|
|AWQ|**AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration** [MLSys 2024]|[[pdf](https://arxiv.org/abs/2306.00978)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/awq--activation-aware-weight-quantization-for-llm-compression-and-acceleration/README.md)]|MIT, SJTU, NVIDIA etc|2023.06|235|
|OneBit|**OneBit: Towards Extremely Low-bit Large Language Models**|[[pdf](https://arxiv.org/abs/2402.11295)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/onebit--towards-extremely-low-bit-large-language-models/README.md)]|THU, HIT|2024.02|4|
|OneBit|**The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**|[[pdf](https://arxiv.org/abs/2402.17764)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/quantization/the-era-of-1-bit-llms--all-large-language-models-are-in-1.58-bits/README.md)]|Microsoft, UCAS|2024.02|39|

## KV Cache
Last update of citation was on 25th July, 2024.

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|vLLM, PagedAttention|**Efficient Memory Management for Large Language Model Serving with PagedAttention** [SOSP 2023]|[[pdf](https://arxiv.org/abs/2309.06180)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/kv-cache/efficient-memory-management-for-large-language-model-serving-with-pagedattention/README.md)]|UC Berkeley, Stanford, UC San Diego|2023.09|496|


## Continuous Batching
Last update of citation was on 5th August, 2024.

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|Cellular Batching|**Low latency rnn inference with cellular batching** [EuroSys 2018]|[[pdf](https://madsys.cs.tsinghua.edu.cn/publication/low-latency-rnn-inference-with-cellular-batching/EUROSYS2018-gao.pdf)]|THU, NYU|2018.04|97|
|ORCA|**Orca: A Distributed Serving System for Transformer-Based Generative Models** [OSDI 2022]|[[pdf](https://www.usenix.org/conference/osdi22/presentation/yu)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/continuous-batching/orca--a-distributed-serving-system-for-transformer-based-generative-models/README.md)]|SNU, FriendliAI|2022.07|195|
|SARATHI|**SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills**|[[pdf](https://arxiv.org/abs/2308.16369)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/continuous-batching/sarathi--efficient-llm-inference-by-piggybacking-decodes-with-chunked-prefills/README.md)]|Microsoft, GIT|2023.08|36|

## HW/SW Co-design

## Framework/System/Architecture

## More
Last update of citation was on 8th August, 2024.

|Keywords | Title | Paper | Affiliation | Date | Citation|
|:---:|:---:|:---:|:---:|:---:|:---:|
|Block Transformer|**Block Transformer: Global-to-Local Language Modeling for Fast Inference**|[[pdf](https://arxiv.org/abs/2406.02657)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/more/block-transformer--global-to-local-language-modeling-for-fast-inference/README.md)]|KAIST, LG, Google|2024.06|2|
|TTT|**Learning to (Learn at Test Time): RNNs with Expressive Hidden States**|[[pdf](https://arxiv.org/abs/2407.04620)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/more/learning-to--learn-at-test-time---rnns-with-expressive-hidden-states/README.md)]|Stanford, UC San Diego, UC Berkeley etc|2024.07|3|
|LazyLLM|**LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference**|[[pdf](https://arxiv.org/abs/2407.14057)] [[intro](https://github.com/shishishu/LLM-Inference-Acceleration/blob/main/more/lazyllm--dynamic-token-pruning-for-efficient-long-context-llm-inference/README.md)]|Apple, Meta|2024.07||",['shishishu'],1,0.63,0,,,,,,1,,,,
558121688,R_kgDOIURC2A,Kd_NN_Distribution,SIO-Ocean-Optics-Research-Laboratory/Kd_NN_Distribution,0,SIO-Ocean-Optics-Research-Laboratory,https://github.com/SIO-Ocean-Optics-Research-Laboratory/Kd_NN_Distribution,,0,2022-10-26 23:53:54+00:00,2024-12-26 14:33:02+00:00,2024-05-21 16:43:32+00:00,,206,3,3,MATLAB,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,3,main,1,1,"# Kd_NN_Distribution
---
An implementation of the neural network algorithm created originally by Cedric Jamet and co-workers for estimating the K<sub>d</sub> values at any wavelength. This version of the Kd_NN model can produce K<sub>d</sub> at any wavelength (but currently recommended for the visible spectral range because no validation was carried out outside this range), using input R<sub>rs</sub> at five light wavelengths (443 nm, 488 nm, 531 nm, 547 nm, 667 nm) corresponding to spectral bands available on ocean color sensor MODIS. The complete development and validation of the original Kd_NN model is described in [Jamet et al., 2012](https://doi.org/10.1029/2012JC008076) and updated in [Loisel et al., 2018](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2017JC013632) and [Jorge et al., 2021](https://doi.org/10.1016/j.rse.2021.112537). The presented version of the Kd_NN model source code is in MATLAB file format. In this version of the Kd_NN code we introduced some changes with the primary purpose to streamline the structure of the code and facilitate its application by users. The Kd_NN software can be used in conjunction with the inverse reflectance LS2 model to enable estmation of the inherent optical properties of seawater (see the separate LS2_Distribution repository). 

This README document provides information about the files within the Kd_NN_Distribution repository.

---

## Kd_NN_MODIS.m:
Neural network model to compute the K<sub>d</sub> values at a single preselected output light wavelength for a given set of input values of spectral R<sub>rs</sub>(Î») and solar zenith angle, where Î» is at MODIS wavelengths. Returns K<sub>d</sub>(Î»). See supporting documentation for further details.

## Kd_NN_LUT_MODIS.mat:
Look-up tables (LUTs) necessary to run Kd_NN_MODIS.m. The structure contains three fields, each of which is necessary to run the neural network. See Kd_NN_MODIS.m function documentation for further details about the .mat file.

## Kd_NN_test_run_MODIS.m:
Script which tests Kd_NN_MODIS.m on 100 sample inputs of spectral R<sub>rs</sub>(Î») defined at MODIS bands, each accompanied with input solar zenith angle. The code calculates K<sub>d</sub> at output light wavelengths within the input domain. Note that the output light wavelength can be the same or can differ between the sample inputs, where a single sample input is defined by a set of five spectral values of R<sub>rs</sub>(Î») at MODIS wavelengths and solar zenith angle.

## Kd_NN_test_run_MODIS.xls:
Spreadsheet containing the input and resulting output data obtained from the application of the Kd_NN_MODIS function on 100 sample inputs to determine K<sub>d</sub> at various output wavelengths within the input domain. The file is the original output file generated by Kd_NN_test_run_MODIS.m.

---
Contributors: Matthew Kehrli, Aster Taylor, Rick A. Reynolds, and Dariusz Stramski\
Contacts: Matthew Kehrli<sup>1</sup> (mdkehrli@ucsd.edu | mdkehrli@gmail.com), Rick Reynolds<sup>1</sup> (rreynolds@ucsd.edu), Dariusz Stramski<sup>1</sup>  (dstramski@ucsd.edu), CÃ©dric Jamet<sup>2</sup> (cedric.jamet@univ-littoral.fr)\
<sup>1</sup> Ocean Optics Research Laboratory, Scripps Institution of Oceanography, University of California San Diego\
<sup>2</sup> Laboratoire dâ€™Oceanologie et de Geosciences, Universite du Littoral Cote dâ€™Opale, Universite Lille, CNRS, Wimereux, France
","['mdkehrli', 'dstramski']",1,0.7,0,,,,,,0,,,,
579872334,R_kgDOIpAmTg,Wizardry.Code,snafaru/Wizardry.Code,0,snafaru,https://github.com/snafaru/Wizardry.Code,Wizardry Proving Grounds v3.1 - Editing and Compiling WIZARDRY.CODE and SYSTEM.STARTUP - Apple II - UCSD Pascal 1.1,0,2022-12-19 06:29:34+00:00,2025-01-25 12:57:25+00:00,2024-07-17 23:40:43+00:00,,1025,32,32,,1,1,1,1,0,0,6,0,0,0,,1,0,0,public,6,0,32,main,1,,,['snafaru'],0,0.69,143,,,,,,4,,,,
300389478,MDEwOlJlcG9zaXRvcnkzMDAzODk0Nzg=,Object-Oriented-Java-UC_San-Diago,srajak892/Object-Oriented-Java-UC_San-Diago,0,srajak892,https://github.com/srajak892/Object-Oriented-Java-UC_San-Diago,All the projects files and assignments used in this Course,0,2020-10-01 18:50:10+00:00,2020-10-01 18:56:09+00:00,2020-10-01 18:56:07+00:00,,11965,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,," $$$$$$\                                                $$$$$$$\                          $$\       
$$  __$$\                                               $$  __$$\                         $$ |      
$$ /  \__|$$\   $$\ $$$$$$$\  $$$$$$$\  $$\   $$\       $$ |  $$ | $$$$$$\  $$\  $$$$$$\  $$ |  $$\ 
\$$$$$$\  $$ |  $$ |$$  __$$\ $$  __$$\ $$ |  $$ |      $$$$$$$  | \____$$\ \__| \____$$\ $$ | $$  |
 \____$$\ $$ |  $$ |$$ |  $$ |$$ |  $$ |$$ |  $$ |      $$  __$$<  $$$$$$$ |$$\  $$$$$$$ |$$$$$$  / 
$$\   $$ |$$ |  $$ |$$ |  $$ |$$ |  $$ |$$ |  $$ |      $$ |  $$ |$$  __$$ |$$ |$$  __$$ |$$  _$$<  
\$$$$$$  |\$$$$$$  |$$ |  $$ |$$ |  $$ |\$$$$$$$ |      $$ |  $$ |\$$$$$$$ |$$ |\$$$$$$$ |$$ | \$$\ 
 \______/  \______/ \__|  \__|\__|  \__| \____$$ |      \__|  \__| \_______|$$ | \_______|\__|  \__|
                                        $$\   $$ |                    $$\   $$ |                    
                                        \$$$$$$  |                    \$$$$$$  |                    
                                         \______/                      \______/                     

unfolding_app_template and UC San Diego/Coursera MOOC starter code
==================================================================

This is a skeleton to use Unfolding in Eclipse as well as some starter
code for the Object Oriented Programming in Java course offered by 
UC San Diego through Coursera.

A very basic Unfolding demo you'll find in the source folder in the default package. 
For more examples visit http://unfoldingmaps.org, or download the template with
examples.

The module folders contain the starter code for the programming assignments
associated with the MOOC.

Get excited and make things!


INSTALLATION

Import this folder in Eclipse ('File' -> 'Import' -> 'Existing Projects into
Workspace', Select this folder, 'Finish')


MANUAL INSTALLATION

If the import does not work follow the steps below.

- Create new Java project
- Copy+Paste all files into project
- Add all lib/*.jars to build path
- Set native library location for jogl.jar. Choose appropriate folder for your OS.
- Add data/ as src


TROUBLE SHOOTING

Switch Java Compiler to 1.6 if you get VM problems. (Processing should work with Java 1.6, and 1.7)




",['srajak892'],1,0.85,0,,,,,,1,,,,
95382258,MDEwOlJlcG9zaXRvcnk5NTM4MjI1OA==,AlgorithmicToolBox-UCSD,stalin18/AlgorithmicToolBox-UCSD,0,stalin18,https://github.com/stalin18/AlgorithmicToolBox-UCSD,This repository contains solutions to programming assignments of the course Algorithmic Toolbox by UC San Diego. Link: https://www.coursera.org/learn/algorithmic-toolbox/home/welcome,0,2017-06-25 19:50:57+00:00,2017-06-25 19:53:59+00:00,2017-06-26 06:54:30+00:00,,13,0,0,C++,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,,"# AlgorithmicToolBox-UCSD
This repository contains solutions to programming assignments of the course Algorithmic Toolbox by UC San Diego. Link: https://www.coursera.org/learn/algorithmic-toolbox/home/welcome
",['stalin18'],1,0.74,0,,,,,,1,,,,
388449308,MDEwOlJlcG9zaXRvcnkzODg0NDkzMDg=,DSE200x-Projects,Stewart-Robertson/DSE200x-Projects,0,Stewart-Robertson,https://github.com/Stewart-Robertson/DSE200x-Projects,Two projects done when first learning python for data science via UC San Diego on EdX,0,2021-07-22 12:10:04+00:00,2021-08-05 15:15:23+00:00,2021-08-05 15:15:20+00:00,,1357,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# DSE200x-Projects
Two projects done when first learning python for data science via UC San Diego on EdX

The projects use
* Python
* Pandas
* NumPy
* Matplotlib
* Scikit-Learn

Project 1

This one - CO2, Urbanisation, and GDP - was a simple ""mini-project"" undertaken in 2020. The aim was to use a publicly available dataset, structure some questions
and convey conclusions via a PowerPoint presentation. Analysis was done using python, NumPy, Pandas, and Matplotlib. The definition for the project was broad and any dataset
could be used.

I've uploaded both files in PDF format because the powerpoint presentation is attached at the end of the jupyter notebooks.

Project 2

This was a larger project and I wanted to use it as an opportunity to get some practice implementing simple machine learning algorithms for the first time.
It was similar to the first project in that the scope was fairly broad, as long as it was an original project with analysis done with python and asociated packages,
and conclusions conveyed via PowerPoint presentation.
",['Stewart-Robertson'],1,0.61,0,,,,,,1,,,,
41586132,MDEwOlJlcG9zaXRvcnk0MTU4NjEzMg==,EduMiP,StrawsonDesign/EduMiP,0,StrawsonDesign,https://github.com/StrawsonDesign/EduMiP,,0,2015-08-29 08:20:52+00:00,2024-01-12 11:27:32+00:00,2017-04-26 23:59:23+00:00,,98650,28,28,,1,1,1,1,0,0,11,0,0,2,,1,0,0,public,11,2,28,master,1,,,['StrawsonDesign'],1,0.77,0,,,,,,9,,,,
83347203,MDEwOlJlcG9zaXRvcnk4MzM0NzIwMw==,vehicle-and-lane-detection,sumitbinnani/vehicle-and-lane-detection,0,sumitbinnani,https://github.com/sumitbinnani/vehicle-and-lane-detection,Vehicle Detection using HOF Features,0,2017-02-27 19:17:36+00:00,2024-09-07 11:33:27+00:00,2023-02-22 19:02:21+00:00,,68429,3,3,Jupyter Notebook,1,1,1,1,0,0,5,0,0,0,,1,0,0,public,5,0,3,master,1,,"
# Vehicle Detection Project Report

***

_This file was generated using [this jupyter notebook](./Vehicle-Detection.ipynb) and code for the images used in this report can be found in the same._

## Goal and Objective
---

The goals / steps of this project are the following:

* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier.
* Optionally, you apply color transform and append binned color features, to HOG feature vector. 
* Train a classifier to disinguish between car and non-car images
* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.
* Run vehicle detection pipeline on a video stream and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.
* Estimate a bounding box for vehicles detected.

## Model Training
---
_The jupyter notebook containing code for model training can be [found here](./Vehicle-Detection-Model-Training.ipynb)._


### 1.  HOG features

The code for HOG feature extraction can be found in `./utils/featureExtraction.py`.  

I started by reading in all the `vehicle` and `non-vehicle` images.  Here is an example of one of each of the `vehicle` and `non-vehicle` classes:


![png](./output_images/output_3_1.png)


I then explored different color spaces and different `skimage.hog()` parameters (`orientations`, `pixels_per_cell`, and `cells_per_block`).  I grabbed random images from each of the two classes and displayed them to get a feel for what the `skimage.hog()` output looks like.

Here is an example using the `YCrCb` color space and HOG parameters of `orientations=8`, `pixels_per_cell=(8, 8)` and `cells_per_block=(2, 2)`:


![png](./output_images/output_5_1.png)


### 2. Feature Extraction for Model

I tried various combinations of color spaces and parameters before finally settling with following:

```
color_space = 'YCrCb'
spatial_size = (32, 32)
hist_bins = 32
orient = 9
pix_per_cell = 8
cell_per_block = 2
hog_channel = 'ALL'
spatial_feat = True
hist_feat = True
hog_feat = True
```

Increasing the orientation enhanced the accuarcy of the finally trained classifier, but increased the time required for computation.

The `color_space` was decided by training a classifier on different color spaces for spatial features, and `YCrCb` performed better than `RGB`, `HLS`, and `HSV`. 

### 3. Data Augmentation and Train-Test Split 

The images were fliped and added back to the directory containing original images as an augmentation step.

The `train_test_split` from `sklearn.model_selection` was used to randomized the data and make a 80-20% train-test split. The split was made so as to keep the ratio of vehicles and non-vehicles similar.

### 4. Model Training

The extracted features where fed to `LinearSVC` model of `sklearn` with default setting of `square-hinged` loss function and `l2` normalization. The trained model had accuracy of `99.47%` on test dataset. The SVC with rbf kernel performed better with accuracy of `99.78%` as compared to the LinearSVC but was very slow in predicting labels and hence was discarded.

The trained model along with the parameters used for training were written to a `pickle` file to be further used by vehicle detection pipeline.

** _Model training code can be [found here](./Vehicle-Detection-Model-Training.ipynb)._ **

## Vehicle Detection Pipeline
---

### 1. Sliding Window Search
A single function, `find_cars` in `./utils/featureExtraction.py`, is used to extract features using hog sub-sampling and make predictions. The hog sub-sampling helps to reduce calculation time for finding HOG features and thus provided higher throughput rate. A sample output from the same is shown below.

Code with multi-scale window search and heatmap to reduce false positives have been implemented in the class `VehicleDetector` in `./utils/vehicle_detector.py` and is discussed in upcoming sections.

![png](./output_images/output_10_1.png)


### 2. Multi-Scale Search

The scale for the multi-window search and overlap to be considered was decided emperically.

The multi-scale window approach prevents calculation of feature vectors for the complete image and thus helps in speeding up the process. The following scales were emperically decided each having a overlap of `75%` (decided by `cells_per_step` which is set as `2`):


Scale 1:
```
ystart = 380
ystop = 480
scale = 1
```

Scale 2:
```
ystart = 400
ystop = 600
scale = 1.5
```

Scale 3:
```
ystart = 500
ystop = 700
scale = 2.5
```

The figure below shows the multiple scales under consideration overlapped on image.


![png](./output_images/output_12_0.png)


### 3. Avoiding False Positives and Label Detection

#### A. Hard Data Mining
Falsely detected patch were explicitly used to create a negative example added to training set. The false positives were avoided by using wrongly classified examples and adding it to the training dataset.

#### B. Feature Selection
Using `YCrCb` color space, the number of false positives were stemmed.

#### C. Heatmaps and Label Detection
I recorded the positions of positive detections in each frame of the video.  From the positive detections I created a heatmap and then thresholded that map to identify vehicle positions.  I then used `scipy.ndimage.measurements.label()` to identify individual blobs in the heatmap.  I then assumed each blob corresponded to a vehicle.  I constructed bounding boxes to cover the area of each blob detected.  

![png](./output_images/output_14_1.png)


### 4. Search Optimization (Restricted Search)

The search was optimized by processing complete frames only once every 10 frames, and by having a restricted search in the remaining frames. The restricted search is performed by appending 50 pixel to the heatmap found in last three frames. Look at the implementation of `find_cars` method of `VehicleDetector` in `./utils/vehicle_detector.py`.

![png](./output_images/output_16_1.png)


## Video Implementation
---

### 1. Vehicle Detection
The youtube video of the final implementation can be accessed by clicking the following image link.

[![VehicleDetection](http://img.youtube.com/vi/cpCwpOtWZs8/0.jpg)](http://www.youtube.com/watch?v=cpCwpOtWZs8)


<video width=""960"" height=""540"" controls>
  <source src=""project_video_output_without_lanes.mp4"">
</video>


### 2. Simulateous Vehicle and Lane Detection 

The youtube video of the opional implementation of simultaneous vechicle and lane detection can be accessed by clicking the following image link. The code for the same can be accessed [here](./Simultaneous-Vehicle-and-Lane-Detection.ipynb).

[![VehicleDetection](http://img.youtube.com/vi/PkLdtqa_Qts/0.jpg)](http://www.youtube.com/watch?v=PkLdtqa_Qts)


## Discussion
---

A neural network based model might provided better results for the classification for vehicles. Also, [U-Net Segmentation](https://arxiv.org/abs/1505.04597) might provided superior results as compared to window-based search approach.

The developed pipeline may possibly fail in varied lighting and illumination conditions. Also, the multi-window search may be optimized further for better speed and accuracy.

## Cite
---
```
@book{binnani2019vision,
  title={Vision-based Autonomous Driving},
  author={Binnani, Sumit},
  year={2019},
  publisher={University of California, San Diego}
}
```
","['sumitbinnani', 'ryan-keenan']",1,0.67,0,,,,,,2,,,,
9355322,MDEwOlJlcG9zaXRvcnk5MzU1MzIy,SAGENext,sungwonnam/SAGENext,0,sungwonnam,https://github.com/sungwonnam/SAGENext,SAGENext: the next generation of SAGE,0,2013-04-10 20:29:52+00:00,2019-08-03 17:48:02+00:00,2013-05-29 03:53:51+00:00,,8710,2,2,C++,1,1,1,1,0,0,1,0,0,5,,1,0,0,public,1,5,2,master,1,,,"['sungwonnam', 'arthurnishimoto', 'ssathy2', 'MaximumWaffle']",1,0.68,0,,,,,,1,,,,
95954271,MDEwOlJlcG9zaXRvcnk5NTk1NDI3MQ==,flashcard-generator,TGoodson/flashcard-generator,0,TGoodson,https://github.com/TGoodson/flashcard-generator,UCSD homework.,0,2017-07-01 09:17:25+00:00,2017-07-01 09:23:31+00:00,2017-07-01 09:24:57+00:00,,5,0,0,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['TGoodson'],1,0.73,0,,,,,,0,,,,
170913537,MDEwOlJlcG9zaXRvcnkxNzA5MTM1Mzc=,CSE222A-CourseProject,TheSithPadawan/CSE222A-CourseProject,0,TheSithPadawan,https://github.com/TheSithPadawan/CSE222A-CourseProject,Course project for UCSD CSE222A,0,2019-02-15 18:57:03+00:00,2024-05-21 12:41:46+00:00,2019-04-14 16:48:36+00:00,,4039,2,2,Python,1,1,1,1,0,0,1,0,0,0,mit,1,0,0,public,1,0,2,master,1,,,"['TheSithPadawan', 'saurabhgoyaliitr']",1,0.58,0,,,,,,2,,,,
122658023,MDEwOlJlcG9zaXRvcnkxMjI2NTgwMjM=,Income-Prediction---UC-San-Diego,ToniPadilla/Income-Prediction---UC-San-Diego,0,ToniPadilla,https://github.com/ToniPadilla/Income-Prediction---UC-San-Diego,Income prediction project for UC San Diego Pyhton for Data Science course,0,2018-02-23 18:28:05+00:00,2018-02-23 18:28:05+00:00,2018-02-23 18:28:05+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],1,0.74,0,,,,,,0,,,,
109100839,MDEwOlJlcG9zaXRvcnkxMDkxMDA4Mzk=,Garnett-v2,ttsd-webmaster/Garnett-v2,0,ttsd-webmaster,https://github.com/ttsd-webmaster/Garnett-v2,A progressive web application for UCSD Theta Tau,0,2017-11-01 07:29:45+00:00,2024-11-20 07:54:13+00:00,2024-11-20 07:54:09+00:00,https://garnett-app.herokuapp.com,69580,0,0,JavaScript,1,1,1,1,0,0,3,0,0,31,,1,0,0,public,3,31,0,master,1,,,"['kaiserpk', 'simon-quach', '3605031', 'angelaa167', 'ClarkPhan', 'jwyan', 'desudhanvi', 'justin-chiang', 'DhanviDesu']",1,0.68,0,,,,,,7,,,,
79927475,MDEwOlJlcG9zaXRvcnk3OTkyNzQ3NQ==,MicrobeDS,twbattaglia/MicrobeDS,0,twbattaglia,https://github.com/twbattaglia/MicrobeDS,"A repository for large-scale microbiome datasets, formatted for phyloseq",0,2017-01-24 16:04:21+00:00,2025-02-20 01:47:28+00:00,2024-04-08 15:53:16+00:00,,163644,36,36,R,1,1,1,1,0,0,7,0,0,1,,1,0,0,public,7,1,36,master,1,,,['twbattaglia'],0,0.72,0,,,,,,4,,,,
225700385,MDEwOlJlcG9zaXRvcnkyMjU3MDAzODU=,ShipsDetection,twoSmallWong/ShipsDetection,0,twoSmallWong,https://github.com/twoSmallWong/ShipsDetection,,0,2019-12-03 19:37:07+00:00,2019-12-12 21:27:01+00:00,2019-12-12 21:26:59+00:00,,2847,1,1,Jupyter Notebook,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,1,master,1,,"# ShipsDetection: Exploring neural network architectures for locating ships in images
### Executable Files
For a quick demo, run the Jupyter Notebook `Demo.ipynb`.  
For a full training on the dataset, run the Jupyter Notebook `train.ipynb`.

### Requirements
The dataset can be downloaded on the kaggle competition website[1].  
In the notebooks, the following locations are referenced.  
Adapt the code or make sure to recreate the data structure:  
csv data for labels: `/datasets/ee285f-public/airbus_ship_detection/`  
training data: `/datasets/ee285f-public/airbus_ship_detection/train_v2/`  
test data: `/datasets/ee285f-public/airbus_ship_detection/test_v2/`  

To run the notebook, you need the following packages installed:
- tensorflow
- pytorch
- matplotlib
- pandas
- scikit.image
- scikit.learn

### ECE 285 Group Project Members
Jiacheng Hu
University of California San Diego  
jih135@ucsd.edu  
A91013815 

Kai Ye
University of California San Diego   
k1ye@eng.ucsd.edu  
A53309088 

Pu Cheng
University of California San Diego    
pucheng@eng.ucsd.edu
A53306940

Zhenyan Wang
University of California San Diego  
zhw028@ucsd.edu 
A53300836

### References
[1] - https://www.kaggle.com/c/airbus-ship-detection
","['twoSmallWong', 'ustc-pu']",1,0.8,0,,,,,,1,,,soc-ucsd,
86635028,MDEwOlJlcG9zaXRvcnk4NjYzNTAyOA==,mali-dual-crispr-pipeline,ucsd-ccbb/mali-dual-crispr-pipeline,0,ucsd-ccbb,https://github.com/ucsd-ccbb/mali-dual-crispr-pipeline,"This repository contains code for the dual-CRISPR screen analysis pipeline developed to analyze results from the dual-CRISPR screening system set up by the labs of Dr. Prashant Mali and Dr. Trey Ideker.  The software is developed by Amanda Birmingham and Roman Sasik of the Center for Computational Biology and Bioinformatics at the University of California, San Diego.",0,2017-03-29 22:27:31+00:00,2021-01-12 07:06:20+00:00,2017-10-03 06:04:21+00:00,,637668,4,4,Python,1,1,1,1,0,0,2,0,0,4,mit,1,0,0,public,2,4,4,master,1,1,"# Dual CRISPR Screen Analysis Quick-Start Guide
Amanda Birmingham, CCBB, UCSD (abirmingham@ucsd.edu)

## Table of Contents
* Installation
* Library Definition File Set-Up
* Count Pipeline Execution
* Score Pipeline Execution
* Appendix: Configuration File Modifications

## Installation

This software is provided through conda, a cross-platform package manager that performs installation and building of software packages with all their required dependencies, anc can be installed on any linux-64 or osx-64 platform. **Windows installation is not supported at this time.**

Download and run the installation script:

	curl https://raw.githubusercontent.com/ucsd-ccbb/mali-dual-crispr-pipeline/master/install_dual_crispr.sh -o install_dual_crispr.sh

    	bash install_dual_crispr.sh
	
	source ~/.bashrc

   * This may take several minutes, as many software libraries are being installed!


## Library Definition File Set-Up

Information about the library or libraries of dual CRISPR constructs used in the screen is provided to the pipeline in library definition files--a specially formatted tab-delimited text files created by the user.  These are placed in the `~/dual_crispr/library_definitions` directory, where the software automatically discovers them.  Additional details about these files are available on the pipeline's wiki at [https://github.com/ucsd-ccbb/mali-dual-crispr-pipeline/wiki/Library-Definition-Files](https://github.com/ucsd-ccbb/mali-dual-crispr-pipeline/wiki/Library-Definition-Files) .

### Requirements
1. Information about your dual CRISPR construct library, including unique construct ids, their target and constituent probe ids, and their probe sequences
2. A text editor such as TextEdit, vim, or emacs (do not use Word!)

### Steps
1. Create a new text file containing the following text:

		# library_name = TestLib
		# min_trimmed_grna_len = 19
		# max_trimmed_grna_len = 21
		construct_id	target_a_id	probe_a_id	probe_a_seq	target_b_id	probe_b_id	probe_b_seq

2. Replace ""TestLib"" with a short, easy-to-type name descriptive of your construct library
3. Replace ""19"" with the minimum allowable length for a detected gRNA sequence after trimming the scaffold sequences off a read; any trimmed read shorter than this length will be excluded from analysis
4. Replace ""21"" with the maxiumum allowable length for a detected gRNA sequence after trimming the scaffold sequences off a read; any trimmed read longer than this length will be excluded from analysis
5. On the line directly beneath the one starting with ""construct_id"", paste in the tab-separated columns of information about your library, with each line containing information about one construct

	* Tab-separated columns are the default format of data copied from Excel, making them easy to produce
	* Specifications for the seven required columns are:

		* `construct_id`: the unique name of the construct, specified in the format probe\_a\_id\_\_probe\_b\_id (e.g., `SMARCA4_chr19_11094819__BRD4_chr19_15376361`, or `NonTargetingControlGuideForHuman0352__SETD2_chr3_47142972`)
		* `target_a_id`: the identifier for the probe's target, usually a gene symbol (e.g., `SMARCA4`, `BRD4`, `SETD2`, `NonTargetingControlGuideForHuman0412`, etc.)
		* `probe_a_id`: the identifier for a specific probe, e.g., `SMARCA4_chr19_11094819`, `BRD4_chr19_15376361`, NonTargetingControlGuideForHuman0352`, `SETD2_chr3_47142972`, etc.)
		* `probe_a_seq`: the DNA-alphabet sequence of the gRNA of probe A, e.g. `TTCAGGGGAAGTATTACAAA`, `AAActgcaTAGCAAGTTgA`, etc.  Sequences may include only canonical DNA bases (A, C, G, and T).  While both upper and lower-case letters may be included, the sequence will be converted to all upper-case before use in the pipeline.
		* The specifications for target\_b\_id, probe\_b\_id, and probe\_b\_seq mirror those of target\_a\_id, probe\_a\_id, and probe\_a\_seq given above.

6. Save this file with the name of your choice and a `.txt` extension
7. Place it in your `~/dual_crispr/library_definitions` directory

	* It will now be available for you to reference when calling the counting and scoring pipelines described below

## Count Pipeline Execution

The count pipeline takes in raw fastq or fastq.gz files from the sequencing center.  It trims and length-filters the reads, then identifies and counts which constructs they represent, and creates output count and plot files.  Users can familiarize themselves with its products by running the count pipeline on a tiny sample dataset provided with the software installation, using the command

	count_dual_crispr CountTest TestLib ~/dual_crispr/test_data/test_set_1 ~/dual_crispr/test_outputs

### Requirements

1. Your user name and password for the FTP server on which your fastq data reside
2. The full URL of the folder on the FTP server in which your fastq data reside

### Steps

1. Create a directory for your fastq data and download it there

	* In the following commands, replacing `fastq_dir_name` everywhere with the name of this run (e.g., `160817_D00611_0339_BHWTT2BCXX`)
	* Replace XXXX and YYYY with the user name and password of the FTP server, and ZZZZ with the full URL of the folder in which the fastq data reside
	* Since fastq data are often large, ensure you make your new directory on a drive with adequate space to hold them!

			mkdir fastq_dir

			cd fastq_dir

			wget --user XXXX --password YYYY -nd ftp://ZZZZ/*.fastq.gz

	* Depending on how much data you have, this may take from a few minutes to a few hours!

2. Run the count pipeline script

	* Provide an alphanumeric-only name for your dataset in place of `dataset_name`, and input the recognized library name for the library used in your screen (e.g., ""CV4"") in place of `library_name`. Specify the complete path to the fastq directory you created above in place of `fastq_dir_path`, and the complete path to the directory in which you want the folder of output files to be created in place of `output_dir_path`

			count_dual_crispr dataset_name library_name fastq_dir_path output_dir_path

3.  Wait for the run to complete

	* This frequently takes several hours for a typical dataset

4.  After the run is complete, find the results directory

	* `cd` to the directory you input above as `output_dir_path`
	* Look for a folder whose name starts with the value you input above as `dataset_name` and ends with a timestamp suffix matching the timeframe of your most recent run (e.g., `MyTestDataset_20160804205646`)

5. At this point, you may continue to run the score pipeline below if desired


## Score Pipeline Execution

The score pipeline takes in counts files, such as those produced by the count pipeline.  It annotates them with the information needed by the scoring code, determines abundance thresholds, and then calculates fitness and pi scores, and creates output score and plot files. Users can familiarize themselves with its products by running the score pipeline on a tiny sample dataset provided with the software installation, using the command

	score_dual_crispr ScoreTest LargerTestLib ~/dual_crispr/test_data/test_set_6a,~/dual_crispr/test_data/test_set_6b 21,28 ~/dual_crispr/test_outputs --test

### Requirements

1. A file (or multiple files) containing the counts for all the samples in the experiment you wish to score, such as the `*_combined_counts.txt` file produced by the count pipeline

### Steps

1. Run the score pipeline script

	* As in the count pipeline, provide an alphanumeric-only name for your dataset in place of `dataset_name`, and input the recognized library name for the library used in your screen (e.g., ""CV4"") in place of `library_name`.  Replace `counts_fp_or_dir` with the path identified above in step 3; if wish to combine multiple counts files, you may provide multiple paths separated by commas **ONLY** (no spaces!) `day_timepoints_str` is a list, separated by commas **ONLY** only, providing--in order--the days on which timepoints were collected (e.g., 3,14,21,28). Provide the complete path to the directory in which you want the folder of output files to be created in place of `output_dir_path` .

			score_dual_crispr dataset_name library_name counts_fp_or_dir day_timepoints_str output_dir_path

2.  Wait for the run to complete

	* This usually takes between 20 minutes and an hour for a typical dataset


## Appendix: Configuration File Modifications

All user-configurable settings for the software that are not passed in through the command-line arguments are specified in the `config.txt` file locationed in the `~/dual_crispr` directory, including number of processors on which to run the pipeline, number of mismatches allowed in assigning reads to constructs, number of iterations performed when estimating the pi score, and so forth.  Novice users should probably avoid modifying this, as it is very sensitive to mistakes in spelling, capitalization, spacing, etc, but expert users will find that it allows great flexibility in modifying the parameters and behavior of the pipelines.  Additional information on settings specified in the configuration file   is availabe on the project wiki at [https://github.com/ucsd-ccbb/mali-dual-crispr-pipeline/wiki/Configuration-File](https://github.com/ucsd-ccbb/mali-dual-crispr-pipeline/wiki/Configuration-File).
",['AmandaBirmingham'],1,0.64,0,,,,,,5,,,,
624086810,R_kgDOJTLPGg,lecture1,ucsd-compilers-s23/lecture1,0,ucsd-compilers-s23,https://github.com/ucsd-compilers-s23/lecture1,,0,2023-04-05 18:04:40+00:00,2023-04-05 18:04:53+00:00,2023-06-09 16:13:59+00:00,,33,0,0,Rust,1,1,1,1,0,0,3,0,0,0,,1,0,0,public,3,0,0,main,1,1,,['jpolitz'],1,0.79,0,,,,,,4,,,,
696597339,R_kgDOKYU7Ww,cse12-pa1-Testing,ucsd-cse12-f23/cse12-pa1-Testing,0,ucsd-cse12-f23,https://github.com/ucsd-cse12-f23/cse12-pa1-Testing,,0,2023-09-26 04:20:12+00:00,2023-10-02 13:53:37+00:00,2023-09-26 04:20:31+00:00,,323,0,0,Java,1,1,1,0,0,0,4,0,0,0,,1,0,0,public,4,0,0,master,1,1,,"['ucsd-miranda', 'CheeryW', 'derek-hwang27']",1,0.81,0,,,,,,0,,,SIO-Ocean-Optics-Research-Laboratory,
778347158,R_kgDOLmSilg,ucsd-cse12-sp24.github.io,ucsd-cse12-sp24/ucsd-cse12-sp24.github.io,0,ucsd-cse12-sp24,https://github.com/ucsd-cse12-sp24/ucsd-cse12-sp24.github.io,,0,2024-03-27 14:53:51+00:00,2024-06-15 15:41:35+00:00,2024-06-15 15:41:32+00:00,,64880,0,0,Java,1,1,1,1,1,0,3,0,0,0,other,1,0,0,public,3,0,0,main,1,1,,"['ucsd-miranda', 'anmoldtu']",1,0.71,0,,,,,,0,,,,
634025628,R_kgDOJcp2nA,stringsearch-data,ucsd-cse15l-s23/stringsearch-data,0,ucsd-cse15l-s23,https://github.com/ucsd-cse15l-s23/stringsearch-data,,0,2023-04-28 20:58:53+00:00,2023-04-28 20:58:53+00:00,2023-04-28 21:00:12+00:00,,12129,0,0,,1,1,1,1,0,0,32,0,0,0,,1,0,0,public,32,0,0,main,1,1,,['jpolitz'],1,0.76,0,,,,,,1,,,,
457083985,R_kgDOGz6MUQ,grade-markdown-parse,ucsd-cse15l-w22/grade-markdown-parse,0,ucsd-cse15l-w22,https://github.com/ucsd-cse15l-w22/grade-markdown-parse,,0,2022-02-08 19:58:36+00:00,2023-11-09 22:05:40+00:00,2022-02-08 20:08:05+00:00,,0,0,0,Java,1,1,1,1,0,0,59,1,0,0,,1,0,0,public,59,0,0,main,1,1,,['jpolitz'],1,0.81,0,,,,,,1,,,,
250615413,MDEwOlJlcG9zaXRvcnkyNTA2MTU0MTM=,00-lambda,ucsd-cse230/00-lambda,0,ucsd-cse230,https://github.com/ucsd-cse230/00-lambda,,0,2020-03-27 18:35:18+00:00,2022-09-26 13:39:29+00:00,2023-09-26 20:21:35+00:00,,18,0,0,Haskell,1,1,1,1,0,0,5,0,0,0,mit,1,1,0,public,5,0,0,master,1,1,,"['ranjitjhala', 'michaelborkowski', 'rosekunkel', 'gokhankici']",1,0.77,0,,,,,,2,,,,
274459523,MDEwOlJlcG9zaXRvcnkyNzQ0NTk1MjM=,ml-mangrove,UCSD-E4E/ml-mangrove,0,UCSD-E4E,https://github.com/UCSD-E4E/ml-mangrove,Machine Learning Development and code for the Mangrove Monitoring Project,0,2020-06-23 16:46:38+00:00,2025-02-15 02:13:43+00:00,2025-02-15 02:13:40+00:00,,166500,13,13,Jupyter Notebook,1,1,1,1,0,0,2,0,0,9,,1,0,0,public,2,9,13,master,1,1,,"['dillhicks', 'gagewrye', 'mpham8', 'Jasonnyang', 'ElijahZY', 'scole02', 'Skylar-Shi', 'dependabot[bot]', 'Azhou2023', 'Scorpio11Rain']",1,0.84,0,,,,,,9,,,,
274459291,MDEwOlJlcG9zaXRvcnkyNzQ0NTkyOTE=,web-mangrove,UCSD-E4E/web-mangrove,0,UCSD-E4E,https://github.com/UCSD-E4E/web-mangrove,,0,2020-06-23 16:45:24+00:00,2021-02-08 19:30:35+00:00,2023-07-23 21:04:58+00:00,,192794,2,2,CSS,1,1,1,1,0,0,2,0,0,13,,1,0,0,public,2,13,2,master,1,1,,"['nicolemeister', 'dillhicks', 'paulpan05', 'dependabot[bot]', 'tianhengMa']",1,0.84,0,,,,,,10,,,,
221539429,MDEwOlJlcG9zaXRvcnkyMjE1Mzk0Mjk=,datahub-example-notebook,ucsd-ets/datahub-example-notebook,0,ucsd-ets,https://github.com/ucsd-ets/datahub-example-notebook,,0,2019-11-13 19:50:44+00:00,2024-09-24 21:49:14+00:00,2024-09-24 21:49:11+00:00,,47,13,13,Dockerfile,1,1,1,1,0,0,22,0,0,0,,1,1,0,public,22,0,13,main,1,1,,"['davidzyx', 'RockfordMankiniUCSD', 'dtandersen', 'wesuuu', 'matthewf-ucsd', 'pjamason']",1,0.78,0,,,,,,7,,,,
756253223,R_kgDOLROCJw,2024Spring,UCSD-Historical-Enrollment-Data/2024Spring,0,UCSD-Historical-Enrollment-Data,https://github.com/UCSD-Historical-Enrollment-Data/2024Spring,Spring 2024 Enrollment Data @ UCSD,0,2024-02-12 09:45:47+00:00,2024-05-29 04:19:59+00:00,2024-05-29 04:19:27+00:00,,19598231,0,0,,1,1,1,0,0,0,2,0,0,0,,1,0,0,public,2,0,0,main,1,1,,['rybplayer'],1,0.71,0,,,,,,0,,,,
137826011,MDEwOlJlcG9zaXRvcnkxMzc4MjYwMTE=,public_html,UCSD-SUMS/public_html,0,UCSD-SUMS,https://github.com/UCSD-SUMS/public_html,UCSD SUMS website.,0,2018-06-19 01:41:09+00:00,2020-10-08 06:55:59+00:00,2020-10-08 06:55:57+00:00,http://sums.ucsd.edu,204776,0,0,HTML,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,1,,"['dleestat', 'zhangjunhao0', 'TheDocTrier']",1,0.71,0,,,,,,1,,,,
18184201,MDEwOlJlcG9zaXRvcnkxODE4NDIwMQ==,Decorator,UCSD/Decorator,0,UCSD,https://github.com/UCSD/Decorator,Give Web developers across campus an easy way to build pages that have the UC San Diego branding and include the visual identity standards.,0,2014-03-27 17:10:55+00:00,2019-08-09 06:22:15+00:00,2025-03-06 01:28:29+00:00,,36324,2,2,HTML,1,1,1,1,0,0,4,0,0,6,,1,0,0,public,4,6,2,master,1,1,,"['a6wu', 'chorta', 'misteroh']",1,0.82,71,,,,,,6,,,,
141606204,MDEwOlJlcG9zaXRvcnkxNDE2MDYyMDQ=,2018-09-14-UCSDLC,ucsdlib/2018-09-14-UCSDLC,0,ucsdlib,https://github.com/ucsdlib/2018-09-14-UCSDLC,,0,2018-07-19 16:37:51+00:00,2018-09-17 15:41:31+00:00,2018-09-17 15:41:32+00:00,https://ucsdlib.github.io/2018-09-14-UCSDLC/,2997,0,0,Python,1,1,1,1,1,0,2,0,0,2,other,1,0,0,public,2,2,0,gh-pages,1,1,,"['rgaiacs', 'fmichonneau', 'wking', 'U2NG', 'abbycabs', 'maxim-belkin', 'anenadic', 'willingc', 'katrinleinweber', 'gdevenyi', 'jduckles', 'pbanaszkiewicz', 'maneesha', 'lexnederbragt', 'drlabratory', 'ethanwhite', 'andreww', 'DamienIrving', 'lmichael107', 'jiffyclub', 'dlebauer', 'mawds', 'konrad', 'vahtras', 'PBarmby', 'tomwright01', 'tracykteal', 'abought', 'wclose', 'neon-ninja', 'mr-c', 'ErinBecker', 'jsta', 'widdowquinn', 'stopfstedt', 'Spaxe', 'mckays630', 'brainstorm', 'synesthesiam', 'mkcor', 'lzamparo', 'zonca', 'anelda', 'arokem', 'bhjolly', 'brandoncurtis', 'evanwill', 'IanLee1521', 'iglpdc', 'JasonJWilliamsNY', 'jstaf', 'pipitone', 'bast', 'palderman', 'pbieberstein', 'olgabot', 'davis68', 'MikeTrizna', 'mikej888', 'mfoos', 'mstimberg', 'lmweber', 'marwahaha', 'aaren', 'remram44', 'sclayton29', 'sritchie73', 'souravsingh', 'gawbul', 'timtomch', 'twhitehead', 'yashasvigirdhar', 'cengel', 'jcoliver', 'naught101', 'godfoder', 'agngrant', 'alee', 'amyrhoda', 'andrewsanchez', 'aprokop', 'arfon', 'ahmadia', 'benwaugh', 'BinxiePeterson', 'bkatiemills', 'ctb', 'caseyyoungflesh', 'dpshelio', 'embray', 'fperez', 'gregcaporaso', 'jnothman', 'jdblischak', 'qjcg', 'jonc125', 'jlehtoma', 'jules32']",1,0.81,0,"---
layout: page
title: ""Contributor Code of Conduct""
---
As contributors and maintainers of this project,
we pledge to follow the [Carpentry Code of Conduct][coc].

Instances of abusive, harassing, or otherwise unacceptable behavior
may be reported by following our [reporting guidelines][coc-reporting].

{% include links.md %}
","# Contributing

[Software Carpentry][swc-site] and [Data Carpentry][dc-site] are open source projects,
and we welcome contributions of all kinds:
new lessons,
fixes to existing material,
bug reports,
and reviews of proposed changes are all welcome.

## Contributor Agreement

By contributing,
you agree that we may redistribute your work under [our license](LICENSE.md).
In exchange,
we will address your issues and/or assess your change proposal as promptly as we can,
and help you become a member of our community.
Everyone involved in [Software Carpentry][swc-site] and [Data Carpentry][dc-site]
agrees to abide by our [code of conduct](CONDUCT.md).

## How to Contribute

The easiest way to get started is to file an issue
to tell us about a spelling mistake,
some awkward wording,
or a factual error.
This is a good way to introduce yourself
and to meet some of our community members.

1.  If you do not have a [GitHub][github] account,
    you can [send us comments by email][contact].
    However,
    we will be able to respond more quickly if you use one of the other methods described below.

2.  If you have a [GitHub][github] account,
    or are willing to [create one][github-join],
    but do not know how to use Git,
    you can report problems or suggest improvements by [creating an issue][issues].
    This allows us to assign the item to someone
    and to respond to it in a threaded discussion.

3.  If you are comfortable with Git,
    and would like to add or change material,
    you can submit a pull request (PR).
    Instructions for doing this are [included below](#using-github).

## Where to Contribute

1.  If you wish to change the template used for workshop websites,
    please work in <https://github.com/swcarpentry/workshop-template>.
    The home page of that repository explains how to set up workshop websites,
    while the extra pages in <https://swcarpentry.github.io/workshop-template>
    provide more background on our design choices.

2.  If you wish to change CSS style files, tools,
    or HTML boilerplate for lessons or workshops stored in `_includes` or `_layouts`,
    please work in <https://github.com/swcarpentry/styles>.

## What to Contribute

There are many ways to contribute,
from writing new exercises and improving existing ones
to updating or filling in the documentation
and and submitting [bug reports][issues]
about things that don't work, aren't clear, or are missing.
If you are looking for ideas,
please see [the list of issues for this repository][issues],
or the issues for [Data Carpentry][dc-issues]
and [Software Carpentry][swc-issues] projects.

Comments on issues and reviews of pull requests are just as welcome:
we are smarter together than we are on our own.
Reviews from novices and newcomers are particularly valuable:
it's easy for people who have been using these lessons for a while
to forget how impenetrable some of this material can be,
so fresh eyes are always welcome.

## What *Not* to Contribute

Our lessons already contain more material than we can cover in a typical workshop,
so we are usually *not* looking for more concepts or tools to add to them.
As a rule,
if you want to introduce a new idea,
you must (a) estimate how long it will take to teach
and (b) explain what you would take out to make room for it.
The first encourages contributors to be honest about requirements;
the second, to think hard about priorities.

We are also not looking for exercises or other material that only run on one platform.
Our workshops typically contain a mixture of Windows, macOS, and Linux users;
in order to be usable,
our lessons must run equally well on all three.

## Using GitHub

If you choose to contribute via GitHub,
you may want to look at
[How to Contribute to an Open Source Project on GitHub][how-contribute].
In brief:

1.  The published copy of the lesson is in the `gh-pages` branch of the repository
    (so that GitHub will regenerate it automatically).
    Please create all branches from that,
    and merge the [master repository][repo]'s `gh-pages` branch into your `gh-pages` branch
    before starting work.
    Please do *not* work directly in your `gh-pages` branch,
    since that will make it difficult for you to work on other contributions.

2.  We use [GitHub flow][github-flow] to manage changes:
    1.  Create a new branch in your desktop copy of this repository for each significant change.
    2.  Commit the change in that branch.
    3.  Push that branch to your fork of this repository on GitHub.
    4.  Submit a pull request from that branch to the [master repository][repo].
    5.  If you receive feedback,
        make changes on your desktop and push to your branch on GitHub:
        the pull request will update automatically.

Each lesson has two maintainers who review issues and pull requests
or encourage others to do so.
The maintainers are community volunteers,
and have final say over what gets merged into the lesson.

## Other Resources

General discussion of [Software Carpentry][swc-site] and [Data Carpentry][dc-site]
happens on the [discussion mailing list][discuss-list],
which everyone is welcome to join.
You can also [reach us by email][contact].

[contact]: mailto:admin@software-carpentry.org
[dc-issues]: https://github.com/issues?q=user%3Adatacarpentry
[dc-lessons]: http://datacarpentry.org/lessons/
[dc-site]: http://datacarpentry.org/
[discuss-list]: http://lists.software-carpentry.org/listinfo/discuss
[github]: http://github.com
[github-flow]: https://guides.github.com/introduction/flow/
[github-join]: https://github.com/join
[how-contribute]: https://egghead.io/series/how-to-contribute-to-an-open-source-project-on-github
[issues]: https://github.com/swcarpentry/workshop-template/issues/
[repo]: https://github.com/swcarpentry/workshop-template/
[swc-issues]: https://github.com/issues?q=user%3Aswcarpentry
[swc-lessons]: http://software-carpentry.org/lessons/
[swc-site]: http://software-carpentry.org/
",,,"Please delete the text below before submitting your contribution. 

---

Thanks for contributing! If this contribution is for instructor training, please send an email to checkout@carpentries.org with a link to this contribution so we can record your progress. Youâ€™ve completed your contribution step for instructor checkout just by submitting this contribution.  

Please keep in mind that lesson maintainers are volunteers and it may be some time before they can respond to your contribution. Although not all contributions can be incorporated into the lesson materials, we appreciate your time and effort to improve the curriculum.  If you have any questions about the lesson maintenance process or would like to volunteer your time as a contribution reviewer, please contact Kate Hertweck (k8hertweck@gmail.com).  

---
",7,,,,
118272741,MDEwOlJlcG9zaXRvcnkxMTgyNzI3NDE=,UCSD-Schedule-Planner,ucsdscheduleplanner/UCSD-Schedule-Planner,0,ucsdscheduleplanner,https://github.com/ucsdscheduleplanner/UCSD-Schedule-Planner,A project to help UCSD students plan their schedules quickly and easily.,0,2018-01-20 19:11:55+00:00,2023-06-01 19:22:28+00:00,2022-12-10 01:34:34+00:00,https://sdschedule.com/,71086,7,7,JavaScript,1,1,1,1,1,0,2,0,0,51,mit,1,0,0,public,2,51,7,master,1,1,,"['CTrando', 'dmhacker', 'ctrandotest', 'cyberay01', 'snowme34']",1,0.86,0,,,,,,5,,,,
467803217,R_kgDOG-IcUQ,ECE277-GPU-WI21,udaymallappa/ECE277-GPU-WI21,0,udaymallappa,https://github.com/udaymallappa/ECE277-GPU-WI21,UCSD ECE277 GPU Programming coursework: GPU-accelerated reinforcement learning on CUDA C with Nsight System,0,2022-03-09 06:22:06+00:00,2025-01-20 15:51:14+00:00,2021-08-17 00:14:23+00:00,,17333,7,7,,0,1,1,1,0,0,5,0,0,0,,1,0,0,public,5,0,7,main,1,,,['evawyf'],1,0.76,0,,,,,,0,,,,
831574,MDEwOlJlcG9zaXRvcnk4MzE1NzQ=,pd-vanilla,umlaeute/pd-vanilla,0,umlaeute,https://github.com/umlaeute/pd-vanilla,clone of miller puckette's puredata,0,2010-08-11 17:37:05+00:00,2024-08-24 07:54:42+00:00,2017-02-21 16:25:38+00:00,http://puredata.info,22501,19,19,C,1,1,1,1,0,0,13,0,0,0,other,1,0,0,public,13,0,19,master,1,,,"['millerpuckette', 'umlaeute', 'eighthave', 'chr15m', 'rectang', 'gusano', 'x37v', 'claudeha', 'ch-nry', 'reduzent', 'antlauzon']",1,0.72,0,,,,,,4,,,,
128833675,MDEwOlJlcG9zaXRvcnkxMjg4MzM2NzU=,UC-San-Diego-Wifi-Map,v1nnyc/UC-San-Diego-Wifi-Map,0,v1nnyc,https://github.com/v1nnyc/UC-San-Diego-Wifi-Map,spring 18 project,0,2018-04-09 21:05:30+00:00,2018-06-06 19:32:23+00:00,2018-06-06 19:32:21+00:00,,35207,0,0,JavaScript,1,1,1,1,0,0,0,0,0,1,,1,0,0,public,0,1,0,master,1,,"UC San Diego WiFi Map
====

An application developed for COGS121/CSE170 Human-Computer Interaction Programming Studio 2018 at UC San Diego. Built with Node.js, Bootstrap, and JQuery.

### Link to video (2 min):
https://www.youtube.com/watch?v=ApUqfNJw81Q

### Source Code files:
- create_database.js
	- file for creating the database that containing all location data
- home.html
	- front-end code for home screen (and pop up screen)
- titlePage.html
	- front-end code for title screen
- app.js
	- set up the environment, routing for connecting to front-end
- addSpeed.js
	- add user locations & internet speed to database, close popup and populates text
- home.js
	- change networks, record lists, reference markers, call APIs etc.
- titlePage.js
	- set Google map as background for title page
- style.css
	- styling for UI elements
- markers.db
	- database for the map markers
","['aliaawni', 'thidang', 'tammydesigns']",1,0.85,0,,,,,,2,,,,
79139536,MDEwOlJlcG9zaXRvcnk3OTEzOTUzNg==,Curso_BiologyMeetsProgramming,vencejo/Curso_BiologyMeetsProgramming,0,vencejo,https://github.com/vencejo/Curso_BiologyMeetsProgramming,"Materiales del curso Curso Introductorio Biology Meets Programming: Bioinformatics for Beginners - University of California, San Diego | Coursera",0,2017-01-16 16:58:57+00:00,2017-01-26 12:45:14+00:00,2017-06-13 10:53:32+00:00,,7958,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Curso_BiologyMeetsProgramming
Materiales del curso Curso Introductorio Biology Meets Programming: Bioinformatics for Beginners - University of California, San Diego | Coursera
",['vencejo'],1,0.62,0,,,,,,1,,,,
10978350,MDEwOlJlcG9zaXRvcnkxMDk3ODM1MA==,crisp,vibansal/crisp,0,vibansal,https://github.com/vibansal/crisp,Code for multi-sample variant calling from sequence data of pooled or unpooled DNA samples,0,2013-06-26 20:29:36+00:00,2024-10-09 19:38:52+00:00,2024-10-09 19:38:49+00:00,,3708,19,19,C,1,1,1,1,0,0,9,0,0,7,mit,1,0,0,public,9,7,19,master,1,,"################################################################################################

CRISP: Comprehensive Read Analysis for Identification of SNVs (and short indels) from Pooled sequencing data

Contact: Vikas Bansal, vibansal@ucsd.edu

Citation: 

A statistical method for the detection of variants from next-generation resequencing of DNA pools, V. Bansal. Bioinformatics 26(12), 2010

Efficient and Cost Effective Population Resequencing by Pooling and In-Solution Hybridization. V. Bansal et al. PloS ONE 2011. 


#################################################################################################

Introduction:
=============

CRISP is a software program to detect SNPs and short indels from pooled sequencing data. CRISP is designed to detect both rare and common variants by utilizing sequence reads from next-generation sequencing of multiple DNA pools. CRISP uses a cross-pool comparison approach to distinguish sequencing errors from rare variants. Note that the method is not designed for variant detection from a single pool. CRISP has been evaluated on several pooled sequencing datasets (human and bacterial) generated using the Illumina sequencing platform. In principle, it should work for sequence data from other sequencing platforms. The method requires each pool to be sequenced using the same sequencing platform. 



Installation
=============

CRISP is implemented in C and uses the SAMtools API for reading BAM files. The source code for samtools is included in the source code (subdirectory samtools). Samtools requires certain libraries (libncurses-dev) to compile. Typing ""make all"" should compile both samtools and the CRISP source code. The compiled executable 'CRISP.binary' should be in the 'bin' subfolder. CRISP has been tested on Debian & Ubuntu Linux.  


Running CRISP:
=============


The first step is to align the reads from the sequencing experiment to the reference genome using BWA (or your favorite aligner) and generate sorted BAM file for each pool. To improve detection of indels, it is recommended to run an indel realigner program (such as GATK) to realign reads and generate a realigned BAM file. Once a single bam file for each pool is generated, CRISP can be run on the BAM files to detect variants by comparing against a reference sequence. 

./CRISP [options] --bams file_bam_paths --ref reference.fasta --VCF variantcalls.VCF --poolsize poolsize --bed targets.bed > variantcalls.log


***Important Notes:***

1. CRISP requires at least four arguments: poolsize, reference fasta file, bamfiles and the output VCF file
2. BAM files can be specified in two ways: 
	(a) --bams: list of all bam files in a single text file
	(b) --bam: specify individual bam files on the command line 
3. The reference sequence file should be indexed using 'samtools faidx' and the index file reference.fasta.fai placed in the same directory as reference.fasta
4. For targeted sequencing studies, it is recommended to use a bed file for variant calling. If a bedfile is not specified, the program will evaluate each base in the genome for variant calling.

4. CRISP requires at least two pools to make variant calls, but at least 5 pools are recommended. CRISP should be run separately on pools sequenced on different sequencing instruments.

5. The number of haplotypes in each pool (--poolsize) is assumed to be the same. For variable poolsizes, the poolsize should be specified inn the input file with the list of bam files (see FAQ for details on the format).
   
6. CRISP can be parallelized by calling variants on specific chromosomes (or regions) using the --regions option. This requires the bam files to be indexed. 


Command-line arguments for CRISP
================================

         --bams         textfile with list of bam file paths (one for each pool)
         --bam          bam file for one pool, specify filename for each pool using --bam pool1.bam --bam pool2.bam .... --bam pooln.bam
         --ref       	Indexed Reference Sequence file (fasta)
	 --bed		bedfile with intervals in which variants will be called
         --poolsize     poolsize (number of haploid genomes in each pool), for diploid genomes: 2 x # individuals
         --VCF       	VCF file to which the variant calls will be output 
         --qvoffset  	quality value offset, 33 for Sanger format, 64 for Illumina 1.3+ format
         --mbq       	minimum base quality to consider a base for variant calling, default 10
         --mmq       	minimum read mapping quality to consider a read for variant calling, default 20
         --regions      region(s) in which variants will be called, e.g chr1:654432-763332. BAM files should be indexed for this option with the index file pooln.bam.bai 
         --minc      	minimum number of reads with alternate allele required for calling a variant, default 4
         --ctpval    	threshold on the contingency table p-value for calling position as variant (specified as log10), default is -3.5, increase this threshold as number of pools increases
         --qvpval    	threshold on the quality values based p-value for calling position as variant (specified as log10), default is -5
         --perms     	maximum number of permutations for calculating contingency table p-value, default 20,000
	 --filterreads  filter reads with excessive number of mismatches (and gaps) compared to the reference sequence, Default is 1. Set to 0 to disable filtering 



Output VCF file:
================

CRISP outputs the variants identified to a VCF file. For each variant, CRISP outputs the allele depth (read counts) for the reference and variant alleles at each poisition in the VCF file. This can be used for calculating allele frequencies or doing case-control association analysis. Multi-allelic variants and indels are also reported.

Update: the latest version of CRISP outputs genotypes for each pool (--EM 1, default) as allele counts. The CRISP VCF can be converted to a standard pooled genotype VCF using a script provided in the scripts sub-directory. 

Description of fields
=====================

NP: Number of Pools With Data
VP: Number of Pools with variant allele(s)
DP: Total number of reads (+strand,-strand) across all pools (filtered reads only)
CT: contingency table p-value for each variant allele in same order as listed in column 5
QVpf (QVpr): quality values based p-value for each variant allele using forward(reverse) strand reads 
MQ: number of reads with mapping qualities <10 | 10-19 |  20-39 |  >=40 
VT: variant type, SNV | DELETION | INSERTION 
HP: length in the ambiguity of positioning of indels (homopolymer length or microsatellite length)
FLANKSEQ: This represents the reference haplotype sequence (length spans the homopolymer or microsatellite tract) with 10 bases either side of the variant position (10bases_upstream:reference_haplotype_sequence:10bases_downstream). This is useful to eyeball indels that occur in long homopolymer or microsatellite tracts.

SB: variant demonstrates strand bias
PASS: variant passes all filters 

AF: frequency of variant alleles(s) in the pool in order listed in column 5
ADf: Number of reads aligned to the forward strand of the genome supporting reference allele and the alternate alleles in the order listed
ADr: Number of reads aligned to the reverse strand of the genome supporting reference allele and the alternate alleles in the order listed

Please note that some of these fields may be removed/updated in future releases. 








","['vibansal', 'mys721tx']",1,0.54,0,,,,,,5,,,,
567410436,R_kgDOIdH_BA,bimm143,vichau04/bimm143,0,vichau04,https://github.com/vichau04/bimm143,bioinformatics at UCSD,0,2022-11-17 18:23:45+00:00,2022-12-05 05:07:49+00:00,2022-12-05 05:24:11+00:00,,902,0,0,HTML,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['vichau04'],1,0.6,0,,,,,,1,,,ucsd-progsys,acmucsd
130061656,MDEwOlJlcG9zaXRvcnkxMzAwNjE2NTY=,UCSDUnfoldingMaps,visland/UCSDUnfoldingMaps,0,visland,https://github.com/visland/UCSDUnfoldingMaps,"Monitor worldwide earthquakes and visualize information (magnitude, depth, location, etc.) in a world map, using UnfoldingMaps library.",0,2018-04-18 12:50:45+00:00,2021-10-14 01:17:10+00:00,2018-04-18 12:53:24+00:00,,11662,1,1,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,1,master,1,,,[],1,0.76,0,,,,,,0,,,,
241071859,MDEwOlJlcG9zaXRvcnkyNDEwNzE4NTk=,PhDissertation,vmalis/PhDissertation,0,vmalis,https://github.com/vmalis/PhDissertation,PhD in Physics UCSD,0,2020-02-17 09:49:54+00:00,2023-01-28 11:26:55+00:00,2020-03-16 20:00:10+00:00,,127970,0,0,TeX,1,1,1,1,0,0,0,1,0,0,mit,1,0,0,public,0,0,0,master,1,,,[],1,0.62,0,,,,,,1,,,,
590725817,R_kgDOIzXCuQ,Awesome-EdgeAI,wangxb96/Awesome-EdgeAI,0,wangxb96,https://github.com/wangxb96/Awesome-EdgeAI,"Resources of our survey paper ""Optimizing Edge AI: A Comprehensive Survey on Data, Model, and System Strategies""",0,2023-01-19 03:41:26+00:00,2025-03-06 09:03:49+00:00,2025-01-08 10:12:56+00:00,,3813,75,75,,1,1,1,1,0,0,7,0,0,0,mit,1,0,0,public,7,0,75,main,1,,,['wangxb96'],0,0.67,0,,,,,,2,,,,
83093737,MDEwOlJlcG9zaXRvcnk4MzA5MzczNw==,CSE231-LLVM-Project,WenbinZhu/CSE231-LLVM-Project,0,WenbinZhu,https://github.com/WenbinZhu/CSE231-LLVM-Project,UCSD CSE231 Advanced Compiler - LLVM project,0,2017-02-25 00:14:49+00:00,2023-10-30 05:53:59+00:00,2017-03-28 17:56:25+00:00,,24,12,12,C++,1,1,1,1,0,0,11,0,0,0,,1,0,0,public,11,0,12,master,1,,,['WenbinZhu'],1,0.61,0,,,,,,1,,,,
547873143,R_kgDOIKfhdw,Hyper-Spec,wh-xu/Hyper-Spec,0,wh-xu,https://github.com/wh-xu/Hyper-Spec,A Python library for fast mass spectra clustering.,0,2022-10-08 13:16:49+00:00,2025-02-16 08:26:44+00:00,2024-07-02 04:43:19+00:00,,984,8,8,Python,1,1,1,1,0,0,8,0,0,0,bsd-3-clause,1,0,0,public,8,0,8,main,1,,"[![License bsd-3-clause](https://badgen.net/badge/license/BSD-3/red)](https://github.com/wh-xu/Hyper-Spec/blob/main/LICENSE)
[![JPR](https://img.shields.io/badge/JPR-2023-informational)](https://pubs.acs.org/doi/full/10.1021/acs.jproteome.2c00612)

HyperSpec: Ultra-fast Mass Spectra Clustering in Hyperdimensional Space
=======================================================

<p align=""center"">
    <img src=""./img/logo.png"" width=""400"">
</p>


_HyperSpec_ is a Python library that supports extremely fast spectra clustering. _HyperSpec_ adopts the brain-inspired hyperdimensional (HD) computing to project the spectra data into binary hyperdimensional space to obtain better clustering quality and faster clustering speed. _HyperSpec_ shortens the runtime on the draft human proteome dataset with 25 million spectra from a few hours to <15 minutes. The software is available as open-source under the BSD license.


System Requirements
------------------------------------------------------

_HyperSpec_ requires `Python 3.8+` with `CUDA` environment. A GPU should be installed properly. _HyperSpec_ has been tested on two types of NVIDIA GPUs on a Linux platform, including GTX 1080Ti and GTX 3090. 

- Clustering for PXD000561 dataset requires GTX 3090 with larger memory
- Clustering for other dataset with smaller scale requires GTX 1080Ti

Other NVIDIA GPUs should support but need further test. We recommend using high-performance SSD as the storage device for the best performance.

Installation
------------------------------------------------------

Install via Docker
*********************

We recommend installing _HyperSpec_ via docker using the following command:

    docker build --no-cache -f ./docker/Dockerfile -t hyper_spec .
    docker run --gpus all -v /ms-dataset/:/dataset/ -it hyper_spec /bin/bash

Install from Source
*********************

    git https://github.com/wh-xu/Hyper-Spec.git
    sh install.sh

Usage and Example
------------------------------------------------------

    usage: python src/main.py [-h] [--cpu_core_preprocess CPU_CORE_PREPROCESS] [--cpu_core_cluster CPU_CORE_CLUSTER]
                [--batch_size BATCH_SIZE] [--use_gpu_cluster] [--min_peaks MIN_PEAKS]
                [--mz_interval MZ_INTERVAL] [--min_mz_range MIN_MZ_RANGE] [--min_mz MIN_MZ] [--max_mz MAX_MZ] 
                [--remove_precursor_tol REMOVE_PRECURSOR_TOL] [--min_intensity MIN_INTENSITY]
                [--max_peaks_used MAX_PEAKS_USED] [--scaling {off,root,log,rank}] [--hd_dim HD_DIM] [--hd_Q HD_Q] [--hd_id_flip_factor HD_ID_FLIP_FACTOR]
                [--cluster_charges [CLUSTER_CHARGES ...]] 
                [--precursor_tol PRECURSOR_TOL PRECURSOR_TOL] [--rt_tol RT_TOL] [--fragment_tol FRAGMENT_TOL] [--eps EPS]
                [--cluster_alg {dbscan,hc_single,hc_complete,hc_average}]
                [--refine REFINE]
                [--checkpoint CHECKPOINT] [--representative_mgf]
                input_filepath output_filename

    Positional arguments:
    input_filepath          The path containing the `MGF` files for raw spectra data
    output_filename         Output CSV file that stores the clustering results.

    Optional arguments:
    -h, --help                  Show the help messages
    --cpu_core_preprocess       The number of CPU cores used for preprocessing. (default: 6)
    --cpu_core_cluster          The number of CPU cores used for clustering. 
                                Only enable when `use_gpu_cluster` is True. (default: 6)
    --batch_size                The batch size for HD encoding on GPU. (default: 5000)
    --use_gpu_cluster           Flag that determines whether to use DBSCAN 
                                on GPU. (default: True)
    --hd_dim                    The HD dimension. (default: 2048)
    --hd_Q                      The HD quantization level. (default: 16)
    --cluster_charges           The charges to be clustered. (default: 2 3)
    --cluster_alg               Select DBSCAN or hierarchical clustering algorithm (including dbscan, hc_single, hc_complete, and hc_average) for spectra (default: hc_complete) 
    --eps                       The threshold value `eps` for DBSCAN clustering. 
                                (default: 0.4)
    --refine                    Flag to determine whether refine the clustering results.
                                (default: True)
    --representative_mgf        Flag to determine whether exporting the clustering representatives.
                                (default: False)
    --checkpoint                The checkpoint filename to save the encoded HVs of spectra (default: None)


_HyperSpec_ supports running using the command line and takes `MGF` peak files as input and exports the clustering result as a CSV file with each MS/MS spectrum and its cluster label on a single line. Here we provide two examples of running _HyperSpec_:

### Example 1

    python src/main.py ~/dataset/ ./output.csv  --cpu_core_preprocess=4 --cluster_alg dbscan --use_gpu_cluster --cluster_charges 2 3 --eps=0.2 --refine

This will cluster all MS/MS spectra in folder `~/dataset/` on `GPU` and generate the `output.csv` file. The number of CPU cores for preprocessing is `4`. Only `Charge 2` and `Charge 3` are clustered in this configuration. The DBSCAN clustering threshold is `eps=0.2` and post-clustering refinement is `enable`.

### Example 2

    python src/main.py ~/dataset/ ./output.csv  --cpu_core_preprocess=4 --cluster_alg hc_complete --cluster_charges 2 3 --eps=0.25 --refine

This will cluster all MS/MS spectra in folder `~/dataset/` using `hierarchical clustering with complete linkage` on `CPU` and generate the `output.csv` file. The number of CPU cores for preprocessing is `4`. Only `Charge 2` and `Charge 3` are clustered in this configuration. The hierarchical clustering threshold is `eps=0.25` and post-clustering refinement is `enable`.

Exported results format
------------------------------------------------------
The exported meta data for clustering results are compressed and stored in `parquet` file, which records `bucket`, `precursor_charge`, `precursor_mz`, `identifier`, `scan`, `retention_time`, `cluster`, and `is_representative` information. The format is given as:

|bucket|precursor_charge|precursor_mz|identifier|scan                              |retention_time|cluster   |is_representative|
|------|----------------|------------|----------|----------------------------------|--------------|----------|-----------------|
|598   |2               |300.148804  |Adult_Gallbladder_bRP_Elite_53_f07|338                               |165.133194    |664       |True             |
|5384  |3               |1796.564697 |Fetal_Ovary_bRP_Velos_41_f18|4875                              |2896.885986   |4455302   |False            |


How HyperSpec Works
------------------------------------------------------

<p align=""center"">
    <img src=""./img/tog.png"" width=""600"">
</p>

1. _HyperSpec_ first encodes the processed spectra into binary hypervector (HV) with ultra-high dimension (>1000) based on level-id encoding method. The encoding module is implemented and optimized for GPU for shorter runtime.
2. The entire dataset is divided into small buckets and the pairwise Hamming distance matrix for each bucket is computed. _HyperSpec_ implements very efficient Hamming distance computation kernels on GPU.
3. _HyperSpec_ finally clusters each spectra bucket using DBSCAN algorithm. Thanks HD computing's lightweight computation and powerful data presentation capability, _HyperSpec_ achieves significant speedup over other spectra clustering tools. Most of spectra datasets can be clustered within a few minutes.


Publication
------------------------------------------------------
1. Xu, Weihong, Jaeyoung Kang, Wout Bittremieux, Niema Moshiri, and Tajana Rosing. ""HyperSpec: Ultrafast Mass Spectra Clustering in Hyperdimensional Space."" [Journal of Proteome Research (2023)](https://pubs.acs.org/doi/full/10.1021/acs.jproteome.2c00612).
2. Sumukh Pinge, Weihong Xu, Jaeyoung Kang, Tianqi Zhang, Niema Moshiri, Wout Bittremieux, and Tajana Rosing. ""SpecHD: Hyperdimensional Computing Framework for FPGA-Based Mass Spectrometry Clustering."" [Design, Automation & Test in Europe Conference & Exhibition (DATE) 2024](https://ieeexplore.ieee.org/abstract/document/10546776).


Contact
------------------------------------------------------

For more information, post an issue or send an email to <wexu@ucsd.edu>.
",['wh-xu'],1,0.67,0,,,,,,2,,,,
259769768,MDEwOlJlcG9zaXRvcnkyNTk3Njk3Njg=,PostProcessForecasts,WillyChap/PostProcessForecasts,0,WillyChap,https://github.com/WillyChap/PostProcessForecasts,Beta for Pangeo Postprocessing,0,2020-04-28 22:52:08+00:00,2022-05-04 00:02:38+00:00,2020-06-02 23:45:16+00:00,,1357,5,5,Jupyter Notebook,1,1,1,1,0,0,6,0,0,0,,1,0,0,public,6,0,5,master,1,,"
# Weather Forecasts for Machine Learning Post-processing 

### A Repository for the Rapid Development of Machine Learning Post-Processing Methods. 

### Associated Publications: 

 -- If you are using this data, please cite: --

1) Towards Implementing AI Post-processing in Weather and Climate: Proposed Actions from the Oxford 2019 Workshop.


2) Chapman, William E.; Lerch, Sebastian; Kirkwood, Charlie; Subramanian, Aneesh C.; Matsueda, Mio; Haupt, Sue E. (2020). Postprocessing model V 1.0. In Data for: Towards Implementing AI Post-processing in Weather and Climate: Proposed Actions from the Oxford 2019 Workshop. UC San Diego Library Digital Collections. https://doi.org/10.6075/J08S4NDM


## Downloading the Data: 

<pre><code> wget https://library.ucsd.edu/dc/object/bb88449405/_2_1.zip/download
</code></pre>

then export the path to this data directory: 
<pre><code> 
export POST_PROCESS_FORECASTS_DATA=/Path/To/Unzipped/File/All_Zarr
</code></pre>

### Conda Environment: 

We recommend using the package_spec_file.txt and anaconda to set up your anaconda environment: 

Download and install anaconda here: 

https://docs.anaconda.com/anaconda/install/

Then run:

<pre><code> 
conda create --name <env> --file package_spec_file.txt
</code></pre>

Additionally, if you run into the weird situation where your notebook server won't run in the project's venv and will not load the venv's version of python containing xarray and all of the other ML packages.  This is a known bug. You can remedy this by editing /anaconda3/share/jupyter/kernels/python3/kernel.json to point to the venv path.  This is described in this StackOverflow thread in case you run into it.  See Wrong kernel configuration: Kernel is configured to use system Python.

https://stackoverflow.com/questions/58068818/how-to-use-jupyter-notebooks-in-a-conda-environment

### File Organization: 
The file download will be a folder called ""All_Zarr"", which contains 21 seperate Zarr file structures. 

See the *notebooks* folder jupyter notebooks for easy ingest of a specific data set, and gain access to metrics of comparison. We recommend starting with */notebooks/Post_IVT_GFS.ipynb* for deterministic or spatially gridded forecast, and */notebooks/PostProcess_ECMWFt2m.ipynb* for ensemble methods.


## Data Descriptions: 

This data set contains 5 seperate forecasted weather fields along with the verifying values, all packaged in a clean format. 
The descriptions are as follows. The notebooks contain simple ways to download and methods to benchmark against. The goal is for rapid development of statistical methods to improve our global weather forecasts. The forecasts include: 


#### 1.1 MJO Ensemble Forecasts

Files are from 8 modeling centers [CMA, CMC, CPTEC, ECMF, JMA, KMA, NCEP, UKMO] 

The zarr path has the type All_Zarr/MJO_XXXXzar where XXXX represents the center (e.g. ./All_Zarr/MJO_ECMWFzar )

We also include a database of climate variability modes identified from six separate operational weather forecast models for more than a decade worth of forecasts. The Madden-Julian Oscillation (MJO - Madden and Julian 1977, 1994), a dominant intraseasonal mode of variability in the Tropics and a significant source of predictability globally on subseasonal timescales, has been identified using statistical techniques on forecast variables. We use the zonal winds at 850 hPa, 200 hPa and outgoing longwave radiation from both the forecast models and observations to diagnose the MJO and evaluate its forecast skill. 

#### 1.2 PNA Ensemble Forecasts

Files are from 8 modeling centers [CMA, CMC, CPTEC, ECMF, JMA, KMA, NCEP, UKMO]

The zarr path has the type All_Zarr/PNA_XXXXzar where XXXX represents the center (e.g. ./All_Zarr/MJO_ECMWFzar )


Similarly, the Pacific North American pattern which is a large-scale weather pattern over the Pacific Northwest region has been identified using the geopotential height field (Wallace and Gutzler 1981) in both observations and model forecasts. These datasets are provided as benchmark datasets for training post-processing algorithms to improve forecasts of these large scale modes of variability and concomitantly subseasonal forecast skill of other related weather patterns.  


#### 1.3 Global Forecast System Integrated Vapor Transport 
Files are from the NCEP GFS model, and has 3 forecast lead times (006hr,048hr,168hr) 
The zarr path has the type All_Zarr/GFSIVT_FXXX_zarr where XXXX represents forecast lead (e.g. ./All_Zarr/GFSIVT_F048_zarr )


GFS predictions (Moorthi et al., 2001) at a 0.5â€degree horizontal spatial resolution on 64 vertical levels for daily 0000 and 1200 UTC model initializations are utilized to calculate the forecasted magnitude of integrated vapor transport (IVT). IVT is a combined momentum and thermodynamic metric which integrates specific humidity and u and v components of the wind speed from 1000 to 300 hpa. Here we present three forecast lead times of 1-day, 2-days, and 1 week from 2006 to 2018. This includes ~8000 data ï¬elds for every forecast lead time or ~24,000 forecasted ï¬elds across all lead times. The region of interest spans coastal North America and the Eastern Paciï¬c from 180Â°W to 110Â°W longitude, and 10Â°N to 60Â°N latitude. IVT from the National Aeronautics and Space Administration's Modern-Era Retrospective Analysis for Research and Applications version 2 (MERRA-2) reanalysis is also packaged and serves as ground truth data. MERRA-2 data are resolved on a 0.625 x 0.5 degree grid and interpolated to 21 pressure levels between 1000 and 300 hpa for IVT calculation (Gelaro et al. 2017; McCarty et al., 2016). For consistency, GFS predictions are then remapped to this grid resolution using a 1st and second order conservative remapping scheme. Further details can be found in Chapman et al 2019. 
 
#### 1.4 ECMWF Two-Meter Temperature Ensemble over Germany 
Files are from the ECMWF 51 member ensemble, and contains 048hr forecast's of T2m 

The zarr path has the type All_Zarr/ECMWFt2m_zar

 
An example of short-range forecasts and verifying observations is a dataset of temperature observations at 537 stations over Germany and predictors derived from the ECMWF ensemble prediction system from 2007 to 2016. Predictors are mean and standard deviation of 48-hour ahead 50-member ECMWF ensemble forecasts of temperature and optimally interpolated to station locations. The corresponding observations (valid at 00UTC) are obtained from surface synoptic observations stations operated by the German weather service. Details (including a list of predictors) are available in Rasp and Lerch (2018).
 
#### 1.5 UK surface road conditions
Files are from the UKMO ensemble, and contains road temperature conditions in the UK 

The zarr path has the type All_Zarr/Hrly_RoadForecast_zarr

 
This dataset contains numerical weather prediction forecasts from all models in the UK Met Office's Road Surface Temperature (MORST) forecasting system, along with corresponding road network temperature observations from Highways England. Data are provided for four random sites (location undisclosed) and spans 98 days from mid-December 2018 to late March 2019 on an hourly forecast lead basis from 0 to 168 hours. Ground truth data are provided by the road surface temperature observed at the road network weather station for the concurrent forecast time. The dataset spans 2342 forecasting hours for each of the four sites. Spanning all lead times and owing to the fact that a multitude of forecasts are made for each hour by the time it is observed, the dataset spans over 1.34 million forecasts.


Acronym key:
---
T2m  = Two Meter Temperature 

MJO = Madden Julian Oscillation

PNA = Pacific North American Pattern 

GFS = Global Forecast System 

CMA = China Meteorological Administration

CMC = Canadian Meteorological Center

CPTEC = Center for Weather Forecasting and Climate Studies (Brazil)

ECMWF = European Center for Medium Range Weather Forecasting 

JMA = Japanese Meteorological Agency

KMA = Korean Meteorological Agency

NCEP = National Center for Environmental Prediction

UKMO = United Kingdom Meteorological Office





",['WillyChap'],1,0.6,0,,,,,,2,,,,
97460369,MDEwOlJlcG9zaXRvcnk5NzQ2MDM2OQ==,OgreIK,wuv-ogre/OgreIK,0,wuv-ogre,https://github.com/wuv-ogre/OgreIK,An inverse kinetics wrapper for ogre of BussIK,0,2017-07-17 09:43:16+00:00,2020-08-12 17:02:35+00:00,2017-07-17 11:02:18+00:00,,17,1,1,C++,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,1,master,1,,"# OgreIK
An inverse kinetics wrapper for ogre of BussIK (written by Samuel R. Buss)

BussIK is part of the bullet physics engine and can be found under thieir examples/ThirdPartyLibs, 

or from the authors site

http://www.math.ucsd.edu/~sbuss/ResearchWeb/ikmethods/index.html
",['wuv-ogre'],1,0.71,0,,,,,,1,,,AlexandrovLab,
434801321,R_kgDOGeqKqQ,230hw,WZZ1998/230hw,0,WZZ1998,https://github.com/WZZ1998/230hw,UCSD CSE230 Homework,0,2021-12-04 03:57:55+00:00,2021-12-04 03:57:56+00:00,2017-01-06 03:53:26+00:00,,573,0,0,,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['kaiwensun'],1,0.7,0,,,,,,1,,,,
296471515,MDEwOlJlcG9zaXRvcnkyOTY0NzE1MTU=,Data_Structures_and_Algorithms,xwilchen/Data_Structures_and_Algorithms,0,xwilchen,https://github.com/xwilchen/Data_Structures_and_Algorithms,assignments of Data Structures and Algorithms from UC San Diego on Coursera,0,2020-09-18 00:20:57+00:00,2020-10-17 21:21:35+00:00,2020-10-17 21:21:33+00:00,,5469,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Data_Structures_and_Algorithms
This repo stores my assignments of Data Structures and Algorithms from UC San Diego on Coursera
",['xwilchen'],1,0.84,0,,,,,,1,,,,
413931899,R_kgDOGKwZew,Quantized_Neural_Nets,YixuanSeanZhou/Quantized_Neural_Nets,0,YixuanSeanZhou,https://github.com/YixuanSeanZhou/Quantized_Neural_Nets,"Code to implement the experiments in ""Post-training Quantization for Neural Networks with Provable Guarantees"" by Jinjie Zhang, Yixuan Zhou, and Rayan Saab (2022).",0,2021-10-05 18:16:53+00:00,2024-12-23 08:10:04+00:00,2023-06-02 16:56:59+00:00,,130872,11,11,Python,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,11,main,1,,"# Post-training Quantization for Neural Networks with Provable Guarantees

#### Authors: [Jinjie Zhang](https://jayzhang0727.github.io/) (jiz003@ucsd.edu), [Yixuan Zhou](https://yixuanseanzhou.github.io/) (yiz044@ucsd.edu) and [Rayan Saab](https://mathweb.ucsd.edu/~rsaab/) (rsaab@ucsd.edu)

## Overview 
This directory contains code necessary to run a post-training neural-network quantization method GPFQ, that
is based on a greedy path-following mechanism. One can also use it to reproduce the experiment results in our paper [""Post-training Quantization for Neural Networks with Provable Guarantees""](https://arxiv.org/abs/2201.11113). In this paper, we also prove theoretical guarantees for the proposed method, that is, for quantizing a single-layer network, the relative square error essentially decays linearly in the number of weights â€“ i.e., level of over-parametrization. 

![Quantization Scheme](./imgs/algorithm.png)

If you make use of this code or our quantization method in your work, please cite the following paper:

    @article{zhang2023post,
      title={Post-training quantization for neural networks with provable guarantees},
      author={Zhang, Jinjie and Zhou, Yixuan and Saab, Rayan},
      journal={SIAM Journal on Mathematics of Data Science},
      volume={5},
      number={2},
      pages={373--399},
      year={2023},
      publisher={SIAM}
    }

*Note:* The code is designed to work primarily with the ImageNet dataset. Due to the size of this dataset, it is likely one may need heavier computational resources than a local machine. Nevertheless, the experiments can be run, for example, using a cloud computation center, e.g. AWS. When we run this experiment, we use the `p3.8xlarge` EC2 instance with a disk space of `300GB`. GPUs can significantly accelerate quantization and inference (20 times faster than CPUs).

## Installing Dependencies
We assume a python version that is greater than `3.8.0` is installed in the user's 
machine. In the root directory of this repo, we provide a `requirements.txt` file for installing the python libraries that will be used in our code. 

To install the necessary dependency, one can first start a virtual environment
by doing the following: 
```
python3 -m venv .venv
source .venv/bin/activate
```
The code above should activate a new python virtual environments.

Then one can make use of the `requirements.txt` by 
```
pip3 install -r requirements.txt
```
This should install all the required dependencies of this project. 

## Obtaining ImageNet Dataset

In this project, we make use of the Imagenet dataset, 
in particular, we use the ILSVRC-2012 version. 

To obtain the Imagenet dataset, one can submit a request through this [link](https://image-net.org/request).

Once the dataset is obtained, place the `.tar` files for training set and validation set both under the `data/ILSVRC2012` directory of this repo. 

Then use the following procedure to unzip Imagenet dataset:
```
# Extract the training data and move images to subfolders:
mkdir ILSVRC2012_img_train
mv ILSVRC2012_img_train.tar ILSVRC2012_img_train 
cd ILSVRC2012_img_train 
tar -xvf ILSVRC2012_img_train.tar && rm -f ILSVRC2012_img_train.tar
find . -name ""*.tar"" | while read NAME ; do mkdir -p ""${NAME%.tar}""; tar -xvf ""${NAME}"" -C ""${NAME%.tar}""; rm -f ""${NAME}""; done

# Extract the validation data:
cd ..
mkdir ILSVRC2012_img_val
mv ILSVRC2012_img_val.tar ILSVRC2012_img_val && cd ILSVRC2012_img_val
tar -xvf ILSVRC2012_img_val.tar && rm -f ILSVRC2012_img_val.tar
``` 

## Running Experiments

The implementation of GPFQ and its sparse mode in our paper is contained in `src/main.py`. 

1. Before running the `main.py` file, navigate to the `logs` directory and run `python init_log.py`. This will prepare a log file `Quantization_Log.csv` which is used to store the results of the experiment. 

2. Open the `src` directory and run `python main.py -h` to check hyperparameters, including the number of bits/batch size used for quantization, the scalar of alphabets, the probability for subsampling in CNNs, and regularizations used for sparse quantization etc.

3. To start the experiment, we provide an example: If we want to quantize the ResNet-18 using ImageNet data with bit = 4, batch_size = 512, scalar = 1.16, then we can try this:
```
python main.py -model resnet18 -b 4 -bs 256 -s 1.16
```
There are other options we can select, see `main.py`.

## Examples of Quantized Models 

Use this [link](https://drive.google.com/drive/folders/1M1xioh_YrFXwsNtNpOEjLPbQogL1Llh-?usp=sharing) (Google Drive) to review and download quantized models (alexnet, vgg16, resnet18, resnet50) that are generated by our quantization method with different bits. The choice of all parameters is indicated by the model file name. 

Please open Readme.ipynb for more details. 
","['YixuanSeanZhou', 'jayzhang0727']",1,0.67,0,,,,,,2,,,,
116321682,MDEwOlJlcG9zaXRvcnkxMTYzMjE2ODI=,ucsdReductionCode,zactuscactus/ucsdReductionCode,0,zactuscactus,https://github.com/zactuscactus/ucsdReductionCode,,0,2018-01-05 00:36:07+00:00,2023-01-03 17:18:35+00:00,2018-06-05 20:03:38+00:00,,39043,3,3,Matlab,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,3,master,1,,,[],0,0.8,0,,,,,,1,,,,
223303181,MDEwOlJlcG9zaXRvcnkyMjMzMDMxODE=,deeplearning-PA,zhousiyu627/deeplearning-PA,0,zhousiyu627,https://github.com/zhousiyu627/deeplearning-PA,ucsd,0,2019-11-22 02:05:10+00:00,2019-11-22 09:48:17+00:00,2019-11-22 09:48:15+00:00,,7779,0,0,Python,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,,,['zhousiyu627'],0,0.65,0,,,,,,1,,,,
402613774,MDEwOlJlcG9zaXRvcnk0MDI2MTM3NzQ=,Brightlight-Treatment-Detector,ZMXSSC/Brightlight-Treatment-Detector,0,ZMXSSC,https://github.com/ZMXSSC/Brightlight-Treatment-Detector,For UC San Diego Health,0,2021-09-03 01:44:39+00:00,2022-04-22 17:05:11+00:00,2023-10-06 03:43:10+00:00,,315,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Brightlight Treatment Detector
For UC San Diego Health
***
This is a java-based android app that I made over the summer of 2021 while I was interning at UC San Diego Health. Light therapy is widely used to improve people's health quality. However, when we send the lightbox to the patient, we are not sure if they will take it seriously(to actually use it). So I made this app to help our doctors.

When an inexpensive Android smartphone is set up in front of the light treatment device (most of the time the patient will hang the phone around their neck), this app will continuously monitor whether a patient is sitting in front of the light correctly.
This app can:
1. Upon the patient enters their ID(which is used to track patient's identity in the database), they can start recording the illuminance value by clicking the ""start"" button.
2. By clicking the ""stop"" button, the illuminance values recording will be terminated. Then, it will generate a chart(adapted from [here](https://github.com/PhilJay/MPAndroidChart ""Mikephil Android chart"")) with the x-axis being time(second), y-axis being the illuminance(lux) value.
3. The patient then could upload their data to the firebase realtime database.
4. According to the data, one can determine if a patient is following instructions. For example, if the doctor ends up getting a flat chart from the patient, then possibly this patient is sitting in front of the lightbox the entire time. However, if the doctor ends up getting an uneven chart, then possibly this patient might not be sitting in front of the lightbox the entire time.

## Upcoming features that I'm working on:
1. Better UI with accommodation(Considering the majority of our users are patients, it's important that the UI should not be not too complicated).

### Further feature idea(s):
1. May associate with wearable device(s) as phone is not that portable while hanging.
",['ZMXSSC'],1,0.71,0,,,,,,1,,,UCSD-E4E,
147309839,MDEwOlJlcG9zaXRvcnkxNDczMDk4Mzk=,DSE220x,ZohebAbai/DSE220x,0,ZohebAbai,https://github.com/ZohebAbai/DSE220x,UCSanDiegoX: DSE220x : Machine Learning Fundamentals Course,0,2018-09-04 08:01:27+00:00,2023-01-28 09:07:16+00:00,2018-10-11 18:29:17+00:00,https://courses.edx.org/courses/course-v1:UCSanDiegoX+DS220x+1T2018/course/,18552,15,15,Jupyter Notebook,1,1,1,1,0,0,25,1,0,0,,1,0,0,public,25,0,15,master,1,,"# UCSanDiegoX: DSE220x : Machine Learning Fundamentals 

### Course Instructor: Sanjoy Dasgupta, Professor of Computer Science and Engineering, UC San Diego

## Learning Objectives
This course is an intensive introduction to the most widely-used machine learning methods. 
* The first goal is to provide a basic intuitive understanding of these techniques: what they are good for, how they work, how they relate to one another, and their strengths and weaknesses. 
* The second goal is to provide a hands-on feel for these methods through experiments with suitable data sets, using Jupyter notebooks. 
* The third goal is to understand machine learning methods at a deeper level by delving into their mathematical underpinnings. This is crucial to being able to adapt and modify existing methods and to creatively combining them.

## Topics Covered
* Taxonomy of prediction problems
* Basics of Linear Algebra and Probability
* Nearest neighbor methods and families of distance functions
* Generalization: what it means; overfitting; selecting parameters using cross-validation
* Generative modeling for classification, especially using the multivariate Gaussian
* Linear regression and its variants
* Logistic regression
* Optimization: deriving stochastic gradient descent algorithms and testing convexity
* Linear classification using the support vector machine
* Nonlinear modeling using basis expansion and kernel methods
* Decision trees, boosting, and random forests
* Methods for flat and hierarchical clustering
* Principal component analysis
* Autoencoders, distributed representations, and deep learning

## Opinion/Comments
#### I audited for this course and pledged to complete it. I finished every Engagement, Quiz, Problem Set and Programming Assignment. I believe this is one of the best online course on fundamentals of ML as it maintains a right balance between theory and programming.

#### I have provided my Assignments here (as an evidence of finishing and maintaining a repository for the course), which I completed during a month's time with whatever knowledge I gathered during the course without any help. They are definitely not the efficient ones but correct for sure. Iff you fork it, found an efficient solution, don't forget to send a pull request. 

#### Thanks for passing by!
",['ZohebAbai'],1,0.65,0,,,,,,0,,,,
17277692,MDEwOlJlcG9zaXRvcnkxNzI3NzY5Mg==,COGS120,zzhangy/COGS120,0,zzhangy,https://github.com/zzhangy/COGS120,COGS120 at UCSD,0,2014-02-28 06:41:18+00:00,2014-10-16 16:54:29+00:00,2014-02-28 06:38:26+00:00,notepull1.herokuapp.com,10894,0,0,CSS,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,"['zzhangy', 'anindyabasu', 'howdyitshelena']",1,0.76,0,,,,,,1,,,,
65396688,MDEwOlJlcG9zaXRvcnk2NTM5NjY4OA==,OOPproject,dingye001/OOPproject,0,dingye001,https://github.com/dingye001/OOPproject,UCSD,0,2016-08-10 16:05:02+00:00,2016-08-10 16:05:02+00:00,2016-08-10 16:05:02+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],-1,0.74,0,,,,,,1,,,,
122149788,MDEwOlJlcG9zaXRvcnkxMjIxNDk3ODg=,Toolbox,liu522/Toolbox,0,liu522,https://github.com/liu522/Toolbox,algorithm toolbox UCSD,0,2018-02-20 03:12:39+00:00,2018-02-20 03:12:39+00:00,2018-02-20 03:12:40+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],-1,0.64,0,,,,,,0,,,,
20208158,MDEwOlJlcG9zaXRvcnkyMDIwODE1OA==,UCSDBigData,zhpSweden/UCSDBigData,0,zhpSweden,https://github.com/zhpSweden/UCSDBigData,,0,2014-05-27 05:31:04+00:00,2014-05-27 05:31:04+00:00,2014-05-27 05:31:04+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],-1,0.62,0,,,,,,1,,,,