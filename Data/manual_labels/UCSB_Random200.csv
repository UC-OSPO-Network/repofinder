id,node_id,name,full_name,private,owner,html_url,description,fork,created_at,updated_at,pushed_at,homepage,size,stargazers_count,watchers_count,language,has_issues,has_projects,has_downloads,has_wiki,has_pages,has_discussions,forks_count,archived,disabled,open_issues_count,license,allow_forking,is_template,web_commit_signoff_required,visibility,forks,open_issues,watchers,default_branch,score,organization,readme,contributors,manual_label,prediction_nn,prediction,release_downloads,code_of_conduct,contributing,security_policy,issue_templates,pull_request_template,subscribers_count,,,
56785577,MDEwOlJlcG9zaXRvcnk1Njc4NTU3Nw==,CS20-S16-lab04,UCSB-CMPTGCS20-S16/CS20-S16-lab04,0,UCSB-CMPTGCS20-S16,https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab04,,0,2016-04-21 15:33:37+00:00,2016-04-22 17:49:35+00:00,2016-04-26 09:12:31+00:00,,34,0,0,Python,1,1,1,1,0,0,1,0,0,0,mit,1,0,0,public,1,0,0,master,1,1,"Introduction
============

More practice with writing functions and tests
----------------------------------------------

In this lab, we continue practicing writing functions and tests, in
the same style as some of our previous labs.

The difference is that the functions we are writing will be a bit more
challenging.

You may work individually, OR in a pair, as you see fit.

Step by Step
============

Step 0: Register as either working alone, or working in a pair
--------------------------------------------------------------

Make a directory or folder for lab04.  We suggest `~/cs20/lab04`,
which as you may recall, means:

* a `cs20` folder inside your home folder
* then, a `lab04` folder inside that.

We are now going to get two files from the web.

Step 1: Copy some code into `lab04Funcs.py`
-----------------------------------------

We are going to copy some code from `lab04Funcs.py`
into a file with the same name under your `~/cs20/lab04` folder

* As a plain file: [lab04Funcs.py](https://raw.githubusercontent.com/UCSB-CMPTGCS20-S16/CS20-S16-lab04/master/lab04Funcs.py)
* On github: [lab04Funcs.py on github](https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab04/blob/master/lab04Funcs.py)

In IDLE, select ""File=&gt;New Window"" to open a new ""untitled"" window for Python code.

When it comes up, click and drag the window by its title bar over to the right of your Python Shell window.

Now, open this link. (You may want to ""right click"", or on Mac, ""control-click"", to open it in a new window or tab.)

Use the ""Save As"" option to save that file in the `~/cs20/lab04` folder with the name `lab04Funcs.py`

Step 2: Copy some more code from `lab04Tests.py`
-----------------------------------------------

Now we are going to do the same thing again, with a second file of Python code.

We are going to copy some code from `lab04Tests.py`
into a file with the same name under your `~/cs20/lab04` folder

* As a plain file: [lab04Tests.py](https://raw.githubusercontent.com/UCSB-CMPTGCS20-S16/CS20-S16-lab04/master/lab04Tests.py)
* On github: [lab04Tests.py on github](https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab04/blob/master/lab04Tests.py)

* You may want to ""right click"", or on Mac, ""control-click"", to open it in a new window or tab.
* We want to copy code from that version of `lab04Tests.py` into a file with the same name under your `~/cs20/lab04` folder.

In IDLE, select ""File=&gt;New Window"" *again* to open *yet another* new ""untitled"" window for Python code.

When it comes up, click and drag the window some place so that you can get to it, your `lab04Funcs.py` window, the web browser window with `lab04Tests.py` and to your Python Shell window easily by clicking.

Use the ""Save As"" option to save that file in the`~/cs20/lab04` folder with the name `lab04Tests.py`

Remember that upper vs. lower case matter. Save it again if you didn't get it exactly right the first time, and use the `rm` command to remove (delete) any files that are in the wrong place.

Once you see that you have `lab04Funcs.py` and `lab04Tests.py` under your `~/cs20/lab04` directory, you are good to move on to the next step.

Step 3: Importing functions from our lab02 file
-----------------------------------------------

Take a look inside your `lab04Funcs.py` file, and you'll see these two lines near the top:

    from lab02Funcs import isList
    from lab02Funcs import isSimpleNumeric

What we are doing here is pulling in two functions from our lab02 work.

We are going to NEED an `isList` function and an `isSimpleNumeric` function to do the work for lab04. But, we don't want to have to write those functions from scratch.

So we can REUSE the code. All we have to do is copy over the `lab02Funcs.py` file from our lab02 directory into our lab04 directory.

So, make a copy of your `lab02Funcs.py` from the earlier lab, and put it in the same folder/directory with your `lab04Funcs.py` and `lab04Tests.py` files.

When you've copied the `lab02Funcs.py` file over, and you see that you have all three files that we are going to need for this week's lab, you can get started on the programming part.

Step 4: Fixing function stubs, adding functions, adding tests
-------------------------------------------------------------

As we discussed in lecture, when writing functions along with test cases, we often start with ""stub"" versions.

These allow us to ""test the test"" to make sure that when the function is bogus, that the tests work correctly.

If you look through the `lab04Funcs.py` file, you will see several function definitions that are ""stub"" versions.

Run the `lab04Tests.py` file, and you'll see that many of the tests are failing, because the function in question returns the string ""stub"" instead of the answer that it should.

Go through the file, and replace the stubs with correct values.

In addition, you'll also find:

-   several places in `lab04Funcs.py` where there are comments with ""@@@"" signs that tell you to add new function definitions.

Follow all of the instructions.

-   As you follow the instructions with the @@@ in them, REMOVE THE COMMENTS THAT HAVE THE @@@ IN THEM.

You can always look back at the versions of the files on the web if you want to see what the instructions originally said.

If you leave any of the @@@ comments in the file, points may be deducted.

When you have:

-   fixed all the stubs, and the tests cases pass
-   added all the functions you are supposed to add

Then you are ready to submit!

### A few helpful hints

At the bottom of the file, you'll see that you can select either to run ALL tests, or ONLY the test for a certain function.

Follow the instructions there if you want to focus on just one function at a time.

Step 5: Getting ready to submit
-------------------------------

We are just about ready to submit your work for grading.

But first, some important preparation steps:

### Step 5a: Add your name(s) and email to the top of the file

This step is worth 10 points (10% of your grade) so don't forget it.

<b>(Yeah, ""grade"", ha ha. If you are in the CCS version of this course, just go with me on this.    It was easier to leave this all in that edit it out.   The ""grade"" stuff is still a good indication of how programming work is evaluated and assessed in traditional-style courses, so probably good for you to know in case you choose to study CS further.)</b>

At the top of BOTH the `lab04Funcs.py` file, and the `lab04Tests.py` file, add the following lines of code. They should be at the VERY top, the VERY first lines.

But, change the name here to YOUR name, the lab section to YOUR lab section, and the email to YOUR email (use your umail address, not a gmail, yahoo or hotmail address.)

Add the word SOLO or PAIR, and if working in a pair, put both names (one per line)

    # lab04Funcs.py  SOLO, Gina Gaucho, ggaucho@umail.ucsb.edu 

    # lab04Tests.py  SOLO, Gina Gaucho, ggaucho@umail.ucsb.edu 

OR:

    # lab04Funcs.py  PAIR, Gordon Gaucho, ggaucho@umail.ucsb.edu 
    # lab04Funcs.py  PAIR, Martin Perez, mperez07@umail.ucsb.edu 

    # lab04Tests.py  PAIR, Gordon Gaucho, ggaucho@umail.ucsb.edu 
    # lab04Tests.py  PAIR, Martin Perez, mperez07@umail.ucsb.edu 

### Step 5b: Check your lab against the grading rubric

**Again, if you are in the CCS version of the course, this section and the grading rubric at the bottom are provided just to give you an idea of what might be considered important in grading if you decide to take other computer science courses in the future, and so you can use it as a checklist for completion.**

To maximize your grade, it is good to check your OWN lab against the SAME criteria the TA and instructor will use to grade it—BEFORE you submit it!

Open these lab instructions in a second browser window. Scroll down to the bottom of the lab, to the grading section.

Find the list of grading criteria. Check your own work against each of those.

If there are any parts that don't make sense to you, be sure to ask the TA/Instructor about those.

If you see that you've done everything correctly, then you are ready to submit.

Step 6: Submit your assignment via submit.cs
-------------------------------------------------------

Here's the link: https://submit.cs.ucsb.edu/form/project/471/submission

If you happen to be working on CSIL, you can also submit by typing

```
~submit/submit -p 471 lab02Funcs.py lab04Funcs.py
```

Evaluation and Grading
======================

-   lab04 directory submitted (10 pts) and contains:
    -   `lab02Funcs.py` (5 pts)
    -   `lab04Funcs.py` (5 pts)

<!-- -->

-   In `lab04Funcs.py`:
    -   name(s) at top (10 pts)
    -   (15 pts) corrected problems with `notStringContainingE(word)` so that it passes tests
    -   (15 pts) corrected problems with `hasNoX(word)` so that it passes tests
    -   (30 pts) correct version of `isListOfIntegers(theList)`
    -   (30 pts) correct version of `isListOfEvenIntegers(theList)`
    -   (30 pts) correct version of `totalLength(listOfStrings)`
    -   (30 pts) correct version of `lengthOfEach(listOfStrings)`
    -   (30 pts) correct version of `countEvens(listOfInts)`
    -   (30 pts) correct version of `onlyEvens(listOfInts)`
    -   all @@@ comments removed (10 pts)



-   In `lab04Tests.py`:
    -   (10 pts) Nothing changed except adding comment to first lines with name
    -   Note: if tests are modified to make them pass (instead of modifying the code to make it pass the tests) then additional points may be deducted. Don't modify the tests. Modify the code so that it passes the tests.



-   General (30 pts)
    -   following instructions
    -   submitting work on time
    -   anything else specified in the instructions

<hr>
Copyright 2014,2015, Phillip T. Conrad, CS Dept, UC Santa Barbara. Permission to copy for non-commercial, non-profit, educational purposes granted, provided appropriate credit is given; all other rights reserved.
","['sarahmzhong', 'pconrad']",1,,0.66,0,,,,,,2,,UCSBarchlab,/ucsb/
57425752,MDEwOlJlcG9zaXRvcnk1NzQyNTc1Mg==,UCSD-Graphs,wyatli/UCSD-Graphs,0,wyatli,https://github.com/wyatli/UCSD-Graphs,Advances data structure(Graph) and Algorithms from UCSB Coursera,0,2016-04-30 03:40:09+00:00,2016-04-30 03:54:20+00:00,2016-04-30 03:54:17+00:00,,316,0,0,Java,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"# UCSD-Graphs
Advances data structure(Graph) and Algorithms from UCSB Coursera

###Week 1 : Introduction to the course and graphs

>basicgraph.Graph.java<br>
>basicgraph.GraphAdjList.java<br>
>basicgraph.GraphAdjMatrix.java<br>

###Week 2 : Class design and simple graph search(BFS)

>roadgraph.MapGraph.java<br>
>week2example.Maze.java<br>
>week2example.MazeLoader.java<br>
>week2example.MazeNode.java<br>

###Week 3 : Finding shortest path using Dikstra's Algorithm and A*Seach
>see http://www.cnblogs.com/technology/archive/2011/05/26/2058842.html exlains the algo of A* search<br>
>MapGraph.java<br>

###Utility files

>geography.GeographicPoint.java<br>
>geography.RoadSegment.java<br>
>util.GraphLoader.java<br>
",['wyatli'],1,,0.79,0,,,,,,1,,ucsb-seclab,library-ucsb
1771842,MDEwOlJlcG9zaXRvcnkxNzcxODQy,IntWebData,sckott/IntWebData,0,sckott,https://github.com/sckott/IntWebData,Interface with the Interaction Web Database,0,2011-05-19 15:15:02+00:00,2013-12-04 02:03:05+00:00,2011-05-19 15:18:08+00:00,http://r-ecology.blogspot.com/,89,2,2,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,2,master,1,,"This repo is for the development of a package for interfacing with the Interaction Web Database (http://www.nceas.ucsb.edu/interactionweb/), a website that hosts datasets on ecological networks. The package goals are to allow download of datasets, querying of taxonomic names in the datasets, and simple network plotting (using package bipartite). ",['sckott'],1,,0.74,0,,,,,,1,,LuaAV,
669670757,R_kgDOJ-pdZQ,alab-ucsb,alab-ucsb/alab-ucsb,0,alab-ucsb,https://github.com/alab-ucsb/alab-ucsb,Config files for my GitHub profile.,0,2023-07-23 03:49:10+00:00,2023-07-23 03:49:10+00:00,2023-07-23 16:38:46+00:00,https://github.com/alab-ucsb,0,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"Hi, you've reached the Alexander lab github. We are a neuroscience research group studying spatial cognition, learning, and memory in the Department of Psychological and Brain Sciences at UC Santa Barbara.



<!---
alab-ucsb/alab-ucsb is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
",['alab-ucsb'],1,,0.88,0,,,,,,1,,SEAL-UCSB,
464005168,R_kgDOG6goMA,UCSBHistoricalCourseScraper,JNewman-cell/UCSBHistoricalCourseScraper,0,JNewman-cell,https://github.com/JNewman-cell/UCSBHistoricalCourseScraper,Finds all past course offerings for certain subjects and compiles each quarter into a specific csv file for use in choosing electives and planning out Major class schedules.,0,2022-02-27 01:03:22+00:00,2024-10-30 23:14:31+00:00,2023-02-02 06:28:47+00:00,,12,1,1,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"# UCSBHistoricalCourseScraper

Finds all courses and their respective names for certain class subjects using their shortened classification (e.g. ECE, CMPSC for Electrical Engineering and Computer Science) and compiles each quarter of the last year into a quarter-specific csv file for use in Excel or Google Sheets. This is accomplished through website scraping of the UCSB course website, this speeds up the process for searching through every course significantly. Some setbacks were the loading speed of the UCSB website itself, so I had to slow down the script at certain places so that the data could be read.

## Getting Started

These instructions will give you a copy of the project up and running on
your local machine for development and testing purposes. See deployment
for notes on deploying the project on a live system.

### Prerequisites

Requirements for the software and other tools to build, test, and push
- [Chrome Driver](https://chromedriver.chromium.org/getting-started)
- [Selenium and Pandas Python Packages](https://packaging.python.org/en/latest/tutorials/installing-packages/)
 
 The chrome driver is needed in addition to an installation of python to run the script.
 Hopefully, this program is useful and makes it easier to choose classes!
",['JNewman-cell'],1,,0.86,0,,,,,,1,,UCSB-NLP,
16060272,MDEwOlJlcG9zaXRvcnkxNjA2MDI3Mg==,ucsbphil,SimpsonHomer/ucsbphil,0,SimpsonHomer,https://github.com/SimpsonHomer/ucsbphil,,0,2014-01-20 03:38:55+00:00,2014-09-13 22:11:47+00:00,2014-01-20 01:39:42+00:00,,220077,0,0,JavaScript,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['dunn'],1,,0.71,0,,,,,,1,,AlloSphere-Research-Group,
60858010,MDEwOlJlcG9zaXRvcnk2MDg1ODAxMA==,faculty-scraper,barc-iitkgp/faculty-scraper,0,barc-iitkgp,https://github.com/barc-iitkgp/faculty-scraper,A tool to scrape the faculty details of QS Top 30 Institutes.,0,2016-06-10 15:29:13+00:00,2025-02-06 12:15:33+00:00,2022-09-20 08:55:53+00:00,,129,11,11,Ruby,1,1,1,1,0,0,8,0,0,5,gpl-3.0,1,0,0,public,8,5,11,master,1,1,"DESCRIPTION 
-----------
This tool will scrape through faculty details of various colleges & store them in .csv format in the data/ folder.

SUPPORTED COLLEGES 
------------------

<p> This list is not necessarily in the same order as the QS Top 30 ranks </p>

<table>
<tr> <th> # </th> <th> College name </th> <th> Number of contacts </th> </tr>
<tr> <td> (1) </td> <td> Berkeley University </td> <td> 125 </td> </tr>
<tr> <td> (2) </td> <td> Cambridge University </td> <td> 1420 </td> </tr>
<tr> <td> (3) </td> <td> Delft University of Technology </td> <td> 485 </td> </tr>
<tr> <td> (4) </td> <td> École Polytechnique Federale De Lausanne </td> <td> 145 </td> </tr>
<tr> <td> (5) </td> <td> ETH Zurich University </td> <td> 626 </td> </tr>
<tr> <td> (6) </td> <td> Georgia University </td> <td> 142 </td> </tr>
<tr> <td> (7) </td> <td> Harvard  University  </td> <td> 101 </td> </tr>
<tr> <td> (8) </td> <td> Massachusetts Institute of Technology </td> <td> 165 </td> </tr>
<tr> <td> (9) </td> <td> Melbourne University </td> <td> 168 </td> </tr>
<tr> <td> (10) </td> <td> Oxford University </td> <td> 233 </td> </tr>
<tr> <td> (11) </td> <td> Peking  University </td> <td> 111 </td> </tr>
<tr> <td> (12) </td> <td> Stanford University </td> <td> 114 </td> </tr>
<tr> <td> (13) </td> <td> University of California, Santa Barbara </td> <td> 41 </td> </tr>
<tr> <td> (14) </td> <td> University of California,Los Angeles </td> <td> 79 </td> </tr>
<tr> <td> (15) </td> <td> University of Illinois at Urbana–Champaign </td> <td> 106 </td> </tr>
<tr> <td> (16) </td> <td> Yale University </td> <td> 23 </td> </tr>
<tr> <th> # </th> <th> Total number of contacts </th> <th> 4084 </th> </tr>
</table>


USING THE TOOL <img src=""https://api.travis-ci.org/barc-iitkgp/faculty-scraper.svg"">
--------------
Type the following commands on a terminal -
<br>`git clone git@github.com:barc-iitkgp/faculty-scraper.git`
<br> `cd faculty-scraper/scripts` 
<br> `ruby college_name.rb`

LICENSE
-------
Licensed under GNU General Public License v3.0 (GPLv3).
","['athityakumar', 'the-ethan-hunt', 'sgdgp']",0,,0.66,0,,,,,,2,,UCSB-VRL,
1475838,MDEwOlJlcG9zaXRvcnkxNDc1ODM4,GauchoMobile,gonfunko/GauchoMobile,0,gonfunko,https://github.com/gonfunko/GauchoMobile,iPhone client for UCSB GauchoSpace course management system,0,2011-03-13 21:19:55+00:00,2024-08-21 22:03:36+00:00,2013-05-28 04:13:50+00:00,,30325,6,6,Objective-C,1,1,1,1,0,0,1,0,0,0,bsd-2-clause,1,0,0,public,1,0,6,master,1,,"GauchoMobile
Read Me 

GauchoMobile is a native iPhone client for UCSB's GauchoSpace course management system.
At the present, it allows you to view grades, assignments, participants and the free form links/text associated with every course you are enrolled in on GauchoSpace.
It was developed as part of CS 48 (http://www.cs.ucsb.edu/~mikec/cs48/index.html) by Aaron Dodson, Kenneth Bedolla, Mauricio Hernandez and Christian Jimenez.

---------------------------------------------------------

FAQs:

Q: Why does GauchoMobile say No Assignments? GauchoSpace lists some on the course homepage.
A: GauchoSpace only displays assignments from the actual Assignments ""mode"" of GauchoSpace. Assignments listed on the course homepage should be visible in the Dashboard section.

Q: How come the information displayed is out of date?
A: To save you time and battery power, GauchoMobile caches the information it downloads from GauchoSpace. This means that assignments, grades, etc. are instantly available,
but may also mean that you don't see the most recent information. To make sure you're up to date, go to the information you want to update, pull the table down and release it. In the case
of assignments, you'll need to switch to landscape orientation to be able to drag far enough to reload the information.

Q: Why isn't GauchoMobile able to download any information when I launch it after not using it for a while?
A: This is a bug. Since GauchoSpace logins expire after a while, GauchoMobile isn't able to access your information if it logged in a while ago. Double click the device home button, tap the
red minus button on GauchoMobile and relaunch it to work around this problem.

---------------------------------------------------------

GauchoSpace is a Moodle site, which means that GauchoMobile may be able to work with any other Moodle site. We haven't tested this, but only moderate modifications should be required
to get it working. First, try just switching out the URLs in GMSourceFetcher.m. If that doesn't work, you may need to modify the parsers, especially if your school uses a different
version of Moodle. You'll also probably want to change the colors of the nav bars/loading views and graphs to match your school colors (unless those happen to be blue and gold) and switch
out the images displayed on the login view. If you get GauchoMobile working for your school, let us know!

----------------------------------------------------------

If you like GauchoMobile, why not become a fan on Facebook: https://www.facebook.com/pages/Gaucho-Mobile/156258474432978",['gonfunko'],1,,0.79,0,,,,,,2,,NCEAS,
514470571,R_kgDOHqoyqw,iac-dns-coredns,library-ucsb/iac-dns-coredns,0,library-ucsb,https://github.com/library-ucsb/iac-dns-coredns,Contains IaC for the UCSB Library's CoreDNS Deployment,0,2022-07-16 03:52:48+00:00,2022-07-16 03:54:33+00:00,2022-07-17 01:15:27+00:00,,19,0,0,HCL,0,1,0,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,1,,['joshSpreston'],1,,0.87,0,,,,,,1,,move-ucsb,
183289227,MDEwOlJlcG9zaXRvcnkxODMyODkyMjc=,UCSB-Menu-assistant,ArthurG0/UCSB-Menu-assistant,0,ArthurG0,https://github.com/ArthurG0/UCSB-Menu-assistant,,0,2019-04-24 18:56:53+00:00,2019-07-13 04:17:37+00:00,2019-07-13 04:17:36+00:00,,3,0,0,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,# UCSB-Menu-assistant,['ArthurG0'],1,,0.86,0,,,,,,0,,CARDAMOM-framework,
825112185,R_kgDOMS42eQ,DarenUCSB,darenaguilera/DarenUCSB,0,darenaguilera,https://github.com/darenaguilera/DarenUCSB,Config files for my GitHub profile.,0,2024-07-06 20:09:22+00:00,2024-07-06 20:20:47+00:00,2024-07-06 20:19:52+00:00,https://github.com/darenaguilera,2,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"- 👋 Hi, I’m @darenaguilera
- 👀 I’m interested in various concepts revolved around data science, programming, and mathematics, such as machine learning and data engineering!
- 🌱 I’m currently learning additional machine learning methods and tools, as well as practicing cloud computing. 
- 💞️ I’m looking to collaborate on projects to further deepen and expand my knowledge, as well as practical applications to hone my skillset. 
- 📫 How to reach me:
-     Email: daren@ucsb.edu
-     Linkedin: linkedin.com/in/daren-aguilera
- 😄 Pronouns: He/him/his

<!---
- ⚡ Fun fact: ...
---> 

<!---
DarenUCSB/DarenUCSB is a ✨ special ✨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
",['darenaguilera'],1,,0.8,0,,,,,,1,,ucsbieee,
809192513,R_kgDOMDtMQQ,cash-transfer-policy,linusghanadan/cash-transfer-policy,0,linusghanadan,https://github.com/linusghanadan/cash-transfer-policy,,0,2024-06-02 01:10:36+00:00,2024-08-23 00:01:18+00:00,2024-08-23 00:01:14+00:00,,1015,1,1,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"## Impact Analysis of a 1998 Cash-Transfer Program in Rural Mexico

### [Link to Blog (includes R code, code output, and written analysis)](https://linusghanadan.github.io/blog/2024-3-6-post/)

### Context

This project was completed for my Policy Evaluation class, taken as part of my Master's program at UC Santa Barbara. Provided with data and questions, I carried out this analysis using appropriate causal inference modeling techniques.

### Question

How did the 1998 Prospera cash-transfer program impact the value of a household's animal holdings?

### Analysis Summary

Compared pre-treatment characteristics in the treatment and control groups of the 1998 Prospera cash-transfer program. Estimated the Average Treatment Effect (ATE) of the program on a household’s value of owned animals with the First-Difference, Fixed-Effects, and Difference-in-Difference estimators.

### Data

Our data comes from a [2012 research paper published in the American Economic Journal](https://www.aeaweb.org/articles?id=10.1257/app.4.1.164) looking at the Progresa cash-transfer program, which was implemented in rural Mexican villages in 1998. Eligible households that were randomly selected to be part of the program were provided bi-monthly cash-transfers of up to 550 pesos per month. These cash-transfers were conditional on children attending school, family members obtaining preventive medical care, and attending health-related education talks. In total, over 17,000 households were part of the Progresa program.

**The outcome and treatment variables are:**

-   **vani** = value of animals owned by household (in 1997 USD)

-   **treatment** = dummy variable indicating whether an individual was part of the cash-transfer program (equal to 1 if the individual was part of the program)

**There are 55 control variables, including:**

-   **dirtfloor97** = dummy variable indicating whether a household had a dirt floor in 1997

-   **electricity97** = dummy variable indicating whether a household had electricity in 1997

-   **homeown97** = dummy variable indicating whether a household owned a house in 1997

-   **female_hh** = dummy variable indicating whether a household has a female head of household

-   **age_hh** = head of household age

-   **educ_hh** = head of household years of education
",['linusghanadan'],1,,0.65,0,,,,,,1,,geometric-intelligence,
118831647,MDEwOlJlcG9zaXRvcnkxMTg4MzE2NDc=,dj48,coolstar/dj48,0,coolstar,https://github.com/coolstar/dj48,DJ app for UCSB CS48 project,0,2018-01-24 22:44:54+00:00,2021-04-23 03:04:39+00:00,2018-11-02 03:50:42+00:00,,66422,1,1,JavaScript,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,1,master,1,,"# DJ48 - CS48 Project at UCSB
## Final Project

### Description
DJ48 is a web-based DJ application that allows users to upload and play tracks, add live effects, and produce recordings of their mixes.

### Table of Contents
* [Features](https://github.com/coolstar/dj48#features)
  * [Track Retrieval](https://github.com/coolstar/dj48#track-retrieval)
  * [Audio Visualization](https://github.com/coolstar/dj48#audio-visualization)
  * [Playback Controls](https://github.com/coolstar/dj48#playback-controls)
  * [Sync BPMs](https://github.com/coolstar/dj48#sync-bpms)
  * [Real-Time Effects](https://github.com/coolstar/dj48#real-time-effects)
* [Build, Execute, and Run](https://github.com/coolstar/dj48#build-execute-and-run)
  * [Local Access](https://github.com/coolstar/dj48#local-access)
  * [Server Access](https://github.com/coolstar/dj48#server-access)
* [Testing](https://github.com/coolstar/dj48#testing)
* [Known Bugs](https://github.com/coolstar/dj48#known-bugs)
* [Dependencies](https://github.com/coolstar/dj48#dependencies)

### Features
#### Track Retrieval
* User can upload up to two audio files from their local filesystem
* System prepares the track(s) for playing, mixing, and recording
#### Audio Visualization
* Utilizes Fourier Transform to decompose tracks into its frequencies
* Using the above decomposition, displays a spectrogram
* Using a drop-down box, can change visualization to a sine wave
* Sine wave visualization shows amplitudes of combined frequencies across time
#### Playback Controls
* Play and pause in one button, switches functions on press
* Volume control
* Live playback of tracks with their effects and filters
* Seekbar that shows progress of track, and allows position to be changed
#### Sync BPMs
* Averages the BPM of the two tracks
* Sets the BPM of both tracks to the above calculated average
#### Recording
* Switch to enable/disable recording
* Records audio output from the web-page
#### Macros
* Record macros that log your inputs on the webpage
* Replay these macros back in time with your original inputs
* Import or write macros manually in Ace editor
#### Real-Time Effects
##### Pitch
* Shifts frequencies higher or lower
* Percentage-based
##### Tempo
* Increases or decreases tempo, or beats-per-minute
* Percentage-based
##### Delay
* Plays back sound in defined intervals
* Echo effect
##### Ping-Pong Delay
* Similar to regular Delay
* On each feedback loop, output is swapped between left and right channels
##### Dub Delay
* Similar to regular Delay
* On each feedback loop, output is routed through a biquad filter
* Biquad filter ""dubs"" (swirling, psychedelic effect) successive echoes
##### Distortion
* Alters sound by increasing gain, producing ""fuzzy"", ""growling"", or ""gritty"" tone
* aka Overdrive
##### Quadrafuzz
* Divides sound into separate bands
* Applies distortion effects to each band independently
##### Flanger
* Swirling effect
* Delays a copy of the sound by a small, gradually changing period
* Blends the copy back into the original signal
* Produces ""comb filtering"", constructive and destructive interference
##### Compressor
* Squashes an audio signal's dynamic range, ratio between largest and smallest values
* Reduces volume of loud sounds
* Amplifies quiet sounds
##### Low-Pass Filter
* Passes signals with frequencies lower than cutoff
* Attenuates signals with frequencies higher than the cutoff
##### High-Pass Filter
* Passes signals with frequencies higher than cutoff
* Attenuates signals with frequencies lower than cutoff
##### Stereo Panner
* Adjusts the distribution of the sound signal between the left and right channels
##### Reverb
* Simulates particular physical environments
* Simulates the resonance or repercussion of sound in that environment
##### Ring Modulator
* Multiplies the track signal with a sine wave modulating the track
* Recreates the distortion applied to audio signals as it travels through diode nodes
* Cybermen and The Daleks from Dr Who
##### Tremolo
* Changes volume of the sound over time
* Similar outcome to changing volume up and down periodically

### Build, Execute, and Run
#### Local Access
  Note: Recorder feature requires web workers; some browsers may not allow this functionality on local files.  
  In this case, see the below section '[Server Access]'(https://github.com/coolstar/dj48#server-access).
1. Clone repo.
2. Checkout 'finalproject' branch.
3. Open the top-level index.html file.
4. Load songs by clicking either upload button, and choosing mp3 files of your choice.  
   Samples are provided for convenience in 'samples' folder of repo.
5. Click the sync button (tooltip: 'Sync') at the top of the page to set the BPMs of both tracks to the average of the two, if necessary.
6. Click respective play buttons to play individual tracks, or click the play button (tooltip: 'Play All') at the top to play both at once.
7. Add and modify effects using their respective sliders.
8. The visualizer setting can be changed by selecting your choice from the dropdown menu next to 'Visualizer setting'.
9. Create a macro that copies user inputs on the transport and effects controls by clicking on the record button (tooltip: 'Record Macro').
10. Replay a macro by clicking on the play button (tooltip: 'Play Macro').
11. To import a macro, click on the button with tooltip: 'Upload Macro'.
#### Server Access
To more conveniently view the application, visit http://cs48-vps.coolstar.org/finalproject/dj48/.  
The recording feature works on this server-hosted application.
1. Load songs by clicking either upload button, and choosing mp3 files of your choice.  
   Samples are provided for convenience in 'samples' folder of repo.
2. Turn on the 'Record' switch to record your output.
3. Click the sync button (tooltip: 'Sync') at the top of the page to set the BPMs of both tracks to the average of the two, if necessary.
4. Click respective play buttons to play individual tracks, or click the play button (tooltip: 'Play All') at the top to play both at once.
5. Add and modify effects using their respective sliders.
6. The visualizer setting can be changed by selecting your choice from the dropdown menu next to 'Visualizer setting'.
7. Recorded output is available by clicking 'Recordings'.
8. Create a macro that copies user inputs on the transport and effects controls by clicking on the record button (tooltip: 'Record Macro').
9. Replay a macro by clicking on the play button (tooltip: 'Play Macro').
10. To import a macro, click on the button with tooltip: 'Upload Macro'.

### Testing
Testing details can be found in the 'tests' directory.

### Known Bugs
* Race condition between playback update and user drag event on seekbar
  * Sometimes prevents proper dragging of seeker

### Dependencies
All libraries below are included in the repo under 'lib'.
* ace
* jquery
* nouislider
* pizzicato
* recorder
* soundtouch
","['coolstar', 'jsmli', 'lawrencekhlim', 'MoSBanapple', 'anhtuanlethanh']",1,,0.8,0,,,,,,3,,ucsb-cs,
53710604,MDEwOlJlcG9zaXRvcnk1MzcxMDYwNA==,ucsb-ros-pkg,mylxiaoyi/ucsb-ros-pkg,0,mylxiaoyi,https://github.com/mylxiaoyi/ucsb-ros-pkg,Automatically exported from code.google.com/p/ucsb-ros-pkg,0,2016-03-12 03:06:45+00:00,2016-03-12 03:07:30+00:00,2016-03-12 03:09:17+00:00,,474,0,0,C++,1,1,0,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['filitchp'],1,,0.82,0,,,,,,1,,CLIVAC,
225558981,MDEwOlJlcG9zaXRvcnkyMjU1NTg5ODE=,QMLE,hanbinhu/QMLE,0,hanbinhu,https://github.com/hanbinhu/QMLE,,0,2019-12-03 07:37:25+00:00,2019-12-10 23:27:54+00:00,2019-12-10 15:21:22+00:00,,34,1,1,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"# Quantum Machine Learning Experiments
This is a course project for ECE594BB (Selected Topics in High-Dimensional Tensor Data Analysis) instructed by Dr. Zheng Zhang at University of California, Santa Barbara. This project aims to utilize the [Google TensorNetwork toolbox](https://github.com/google/TensorNetwork) to perform machine learning over the tree tensor network inspired by quantum computing. This project is mainly based on the following work:

> [1] Ding Liu, Shi-Ju Ran, Peter Wittek, Cheng Peng, Raul Blázquez García, Gang Su, and Maciej Lewenstein. [Machine learning by unitary tensor network of hierarchical tree structure](https://iopscience.iop.org/article/10.1088/1367-2630/ab31ef), *New Journal of Physics*, 21(7), 073059, 2019.

Their code is also available on [Github link](https://github.com/dingliu0305/Tree-Tensor-Networks-in-Machine-Learning).

## Requirements

The code is Python3-based, and the following packages are required to run the repository.

- [TensorNetwork](https://github.com/google/TensorNetwork)
- [tncontract](https://github.com/andrewdarmawan/tncontract)
- [Numpy](https://numpy.org/)
- [Scipy](https://www.scipy.org/)
- [Scikit-learn](https://scikit-learn.org/stable/)
- [Matplotlib](https://matplotlib.org/)
- [PyTorch](https://pytorch.org/)

## Installation

1. Download the entire repository
2. Copy corresponding data files from this [link](https://ucsb.box.com/s/u6hx1wt7pdqab7ojye7gsep9ij44g39d), and the put the content into a folder called `data`.

## Basic Examples

To reproduce the results from [1], the following command can be executed.

`./qmle reproduce --data-path ./data`

To run the experiments using TensorNetwork, the following command can be executed.

`./qmle run --data-path ./data --dataset MNIST`

## Arguments

Please check the arguements of the program with

`./qmle reproduce -h`

or

`./qmle run -h`

There are mainly a few groups of arguments.

- Arguments for logging and output directory: `prefix`, `log`, `log-level`
- Arguments for input: `data-path`, `dataset`
- Arguments for paper reproducing hyperparameter: `num-epoch`, `bond-data`, `bond-inner`, `num-train-single`, `num-test-each`

For more details, please check `utils/arg_parse.py` file.

## TODO
1. Test different hyperparameter setting for the paper reproducing, and collect the results (Jose Acuna)
2. Try more sophiticated normalization method for the image, please check function `image_normalization` in `./third-party/ttn_ref.py`. (Jose Acuna)
3. Use TensorNetwork to implement the entire flow, and generalize for more datasets (Hanbin Hu)
",['jose14520'],1,,0.71,0,,,,,,2,,ucsb-coast-lab,
511305072,R_kgDOHnnlcA,Bees-and-Angiosperms-Interactions,jtmiller28/Bees-and-Angiosperms-Interactions,0,jtmiller28,https://github.com/jtmiller28/Bees-and-Angiosperms-Interactions,"A research oriented respository for exploring bee & flowering plant co-occurrence, interactions, and relational biodiversity",0,2022-07-06 22:04:46+00:00,2022-09-26 17:42:47+00:00,2022-11-28 16:21:32+00:00,,213,0,0,R,1,1,1,1,0,0,0,0,0,17,cc0-1.0,1,0,0,public,0,17,0,main,1,,"# Bee and Angiosperm interaction Maps

This is my research oriented repository for exploring bee & flowering plant co-occurrences, interactions, and relational biodiversity. 

## **Research Question(s)**
1. What drives bee diversity in California? 
2. How can we link flowering plant & bee diversity using open source occurrence data? 
3. What abiotic trends in the level 3 ecoregions of California shape these two groups assemblages?

## **Goals of the Project**
- Using iDigBio & GBIF occurrence records we would like to investigate trends in diversity and spatial distribution of bees & angiosperms of the level 3 EPA ecoregions originating in California.
- Investigate Abiotic & Biotic factors that describe the ecoregions, and how these could act as possible drivers for bee (& angiosperm) diversity.
- Investigate possible interaction space between angiosperm & bee co-occurrences within the ecoregions. 
- Create Reproducible workflow in bash & R for organizing and analyzing occurrence data. 

## **Background**
Recent research indicates that bee diversity at a global scale is driven by warm temperatures & low levels of percipitation (Orr et al. 2021). To test this hypothesis on a more localized level, we are interested in investigating bee diversity drivers within the state of California. California provides an unique case study by containing both high bee diversity (~1600 described species) and spatially hetergenous enviroments. To divide up enviromental gradients in California we are using the [EPA defined ecoregions](https://gaftp.epa.gov/EPADataCommons/ORD/Ecoregions/ca/CA_eco_front_ofr20161021_sheet1.pdf). Pleminary analysis suggests that indeed bee diversity is significantly correlated by warm temperatures & low levels of percipitation within the state of California. An interesting aspect of this however is that these drivers alone don't seem to explain diversity when categorized at the ecoregion level. Our next step for investigating bee diversity is looking at how flowering plant diversity is shaped by the ecoregion designations. 

Flowering plants are a logical next step for our research question for two reasons. First off, part of the criteria for defining the ecoregions is by their flora composition. Therefore identifying what magnitude of diversity exists in angiosperms among the ecoregions as well as relative phylogenetic diversity will help us understand how these assemblages are spatially distributed. Second, bees & plants are well known mutualist that may present interesting co-driven diversity trends at a large spatial scale. 

## Acknowledgments:
- NSF Grant DBI2102006
- iDigBio for funding our research
- Open-source data providers, collection managers, and collectors. In order to give back to the biodiversity informatics community, a goal of this project is to provide reproducible workflow and well noted methodology for dealing with occurrence data. Versions of the compiled occurrence data for bee & angiosperm are planned to be openly published for subsequent research projects involving these groups within the proposed geographic extent.  

**People**
- JT Miller: Repo owner, iDigBio Post-bac researcher at the Soltis Lab University of Florida, and research affiliate at CCBER UC Santa Barbara 
- Katja Seltmann: Project Advisor, Director of CCBER at UCSB. Advisor on Bee diversity, natural history, and biodiversity informatics. 
- Pamela Soltis: Project Advisor, Co-PI for the Soltis Lab at UF. Advisor on Flowering plant diversity and systematics. 
",['jtmiller28'],1,,0.7,0,,,,,,1,,emlab-ucsb,
695831635,R_kgDOKXmMUw,digital-commons-and-public-policy,virgile-dev/digital-commons-and-public-policy,0,virgile-dev,https://github.com/virgile-dev/digital-commons-and-public-policy,A Sciences Po Paris Public Affairs Master course to give students a sense of what digital commons are about and understand their complex ecosystem and interactions with private and public actors.,0,2023-09-24 11:14:06+00:00,2024-10-09 16:53:34+00:00,2024-10-09 16:53:30+00:00,https://virgile-dev.github.io/digital-commons-and-public-policy/,7100,6,6,SCSS,1,1,1,1,1,0,16,0,0,13,mit,1,0,0,public,16,13,6,main,1,,"---
layout: home
title: Digital Commons and Public Policy
nav_exclude: true
permalink: /:path/
seo:
  type: Course
  name: Digital Commons and Public Policy
---

# Navigation

This is a GitHub Pages static website designed for the purpose of teaching Public Affairs Students from Sciences Po Paris about Digital Commons. It's made of:

- [announcements](announcements.md),
- a weekly [course Syllabus](syllabus.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

## It's collaborative !
Of course it's handy to have a site publicly available with the course material. 
Though here the principal purpose is to teach students about how software is made by providing them an hands experience with no coding requirements. 
We'll try and have them create the entries for each week, solve issues, choose a licence etc. all by submitting [pull requests](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests).
We'll use the Github UI to do so but most saavy students can make their changes locally (see bellow).

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).

### Credits
The template used to generate this website is [Just the Class](https://github.com/kevinlin1/just-the-class) which extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!
","['virgile-dev', 'Smritibhat23', 'Giadina2001', 'Maryliz2001']",0,,0.82,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,scalableinternetservicesarchive,
362942520,MDEwOlJlcG9zaXRvcnkzNjI5NDI1MjA=,meds-template,jules32/meds-template,0,jules32,https://github.com/jules32/meds-template,,0,2021-04-29 20:42:38+00:00,2021-04-29 21:27:53+00:00,2021-04-29 21:27:50+00:00,,1892,0,0,CSS,1,1,1,1,1,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,"# MEDS course websites - optional template

This website template is made with [`distill` by RStudio](https://rstudio.github.io/distill/) as an optional starting point for teachers in the Master of Environmental Data Science Program at the Bren School (UC Santa Barbara). 

[Click here](https://allisonhorst.github.io/meds-distill-template/) for a template preview.
.

",['jules32'],1,,0.78,0,,,,,,1,,whatevery1says,
19156038,MDEwOlJlcG9zaXRvcnkxOTE1NjAzOA==,campus-map-tech,springmeyer/campus-map-tech,0,springmeyer,https://github.com/springmeyer/campus-map-tech,Listing of interactive campus maps and the main technology they use,0,2014-04-25 18:22:51+00:00,2024-06-02 10:34:38+00:00,2014-12-19 18:18:57+00:00,,171,24,24,,1,1,1,1,0,0,8,0,0,0,,1,0,0,public,8,0,24,master,1,,"Incomplete listing of interactive campus maps and the main technology they use. Please fork and add more to this list or comment below and I'll add directly.

## open source

Campus maps using open source software

1. [University of Colorado Boulder](http://www.colorado.edu/map/): Leaflet + Mapbox + TileMill + OSM

1. [University of Wisconsin-Madison](http://map.wisc.edu/): Leaflet + Mapbox + TileMill + OSM

1. [Universify of California, Santa Cruz](http://maps.ucsc.edu/): OpenLayers + OSM / Leaflet + OSM

1. [Univerity of Montana](http://map.umt.edu/): TileMill

1. [University of Delaware](http://maps.rdms.udel.edu/map/index.php): OpenLayers + OSM

1. [University of Maryland](https://terpnav.umd.edu/map/): OpenLayers + OSM

1. [Vassar College](http://info.vassar.edu/visit/maps/): OpenLayers + ExtJS


## Google Maps

Campus maps using google maps

1. [Middlebury College](http://www.middlebury.edu/about/campus/campusmap/interactive)

1. [University of Central Florida](http://map.ucf.edu/)

1. [Montana State University](http://www.montana.edu/campusmap/)

1. [University of Washington](http://www.washington.edu/maps/)

1. [Towson University](http://www.towson.edu/main/maps/)

1. [Oregon State University](http://oregonstate.edu/campusmap/)

1. [Washington State University](http://map.wsu.edu/)

1. [University of Alaska Anchorage](http://www.uaa.alaska.edu/map/interactive.cfm)

1. [The New Schoool](http://www.newschool.edu/about/campus-map/)

1. [Northeastern University](http://www.northeastern.edu/neuhome/about/maps.html)

1. [University of Hawaii](http://manoa.hawaii.edu/campusmap/)

1. [Bucknell University](http://www.bucknell.edu/script/communication/map/)

1. [William & Mary](http://www.wm.edu/about/visiting/campusmap/index.php)

1. [Brigham Young University](http://map.byu.edu/)

1. [Utah State University](http://www.usu.edu/map/)

1. [Utah Valley University](http://www.uvu.edu/maps/orem.html)

1. [Weber State University](http://www.weber.edu/weberstatemap/)

1. [University of California, Berkeley](http://www.berkeley.edu/map/googlemap/)

1. [University of California, Davis](http://campusmap.ucdavis.edu)

1. [University of California, Irvine](http:/www.uci.edu/campusmap)

1. [University of California, Riverside](http://campusmap.ucr.edu/imap/)

1. [Stanford University](http://campus-map.stanford.edu/)

## Esri

Campus maps using Esri

1. [University of Kentucky](http://maps.uky.edu/campusmap/)

1. [University of Missouri](http://map.missouri.edu/) 

1. [University of California, Santa Barbara](http://map.geog.ucsb.edu)

1. [University of California, Los Angeles](http://maps.ucla.edu/campus): Esri + Flex

1. [University of Oregon](http://map.uoregon.edu/) - Esri + Flex

1. [Western Washington University](http://www.wwu.edu/map)

## Other

1. [California Polytechnic State University](http://maps.calpoly.edu/) - flash

1. [Louisiana State University](http://campusmap.lsu.edu/map/framesetup.asp) - flash

1. [Humboldt State University](http://humboldt.edu/explore/): OpenLayers + http://www.nucloud.com illustrations

1. [Mount Mary University](http://www.mtmary.edu/campuslife/getting-around-campus/campus-map.html): OpenLayers + http://www.nucloud.com illustrations

1. [Münster University - Leonardo Campus (GER)](http://www.leonardocampus.de/) - HTML5

1. [Southern Utah University](http://www.suu.edu/campmap/campus.html) - image with links to building pages

1. [University of California, San Diego](http://maps.ucsd.edu/mapping/viewer/default.htm): FacilitiesLink

1. [University of Texas at Dallas, Dallas](http://www.utdallas.edu/maps/) - Flash 

","['johannesboyne', 'frewsxcv', 'drewda', 'lesserj', 'roboguy', 'tmcw']",0,,0.85,0,,,,,,2,,,
623580833,R_kgDOJSsWoQ,tasha_test,anastasiaquintana/tasha_test,0,anastasiaquintana,https://github.com/anastasiaquintana/tasha_test,,0,2023-04-04 16:53:29+00:00,2023-04-04 16:53:29+00:00,2023-04-05 17:17:07+00:00,,9,0,0,,1,1,1,1,0,0,0,0,0,0,apache-2.0,1,0,0,public,0,0,0,main,1,,"# This is Tasha's test After conflict resolved!!!

test repo for git and github lesson

## purpose

- create a remote repository on Github
- practice git workflow

## creator

- Tasha is a researcher at UCSB. More can be found at her [website](https://anastasiaquintana.com/). You can email her at [anastasiaquintana@ucsb.edu](mailto:anastasiaquintana@ucsb.edu).


Thank you for the collaboration. -Yulissa

## How to Create a Git Repository
- Go to GitHub webiste, create new repository, name of rep. has to match R file name. ","['anastasiaquintana', 'yperezrojas']",1,,0.75,0,,,,,,1,,,
231648379,MDEwOlJlcG9zaXRvcnkyMzE2NDgzNzk=,w20-lecture-files,ucsb-cs111/w20-lecture-files,0,ucsb-cs111,https://github.com/ucsb-cs111/w20-lecture-files,,0,2020-01-03 19:05:02+00:00,2023-02-07 14:42:56+00:00,2023-01-14 00:02:58+00:00,,26537,2,2,Jupyter Notebook,1,1,1,1,0,0,14,0,0,0,,1,0,0,public,14,0,2,master,1,1,"# UCSB CS111 Winter 2020 Lecture files

Website: <https://ucsb-cs111.github.io/w20/>

Contents:

 - cs111/                             Python code from class; put this directory in your Jupyter directory and ""import cs111""
 - exam_files/                        Sample exam problems.
 - homework_files/                    Extra materials for homework assignments.
 - lecture_files/                     Notes and slides used in class.
 - section_files/                     Files from section.
 - Class_transcript_date_topic.ipynb: Jupyter transcript from class. You should run it yourself.
","['johnrgilbert', 'pconrad']",1,,0.77,0,,,,,,3,,,
411465600,R_kgDOGIZ3gA,AutoCovidUCSBExtension,carlosdelajunior/AutoCovidUCSBExtension,0,carlosdelajunior,https://github.com/carlosdelajunior/AutoCovidUCSBExtension,,0,2021-09-28 23:19:24+00:00,2021-09-28 23:21:51+00:00,2021-09-28 23:21:48+00:00,,317,0,0,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# AutoCovidUCSBExtension
Auto fills the Covid survey by clicking no on everything
You can turn it on and off",['carlosdelajunior'],1,,0.84,0,,,,,,1,,,
301958082,MDEwOlJlcG9zaXRvcnkzMDE5NTgwODI=,ucsb_ccs_labs,Gopu2001/ucsb_ccs_labs,0,Gopu2001,https://github.com/Gopu2001/ucsb_ccs_labs,"CS16, 24, 32",0,2020-10-07 07:24:55+00:00,2021-12-14 22:25:01+00:00,2020-12-14 21:40:32+00:00,,10843,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['Gopu2001'],1,,0.76,0,,,,,,1,,,
690287180,R_kgDOKSTyTA,Portfolio,daniel-costello/Portfolio,0,daniel-costello,https://github.com/daniel-costello/Portfolio,These projects come from my studies in Data Science at UC Santa Barbara and my work for UC Santa Barbara IT Services.,0,2023-09-11 23:01:40+00:00,2023-09-14 18:51:08+00:00,2024-01-20 00:41:53+00:00,,4051,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Portfolio
These projects come from my studies in Data Science at UC Santa Barbara and my work for UC Santa Barbara IT Services.
",['daniel-costello'],1,,0.78,0,,,,,,1,,,
144182403,MDEwOlJlcG9zaXRvcnkxNDQxODI0MDM=,ucsb-cs56-dogwalker,ucsb-cs56-webapps/ucsb-cs56-dogwalker,0,ucsb-cs56-webapps,https://github.com/ucsb-cs56-webapps/ucsb-cs56-dogwalker,Dog walker/playdate matcher,0,2018-08-09 17:13:50+00:00,2020-10-24 21:28:16+00:00,2018-09-14 18:33:17+00:00,,53643,4,4,Java,1,1,1,1,0,0,6,0,0,16,mit,1,0,0,public,6,16,4,master,1,1,"# ucsb-cs56-dogwalker
Dog walker/playdate matcher

make a .env with ur mlab stuff then do . .env before compiling
USE JAVA8

Live here :  https://dogwalker.herokuapp.com/


Future Ideas
 
 show multiple posts for the same username and password
 pick which post to delete instead of deleting all 
 upload images and display them
 disassociate a users profile from posts
 

# Getting it to run: setting up env.sh

To run, the usual steps of `mvn compile exec:java` then visiting `http://localhost:4567` are a good start.

But, you'll get this error message:

```
Error: Must define env variable MONGODB_USER
Error: Must define env variable MONGODB_PASS
Error: Must define env variable MONGODB_NAME
Error: Must define env variable MONGODB_HOST
Error: Must define env variable MONGODB_PORT
Phillips-Mac-mini:sparkjava-rest-mlab-frontend pconrad$ 
```

To fix this, you need to take the following steps.  Note that the steps involving [mlab.com](https://mlab.com/) are pretty self-explanatory if you go to their website, so I'm not including much detail.  You'll figure it out.
1. Create a free account at [mlab.com](https://mlab.com/)
2. Create a deployment on the free tier
3. Create a database.  Call it whatever you like; perhaps `mlab-blog-demo` for example.
4. In that database, create two collections, initially empty
   * a collection called `posts`
   * a collection called `counters`
5. In the `counters` collection, create a document with exactly this content:
   ```json
   {
    ""_id"": ""postId"",
    ""seq"": 0
   }
   ```
6. Keep your [mlab.com](https://mlab.com/) window open; you'll need it.  But now turn back to the command line where you cloned this repo.  You'll see a file called `env.sh.EXAMPLE`.  Copy it to `env.sh`
   ```
   cp env.sh.EXAMPLE env.sh
   ```
7. Edit the env.sh file.  The values in it are just example values.  You'll need to change them as indicated in the next steps.  For each step, you'll get some piece of information from the [mlab.com](https://mlab.com/) window, so arrange your windows side by side where you can see them both.

   Go to the [mlab.com](https://mlab.com/) window and navigate to the page for your database.  If you called it `mlab-blog-demo`, for
   example, that page will have the URL `https://mlab.com/databases/mlab-blog-demo` and it will information like this at the top (this is just an example)
   
   ```
   To connect using the mongo shell:
     mongo ds143932.mlab.com:43932/cs56-m18-demo -u <dbuser> -p <dbpassword>
   To connect using a driver via the standard MongoDB URI (what's this?):
     mongodb://<dbuser>:<dbpassword>@ds143932.mlab.com:43932/cs56-m18-demo
   ```
   You should also see tabs for Collections, Users, Stats, Backups and Tools.

8. Now, open up env.sh for editing.  The first two lines say:
   ```
   export MONGODB_USER=testuser
   export MONGODB_PASS=abcd1234
   ```
   DO NOT CHANGE THESE TO THE USERNAME AND PASSWORD YOU USED TO LOGIN TO [mlab.com](https://mlab.com/)!!! These are a different
   user and password, that you are going to create right now in the [mlab.com](https://mlab.com/) window.
   
   In your file, create a username (Literally using `testuser` is fine).  For password, make up a good long random password, such as
   `8sfvlSFE13RGDG2`.  The longer and more random the better, because you are never going to have to remember or type in this password;
   You are going to enter it once in this file; then copy and paste it into MLab when you create the user/password, and then never have
   to type it again.  Please DON'T literally use `abcd1234` or `8sfvlSFE13RGDG2`.
   
   Type it in the `env.sh` file first.  Then click the ""Users"" tab, and look over to the right side of the screen for the ""Add database user"" button.  Click it, and enter the username and password that you just created (e.g. `testuser` and `8sfvlSFE13RGDG2`.  You'll want to copy/paste the password since you have to type it twice.)
   
   Now, we'll move on to the other values in the `env.sh` file.
   
9. For these values, you are going to find these on the Mlab screen for your database:
   
  * For `MONGODB_NAME` change it from `cs56-m18-demo` to whatever the name of your database is (e.g. `mlab-blog-demo`)
  * For `MONGODB_HOST` and `MONGO_PORT` find the thing that says:
      ``` 
      To connect using the mongo shell:
        mongo ds144023.mlab.com:47245/cs56-m18-demo -u <dbuser> -p <dbpassword>
      ```
      In this example, `MONGODB_HOST` should be `ds144023.mlab.com` and `MONGODB_PORT` should be `47245`.
      
10. Once you've made these edits, you need to type the following so that these environment variables take effect:
   ```
   . env.sh
   ```
   This sets up the environment variables that the Java code will read from.
   
   While the previous steps 1-9 are ""one time only"" steps, this final step must be done each time you log in to a term Unix terminal
   session; the environment variable are defined as part of the current process.
   
Once you've done these steps, you should be able to run and not see the error message about defining environment variables.

```
Error: Must define env variable MONGODB_USER
etc..
```

So try doing `mvn compile exec:java` again, and visiting `http://localhost:4567`
      
# More detail

This code shows a way to use:
* Lombok (<https://projectlombok.org>) to reduce the Java boilerplate you need for pure data classes.
   * Basically, you put `@lombok.Data` on your class, and then you don't need to write constructors, getters,
      setters, `toString`, `equals`, `hashCode`, etc.   Lombok does it for you.
   * Note that this feature is coming in later versions of Java (though use of Java beyond Java 8 in the real
      world is still limited, as of Summer 2018.   Java 8 is the ""long-term-support"" version; Java 11 is only
      just about to become that later in 2018.)
* Jackson and Gson to convert data to/from JSON automatically
* Building a RESTful API (one that ""speaks in JSON"") using SparkJava


# Modifications from the original [reducing-java-boilerplate](http://sparkjava.com/tutorials/reducing-java-boilerplate) tutorial:

* The original is all in one `.java` source file.  I broke it up.
   * All one source file is convenient for a  quick demo example.
   * It is NOT intended as an example of good practice.
* The original isn't set up to be conveniently deployable on Heroku
   * I added the port number settings, a `Procfile`, and the Maven code in the `pom.xml` to enable `mvn heroku:deploy`
* The original uses `Map` instead of `Map<Integer,Post>`, for example, which triggers deprecation warnings, and in one case, a compiler fatal error.
   * I modified the code to remove these issues.
   
# Testing the RESTful API:

Since this app is a RESTFUL api that ""speaks JSON"", you'll need to use special techniques to test it.

The original tutorial shows testing it with a Chrome extension called Postman, but that Chrome extension
appears to be deprecated, and the replacements for it are heavyweight, and require giving access to your
Google account, etc. to unknown parties.  I'd suggest using a different approach.

Here's a tutorial that shows how to test it with plain old curl at the CLI (e.g. the command line on CSIL):

* [Test a REST API with curl](https://www.baeldung.com/curl-rest)

And here's an example that shows how to do the tests originally shown in the tutorial with Postman, but
using curl.

Before we start: let's acknowledge a possible confusion between:
* `POST`, all caps, which is an HTTP method type (`GET` vs. `POST` vs. `PUT`, vs. `DELETE` etc.)
* post, which is an example of a single message on a blog (i.e. a blog post).

Those words are both spelled p-o-s-t, but they are entirely separately concepts.  I'll use `POST` when I mean
the http method, and ""post"" when I just mean one of the messages on the blog, or the ""object"" that represents
one of those messages.

Now let's get started. Start the application running on `localhost:4567` in one terminal window using `mvn compile exec:java`.  In a second terminal window, use `curl http://localhost:4567/posts`.   This does a simple `GET` http request to the server, and what is returned in the JSON representation of all the posts currently stored on the server.  


```
$ curl http://localhost:4567/posts
[ ]$ 
```

At the moment, that's an empty list, which in JSON is represneted as `[ ]`.

So if we want some posts in the list, we'll need to add some.

If you `cd` into the directory `testdata`, you'll see that I've created some files that represent
blog posts formatted in JSON.  For example, the contents of the file `post1.json` is this:

```json
{
    ""title"" : ""A post about Spark"",
    ""content"" : ""Spark is quite cool!"",
    ""categories"" : [""java"",""web apps""]
}
```

The curl command can be used with the `-d` option (which stands for data) to do a `POST` request to add this post to the blog.  Here's what that looks like.    This sends a `POST` request to the url, with the payload (content) being the contents of the file `post1.json`:

```
$ curl -d @post1.json http://localhost:4567/posts
1$
```

A few notes about that:

* The response from the server was just the integer `1`; you can see that response before the `$` which is the CLI prompt.  The server responded with the `id` of the object we created.

If we repeat this command a few times, we get `2`, `3`, `4` etc.:

```
$ curl -d @post1.json  http://localhost:4567/posts
3$ curl -d @post1.json  http://localhost:4567/posts
4$
```

If we then simply use `curl http://localhost:4567/posts` again, we get a list of all of these posts formatted in JSON:

```
$ curl http://localhost:4567/posts
[ {
  ""id"" : 1,
  ""title"" : ""A post about Spark"",
  ""categories"" : [ ""java"", ""web apps"" ],
  ""content"" : ""Spark is quite cool!""
}, {
  ""id"" : 2,
  ""title"" : ""A post about Spark"",
  ""categories"" : [ ""java"", ""web apps"" ],
  ""content"" : ""Spark is quite cool!""
}, {
  ""id"" : 3,
  ""title"" : ""A post about Spark"",
  ""categories"" : [ ""java"", ""web apps"" ],
  ""content"" : ""Spark is quite cool!""
}, {
  ""id"" : 4,
  ""title"" : ""A post about Spark"",
  ""categories"" : [ ""java"", ""web apps"" ],
  ""content"" : ""Spark is quite cool!""
} ] $
```

If we stop and restart the webapp, we will see that since this list is just in memory, and not in a database, it does not persist (i.e. stick around).   If we want that, we need to store it in a database with each operation.

So after stopping and restarting the server, once again, we have an empty list:

```
$ curl http://localhost:4567/posts
[ ]$ 
```

To test methods other than `GET` and `POST`, use the `-X` flag.  For example, to
test `DELETE` method, you can use:

```
$ curl -X DELETE http://localhost:4567/posts/13
```


# How to compile and run

| To do this | Do this |
| -----------|-----------|
| run the program | Type `mvn exec:java`.  Visit the web page it indicates in the message |
| check that edits to the pom.xml file are valid | Type `mvn validate` |
| clean up so you can recompile everything  | Type `mvn clean` |
| edit the source code for the app | edit files in `src/main/java`.<br>Under that the directories for the package are `edu/ucsb/cs56/pconrad`  |
| edit the source code for the app | edit files in `src/test/java`.<br>Under that the directories for the package are `edu/ucsb/cs56/pconrad`  |
| compile    | Type `mvn compile` |
| run junit tests | Type `mvn test` |
| build the website, including javadoc | Type `mvn site-deploy` then look in either `target/site/apidocs/index.html`  |
| copy the website to `/docs` for publishing via github-pages | Type `mvn site-deploy` then look for javadoc in `docs/apidocs/index.html` |        
| make a jar file | Type `mvn package` and look in `target/*.jar` |

| run the main in the jar file | Type `java -jar target/sparkjava-demo-01-1.0-jar-with-dependencies.jar ` |
| change which main gets run by the jar | Edit the `<mainClass>` element in `pom.xml` |
| deploy to heroku | change the `<appname>` element and the name of the jar file in both pom.xml and Procfile, then use `heroku login`, then `mvn heroku:deploy` |
","['andrewdoanutz', 'omerco1', 'connordaly1', 'pconrad', 'tim2167', 'atahiraj', 'Lele521']",1,,0.8,0,,,,,,0,,,
493836589,R_kgDOHW9ZLQ,PhyloAssigner_python_UCSB,BIOS-SCOPE/PhyloAssigner_python_UCSB,0,BIOS-SCOPE,https://github.com/BIOS-SCOPE/PhyloAssigner_python_UCSB,phyloassigner rewritten phyton v0.9,0,2022-05-18 21:55:03+00:00,2024-06-04 12:55:21+00:00,2024-06-04 12:55:17+00:00,,2626,1,1,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,1,"# PhyloAssigner_python_UCSB

+ code&instructions by Fabian Wittmers

### background

This repository contains a working version of PhyloAssigner. The tool produces results that are comparable with the original version of this tool as published in 2013 by Kevin Vergin (Vergin et al. 2013). 
It does not rely on any of the old code and is written in fully written in python3, resulting in a more userfriendly application and easier installation.
This rewrite includes a small bugfix on how the old perl-code handled the computation of LCA placements, but runs on the same basic principle as the original PhyloAssigner.

### installation

PhyloAssigner handles alignment, reformatting, placement and output summary all within one command and therefore relies on some dependencies. I advice to run PhyloAssigner on a linux system, idealy a cluster with a good chunk of RAM, although it can run on low RAM systems just fine (will just take longer). It installation is simple, all dependencies can be installed in 1 command by creating a new conda environment to run PhyloAssigner in.

```{bash}
conda env create -f pythonassigner_linux.yml
```

### command structure

```{bash}
usage: pythonassigner_v0.9.py [-h] -o OUT_DIR -r REF_ALIGN -t REF_TREE -q
                              QUERY_SEQS -m MAPPING [-T THREADS] [-p PLACER]

run PythonAssigner through the command-line. This is an updated version of PhyloAssigner, 
    originally written in 2012 in perl. See: Vergin et al. 2013 supplementary information for more details; Rewritten 
    in python3 by Fabian Wittmers 2021/2022 

optional arguments:
  -h, --help            show this help message and exit
  -o OUT_DIR, --out_dir OUT_DIR
                        output directory were result files should be stored
  -r REF_ALIGN, --ref_align REF_ALIGN
                        reference alignment file. Must contain the same
                        sequence identifiers as in the reference tree
  -t REF_TREE, --ref_tree REF_TREE
                        reference tree file (newick formatted). Must contain
                        the same sequence identifiers as in the reference
                        alignment
  -q QUERY_SEQS, --query_seqs QUERY_SEQS
                        fasta file of sequences you want to place on reference
                        tree
  -m MAPPING, --mapping MAPPING
                        taxonomy mapping file: edge number in first column +
                        corresponding taxonomy in second column. If edge is a
                        tip, then tip label in third.
  -T THREADS, --threads THREADS
                        specify the number of threads to use in parallel
                        computation steps
  -p PLACER, --placer PLACER
                        specify which placement algorithm to use, choose
                        between 'pplacer' or 'epang'. Alternatively, you can
                        run 'compare' mode to compare both placement
                        algorithms
```

### currently available databases

This git contains a collection of placement reference trees build by different members of the WordenLab, Luis Bolanos, and Kevin Vergin.

Currently available databases (and the paper in which they were published) comprise:
+ Global 16S
  + Vergin et al. 2013; ""High-resolution SAR11 ecotype dynamics at the Bermuda Atlantic Time-series Study site by phylogenetic placement of pyrosequences""
+ SAR11
  + Bolanos et al. 2021; ""Seasonality of the Microbial Community Composition in the North Atlantic""
  + see: https://github.com/lbolanos32/NAAMES_2020
+ SAR202
  + Landy et al. 2017; ""SAR202 Genomes from the Dark Ocean Predict Pathways for the Oxidation of Recalcitrant Dissolved Organic Matter""
  + see: https://github.com/lbolanos32/NAAMES_2020
+ Dictyochophyceae (16S plastid)
  + Choi et al. 2021; ""Seasonal and Geographical Transitions in Eukaryotic Phytoplankton Community Structure in the Atlantic and Pacific Oceans""
+ Pelagophyceae (16S plastid)
  + Choi et al. 2021; ""Seasonal and Geographical Transitions in Eukaryotic Phytoplankton Community Structure in the Atlantic and Pacific Oceans""
+ Stramenopiles (16S plastid)
  + Choi et al. 2021; ""Seasonal and Geographical Transitions in Eukaryotic Phytoplankton Community Structure in the Atlantic and Pacific Oceans""
+ Cyanobacteria
  + Sudek et al. 2015; ""Cyanobacterial distributions along a physico-chemical gradient in the Northeastern Pacific Ocean"" 
+ Prochlorococcus
  + *Worden Lab; unpublished* (Strauss&Choi et al. submitted)
+ Cyanobacteria + Plastid
  + Sudek et al. 2015; ""Cyanobacterial distributions along a physico-chemical gradient in the Northeastern Pacific Ocean""
  + Choi et al. 2017; ""Newly discovered deep-branching marine plastid lineages are numerically rare but globally distributed""
+ Viridiplantae (16S plastid)
  + *Worden Lab; unpublished*
+ Chrysophyceae (16S plastid)
  + *Worden Lab; unpublished*
+ Synechococcus  
  + *Worden Lab; unpublished* 

### command example

PhyloAssigner requires 3 reference files, that are part of each PhyloAssigner database in this git:

+ reference tree
  + reference phylogeny to place the ASVs on 
+ reference alignment
  + alignment that was used to reconstruct the reference tree
+ reference mapping
  + connects each edge in the tree with its corresponding label that shall be printed in the results

Those 3 input files are provided. In addition, the user is required to provide an output directory. Optional arguments include the number of threads to use (for the alignment of query and reference sequences) and what placement algorithm to use. The default placement algorithm is PPLACER, so the user does not have to specify it.

```{bash}
python pythonassigner_v0.9.py \
    --out_dir example_output/ \
    --ref_align databases/Global_16S_refDB/ref.aln \
    --ref_tree databases/Global_16S_refDB/ref_tree.txt \
    --query_seqs your_ASVs.fasta \
    --mapping databases/Global_16S_refDB/edge.mapping \
    --threads 32 \
    --placer pplacer
```

### 16S region compatibility

Most of the reference databases provided here have been created over multiple years and they do differ in the 16S region that they are suitable for. Some alignments are specific to the v1v2 region, while others can be used for the v4 or v4v5 region as well. Here is an overview of which databases can be used for which regions: 

+ Global
  + available: 16S v1v2
  + validated: 16S v1v2
+ SAR11
  + available: 16S full_length
  + validated: 16S v1v2 & 16S v4 (on full length alignment)
  + see [here](https://github.com/lbolanos32/NAAMES_2020) for the originally published database, reformatted for the python3 version of phyloassigner now
+ SAR202
  + available: 16S full_length
  + validated: 16S v1v2 & 16S v4 (on full length alignment)
  + see [here](https://github.com/lbolanos32/NAAMES_2020) for the originally published database, reformatted for the python3 version of phyloassigner now
+ Dictyochophyceae
  + available: 16S full_length
  + validated: 16S v1v2 (on full length alignment)
+ Pelagophyceae
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2
+ Stramenopiles
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2
+ Cyanobacteria
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2
+ Prochlorococcus
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2
+ Cyanobacteria + Plastid
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2
+ Viridiplantae
  + available: 16S v1v2 & 16S full_length
  + validated: 16S v1v2

per default, PhyloAssigner currently runs for the v1v2 region. If you want to run amplicons from a different region, some modifications will be necessary for all reference databases that are not validated for the 16S v1v2 region. If a 16S full_length alignment is available these changes can be implemented so please reach out to the author of this git if this becomes relevant to you.
","['FWittmers', 'kevinvergin']",1,,0.74,0,,,,,,4,,,
703247482,R_kgDOKeq0eg,ece153a,BK1031/ece153a,0,BK1031,https://github.com/BK1031/ece153a,Assignments from the ECE153A course at UCSB.,0,2023-10-10 22:07:49+00:00,2023-10-11 10:41:58+00:00,2023-12-15 13:50:28+00:00,,23612,0,0,C,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['BK1031'],1,,0.63,0,,,,,,1,,,
260318547,MDEwOlJlcG9zaXRvcnkyNjAzMTg1NDc=,SEM-Lab5,garberadamc/SEM-Lab5,0,garberadamc,https://github.com/garberadamc/SEM-Lab5,"Lab 5 Conditional indirect effects - University of California, Santa Barbara - Structural Equation Modeling, ED216F - Adam Garber",0,2020-04-30 21:05:49+00:00,2020-05-05 17:12:40+00:00,2020-05-05 17:12:37+00:00,,2295,0,0,HTML,1,1,1,1,0,0,10,0,0,0,,1,0,0,public,10,0,0,master,1,,"# SEM-Lab5
Lab 5 Conditional indirect effects - University of California, Santa Barbara - Structural Equation Modeling, ED216F - Adam Garber
",['garberadamc'],1,,0.7,0,,,,,,1,,,
3475527,MDEwOlJlcG9zaXRvcnkzNDc1NTI3,UCSBMemes,serverwave/UCSBMemes,0,serverwave,https://github.com/serverwave/UCSBMemes,,0,2012-02-18 01:53:13+00:00,2014-04-15 17:56:16+00:00,2012-02-18 00:05:52+00:00,,1461,1,1,JavaScript,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,#ERROR!,"['andytcox', 'phrazzld']",0,,0.74,0,,,,,,1,,,
262164558,MDEwOlJlcG9zaXRvcnkyNjIxNjQ1NTg=,SEM-Lab6,garberadamc/SEM-Lab6,0,garberadamc,https://github.com/garberadamc/SEM-Lab6,"Lab 6 Latent Growth Models - University of California, Santa Barbara - Structural Equation Modeling, ED216F - Adam Garber",0,2020-05-07 21:41:55+00:00,2020-05-07 22:09:56+00:00,2020-05-07 22:09:54+00:00,,5622,0,0,R,1,1,1,1,0,0,16,0,0,0,,1,0,0,public,16,0,0,master,1,,"# SEM-Lab6
Lab 6 Latent Growth Models - University of California, Santa Barbara - Structural Equation Modeling, ED216F - Adam Garber
",['garberadamc'],1,,0.73,0,,,,,,1,,,
343908461,MDEwOlJlcG9zaXRvcnkzNDM5MDg0NjE=,s21,ucsb-cs24/s21,0,ucsb-cs24,https://github.com/ucsb-cs24/s21,,0,2021-03-02 20:48:12+00:00,2022-02-14 18:48:34+00:00,2022-02-14 18:48:46+00:00,,117020,1,1,HTML,1,1,1,1,1,0,5,0,0,0,,1,0,0,public,5,0,1,main,1,1,"# ucsb-cs24/s21

Jekyll-based website for UCSB CS24 Winter 2021, for shared course materials.

* website: <https://ucsb-cs24.github.io/s21/>
* The theme currently being used can be find in the jekyll-theme value in `_config.yml`
* The navigation is set by the values in `_data/navigation.yml`

# Travis-CI


Build Status: [![Build Status](https://travis-ci.org/ucsb-cs24/w21.svg?branch=master)](https://travis-ci.org/ucsb-cs24/w21)

The continuous integration service [travis-ci.org](https://travis-ci.org) can be used to check whether a Github Pages site is
building properly, and if not, see the syntax errors.

The site for this repo is:  <https://travis-ci.org/ucsb-cs24/s21>

* At that site you can enable builds (if the logo shows grey for no info), or see a log of the latest build.
* Also, see the green dots, yellow dots, and red x's on the [Commit log of this repo](https://github.com/ucsb-cs24/s21/commits/master)
* [These instructions](https://docs.travis-ci.com/user/status-images/) explain how to add a Build Status logo to a README.md
   








To test locally:
* One time setup:
    * `git clone` the repo
    * Install rvm (the Ruby version manager)
    * Run `./setup.sh` to install correct ruby version, bundler version, and bundle the gems
* From then on, to test the site locally:
    * Run `./jekyll.sh
    * Point browser to <http://localhost:4000>
","['dibamirza', 'alexiscole99', 'yingrui-yang', 'myuusubi', 'NeuroscienceScripts']",1,,0.96,0,,,,,,1,,,
270565346,MDEwOlJlcG9zaXRvcnkyNzA1NjUzNDY=,GAMES101,littlekuo/GAMES101,0,littlekuo,https://github.com/littlekuo/GAMES101,my solutions to GAMES101  https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html,0,2020-06-08 07:03:31+00:00,2020-06-09 07:50:01+00:00,2020-06-09 07:49:59+00:00,,4623,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# GAMES101
my solutions to GAMES101(https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html)
",['littlekuo'],1,,0.78,0,,,,,,1,,,
482583762,R_kgDOHMOk0g,games101-codes,jzsherlock4869/games101-codes,0,jzsherlock4869,https://github.com/jzsherlock4869/games101-codes,ucsb games101 (overview of computer graphics) codes,0,2022-04-17 17:03:28+00:00,2024-04-12 05:18:26+00:00,2022-04-17 17:47:57+00:00,,2,1,1,,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,1,main,1,,"# games101 course codes

ucsb games101 (overview of computer graphics) codes

[course video](https://www.bilibili.com/video/BV1X7411F744)
",['jzsherlock4869'],1,,0.7,0,,,,,,1,,,
166607813,MDEwOlJlcG9zaXRvcnkxNjY2MDc4MTM=,rtimulib-ucsb,nasa-watchdog/rtimulib-ucsb,0,nasa-watchdog,https://github.com/nasa-watchdog/rtimulib-ucsb,,0,2019-01-20 00:26:30+00:00,2019-01-30 17:18:36+00:00,2019-01-20 00:50:23+00:00,,1477,1,1,C++,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,1,master,1,1,"# RTIMULib - a versatile C++ and Python 9-dof, 10-dof and 11-dof IMU library

RTIMULib is the simplest way to connect a 9-dof, 10-dof or 11-dof IMU to an embedded Linux system and obtain Kalman-filtered quaternion or Euler angle pose data. Basically, two simple funtion calls (IMUInit() and IMURead()) are pretty much all that's needed to integrate RTIMULib.

## Have questions, need help or want to comment?

Please use the richards-tech user forum at https://groups.google.com/forum/#!forum/richards-tech-user-forum.

## Features

The Linux directory contains the main demo apps for embeeded Linux systems:

* RTIMULibDrive is a simple app that shows to to use the RTIMULib library in a basic way.
* RTIMULibDrive10 adds support for pressure/temperature sensors.
* RTIMULibDrive11 adds support for pressure/temperature/humidity sensors.
* RTIMULibCal is a command line calibration tool for the magnetometers and accelerometers.
* RTIMULibvrpn shows how to use RTIMULib with vrpn.
* RTIMULibDemo is a simple GUI app that displays the fused IMU data in real-time.
* RTIMULibDemoGL adds OpenGL visualization to RTIMULibDemo.

RTIMULib is a C++ library but there are also Python bindings in Linux/python. It's easy to build and install the Python RTIMULib library using the provided setup.py after which any Python script will have access to RTIMULib functionality. See Linux/python.README.md (https://github.com/richards-tech/RTIMULib/blob/master/Linux/python/README.md) for more details. Two demo scripts show how to use the Python interface.

Check out www.richards-tech.com for more details, updates and news.

RTIMULib currently supports the following IMUs:

* InvenSense MPU-9150 single chip IMU.
* InvenSense MPU-6050 plus HMC5883 magnetometer on MPU-6050's aux bus (handled by the MPU-9150 driver).
* InvenSense MPU-6050 gyros + acclerometers. Treated as MPU-9150 without magnetometers.
* InvenSense MPU-9250 single chip IMU (I2C and SPI).
* STM LSM9DS0 single chip IMU.
* STM LSM9DS1 single chip IMU.
* L3GD20H + LSM303D (optionally with the LPS25H) as used on the Pololu AltIMU-10 v4.
* L3GD20 + LSM303DLHC as used on the Adafruit 9-dof (older version with GD20 gyro) IMU. 
* L3GD20H + LSM303DLHC (optionally with BMP180) as used on the new Adafruit 10-dof IMU.
* Bosch BMX055 (although magnetometer support is experimental currently).
* Bosch BNO055 IMU with onchip fusion. Note: will not work reliably with RaspberryPi/Pi2 due to clock-stretching issues.

The LSM9DS1 implementation was generously supplied by XECDesign.

Pressure/temperature sensing is supported for the following pressure sensors:

* BMP180
* LPS25H
* MS5611
* MS5637

Humidity/temperature sensing is supported for the following humidity sensors:

* HTS221
* HTU21D

The humidity infrastructure and HTS221 support was generously supplied by XECDesign. It follows the model used by the pressure infrastructure - see RTIMULibDrive11 for an example of how to use this.

Note that currently only pressure and humidity sensors connected via I2C are supported. Also, an MS5637 sensor will be auto-detected as an MS5611. To get the correct processing for the MS5637, edit the RTIMULib.ini file and set PressureType=5.

By default, RTIMULib will try to autodiscover IMUs, pressure and humidity sensors on I2C and SPI busses (only IMUs on the SPI bus). This will use I2C bus 1 and SPI bus 0 although this can be changed by hand editing the .ini settings file (usually called RTIMULib.ini) loaded/saved in the current working directory by any of the RTIMULib apps. RTIMULib.ini is self-documenting making it easy to edit. Alternatively, RTIMULibDemo and RTIMULibDemoGL provide a GUI interface for changing some of the major settings in the .ini file.

RTIMULib also supports multiple sensor integration fusion filters such as Kalman filters.

Two types of platforms are supported:

* Embedded Linux. RTIMULib is supported for the Raspberry Pi (Raspbian) and Intel Edison. Demo apps for these can be found in the Linux directory and instructions for building and running can be found there. Its prerequisites are very simple - just I2C support on the target system along with the standard build-essential (included in the Raspberry Pi Raspbian distribution by default).

* Desktop (Ubuntu/Windows/Mac). There are two apps (RTHostIMU and RTHostIMUGL) that allow the sensor fusion to be separated from the sensor interfacing and data collection. An Arduino (running the RTArduLinkIMU sketch from the RTIMULib-Arduino repo) fitted with an IMU chip collects the sensor data and sends it to the desktop. RTHostIMU and RTHostIMUGL (this one has an OpenGL visualization of the data) communicate with the Arduino via a USB connection.

The MPU-9250 and SPI driver code is based on code generously supplied by staslock@gmail.com (www.clickdrive.io). I am sure that any bugs that may exist are due to my integration efforts and not the quality of the supplied code!

RTIMULib is licensed under the MIT license.

## Repo structure

### RTIMULib

This is the actual RTIMULib library source. Custom apps only need to include this library.

### Linux

This directory contains the embedded Linux demo apps (for Raspberry Pi and Intel Edison) and also the Python interface to RTIMULib.

### RTHost

RTHost contains the two apps, RTHost and RTHostGL, that can be used by desktops that don't have direct connection to an IMU (as they don't have I2C or SPI interfaces). An Arduino running RTArduLinkIMU from the RTIMULib-Arduino repo provides the hardware interface and a USB cable provides the connection between the desktop and the Arduino.

### RTEllipsoidFit

This contains Octave code used by the ellipsiod fit data generation in RTIMULibCal, RTIMULibDemo, RTIMULibDemoGL, RTHostIMU and RTHostIMUGL. It's important that a copy of this directory is at the same level, or the one above, the app's working directory or ellipsoid fit data generation will fail.

## Note about magnetometer (compass) calibration

It is essential to calibrate the magnetometer or else very poor fusion results will be obtained. For more about this, see http://wp.me/p4qcHg-b4. RTIMULibDemo (GUI) and RTIMULibCal (command line) can be used to do this. They both support magnetometer min/max, magnetometer ellipsoid fit and accelerometer min/max calibration.

Also, if using a non-standard axis rotation (see http://wp.me/p4qcHg-cO), magnetometer calibration (and accelerometer calibration if that has been performed) MUST be run AFTER changing the axis rotation.

## Next Steps

SyntroPiNav (an app for the Raspberry Pi) and SyntroNavView can be used as a convenient system to experiment with IMU chips, drivers and filters. SyntroPiNav runs on the Pi and transmits IMU data along with filter outputs over a LAN to SyntroNavView running on an Ubuntu PC. SyntroNavView also displays the data and provides a 3D graphics view of the calculated pose.

Since all IMU data is sent to SyntroNavView, SyntroNavView can run its own local filter. This makes it a very convenient testbed for new filter development as the speed of the desktop can be used to accelerate implementation and testing. When ready, the updated RTIMULib can be compiled into SyntroPiNav and should work exactly the same as on the desktop.

SyntroPiNav is available as part of the richards-tech SyntroPiApps repo (https://github.com/richards-tech/SyntroPiApps) while SyntroNavView is available as part of the richards-tech SyntroApps repo (https://github.com/richards-tech/SyntroApps).

## Release history

### June 22 2015 - 7.2.1

Improvement to Linux CMakeLists.txt. Added temp comp to HTU21D.

### June 21 2015 - 7.2.0

Added support for HTU21D humidity sensor.

### June 17 2015 - 7.1.0

Added humidity support to the demo apps and created RTIMULibDrive11 and Fusion11.py. Fixed some related build problems. Updated some source headers.

### June 15 2015 - 7.0.3

Improved CMake versioning system.

### June 12 2015 - 7.0.2

Also added SOVERSION to RTIMULibGL build via CMake. Note - on Linux it may be necessary to run ""sudo ldconfig"" after building.

### June 12 2015 - 7.0.1

Added SOVERSION to CMake build library.

### June 9 2015 - 7.0.0

New humidity infrastructure and HTS221 support added. Thanks to XECDesign for this. Due to lack of hardware for testing at this time, this release is somewhat experimental - use 6.3.0 if problems are encountered.

LSM9DS1 support added.

### May 17 2015 - 6.3.0

Added support for the BNO055. The BNO055 always uses its onchip fusion rather than RTIMULib filters. This will not work reliably with the Raspberry Pi/Pi2 due to clock-stretching issues.

### April 30 2015 - 6.2.1

Added second order temperature compensation for MS5611 and MS5637. MS5637 still seems to be affected by temperature - this is being investigated.

### April 24 2015 - 6.2.0

Add support for Bosch BMX055 IMU and MS5637 pressure sensor. See notes above about auto-detection for the MS5637.

The BMX055 implementation is slightly experimental as the magnetometer results show significant asymmetry about zero. The processing of the magnetometer data is fairly complex and there could be an error in it. Calibration is essential for this IMU at the moment.

### March 31 2015 - 6.1.0

Allow RTQF Slerp power to be changed while running while fusion running. Some performance improvements and cleanups.

### March 29 2015 - 6.0.0

Changed RTQF state correction mechanism to use quaternion SLERP. This is a little experimental - if you encounter problems, please use the 5.6.0 release (from the Releases tab).

### March 21 2015 - 5.6.0

Added support for MPU6050 + HMC5883 IMUs (HMC5883 on MPU-6050's aux bus).

### March 20 2015 - 5.5.0

Added support for the MS5611 pressure sensor and also modified MPU-9150 driver to also support the MPU-6050.

### February 21 2015 - 5.4.0

Python API now works with Python 2.7 and Python 3.4.

Changed MPU9150 and MPU9250 drivers so that compass adjust is performed before axis swap.

### January 31 2015 - 5.3.0

Added abilty to set magnetic declination in the .ini file. This value in radians is subtracted from the measured heading before being used by the fusion algorithm.

### January 24 2015 - 5.2.3

Fixed problem with CMakeLists.txt for RTIMULibGL.

### January 19 2015 - 5.2.2

Improved some CMakeLists. RTIMULib can now be built with cmake independently.

### December 29 2014 - 5.2.1

Some improvements to the RTHost CMakelists.txt. Changed Visual Studio version to VS2013.

### December 29 2014 - 5.2.0

Added support for vrpn. There is a new demo app, RTIMULibvrpn, that shows how this works.

RTSettings constructor now optionally allows the directory used for the .ini settings file to be specified. The original constructor uses the working directory whereas the additional constructor allows this bevaiour to be overridden.

Changed install directory to /usr/local/bin when using the supplid Makefiles and qmake instead of /usr/bin. This is to be consistent with cmake-generated makefiles.

### December 15 2014 - 5.1.0

Added support for the LPS25H pressure/temperature sensor.

Addeed support for SPI chip select 1 in addition to chip select 0. A new field, SPISelect, has been added. RTIMULib will try to autodetect SPI bus 0, select 0 and SPI bus 0 select 1 but others can be used if the RTIMULib.ini file is hand-edited.

### December 10 2014 - 5.0.0

Top level directory structure completely reorganized.

Support for pressure sensors.

New demo app, RTIMULibDrive10, to demonstrate use of pressure sensors with RTIMULib.

RTIMULibDemo and RTIMULibDemoGL upgraded to support pressure sensors.

Python library upgraded to support pressure sensors. A new demo script, Fusion10.py, shows how to use the interface.

### December 3 2014 - 4.4.0

Added RTIMULibDemoGL and reorganized the OpenGL components.

### December 3 2014 - 4.3.2

CMake build system now works for the RTHostIMU and RTHostIMUGL apps on Windows and Mac OS X. The full set of apps are built on Linux.

Some minor driver fixes.

RTHostIMUGL now runs on the Raspberry Pi. Simpler (non-ADS) shading is used to imporve performance.

### December 2 2014 - 4.3.1

Fixed the CMakeLists.txt for RTIMULibDemo.

### December 2 2014 - 4.3.0

Added cmake support (see build instructions for more info). This was based on work by Moritz Fischer at ettus.com. As part of this, the qextserialport folder was renamed to RTSerialPort. There are also some small fixes in the MPU-9150/9250 and GD20HM303D drivers.

### November 18 2014 - 4.2.0

Add the IMU axis rotation capability to better handle IMUs in non-standard orientations. See http://wp.me/p4qcHg-cO for more details of how to use this capability.

### November 14 2014 - 4.1.0

Corrected some problems with the continuous gyro bias update system. There is a new function in RTIMU called setGyroContinuousLearningAlpha() that allows the continuous learning rate to be set. RTIMULIB uses a rapid learning rate to collect the initial gyro bias data but then uses a much slower rate for continuous tracking of bias. This function allows the rate to be set if necessary - values can be between 0.0 and 1.0. Setting it to 0.0 turns off continuous learning completely so that gyro bias calculation only occurs during the rapid learning period.

loadSettings() and saveSettings() in RTSettings.cpp are now virtual to give more flexibility in how settings are stored.

### November 8 2014 - 4.0.1

Fixed some missing MPU-9250 related defs in python interface.

### November 7 2014 - 4.0.0

Restructured library to add support for the MPU-9250 and SPI bus. This is a little experimental right now - use V3.1.1 if problems are encountered with existing supported IMUs. The MPU-9250 has been seen to hang when used on the SPI bus at sample rates above 300 samples per second. However, sample rates up to 1000 seem to work fine using I2C.

The RTIMULib apps are now able to auto-detect on the I2C and SPI bus so, if only one supported IMU is present on either bus, the code should find it. Note that only the MPU-9250 is supported by the SPI driver at the moment. There are some new settings in the RTIMULib.ini file related to the SPI bus that may need editing in some systems. The default SPI bus is set 0 which works nicely for the Raspberry Pi. Connect the MPU-9250 to SPI0 and CS0 and it should work without needing to change anythin in RTIMULib.ini.

### November 4 2014 - 3.1.1

Can now supply the .ini name as a command line argument. For example:

    RTIMULibCal Palm
    
would calibrate a settings file called Palm.ini.

### November 1 2014 - 3.1.0

Added the RTIMULibCal application. This implements IMU calibration in no GUI (command line) environments.

### October 13 2014 - 3.0.3

Increased time allowed for ellipse fitting to complete before declaring it finished.

### October 13 2014 - 3.0.2

Added license information to Calibrate.pdf.

### October 13 2014 - 3.0.1

Fixed missing license header in RTEllipsoidFit.

### October 13 2014 - 3.0.0

RTIMULib now support accelerometer calibration and enhanced magnetometer calibration using ellipsoid fitting. Please check the Calibration.pdf document for instructions on how to create the calibration data.

### October 8 2014 - 2.1.2

Fixed some missed license header changes.

### October 8 2014 - 2.1.1

Fixed bug where the first com put was missed on the GUI dropdown in RTHostIMU and RTHostIMUGL.

### October 8 2014 - 2.1.0

Changed license to MIT.

Added RTHostIMU and RTHostIMUGL. These apps use RTArduLink to connect the host system to an IMU connected to an Arduino. This allows processing to be split between the Arduino and the host system. Sensor data collection is performed on the Arduino, sensor fusion and display is performed on the host. This means that the apps will run on hosts without I2C ports (such as PCs). See below for more details.

### October 2 2014 - 2.0.0

Changed the gyro bias calculation to run automatically when the IMU is detected as being stable. This means
that the IMU no longer needs to be kept still for 5 seconds after restart and gyro bias is continually tracked. IMUGyroBiasValid can be called to check if enough stable samples have been obtained for a reasonable bias calculation to be made. If the IMU is stable, this will normally occur within 5 seconds. If not stable at the start, it may take longer but it will occur eventually once enough stable samples have been obtained. If RTIMULibDemo never indicates a valid bias, the #defines RTIMU_FUZZY_GYRO_ZERO and/or RTIMU_FUZZY_ACCEL_ZERO may need to be increased if the gyro bias or accelerometer noise is unusually high. These should be set to be greater than the readings observed using RTIMULibDemo when the IMU is completely stable. In the case of the gyros, this should be the absolute values when the IMU isn't being moved. In the case of the accels, this should be the maximum change in values when the IMU isn't being moved.

Stable gyro bias values are saved to the RTIMULib.ini file in order to speed up restarts. The values will once again be 
updated after enough stable samples have been obtained in order to track long term changes in gyro bias.

If problems are encountered, try version 1.0.4 which is available under the GitHub repo releases tab. Please also report any issues via the GitHub issue system to help improve RTIMULib!

### September 3 2014 - 1.0.4

Fixed message error in RTIMUSettings.

### September 2 2014 - 1.0.3

CompassCalMax was returning m_compassCalMin in PyRTIMU_settings.cpp - changed to max instead. Thanks to Stefan Grufman for finding that.

### August 6 2014 - 1.0.2

Added missing compass sample rate defines for LSM303DLHC and updated settings comments. Thanks to Bill Robertson (broberts4) for spotting that!

### July 29 2014 - 1.0.1

Fixed the python getIMUData function.

### July 7 2014 - 1.0.0

#### Added python bindings

Thanks to avishorp for the python code and Luke Heidelberger for a bug fix.

### April 13 2014 - 0.9.4

#### Added new RTQF fusion filter

RTQF is a very highly stripped down Kalman filter that avoids matrix inversion and lot of other matrix operations. It makes a small performance difference on the Raspberry Pi but would have more impact on lower powered processors.

### April 10 2014 - 0.9.3

#### STM LSM9DS0 IMU Implementation now working

The single chip IMU LSM9DS0 is now working with RTIMULib. An example breakout is available from Sparkfun - https://www.sparkfun.com/products/12636.

### April 9 2014 - 0.9.2

#### STM L3GD20H + LSM303D IMU Implementation now working

The combination of the L3GD20H gyro and LSM303D accel/mag chip is now working. The physical configuration supported is as used on the Pololu Altimu V3 - http://www.pololu.com/product/2469. The pressure chip on the 10-dof version will be supported shortly but 9-dof is working now.

#### STM L3GD20 + LSM303DLHC IMU Implementation now working

The combination of the L3GD20 and LSM303DLHC accel/mag chip is now working. The physical configuration supported is as used on the Adafruit 9-dof IMU - http://www.adafruit.com/products/1714.

### April 7 2014 - 0.9.1

#### Improved performance with MPU-9150

A new caching strategy for the MPU-9150 seems to be achieving 1000 samples per second without fifo overflows using a 900MHz Raspberry Pi and 400kHz I2C bus. This is as reported by RTIMULibDrive with a CPU utilization of 28%. RTIMULibDemo manages 890 samples per second with the MPU-9150 set to 1000 samples per second. The driver gracefully handles this situation although there is increased delay when the application cannot handle the full sample rate.

#### Auto detection of IMU

RTIMULib can now scan for supported IMUs and configure automatically. This is the default behavior now. It handles IMUs at alternate address automatically as well (for example, it will detect an MPU-9150 at 0x68 or 0x69).

#### Partial support for STM L3GD20H/LSM303D IMUs

This is in a very early state and only supports the gyro sensor at the moment.

### April 4 2014 - 0.9.0

Initial release with support for MPU9150.





","['RichardBarnett', 'avishorp']",0,,0.72,0,,,,,,0,,,
520650195,R_kgDOHwh90w,LING194_Game_prototype_M22,aventayolboada/LING194_Game_prototype_M22,0,aventayolboada,https://github.com/aventayolboada/LING194_Game_prototype_M22,Game prototype designed by UCSB undergraduate students in LING194 during Summer 2022,0,2022-08-02 21:09:04+00:00,2022-11-29 23:52:39+00:00,2022-09-12 19:14:19+00:00,,48439,0,0,GDScript,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"<p align=""right"">
<a href=""https://discord.gg/KnJGY9S"">
  <img src=""https://github.com/fenix-hub/ColoredBadges/blob/master/svg/social/discord.svg"" alt=""react"" style=""vertical-align:top; margin:6px 4px"">
</a>
</p>

This plugin is now supported in [Godot Extended Library Discord](https://discord.gg/JNrcucg), check out the [Godot Extended Library Project](https://github.com/godot-extended-libraries)!

<img src=""addons/github-integration/github-logo.png"" align=""left"" width=""64"" height=""64"">

# GitHub Integration
A complete GitHub integration for your Godot Editor! Manage your project without even opening your browser.

Author: *""Nicolo (fenix) Santilio""*  
Version: *1.4.3*  
Godot Version: *3.2.4-rc3*  
Wiki: *[supported](https://github.com/fenix-hub/godot-engine.github-integration/wiki)*  

<img align=""center"" src=""addons/github-integration/screenshots/banner.png"">

## What is this?
*GitHub Integration* is a addon for Godot Engine that I've created mainly for a personal purpose.  
Pushing and Pulling repositories while I'm working on Godot (especially if I'm under a GameJam) could take some time and force me to save the project, open the brwoser/git bash/git gui, and do all the stuff.  
With this little addon which works directly in the editor, managing all your repositories will be very easy.  

## What can it do?
*Github Integration* offers the main functionalities provided by GitHub (and git itself), in a more accessible way.  
Currenlty, you can:
- Manage all of your public and private **repositories**, *including* the ones you share with organizations and the ones in which you are a collaborator (with proper permissions): create, delete, push and clone repositories within your Godot project
- Manage all of your public and private **gists**: delete, edit and create gists with a functional text editor
- Manage collaboration invitations, inviting user to your repositories or accept/decline invitations you have received

## How does it work?
I'm currently working on a [Wiki](https://github.com/fenix-hub/godot-engine.github-integration/wiki) for this plugin. It is a process that will take some time to complete since I want to provide a well-organized wiki with some basic explanations about GitHub itself. Anyway, I'm working on a user-friendly plugin, so everything should be the very ease to use for GitHub experienced users, and a little intuitive for people who never used GitHub or are not so experienced.
If you want to see some screenshots you can find them here `addons/github-integration/screenshots`

## Supporters page
<table>
  <tr>
    <th><img src='https://avatars0.githubusercontent.com/u/9788627?s=64&v=4' alt='@masterworm2' width=""64""/><br/><a href=""https://github.com/masterworm2"">masterworm2</a></th>
    <th><img src='https://avatars0.githubusercontent.com/u/48778172?s=64&v=4' alt='@auctru' width=""64""/><br/><a href=""https://github.com/autcru"">autcru</a></th> 
  </tr>
</table>

## :warning: Disclaimer  
As a ""work in progress"" project, there is *no warranty* for any eventual issue and bug that may broke your project.  
I don't assume any responsibility for possible corruptions of your project. It is always advisable to keep a copy of your project and check any changes you make in your Github repository.  

-----------------
> This text file was created via [TextEditor Integration](https://github.com/fenix-hub/godot-engine.text-editor) inside Godot Engine's Editor.




","['gniu0', 'aventayolboada', 'sabrinasun55', 'MHalbany', 'JayyyyLee', 'Summeryuqing01', 'Nightborne1', 'Towakoko', 'gabrielbernalucsb', 'ahairston1', 'alexisramos44', 'matthewsevilla1']",1,,0.75,0,,,,,,2,,,
48078123,MDEwOlJlcG9zaXRvcnk0ODA3ODEyMw==,codyn,cran/codyn,0,cran,https://github.com/cran/codyn,:exclamation: This is a read-only mirror of the CRAN R package repository.  codyn — Community Dynamics Metrics. Homepage: https://github.com/NCEAS/codyn/  Report bugs for this package: https://github.com/NCEAS/codyn/issues,0,2015-12-16 00:57:49+00:00,2021-04-27 18:17:03+00:00,2020-12-02 09:35:54+00:00,,3186,0,0,R,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,1,"# codyn - Community Dynamics Metrics

[![CRAN_Status_Badge](https://www.r-pkg.org/badges/version/codyn)](https://cran.r-project.org/package=codyn)
[![Build Status](https://travis-ci.com/NCEAS/codyn.png?branch=master)](https://travis-ci.com/NCEAS/codyn)
![Downloads](https://cranlogs.r-pkg.org/badges/grand-total/codyn)
[![Project Status: Active – The project has reached a stable, usable state and is being actively developed.](https://www.repostatus.org/badges/latest/active.svg)](https://www.repostatus.org/#active)

- **Authors**: Lauren Hallett [lauren.m.hallett@gmail.com], Meghan Avolio [meghan.avolio@jhu.edu], Ian T. Carroll [carroll.ian@gmail.com], Sydney K. Jones [syd@sevilleta.unm.edu], Andrew A. MacDonald [a.a.m.macdonald@gmail.com],  Dan F. B. Flynn [flynn@fas.harvard.edu], Peter Slaughter [slaughter@nceas.ucsb.edu], Julie Ripplinger [julie.ripplinger@asu.edu], Scott L. Collins [scollins@sevilleta.unm.edu], Corinna Gries [cgries@wisc.edu], Matthew B. Jones [jones@nceas.ucsb.edu]
- Version 1.x: [doi:10.5063/F1542KJB](https://doi.org/10.5063/F1542KJB)
- Version 2.x: [doi:10.5063/F1N877Z6](https://doi.org/10.5063/F1N877Z6)
- **License**: [Apache 2](https://opensource.org/licenses/Apache-2.0)
- [Package source code on Github](https://github.com/NCEAS/codyn)
- [**Submit Bugs and feature requests**](https://github.com/NCEAS/codyn/issues)

A package to analyze long-term ecological community datasets.

Univariate and multivariate temporal and spatial diversity indices, 
rank abundance curves, and community stability metrics. The functions 
implement metrics that are either explicitly temporal and include the 
option to  calculate them over multiple replicates, or spatial and include 
the option to calculate them over multiple time points. Functions fall into 
five categories: static diversity indices, temporal diversity indices, 
spatial diversity indices, rank abundance curves, and community stability 
metrics. The diversity indices are temporal and spatial analogs to 
traditional diversity indices. Specifically, the package includes functions 
to calculate community richness, evenness and diversity at a given point in 
space and time. In addition, it contains functions to calculate species 
turnover, mean rank shifts, and lags in community similarity between two 
time points.

For an overview of __codyn__, see:
    
- Hallett LM, Jones SK, MacDonald AAA, Jones MB, Flynn DFB, Ripplinger J, Slaughter P, Gries C, Collins SL (2016) *codyn: An R package of community dynamics metrics.* Methods in Ecology and Evolution, 7(10):1146–1151. https://doi.org/10.1111/2041-210X.12569

For a description of the newer spatial methods in __codyn__ v2.x:

- Avolio ML, Carroll IT, Collins SL, Houseman GR, Hallett LM, Isbell F, Koerner SE, Komatsu KJ, Smith MD, Wilcox KR (2019) *A comprehensive approach to analyzing community dynamics using rank abundance curves.* Ecosphere, 10(10):e02881. https://doi.org/10.1002/ecs2.2881


## Installation
From CRAN, the package can be installed using standard tools:
```R
install.packages(""codyn"")
```

## Automated R CMD check with Docker via rhub

To simplify the process of running `R CMD check` on the package, one can easily run the build and tests using
the [`rhub`](https://github.com/r-hub/rhub) package. Use `rhub::platforms()` to get a list of platforms that can be used to build and test.

```r
library(rhub)
chks <- check(platform = c(""debian-gcc-devel"", ""fedora-gcc-devel""), show_status = FALSE)
```

and the checks can be run locally using rhub as well using a docker container:

```r
library(rhub)
local_check_linux(image=""rhub/fedora-gcc-devel"")
```

## Acknowledgments

Work on this package was supported by NSF-ABI grant #1262458 to C. Gries, M. Jones, and S. Collins. Additional support was provided for working group collaboration by the National Center for Ecological Analysis and Synthesis, a Center funded by the University of California, Santa Barbara, and the State of California, and a SESYNC Synthesis Postdoctoral Fellowship to MLA.

",['mbjones'],1,,0.81,0,,,,,,2,,,
122548108,MDEwOlJlcG9zaXRvcnkxMjI1NDgxMDg=,Cohesive-Course-Design,saralafia/Cohesive-Course-Design,0,saralafia,https://github.com/saralafia/Cohesive-Course-Design,This site introduces theories and best practices to guide university course design.,0,2018-02-22 23:30:13+00:00,2018-03-13 20:28:01+00:00,2018-03-13 20:28:00+00:00,https://saralafia.github.io/Cohesive-Course-Design/,27,0,0,,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"## Overview

This website introduces constructive alignment and backward design as frameworks for creating cohesive, effective, student-centered courses. This site also explains how these theories can inform course design. Best practices and takeaways are exemplified by interviews with selected award-winning instructors at the University of California, Santa Barbara (UCSB).

This site has been developed for a graduate course offered at UCSB (College and University Teaching — From Theory to Practice) as part of the [Certificate in College and University Teaching](http://www.graddiv.ucsb.edu/academic/interdisciplinary-emphases-certificate-programs/ccut) program.

![Active Learning](https://steelcase-res.cloudinary.com/image/upload/c_fill,dpr_auto,q_70,h_656,w_1166/v1483616512/www.steelcase.com/eu-es/2017/01/05/16-0015662.jpg ""Active Learning"")

## What are Constructive Alignment and Backward Design?

Constructive alignment and backward design are frameworks for course design and curriculum planning that come out of the educational theory of constructivism. Constructivism puts the student at the center of learning, challenging “banking” models of teaching that view students as blank slates and the teacher as the primary holder of knowledge.   According to constructivist theories of learning, “learners arrive at meaning by actively selecting, and cumulatively constructing, their own knowledge, through both individual and social activity. The learner brings an accumulation of assumptions, motives, intentions, and previous knowledge that envelopes every teaching/learning situation and determines the course and quality of the learning that may take place” (Biggs 348).  Constructivism is the theoretical foundation that informs constructive alignment and backward design. 

### Constructive alignment

**Constructive alignment** is a method of course design in which the learning objectives, assessments of students, and learning activities inform one another and create opportunities for students to co-construct knowledge and meaning in the classroom. Constructive alignment is a continuous, comprehensive process for ensuring that one’s learning outcomes, assessments, and learning activities mutually inform one another. This is a self-reflexive, recursive method for planning that requires opportunities for formative assessment and evaluation in order to check for students’ understanding and evaluate the effectiveness of one’s instruction.  

**Video on constructive alignment:**  
[![Constructive Alignment](https://i2.wp.com/blogs.shu.ac.uk/engagement/files/2016/11/lta-trinity-small.jpg?ssl=1)](https://www.youtube.com/watch?v=HVKezLcGi9c4)

**On Constructive Alignment:**

According to Marton and Booth in “The Learner’s Experience of Learning,” Constructivism ‘is not a particular method but an attitude towards teaching which implies a focal awareness of the learner and the learner's world.., each teacher has to tackle the principles and appropriate them within the context of his or her own teaching” (cited in Biggs 349). Biggs goes on to ask, “But how is the teacher to move from a ""focal awareness ... of the learner's world"", and appropriating principles, to doing things differently?” Constructive alignment is the method of putting constructivist learning approaches (student-centered learning) into practice through one’s course design, a process in which the learning objectives, course assessment, and course activities mutually inform one another.

“Constructivism comprises a family of theories but all have in common the centrality of the learner's activities in creating meaning. These and related ideas have important implications for teaching and assessment. Instructional designers for their part have emphasised alignment between the objectives of a course or unit and the targets for assessing student performance. ‘Constructive alignment’ represents a marriage of the two thrusts, constructivism being used as a framework to guide decision-making at all stages in instructional design: in deriving curriculum objectives in terms of performances that represent a suitably high cognitive level, in deciding teaching/learning activities judged to elicit those performances, and to assess and summatively report student performance” (Biggs 347).

### Backward design

**Backward design** is the pragmatic model of planning that is an initial step for constructive alignment. There are two key ideas to backward design.  First, according to backward design, teachers should be assessing students for understanding and application, higher levels of Bloom’s learning taxonomy, rather than memorization of content.  Second, in their planning, teachers should start from their  desired learning outcomes and design the course, including assessments and learning activities,  backward from that point.

**Video on backward design:**  
[![Constructive Alignment](https://elearninginfographics.com/wp-content/uploads/Designing-eLearning-Courses-Backwards-Infographic-550x420.png)](https://www.youtube.com/watch?v=d8F1SnWaIfE)

In practice, neither constructive alignment nor backward design are strictly linear per se. They are self-reflexive, continuous processes of planning that help teacher zoom-out and consider the big ideas, essential questions, and desired learning outcomes rather than getting overwhelmed by content coverage. Both of these models for course design and planning allow the instructor to place the student and their learning at the center of course design, rather than content, and offer a method for creating cohesive, effective curriculum.

**On Backward Design:**

“Backward design may be thought of as purposeful task analysis: Given a task to be accomplished, how do we get there? Or one might call it planned coaching: What kinds of lessons and practices are needed to master key performances? The approach to curricular design we are advocating is logically forward and commonsensical but backward in terms of conventional habits, whereby teachers typically think in terms of a series of activities (as in the apples unit presented in the Introduction) or how best to cover a topic (as in the world history vignette). This backward approach to curricular design also departs from another common practice: thinking about assessment as something we do at the end, once teaching is completed. Rather than creating assessments near the conclusion of a unit of study (or relying on the tests provided by textbook publishers, which may not completely or appropriately assess our standards), backward design calls for us to operationalize our goals or standards in terms of assessment evidence as we begin to plan a unit or course” (McTighe and Wiggins Understanding by Design). 


## How can these theories inform course design?
By basing syllabi on the learning outcomes of students, you can implement these theories in your teaching. As John Biggs points out, “learning is constructed by what activities the students carry out; learning is about what they do, not about what we teachers do”. To this end, instructors need to envision what students need to get out of the class and how they can reach that goal. The following are some ways to improve teaching with these methods:

### Ensure that students are at the center of the syllabus

How to create a “learner-centered” syllabus (Richmond):

* Forefront instructor accessibility
	* Do not just include office hours.
	* Commit to having face time with students: include email, off-campus meeting opportunities, use of technology (Slack), extra points for out-of-class meetings
* Anticipate student questions
* Provide a detailed learning rationale
	* Include more detail on the syllabus rather than less
* Define and limit course content
* 	Have clear pathways to success
* 	Provide students with resources for success beyond you
* Incorporate opportunities for collaborative learning
* Clearly define your role and the student’s role
* Leave room for negotiation and keep syllabus flexible
* Tie grades to student learning outcomes, not losing points (this is especially important! You cannot have a student centered syllabus without this)

### Identify key learning outcomes and themes

The following table, created by Biggs and McTighe, is a template for getting started with a backward model syllabus:

![Understanding by Design](https://s3.amazonaws.com/vu-wp0/wp-content/uploads/sites/59/2017/05/08103123/Screen-Shot-2017-05-08-at-10.30.18-AM.png ""Understanding by Design"")

### Think about course design from a student perspective

In his article “Enhancing Teaching through Constructive Alignment,” John Biggs cites the Wood’s research in Steffe and Gale’s Constructivism in Education (1995), saying that teachers should do the following:

* Provide instructional situations that elicit subject appropriate activities
* View students' conceptions from their (the students') perspectives 
* See ""errors"" as reflecting the (their) current level of development
* Recognise that substantive learning occurs in periods of conflict, surprise, over periods of time, and through social interaction (349)


### Test student-centered courses to learn from and improve them

Brian Hains and Brittany Smith conducted a case study to examine the development of a student-designed experiential course from both student and faculty perspectives. Seven undergraduate students developed and implemented a 12-day experiential learning course with eight learning outcomes. Results: 

* Direct application on the students’ part
	* Current course instructors had lost sight of the complex multidisciplinary issues facing their future, which left the students feeling unprepared 
* Student accountability
	* Student confidence
	* Participant immersion
	* Interpersonal development
* Student journal and documentary as evaluation
* Yet, faculty felt the professionalism of the course was jeopardized and were hesitant

**In summary, ways to make syllabi student-centered include:**

* Structuring each class/week by having a question for students and build lectures around acquiring the ability to answering that question
* Having a ‘storyline’; that is, anticipating an arc for the course with clear beginning, middle, and end goals - as Dr. Aashish Mehta in Global Studies does
* A somewhat revolutionary/controversial practice is the flipped lecture, which we saw a brief clip of by Dr. Steven Gaulin.

**Video about Dr. Steven Gaulin's flipped lectures:**  
[![GauchoCast](http://www.news.ucsb.edu/sites/www.news.ucsb.edu/files/slideshow_images/2015/gaulin_CROPPED.jpg)](https://gauchocast.ucsb.edu/Panopto/Pages/Viewer.aspx?id=e7b7ece3-027a-433e-b115-16b2b00a78a1)

## What are some best practices and takeaways?

In their article “Navigating the Bumpy Road to Student-Centered Instruction” (1996) Richard M. Felder and Rebecca Brent cite chemical engineer Donald R. Woods’s (1994) work on the beginning stages of introducing a student-centered approach to a class, the members of which were initially very resistant to these new ideas. 

### Comparing the process of introducing a student-centered approach to a class to the stages of psychological trauma (Woods):

1. Shock: ""I don't believe it-we have to do homework in groups and she isn't going to lecture on the chapter before the problems are due?"" 
2. Denial: ""She can't be serious about this-if I ignore it, it will go away."" 
3. Strong emotion: ""I can't do it-I'd better drop the course and take it next semester"" or ""She can't do this to me-I'm going to complain to the department head!"" 
4. Resistance and withdrawal: ""I'm not going to play her dumb games-I don't care if she fails me."" 
5. Surrender and acceptance: ""OK, I think it's stupid but I'm stuck with it and I might as well give it a shot."" 
6. Struggle and exploration: ""Everybody else seems to be getting this-maybe I need to try harder or do things differently to get it to work for me."" 
7. Return of conﬁdence: ""Hey, I may be able to pull this off after all-I think it's starting to work."" 
8. Integration and success. ""YES! This stuff is all right-I don't understand why I had so much trouble with it before."" (1996 [1994]: 2)

I’ve taught enough to have recognized each of these deer-in-headlights stages in the eyes of  many of my students at the very mention of the words “group work” in class. As Felder and Brent go on to say, “Cooperative learning tends to be the hardest student-centered method to sell initially, especially to high academic achievers and strong introverts.” (5) As an ethnomusicologist, I was taught the importance of self-reflexivity in my own research, so, practice what you preach, right? Just as non-music majors in an introductory survey class must be introduced to basic threshold concepts in an engaging way (the 1995 film Mr. Holland’s Opus, albeit clearly given a Hollywood sheen, has many great celluloid examples of high school music teacher Mr. Holland’s process of trial and error in this respect, as does the quoted learning objectives from Dr. Dirkse’s Music Appreciation syllabus quoted on this site), this highly strong introverted academic was thrown into the grieving process of group work in the creation of content for this website:

1. Shock - Group project?!!!?!! Website?!?!?!
2. Denial - IS a river in Egypt… let me continue doing geography quizzes on www.sporcle.com until the project goes away…
3. Strong emotion - NO! There’s no way I can complete this project! I need to remember the official language of Bhutan!
4. Resistance and withdrawal - I’m not going to do it. There’s no point. What I can do is sit here and remember the Oscar winners for Best Picture from 1927-2013.
5. Surrender and acceptance - I guess I have to do it, there’s no other way around it. Has anyone ever really seen the films Cimarron or Cavalcade?
6. Struggle and exploration - My fellow group members really seem to know what they are doing. How?
7. Return of confidence - Hey, if I do work, maybe I too can know what I am doing?
8. Integration and success - A-ha! I have been involved in a group project and now I understand the value of such an undertaking. Every group needs a comedian, right?

Ultimately, the final step is a key takeaway from any course designed around principles of constructive alignment or backward design. By understanding that a class activity has been formulated around these principles, students learn that not only does their newly acquired knowledge have value, the process through which they arrived there has value too.

## How do instructors design cohesive courses at UCSB?
We interviewed several award-winning instructors at UCSB who are putting these teaching theories into practice. To better understand this process, we asked the following questions:

1. What were the **key concepts** for your courses and **how did you assess students** based on them? Do you start with ideas for activities, weekly questions, etc?
2. How have you **structured your classes?** (chronologically, weekly questions, thematically, etc). Has this changed over time?

### [Professor Aashish Mehta, Global Studies](http://www.global.ucsb.edu/people/aashish-mehta)

![Aashish Mehta](http://www.global.ucsb.edu/sites/secure.lsit.ucsb.edu.gisp.d7-2/files/styles/people_node/public/people/photo/Mugshot%20Jan%202018.JPG?itok=n3acVDH5 ""Aashish Mehta"")

[Introduction to Global Socioeconomic and Political Processes - Syllabus](http://es.ucsb.edu/sites/www.es.ucsb.edu/files/sitefiles/academics/courses/pdf/ES1SylF13.pdf)

1. I **minimize the time spent on assessment** in large undergraduate courses. It cannot be done in a way that provides constructive feedback given the resources available. Or, more accurately, if we did do assessment in that way, it would leave no time for teaching - intellectual development and skill acquisition.  Rather, I treat assessment exclusively as a means of incentivizing student effort, so that the time spent teaching is productive time.  I use problem sets for homework to make student engage with skills and concepts; multiple choice tests to make them study; and course participation scores to reward students who are making efforts but falling short due to excessive work commitments or lacuna in their prior education.
2.  Each course is **structured around an ""itinerary"".** I start with a list of concepts/ideas/debates with which they should be familiar. Then I fiddle a lot with sequencing to determine which ones build on knowledge of the others.  Then I order them chronologically, starting from the ground up. Readings are selected last, as a means of backstopping the ideas.

**Course Objectives from Dr. Mehta's Global 2 (Intro to Global Socioeconomic and Political Processes) course syllabus at UCSB:**

This **interdisciplinary** course is designed to introduce students to the study of global socioeconomic and political processes, interactions, and changes that affect the contemporary world. In the twenty years since the end of the Cold War in 1990, the world has changed radically. The break-up of the Soviet Union, the waning of American power, the growing economic strength of Western Europe East Asia and the BRIC countries, the increase in religious and ethnic tensions in South Asia and the Middle East, the US military presence in Afghanistan and Iraq, the emergence of global environmental problems, the rapid spread of new communications technologies, and the global economic recession have given birth to new forms of social and political interactions. In this class, we will try to understand these developments in their regional and global contexts. Roughly **one half of the lectures and readings** will introduce global issues as they effect, and are effected by, people in particular regions of the world. The **other half** will look at key global issues on a transnational level. These will be presented in part through case studies that will **highlight two ideas:** (i) while globalization results from transnational forces, it is manifest nationally in ways that continue to depend upon local conditions and the responses of national governments; and (ii) while the globalization of information networks has made it increasingly easy to know a little about many events and processes, this information remains extremely difficult to interpret. The class is one of the gateway courses for the Global Studies major.

### [Professor Peter Alagona, Environmental Studies and History](http://www.global.ucsb.edu/people/aashish-mehta)

![Peter Alagona](https://static1.squarespace.com/static/51142dd6e4b0f297c4858832/t/51507267e4b045db941cf27c/1431414584756/PeterAlagona.jpg?format=1500w ""Peter Alagona"")

[Introduction to Environmental Studies - Syllabus](http://es.ucsb.edu/sites/www.es.ucsb.edu/files/sitefiles/academics/courses/pdf/ES1SylF13.pdf)

1. There's no magic to what I do. The key to being a good teacher, I think, is (1) caring and (2) continuing to push yourself, sometimes in the absence of strong incentives, to do better. My introductory ES course seeks to develop critical thinking skills. I define ""critical thinking"" as the ability to analyze diverse forms of evidence and assess competing claims. For this reason, I privilege concepts over content. My **threshold concepts** for ES 1 include things like change, complexity, interdisciplinarity, justice, and power. 
2. I used to assess students based on take-home assignments and exams. This year, however, I radically changed the structure of the course, throwing out the take home assignments and eliminating the final exam. I kept the midterms (to make sure students were following along and getting the basic, nuts and bolts ideas), and I replaced the rest with a **5-step scaffolded term paper**. The paper was 8-10 pages long; the instructions were 13. Making this change was a big risk, but it paid off. Students were required to bring in key concepts from the lectures and readings, follow the multiple steps, and hone important research and writing skills. Yet they were able to pick a topic of their choice and do a deep dive into it. A few things need changing, but overall it worked out great. 

**Course Objectives from Dr. Alagona's ES 2 (Intro to Environmental Studies) course syllabus at UCSB:**

* By the time you complete this course you should be able to: 
	* **Describe** some the major structures, functions, processes, and patterns of change in an earth system increasingly shaped by human action 
	* **Explain** some of the basic principles and power relations that influence environmental policy and management in California, the United States, and elsewhere around the world 
	* **Gain a basic understanding** of some key environmental problems, including their causes and the costs and benefits associated with their prospective solutions 
	* **Gain some of the basic skills** necessary to pursue more advanced work in environmental studies and related fields

### [Jeremy Chow, PhD Candidate in English at UCSB, winner of GSA Excellence in Teaching Award 2017](https://www.english.ucsb.edu/people/chow-jeremy)

![Jeremy Chow](http://www.news.ucsb.edu/sites/www.news.ucsb.edu/files/slideshow_images/2015/chow_yang_shake_CROPPED.jpg ""Jeremy Chow"")

1.  As a teacher, I prioritize the application of learning, which, in my classroom, asks students to not only take ownership of their education—they’re paying a lot of money to be here—but to be active participants and consumers of knowledge. By prioritizing this, my students become better readers, writers, and cultural critics. In literary study, we emphasize the ability to write clearly, concisely, and articulately. Teaching this is difficult not only because these concepts are subjective (and culturally varied), but because we need to think more capaciously about what assignments can help our students achieve the goal of becoming better **metacognitive learners**. In my classroom, I asks students to practice writing in different genres (research essay, op-ed, film review, creative writing, etc.) that might open interdisciplinary opportunities and speak to a variety of different learning styles. In addition, I advocate for a seminar-style classroom that champions conversation and discussion. Our goal is not unanimous agreement; rather, I prioritize the process of discussion and open engagement, which values everyone’s voice. I tell my students that we do ourselves a disservice if everyone’s voice is not heard. 
2. Syllabus creation is a tricky beast to wrangle. My syllabi are deeply structured, which extends itself to how I structure my classes each day. **Essential questions** are, just that, essential on a syllabus. A clear idea of assignments and readings are valuable so that students—who may be sitting on the fence about the class—can make an educated decision as to whether this class and this instructor will work for them. With regards to the day-to-day, each day I put an agenda on the board, which guides our conversations. Within that agenda, I ensure that there are activities that allow for group or pair work, independent study, and also a means of information gathering from either me or our conversation as a whole. Each day we discuss, so that features largely in our daily praxis. Though structure has remained the same since my teacher ed days, what has changed is how much lesson planning I prepare before a class. Whereas before I would plan out timestamps—at this time, we’ll move onto this—I now use ideas as guiding lights for the classroom. At the start, I want to focus on this idea. Then move to this activity, then allow for X. At the end, I want to ensure that we looked at y. I do this now, not because of laziness, but because I have learned to be more flexible and adaptable to my students and their needs that day. I may have an agenda in mind, but if we move onto a separate plan of action, I must be prepared to buckle up and enjoy the ride. There is no such thing as useless questions, asides, or tangents. They all lead us to different places and can help orient different types of learning for different learners.

**Essential Questions from Jeremy Chow's English 22 (Introduction to Literature & the Environment) at UCSB:**

Throughout this course, we will ask what constitutes “communication” and/or “contact” between humans and simian nonhumans. How do authors represent these interactions in early modernity? And do these representations change as we move closer to the present, especially with the rise of animal cognition studies and “humane” societies? We must also evaluate the diverse and ever-changing ethical stakes that materialize when considering the modern human relationship with primates. We are thus interested in how humans affect anthropoids; how anthropoids affect humans; and how these relationships are configured by literature, construed broadly.

### [Professor Scott Dirkse, Adjunct Professor of Music at Bakersfield College, UCSB PhD alumnus and 2013 winner of GSA Excellence in Teaching Award](https://www.bakersfieldcollege.edu/performingarts/faculty-staff)

![Scott Dirkse](https://www.bakersfieldcollege.edu/sites/bakersfieldcollege.edu/files/DirkseScott.JPG ""Scott Dirkse"")

1. I do **frequent formative assessments** during class time, no matter the class size. In music appreciation courses, I ask students questions based on active listening tasks and have students respond with group oral responses, finger responses, or written responses, so I may assess their level of mastery and determine which skills need more practice. This allows me to **adjust my teaching** to ensure that students are ready for the summative course assessments that require applying these listening skills in listening reports and in-class quizzes. I've noticed that some instructors are hesitant to employ group response methods in large classes, but I've found it to be a useful tool to keep the students engaged and assess their level of understanding.  
2. When teaching listening skills, I endeavor to select a lot of popular music that **students are already familiar with** as students are first getting acquainted with the new elements. Once students learn these skills, we apply them to the main repertoire for the course.  Although I have explored working with various curriculum timelines, I still prefer to teach my general education music courses with a chronological approach. Because music notation began simply and gradually increased in complexity, it allows me to scaffold students' toolbox of listening skills as the notated music becomes more complex. The repertoire for the course always changes based on the needs and goals of the department and institution at which I'm teaching.

**Course Objectives from Dr. Dirkse’s Music B22 (Music Appreciation) course syllabus at Bakersfield College:**

This course is centered on the belief that all music is interesting, important, and worthy of study. In this course, you will engage with music in a variety of manners. You will **learn** how music is constructed and **develop** critical listening skills that will allow you to appreciate unfamiliar music, talk about different types of music, and listen to your own music in new ways. You will also **acquire** an understanding of the history and development of Western art music and its interactions with culture and society. 

## Connecting Learning to Teaching

Cohesive syllabus and course design is informed by the teaching theories we've explored in GRAD 210:

* The successful instructors we interviewed emphasized the importance of **self-efficacy** and focused on creating **mindsets for long-term learning** (Professor Dirkse, Music).
* At least one instructor explictly named **threshold concepts** and others scaffolded their syllabi and learning outcomes around core concepts (Professor Alagona, Environmental Studies).
* The inclusion of tiered learning outcomes is informed by **Bloom's Taxonomy** for several instructors who shared syllabi with us (Professor Alagona, Environmental Studies).
* These instructors are practicing **responsive teaching** by making room for active learning and prioritizing in-class discussion (Professor Chow, English).
* Using **formative** and **summative assessment** helps instructors better understand students' prior knowledge and interaction with new material (Professor Dirkse, Music).
* There is room for creative **low-stakes** assessment, including a scaffolded term paper and in-class debates (Professor Alagona, Environmental Studies and Professor Mehta, Global Studies).
* Instructors emphasize the importance of **metacognition** as a component of learning that is integral to the course's design (Professor Chow, English). 


## References

Biggs, J. (1996). Enhancing teaching through constructive alignment. Higher education, 32(3), 347-364.

Biggs, J. (1999). Teaching for Quality Learning at University (SHRE & Open University Press, Buckingham).

Dreyfus, R. (1995). Mr. Holland’s Opus. Directed by Stephen Herek. Los Angeles: Buena Vista Pictures.

Hains, B. J., & Smith, B. (2012). Student-centered course design: Empowering students to become self-directed learners. Journal of Experiential Education, 35(2), 357-374.

Felder, R. M., & Brent, R. (1996). Navigating the bumpy road to student-centered instruction. College teaching, 44(2), 43-47.

Reynolds, H. L., & Kearns, K. D. (2017). A planning tool for incorporating backward design, active learning, and authentic assessment in the college classroom. College Teaching, 65(1), 17-27.

Richmond, A. S. (2016). Constructing a Learner-Centered Syllabus: One Professor's Journey. IDEA Paper# 60. IDEA Center, Inc.

Wiggins, G. P., & McTighe, J. (2005). Understanding by design. Alexandria VA: Association for Supervision and Curriculum Development.

Woods, D. R. (1994). How to Gain the Most from PBL, Waterdown, ON.

## Additional Resources

**Links and Podcasts:**

* [Backward design explained by Grant Wiggins](https://youtu.be/4isSHf3SBuQ)
* [Workshop on Backward Design by Ann Wright](https://gauchocast.ucsb.edu/Panopto/Pages/Viewer.aspx?id=5b1459dd-5d1b-41ef-96a8-80f7fdfe044c)
* [Flipped Lecture podcast by Dr. Steven Gaulin](http://tales.id.ucsb.edu/podcasts/)
* [The ""Flipped Lecture"" explained by Dr. Steven Gaulin](https://gauchocast.ucsb.edu/Panopto/Pages/Viewer.aspx?id=e7b7ece3-027a-433e-b115-16b2b00a78a1)
* [Sporcle quizzes, 2007-2018.](https://www.sporcle.com/)
* [Vanderbuilt University’s Center for Teaching](https://cft.vanderbilt.edu/guides-sub-pages/understanding-by-design/#resources)

**Articles on Student-Centered Syllabi**

* [How Students Can Shape the Design of Their Courses](https://www.chronicle.com/article/How-Students-Can-Shape-the/242222)
* [Why You Should Ask Students to Help Design Courses](https://www.chronicle.com/article/Why-You-Should-Ask-Students-to/242208)
* [Your Syllabus Doesn’t Have to Look Like a Contract](https://chroniclevitae.com/news/1864-your-syllabus-doesn-t-have-to-look-like-a-contract)

## Team and Contributions

**[Maite Urcaregui](https://www.english.ucsb.edu/people/urcaregui-maite), Department of English**: What are Constructive Alignment and Backward Design?

**[Leila Zonouzi](http://www.global.ucsb.edu/people/leila-zonouzi), Department of Global Studies**: How can these theories inform course design?

**[Sarah Latanyshyn](http://music.ucsb.edu/people/sarah-latanyshyn), Department of Music**: What are some best practices and takeaways?

**[Sara Lafia](http://www.geog.ucsb.edu/~lafia/), Department of Geography**: How do instructors design cohesive courses at UCSB?
",['saralafia'],1,,0.88,0,,,,,,1,,,
879330574,R_kgDONGmFDg,Webscraper,SojaSurfer/Webscraper,0,SojaSurfer,https://github.com/SojaSurfer/Webscraper,A collection of scripts for web scraping content.,0,2024-10-27 16:16:46+00:00,2024-11-10 08:53:59+00:00,2024-11-14 17:56:45+00:00,,4910,0,0,Python,1,1,1,1,0,0,0,0,0,1,gpl-3.0,1,0,0,public,0,1,0,main,1,,"# Webscraper
A collection of scripts for web scraping content.

## Content

### 1 Presidency Scraper
The PresidencyScraper is a script for web scraping from www.presidency.ucsb.edu.

[View Presidency Scraper](presidencyScraper)

## License
This project is licensed under the GNU General Public License v3.0. See the [LICENSE](./LICENSE.txt) file for details.",['SojaSurfer'],1,,0.71,10,,,,,,1,,,
554675567,R_kgDOIQ-tbw,presidents-discourse-dataset,WhaleCoded/presidents-discourse-dataset,0,WhaleCoded,https://github.com/WhaleCoded/presidents-discourse-dataset,A script for scraping and cleaning all of the written work of past and current presidents of the United States alongside code for analyzing these documents with document embeddings and frequency distributions.,0,2022-10-20 07:44:47+00:00,2022-12-11 20:26:54+00:00,2023-04-27 03:39:56+00:00,,71067,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Moral Foundation's Perspective on American Presidents
This repository contains code for collecting presidential speech data, using word embeddings to create dictionaries sensitive to semantic shift, and evaluating presidential moral tendencies using frequency distributions.

There are README files in each sub folder that contain more information about the code in that folder.

## Getting Started
* Collect the data: You can use the presidential_data_scrape folder to scrape and clean presidential speech data.
* Generate Moral Foundation Dictionaries: You can use the moral_foundation_dictionary folder to generate moral foundation dictionaries. These dictionaries improve upon traditional methods historians use by accounting for semantic shift in words over time.
* Evaluate the Presidents: You can use the evaluation folder to evaluate the presidents using the dictionaries generated in the previous step.

## Index
* `evaluation` - This folder contains code to create and store frequency counts and distributions from moral foundation dictionaries and the scraped presidential speeches.
* `moral_foundation_dictionaries` - This folder contains code to generate and test the validity of moral foundation dictionaries. There are some great utility scripts for make vizualizations in this folder.
* `presidential_data_scrape` - This folder contains the code used to scrape, clean, and store presidential speech data stored by UC Santa Barbara's American Presidency Project.
* `experiment_tsne_embedding_plot.ipynb` - This notebook contains an experiment I ran to analyze the difference between politcal parties using document embeddings. The presidential data scraped and cleaned from the `presidential_data_scrape` folder is embedded using a pre-trained RoBERTA model. The embeddings are then reduced to two dimensions using t-SNE and PCA and plotted. The results seem to just display the time disparity in the data, even after calculating the compnent that represents time and transposing the data into the vector plane that is orthogonal to the time component.",['WhaleCoded'],0,,0.6,0,,,,,,1,,,
651985253,R_kgDOJtyBZQ,elasmo-prm,lmfeitos/elasmo-prm,0,lmfeitos,https://github.com/lmfeitos/elasmo-prm,,0,2023-06-10 17:52:45+00:00,2025-03-04 05:21:59+00:00,2025-03-04 05:21:55+00:00,,125533,1,1,HTML,1,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"# 

This repository contains code used in the paper: 

The associated zenodo repository is located at [![DOI](https://zenodo.org/badge/651985253.svg)](https://doi.org/10.5281/zenodo.14928150)

For any questions, comments, or concerns, please contact Leonardo Feitosa [lmfeitosa@ucsb.edu](lmfeitosa@ucsb.edu) or Allie Caughman [acaughman@ucsb.edu](acaughman@ucsb.edu).

# Instructions

The order of running scripts should be as follows: 

1. The first script is the simulation model `01_fishbase_data_wrangling.Rmd`. This will produce a csv with the life history 
characteristics for modeling in the random forests. Pair this with the raw literature review data from Dryad.
2. The next two files you should run is the 02_random_forest_longline.Rmd and 03_random_forest_trawl_gillnet.Rmd. These
files train and run the random forest and produce figures associated with model validation, as well as the longline
prediction data.
3. the fourth script you should run is sim_prep.R. Input the model prediction data, and this script collects intrinsic growth rates
for each species from the FishLife package.
4. Next, run the retention prohibition simulation in 05_simulation.R. This script produces the resulting simulation dataset.
5. Lastly, run 06_plots.R. This file produces all manuscript figures from the random forest and simulation data sets.

# Repository Structure

## Overview

```
scripts
  |__ 01_fishbase_data_wrangling.Rmd
  |__ 02_random_forest_longline.Rmd
  |__ 03_random_forest_trawl_gillnet.Rmd
  |__ 04_sim_prep.R
  |__ 05_simulation.R
  |__ 06_plots.R
figs
  |__ supp
    |__ supplemental figures
  |__ fig1.pdf
  |__ fig2.pdf
  |__ fig3.pdf
  |__ fig4.pdf
  |__ fig5.pdf
```

# R Version

All code was run using R version 4.1.3

## Required Libraries

+ Data Ingestion, Cleaning, Harmonization, and Organization
  - `tidyverse` (version 1.3.2)
  - `here` (version 1.0.1)
  - `rfishbase` (version 4.1.2)
  - `FishLife` (version 3.1.0)
+ Random Forest Analysis
  - `tidymodels` (version 1.1.1) 
  - `ranger` (version 0.16.0) 
+ Data Visualization
  - `vip` (version 0.4.1)
  - `naniar` (version 1.0.0)
  - `patchwork` (version 1.1.2)
  - `ggpmisc` (version 0.5.5)
  - `ggridges` (version 0.5.6)
  - `ggh4x` (version 0.2.8)
","['acaughman', 'lmfeitos']",1,,0.76,0,,,,,,1,,,
850506478,R_kgDOMrGy7g,Monitoring-water-resources-using-Google-Earth-Engine-and-Javascript,CarlosMendez1997Col/Monitoring-water-resources-using-Google-Earth-Engine-and-Javascript,0,CarlosMendez1997Col,https://github.com/CarlosMendez1997Col/Monitoring-water-resources-using-Google-Earth-Engine-and-Javascript,"Monitoring and control of water resources, surface and groundwater, water balance using satellite images in Cloud-Computing systems such as Google Earth Engine (GEE) and JavaScript language. ",0,2024-09-01 01:03:55+00:00,2025-02-24 10:06:43+00:00,2025-01-24 22:56:23+00:00,,86,3,3,JavaScript,1,1,1,1,0,1,0,0,0,0,,1,1,1,public,0,0,3,main,1,,"# Monitoring water resources using Google Earth Engine (GEE) and JavaScript

## Description

Monitoring and analysis of water resources through remote sensing and satellite images using the `Google Earth Engine (GEE)` platform and `Javascript` language.

Each section is described below:

- First section, introduction to NVDI, MNDWI and AWEI index
- Second section, describes surface water bodies (watersheds, rivers and lakes)
- Third section, shows precipitation and rainfall calculations in time series (monthly and yearly)
- Fourth section, shows the spatial and temporal variations in river levels 
- Fifth section, calculates water balance using precipitation and evapotranspiration
- Sixth section, analyzes reservoir and groundwater levels

## Image collections and datasets

### 01.Introduction
```Javascript
ee.ImageCollection(""COPERNICUS/S2_SR_HARMONIZED"")
```
### 02.Surface Water
```Javascript
ee.ImageCollection(""JRC/GSW1_4/YearlyHistory"")

```
### 03.Precipitation and rainfall
```Javascript
ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')
ee.ImageCollection('UCSB-CHG/CHIRPS/DAILY')
```
### 04.Hidrology
```Javascript
ee.ImageCollection('JRC/GSW1_3/YearlyHistory')
```
### 05.Water balance and drought
```Javascript
ee.ImageCollection('MODIS/006/MOD16A2')
ee.ImageCollection('UCSB-CHG/CHIRPS/PENTAD')
```

### 06.Groundwater
```Javascript
ee.ImageCollection(""NASA/GLDAS/V022/CLSM/G025/DA1D"")
ee.ImageCollection('NASA/GRACE/MASS_GRIDS/MASCON_CRI')
```

## Credits and repository of data

The original code, repositories and scripts used in this project, are available at:

- Google Earth Engine for Water Resources Management (Full Course), Author `Spatial Thoughts`
[Website](https://courses.spatialthoughts.com/gee-water-resources-management.html)

- Aquatic and Hydrological Applications, Author `gee-tutorials` [Website](https://google-earth-engine.com/Aquatic-and-Hydrological-Applications/Water-Balance-and-Drought/) [Github Repository](https://github.com/krishnakafle/gee-tutorials.git)

- Remote Sensing for Water Resources in Earth Engine, Author `Spatial eLearning` [Website](https://courses.spatialelearning.com/p/remote-sensing-for-water-resources-in-google-earth-engine)

- Google Earth Engine for Water Resources, Author `Study Hacks-Institute of GIS & Remote Sensing` [Website](https://www.youtube.com/@gisrsinstitute)

## Conflict of Interest.

The author declare that there is no conflict of interest in the publication of this data and that all authors have approved it for publication.

## Contributing

Pull requests are welcome. For major changes, please open an issue first
to discuss what you would like to change.

Please make sure to update tests as appropriate.
",['CarlosMendez1997Col'],0,,0.72,0,,,,,,1,,,
99814392,MDEwOlJlcG9zaXRvcnk5OTgxNDM5Mg==,netsimile,pdscott/netsimile,0,pdscott,https://github.com/pdscott/netsimile,Implementation of NetSimile anomaly detection algorithm.,0,2017-08-09 13:57:54+00:00,2023-04-18 01:55:47+00:00,2017-08-09 14:02:29+00:00,,4,2,2,Python,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,2,master,1,,"# Implementation of NetSimile anomaly detection algorithm.
See https://cs.ucsb.edu/~victor/pub/ucsb/mae/references/berlingerio-netsimile-2012.pdf

## Required software:
Python 2.7
imported modules: networkx, statistics, scipy, matplotlib, os, sys

## Environmental variables:
None

## Instructions for running:
from command line: 
```python
python anomaly.py [relative path to input directory] [data outputfile] [image outputfile]
```
Example: 
```python
python anomaly.py anomaly/datasets/datasets/enron_by_day/ testout.txt test.png
```

NOTE: The edgelist reader automatically skips the first line of the file since many input
graphs contain node and edge sums as the first line.

## Results Interpretation:
- The distances between each adjacent time series vector are printed to the specified output file.
- Any anomalies (distances which exceed the given threshold) are printed to console.
- The time series plot of distances (and threshold) is written to the specified output file.
",['pdscott'],1,,0.63,0,,,,,,0,,,
493051122,R_kgDOHWNc8g,DataDig,LSingca/DataDig,0,LSingca,https://github.com/LSingca/DataDig,Querying of Data from a large table with functions,0,2022-05-17 01:16:39+00:00,2022-05-17 01:18:08+00:00,2022-05-17 01:17:57+00:00,,31,1,1,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,,['LSingca'],0,,0.71,0,,,,,,1,,,
622323917,R_kgDOJRfozQ,s23,ucsb-cs24/s23,0,ucsb-cs24,https://github.com/ucsb-cs24/s23,,0,2023-04-01 19:12:31+00:00,2024-01-11 22:56:04+00:00,2023-06-05 11:56:34+00:00,,1368,13,13,C++,1,1,1,1,0,0,8,0,0,0,,1,0,0,public,8,0,13,master,1,1,"# CS 24
_Spring 2023_

Welcome to CS 24!  Lecture notes and programming assignments will be linked here
as they're released. If you're looking for administrative information, check the
[syllabus](Syllabus.md).  If you're looking for links specific to this session,
or just have questions, head over to [Piazza](https://piazza.com/ucsb/spring2023/cs24).


## Places & Times

- **Lectures**  14:00 to 15:15 on Mondays and Wednesdays in 1006 North Hall
- **Labs**  09:00 to 13:00 (one hour each) on Fridays in 3525 Phelps Hall
- **Kevin's Office Hours**    15:15 to 16:15 on Mondays in CSIL
- **Surya's Office Hours**    14:00 to 16:00 on Tuesdays in CSIL
- **Huanhua's Office Hours**  14:30 to 15:30 on Thursdays in CSIL
- **Kaiwen's Office Hours**   17:00 to 18:00 on Thursdays in 1002 Henley Hall


## Assignments

_Assignments are due before midnight Pacific Time_

| Name                 | Due
|----------------------|------------
| [Welcome](welcome)   | April 11th
| [FibVec](fibvec)     | April 18th
| [TicTac](tictac)     | April 25th
| [Setree](setree)     | May    2nd
| [GenePool](genepool) | May    9th
| [Counter](counter)   | May   17th
| [Typo](typo)         | May   24th
| [WordHop](wordhop)   | May   31st
| [Lineup](lineup)     | June   9th


## Lectures

_14:00 to 15:15 Mondays and Wednesdays in 1006 North Hall_

| Date           | Topics
|----------------|--------
| April      3rd | Admin stuff; the syllabus; Git
| April      5th | More Git; C++ compilation; memory layout
| April     10th | The stack and the heap; data structures; sequences
| April     12th | More sequences; vectors; linked lists
| April     17th | Stacks and queues; runtimes; big-O notation
| April     19th | Exceptions; encapsulation; sorted sequences; binary search
| April     24th | More sorted sequences; binary search trees; self-balancing trees
| April     26th | Self-balancing trees; tree traversal; sets; the ""big five"" functions
| May        1st | Static (class) functions; more big five; assignment operators
| May        3rd | Maps; more trees; more tree traversal; iterators
| May        8th | Overview of other search trees; hash tables; chaining vs probing
| May       10th | More hash tables; linear and quadratic probing; double hashing
| May       15th | Heaps (priority queues); binary heaps and percolation
| May       17th | More binary heaps; more percolation; leftist heaps
| May       22nd | Binomial heaps; disjoint sets; intro to graphs
| May       24th | More graphs; depth- and breadth-first search; Dijkstra's algorithm
| May       29th | Memorial Day - no lecture!
| May       31st | Minimum spanning trees; Prim's and Kruskal's algorithms
",['xavierholt'],1,,0.72,0,,,,,,6,,,
403927462,MDEwOlJlcG9zaXRvcnk0MDM5Mjc0NjI=,thesisdown,ssalpawuni/thesisdown,0,ssalpawuni,https://github.com/ssalpawuni/thesisdown,,0,2021-09-07 09:57:38+00:00,2021-09-07 10:11:03+00:00,2021-09-07 10:29:21+00:00,,3547,0,0,TeX,1,1,1,1,0,0,0,0,0,0,other,1,0,0,public,0,0,0,master,1,,"
<!-- README.md is generated from README.Rmd via `devtools::build_readme()`. Please edit README.Rmd -->

# thesisdown <img src=""man/figures/thesisdown_hex.png"" align=""right"" width=200 />

This project was inspired by the
[bookdown](https://github.com/rstudio/bookdown) package and is an
updated version of my Senior Thesis template in the `reedtemplates`
package [here](https://github.com/ismayc/reedtemplates). It was
originally designed to only work with the Reed College LaTeX template,
but has since been adapted to work with many different institutions by
many different individuals. Check out the [**Customizing thesisdown to
your
institution**](https://github.com/ismayc/thesisdown#customizing-thesisdown-to-your-institution)
section below for examples.

Currently, the PDF and gitbook versions are fully-functional. The word
and epub versions are developmental, have no templates behind them, and
are essentially calls to the appropriate functions in bookdown.

If you are new to working with `bookdown`/`rmarkdown`, please read over
the documentation available in the `gitbook` template at
<https://ismayc.github.io/thesisdown_book>.

The current output for the four versions is here:

-   [PDF](https://github.com/ismayc/thesisdown_book/blob/master/thesis.pdf)
    (Generating LaTeX file is available
    [here](https://github.com/ismayc/thesisdown_book/blob/master/thesis.tex)
    with other files in the [book
    directory](https://github.com/ismayc/thesisdown_book/tree/master).)
-   [Word](https://github.com/ismayc/thesisdown_book/blob/master/thesis.docx)
-   [ePub](https://github.com/ismayc/thesisdown_book/blob/master/thesis.epub)
-   [gitbook](https://ismayc.github.io/thesisdown_book)

Under the hood, the Reed College LaTeX template is used to ensure that
documents conform precisely to submission standards. At the same time,
composition and formatting can be done using lightweight
[markdown](https://rmarkdown.rstudio.com/authoring_basics.html) syntax,
and **R** code and its output can be seamlessly included using
[rmarkdown](https://rmarkdown.rstudio.com).

## Customizing thesisdown to your institution

In an ideal world, this package would support a variety of different
LaTeX templates from a wide range of institutions and we’d love to get
it there at some point. Until that time, realize that this was designed
to only work with the Reed College LaTeX template but others have
adapted it to work with their institutions. Here are some that have
customized it to fit their needs. It is recommended you review how they
changed the files by comparing their repositories to this one and then
make tweaks to yours as needed. Feel free to file an issue on this repo
if you have questions/troubles.

Have you created a thesisdown template for your institution and would
like to have it included here? Make a PR [similar to the commit done to
include
`jayhawkdown`](https://github.com/ismayc/thesisdown/commit/760113a076767cf67b6e22339e398bd3f15305c5).
I’ll review it and merge it in. Let’s keep the list going!

| College/University                                          | Repository                                                                                    | Based on                                                        |
|:------------------------------------------------------------|:----------------------------------------------------------------------------------------------|:----------------------------------------------------------------|
| American University                                         | [SimonHeuberger/eagledown](https://github.com/SimonHeuberger/eagledown)                       | [benmarwick/huskydown](https://github.com/benmarwick/huskydown) |
| Brock University                                            | [brentthorne/brockdown](https://github.com/brentthorne/brockdown)                             | [zkamvar/beaverdown](https://github.com/zkamvar/beaverdown)     |
| École Doctorale de Mathématiques Hadamard                   | [abichat/hadamardown](https://github.com/abichat/hadamardown)                                 | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Drexel University                                           | [tbradley1013/dragondown](https://github.com/tbradley1013/dragondown)                         | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Duke University                                             | [mine-cetinkaya-rundel/thesisdowndss](https://github.com/mine-cetinkaya-rundel/thesisdowndss) | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Graduate Institute of International and Development Studies | [jhollway/iheiddown](https://github.com/jhollway/iheiddown)                                   | [ulyngs/oxforddown](https://github.com/ulyngs/oxforddown)       |
| Heidelberg University, Faculty of Biosciences               | [nkurzaw/heididown](https://github.com/nkurzaw/heididown)                                     | [phister/huwiwidown](https://github.com/phister/huwiwidown)     |
| Humboldt University of Berlin                               | [phister/huwiwidown](https://github.com/phister/huwiwidown)                                   | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Kansas State University                                     | [emraher/wildcatdown](https://github.com/emraher/wildcatdown)                                 | [benmarwick/huskydown](https://github.com/benmarwick/huskydown) |
| Massachusetts Institute of Technology                       | [ratatstats/manusdown](https://github.com/ratatstats/manusdown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Oregon State University                                     | [zkamvar/beaverdown](https://github.com/zkamvar/beaverdown)                                   | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Oxford University                                           | [davidplans/oxdown](https://github.com/davidplans/oxdown)                                     | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Queen's University                                          | [eugenesit/gaelsdown](https://github.com/eugenesit/gaelsdown)                                 | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Smith College                                               | [SmithCollege-SDS/pioneerdown](https://github.com/SmithCollege-SDS/pioneerdown)               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Southampton University                                      | [dr-harper/sotonthesis](https://github.com/dr-harper/sotonthesis)                             | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Stanford University                                         | [mhtess/treedown](https://github.com/mhtess/treedown)                                         | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Universidade Federal do Rio de Janeiro                      | [COPPE-UFRJ/coppedown](https://github.com/COPPE-UFRJ/coppedown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Université Paris-Saclay                                     | [abichat/hadamardown](https://github.com/abichat/hadamardown)                                 | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University College London                                   | [benyohaiphysics/thesisdownUCL](https://github.com/benyohaiphysics/thesisdownUCL)             | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Arizona                                       | [kelseygonzalez/beardown](https://github.com/kelseygonzalez/beardown)                         | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of California, Davis                             | [ryanpeek/aggiedown](https://github.com/ryanpeek/aggiedown)                                   | [DanOvando/gauchodown](https://github.com/DanOvando/gauchodown) |
| University of California, Santa Barbara                     | [DanOvando/gauchodown](https://github.com/DanOvando/gauchodown)                               | [benmarwick/huskydown](https://github.com/benmarwick/huskydown) |
| University of Florida                                       | [ksauby/thesisdownufl](https://github.com/ksauby/thesisdownufl)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Freiburg                                      | [vivekbhr/doctorRbite](https://github.com/vivekbhr/doctorRbite)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Kansas                                        | [wjakethompson/jayhawkdown](https://github.com/wjakethompson/jayhawkdown)                     | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Manchester                                    | [juliov/uomthesisdown](https://github.com/JulioV/uomthesisdown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Minnesota                                     | [zief0002/qmedown](https://github.com/zief0002/qmedown)                                       | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of New South Wales                               | [rensa/unswthesisdown](https://github.com/rensa/unswthesisdown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Salzburg                                      | [irmingard/salzburgthesisdown](https://github.com/irmingard/salzburgthesisdown)               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Toronto                                       | [mattwarkentin/torontodown](https://github.com/mattwarkentin/torontodown)                     | [zkamvar/beaverdown](https://github.com/zkamvar/beaverdown)     |
| University of Washington                                    | [benmarwick/huskydown](https://github.com/benmarwick/huskydown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| TU Wien                                                     | [ben-schwen/robotdown](https://github.com/ben-schwen/robotdown)                               | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| University of Bristol                                       | [mattlee821/bristolthesis](https://github.com/mattlee821/bristolthesis)                       | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Universidade Federal de Santa Catarina                      | [lfpdroubi/ufscdown](https://github.com/lfpdroubi/ufscdown)                                   | [ismayc/thesisdown](https://github.com/ismayc/thesisdown)       |
| Universiteit van Amsterdam                                  | [lcreteig/amsterdown](https://github.com/lcreteig/amsterdown)                                 | [benmarwick/huskydown](https://github.com/benmarwick/huskydown) |

### Using thesisdown from Chester’s GitHub

Special thanks to [Ben Marwick](https://github.com/benmarwick) for
helping to add a lot more clarity to the directions below from the
[README of his spin-off `huskydown`
package](https://github.com/benmarwick/huskydown/blob/master/README.md).

Using {thesisdown} has some prerequisites which are described below. To
compile PDF documents using **R**, you are going to need to have LaTeX
installed. By far the easiest way to install LaTeX on any platform is
with the [tinytex](https://yihui.name/tinytex/) R package:

``` r
install.packages(c('tinytex', 'rmarkdown'))
tinytex::install_tinytex()
# after restarting RStudio, confirm that you have LaTeX with
tinytex:::is_tinytex()
```

You may need to install a few extra LaTeX packages on your first attempt
to knit as well. Here is one such example of how to do so:

``` r
tinytex::tlmgr_install(""babel-portuges"")
```

To use {thesisdown} from
[RStudio](https://www.rstudio.com/products/rstudio/download/):

1.  Ensure that you have already installed LaTeX and the fonts described
    above, and are using the latest version of
    [RStudio](https://www.rstudio.com/products/rstudio/download/). You
    can use `thesisdown` without RStudio. For example, you can write the
    Rmd files in your favorite text editor
    (e.g. [Atom](https://atom.io/),
    [Notepad++](https://notepad-plus-plus.org/)). But RStudio is
    probably the easiest tool for writing both R code and text in your
    thesis. It also provides a nice way to build your thesis while
    editing. We’ll proceed assuming that you have decided to use the
    RStudio workflow.

2.  Install the {bookdown} and {thesisdown} packages. Note that
    {thesisdown} is not available on CRAN at the moment and that’s why
    `install.packages(""thesisdown"")` won’t work. Use
    `remotes::install_github()` as shown below instead to install the
    package.

    ``` r
    if (!require(""remotes"")) 
      install.packages(""remotes"", repos = ""https://cran.rstudio.org"")
    remotes::install_github(""rstudio/bookdown"")
    remotes::install_github(""ismayc/thesisdown"")
    ```

          Note that you may need to restart RStudio at this point for
the following dialog to show up.

3.  Get started with the {thesisdown} template. There are two options
    for doing so.

-   3a) **RECOMMENDED** Create a new RStudio project with a {thesisdown}
    template.

    In RStudio, click on **File** &gt; **New Project** &gt; **New
    Directory**. Then select **Thesis Project using thesisdown** from
    the dropdown that will look something like the image below. You’ll
    see the graduation cap as the icon on the left for the appropriate
    project type.

    ![](https://raw.githubusercontent.com/ismayc/thesisdown/master/docs/reference/figures/thesis_proj.png)

    Next, give your project a name and specify where you’d like the
    files to appear. In the screenshot below, the project name is
    `my_thesis` and it will appear as a new folder on my Desktop.

    ![](https://raw.githubusercontent.com/ismayc/thesisdown/master/docs/reference/figures/thesis_proj_name.png)

    If you got this far, skip over step 3b which is the older version of
    getting the template. It might force you to change some of the
    directories to get knitting to work and has some other limitations
    as well. That’s why step 3a is recommended.

-   3b) Use the **New R Markdown** dialog to select **Thesis**:

    ![](https://raw.githubusercontent.com/ismayc/thesisdown/master/docs/reference/figures/thesis_rmd.png)

    Note that this will currently only **Knit** if you name the
    directory `index` as shown above. This guarantees that `index.html`
    is generated correctly for the Gitbook version of the thesis.

4.  After choosing which type of output you’d like in the YAML at the
    top of `index.Rmd`, **Knit** the `index.Rmd` file to get the book in
    PDF or HTML formats.

### Day-to-day writing of your thesis

You need to edit the individual chapter R Markdown files to write your
thesis. It’s recommended that you version control your thesis using
GitHub if possible. RStudio can also easily sync up with GitHub to make
the process easier. While writing, you should `git commit` your work
frequently, after every major activity on your thesis. For example,
every few paragraphs or section of text, and after major step of
analysis development. You should `git push` at the end of each work
session before you leave your computer or change tasks. For a gentle,
novice-friendly guide to getting starting with using Git with R and
RStudio, see <https://happygitwithr.com/>.

## Rendering

To render your thesis into a PDF, open `index.Rmd` in RStudio and then
click the “knit” button. To change the output formats between PDF,
gitbook and Word, look at the `output:` field in `index.Rmd` and
comment-out the formats you don’t want.

The PDF file of your thesis will be deposited in the `_book/` directory,
by default.

## Components

The following components are ones you should edit to customize your
thesis:

### `_bookdown.yml`

This is the main configuration file for your thesis. You can change the
name of your outputted file here for your thesis and other options about
your thesis here.

### `index.Rmd`

This file contains all the meta information that goes at the beginning
of your document. You’ll need to edit the top portion of this file (the
YAML) to put your name on the first page, the title of your thesis, etc.
Note that you need to have at least one chapter start in the `index.Rmd`
file for the build to work. For the template, this is done with
`# Introduction` in the example from the template.

### `01-chap1.Rmd`, `02-chap2.Rmd`, etc.

These are the Rmd files for each chapter in your dissertation. Write
your thesis in these. If you’re writing in RStudio, you may find the
[wordcount addin](https://github.com/benmarwick/wordcountaddin) useful
for getting word counts and readability statistics in R Markdown
documents.

### `bib/`

Store your bibliography (as bibtex files) here. We recommend using the
[citr addin](https://github.com/crsh/citr) and
[Zotero](https://www.zotero.org/) to efficiently manage and insert
citations.

### `csl/`

Specific style files for bibliographies should be stored here. A good
source for citation styles is
<https://github.com/citation-style-language/styles#readme>.

### `figure/` and `data/`

Store your figures and data here and reference them in your R Markdown
files. See the [bookdown book](https://bookdown.org/yihui/bookdown/) for
details on cross-referencing items using R Markdown.
","['ismayc', 'nicksolomon', 'abichat', 'shirdekel', 'simonpcouch', 'tbradley1013', 'keurcien', 'mralbu', 'nkurzaw', 'mattlee821', 'ben-schwen', 'ruaridhw', 'pcastellanoescuder', 'phinguyen44', 'mmahmoudian', 'mavogel', 'lcreteig', 'JulioV', 'trashbirdecology', 'jhollway', 'Bisaloo', 'eugenesit', 'rudeboybert']",0,,0.64,0,,,,Directory exists,,1,,,
274750963,MDEwOlJlcG9zaXRvcnkyNzQ3NTA5NjM=,LAMMPSatUCSB,shuozhixu/LAMMPSatUCSB,0,shuozhixu,https://github.com/shuozhixu/LAMMPSatUCSB,,0,2020-06-24 19:19:42+00:00,2024-12-18 13:54:42+00:00,2023-09-19 19:53:07+00:00,,2091,7,7,Shell,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,7,master,1,,"# Preamble

This GitHub repository was created when I was [a postdoc at UC Santa Barbara](https://labs.me.ucsb.edu/beyerlein/irene/members/xu). Thus, it may not be update-to-date.

Based on this repository, my Ph.D. student [Anshu Raj](https://scholar.google.com/citations?user=3SNS6QsAAAAJ&hl=en) and I have created another GitHub repository named [LAMMPSatOU](https://github.com/ANSHURAJ11/LAMMPSatOU), providing guide on running LAMMPS simulations on University of Oklahoma supercomputer, [OSCER](https://www.ou.edu/oscer).

# Introduction

As a student in the Beyerlein group at UC Santa Barbara, you will learn atomistic simulations via LAMMPS on a UCSB cluster named Pod.

# Pod

1. [Request a user account](https://csc.cnsi.ucsb.edu/forms/user-account) at the Center for Scientific Computing at UCSB.
2. Wait for the user account to be approved --- you will receive an email. In what follows, I will assume that your account is `ucsb-intern` and your password is `ucsb-intern-pw`.
3. To use Pod, these webpages may help:
        - [HPC at UCSB](https://csc.cnsi.ucsb.edu/docs/getting-started-0)
        - [Pod](http://csc.cnsi.ucsb.edu/docs/pod-cluster)
        - [SLURM](https://slurm.schedmd.com/quickstart.html)
        - [SLURM at UCSB](https://csc.cnsi.ucsb.edu/docs/slurm-job-scheduler)

# UCSB VPN

To connect to Pod, you need the [UCSB VPN](https://www.it.ucsb.edu/vpn) unless you are using the [campus network](https://www.it.ucsb.edu/wireless-networking).

# FTP client

You need a file transfer protocol (FTP) client to transfer data between Pod and your local computer. Feel free to use any FTP client. Here is [a selected list](https://en.wikipedia.org/wiki/Comparison_of_FTP_client_software).

I personally recommend FileZilla. Below is an instruction:

1. Download and install [Filezilla Client](https://filezilla-project.org/) on your local computer.
2. Open it.
3. The first time you use it, File --> Site Manager --> New site --> rename it 'Pod', then in the window on the right hand side:
        - Protocol: SFTP - SSH File Transfer Protocol
        - Host: pod-login1.cnsi.ucsb.edu
        - Logon Type: Normal
        - User: ucsb-intern
        - Password: ucsb-intern-pw
        - Connect
4. The next time you use it, File --> Site Manager --> select 'Pod', then 'Connect'.
5. To transfer files between Pod and your local computer, please refer to [this page](https://wiki.filezilla-project.org/Using).

# Terminal emulator

You also need a terminal emulator to 'talk with' Pod, e.g., submit a job. Feel free to use any terminal emulator. Here is [a selected list](https://en.wikipedia.org/wiki/List_of_terminal_emulators).

On Windows, UCSB recommends [Putty](http://csc.cnsi.ucsb.edu/docs/windows-puttyxming).

On Mac and Linux, without installing any new emulator, you may open the default terminal and type

`ssh ucsb-intern@pod.cnsi.ucsb.edu`

then hit Return. Then you will be asked to provide your password. Type your own password, e.g.,

`ucsb-intern-pw`

then hit Return.

Note: Type the password anyway even though nothing is showing up

If you are not familiar with Linux, please refer to these webpages:

- [Ubuntu](https://ubuntu.com/tutorials/command-line-for-beginners#1-overview)
- [Basic Linux commands](https://www.hostinger.com/tutorials/linux-commands)

You also need a software package to edit text files on Pod. Again, feel free to use anything. Here is [a selected list](https://en.wikipedia.org/wiki/List_of_text_editors). I recommend vim, which is already installed on Pod (and most, if not all, Mac and Linux systems). If you are not familiar with vim, please refer to these webpages:

- [vim 101](https://www.engadget.com/2012-07-10-vim-how-to.html)
- [Getting started with vim](https://opensource.com/article/19/3/getting-started-vim)
- [A quick start guide for vim beginners](https://eastmanreference.com/a-quick-start-guide-for-beginners-to-the-vim-text-editor)

# LAMMPS

LAMMPS is an open-source software package for atomistic simulations. So you first need to understand how atomistic simulations work. There are three main types of atomistic simulation methods

- [Molecular dynamics (MD)](https://en.wikipedia.org/wiki/Molecular_dynamics)
- Molecular statics (MS)
- Monte Carlo method, e.g., [kinetic Monte Carlo](https://en.wikipedia.org/wiki/Kinetic_Monte_Carlo)

To learn the basics of MD and MS, please read, respectively, Chapter 9 and Chapter 6 of [this book](https://drive.google.com/file/d/0Bxsx9iwZLpZxS0RENllIRnd2LWc/view?usp=sharing&resourcekey=0--hdU-45Sb2q9H8VTZo_C9Q). The Google Drive link is private, so you need to request access.

And here are more references on MD:

- [Introduction to Molecular Dynamics Simulation](http://2009.igem.org/wiki/images/3/3e/Introduction_to_molecular_Dynamics_Simulation.pdf)
- [Basic Molecular Dynamics](http://li.mit.edu/Archive/Papers/05/Li05-2.8.pdf)
- [A Molecular Dynamics Primer](https://web.mst.edu/vojtat/class_5403/ercolessi.pdf)

To learn LAMMPS, you may start with [this page](https://lammps.sandia.gov/tutorials.html) and [this page](https://icme.hpc.msstate.edu/mediawiki/index.php/LAMMPS_tutorials.html).

Note: LAMMPS is installed on Pod, so you don't need to install it yourself.

# An example: Calculating the GSFE curve in a BCC metal

First, to understand the generalized stacking fault energy (GSFE) curve, read these materials:

- Sections 2 & 3 of: Shuozhi Xu, Yanqing Su, Lauren T.W. Smith, Irene J. Beyerlein, [Frank-Read source operation in six body-centered cubic refractory metals](http://dx.doi.org/10.1016/j.jmps.2020.104017), J. Mech. Phys. Solids 141 (2020) 104017
- Shuozhi Xu, Emily Hwang, Wu-Rong Jian, Yanqing Su, Irene J. Beyerlein, [Atomistic calculations of the generalized stacking fault energies in two refractory multi-principal element alloys](http://dx.doi.org/10.1016/j.intermet.2020.106844), Intermetallics 124 (2020) 106844

The GSFE curve is just one curve taken from the GSFE surface, also known as the &gamma;-surface, which is usually calculated in FCC metals. To know more about the GSFE surface, please read

- Yanqing Su, Shuozhi Xu, Irene J. Beyerlein, [Density functional theory calculations of generalized stacking fault energy surfaces for eight face-centered cubic transition metals](http://dx.doi.org/10.1063/1.5115282), J. Appl. Phys. 126 (2019) 105112

When you are ready to run simulations, download five files to a local directory `local_gsfe` on your local computer. The first four files can be downloaded from this GitHub repository, including

- `lmp_gsfe.batch`, which is for job submission
- `lmp_gsfe.data`, which is the LAMMPS data file
- `lmp_gsfe.in`, which is the LAMMPS input file
- `gsfe_curve.sh`, which is the post-processing bash script

The fifth file is

- `MoNbTi_A_atom.eam.alloy`, which is the interatomic potential file and can be downloaded from [this page](https://github.com/wrj2018/Intermetallics_2020)

Then on Pod, create a new directory in your `$HOME`. Say the directory is named `pod_gsfe`. The command is

`mkdir pod_gsfe`

Then upload, via Filezilla, the five files from your local computer to `pod_gsfe` on Pod. 

Then, in your terminal emulator, type

`cd pod_gsfe`

then hit Return. Then submit the job by typing

`sbatch lmp_gsfe.batch`

then hit Return. To check the status of the job, type

`squeue -u ucsb-intern`

then hit Return. You will see two lines. In the first line, there is a term `ST`, which stands for 'status'. If, at the same location of the second line, you see `PD`, the job is pending. Recheck the status later. If you see `R`, the job is running. If you only see one line, the job is finished. This, however, can mean one of the two things:

- The job was finished because of an error. In this case, check these three files: `lmp_gsfe.out`, `lmp_gsfe.err`, and `log.lammps`. They provide you information on what caused the error(s). In particular, the last file is the log file of LAMMPS, which would present an error message in the last line. Please refer to [this page](https://lammps.sandia.gov/doc/Errors_messages.html) for the explanation of each error message. Once you figure out what went wrong, fix the problem, and resubmit the job
- The job was finished successfully. In this case, the file `lmp_gsfe.err` is empty. Proceed to the next step.

You will find a lot of files in the directory. One file is called `gsfe_ori`. In the same directory on Pod, type

`sh gsfe_curve.sh`

then hit Return. You will find a new file called `gsfe`. The first and second columns of this file, respectively, are the _x_ and _y_ axes of the 'MoNbTi<sub>_A_</sub>' curve in Figure 2(a) of [this paper](http://dx.doi.org/10.1016/j.intermet.2020.106844). Download `gsfe` to your local computer, plot it, and see if you get the same curve.

As usual, feel free to use any software to plot the curve. Here is [a selected list](https://en.wikipedia.org/wiki/List_of_information_graphics_software). I recommend Gnuplot. There are many tutorials on Gnuplot, e.g., [this one](https://www.usm.uni-muenchen.de/CAST/talks/gnuplot.pdf).

Now, go back to the file `lmp_gsfe.in` and read it. Look up the meaning of each LAMMPS command on [this page](https://lammps.sandia.gov/doc/Commands_all.html).

Note: If you use any file from this section in your published work, please cite

- Shuozhi Xu, Emily Hwang, Wu-Rong Jian, Yanqing Su, Irene J. Beyerlein, [Atomistic calculations of the generalized stacking fault energies in two refractory multi-principal element alloys](http://dx.doi.org/10.1016/j.intermet.2020.106844), Intermetallics 124 (2020) 106844

# OVITO

In the directory on Pod, `pod_gsfe`, you will find a lot of dump files, which contain information of atomic positions. To visualize these files, download them, via Filezilla, to your local computer. Then install [OVITO](http://www.ovito.org/) on your computer. Read [this page](http://www.ovito.org/docs/current/) to learn how to use it.

# Another example: Calculating the Peierls stress of a screw dislocation in a BCC metal

First, to understand dislocations, I recommend these readings depending on how much you already know and how much more you want to know.

- Beginner-level:

        - D. Hull, D.J. Bacon, [Introduction of Dislocations](https://www.amazon.com/Introduction-Dislocations-Goldsmiths-Professor-University/dp/0080966721), 5th edition, 2011 [[PDF](https://drive.google.com/file/d/0Bxsx9iwZLpZxRktuUVozXzB6QWs/view?usp=sharing)]
        - Yu N Osetsky, D J Bacon, [An atomic-level model for studying the dynamics of edge dislocations in metals](http://dx.doi.org/10.1088/0965-0393/11/4/302), Modelling Simul. Mater. Sci. Eng. 11 (2003) 427
        - Wu-Rong Jian, Min Zhang, Shuozhi Xu, Irene J. Beyerlein, [Atomistic simulations of dynamics of an edge dislocation and its interaction with a void in copper: A comparative study](http://dx.doi.org/10.1088/1361-651X/ab8358), Modelling Simul. Mater. Sci. Eng. 28 (2020) 045004

- Intermediate-level:

        - D.J. Bacon, Y.N. Osetsky, D. Rodney, [Dislocation-obstacle interactions at the atomic level](http://dx.doi.org/10.1016/S1572-4859(09)01501-0), in _Dislocations in Solids_, 15 (2009) 1--90 [[PDF](http://ilm-perso.univ-lyon1.fr/~drodney/dr_articles/2009_Dislo_In_Solids%5BBacon_Osetsky_Rodney%5D.pdf)]
        - Jaehyun Cho, Till Junge, Jean-Fran&ccedil;ois Molinari, Guillaume Anciaux, [Toward a 3D coupled atomistic and discrete dislocation dynamics simulation: dislocation core structures and Peierls stresses with several character angles in FCC aluminum](http://dx.doi.org/10.1186/s40323-015-0028-6), Adv. Model. Simul. Eng. Sci. 2 (2015) 12
        - Vasily V. Bulatov, Wei Cai, [Computer Simulations of Dislocations](https://www.amazon.com/Computer-Simulations-Dislocations-Materials-Modelling/dp/0198526148), 2006 [[PDF](https://drive.google.com/file/d/0Bxsx9iwZLpZxMHl2cVp6QVdRWWM/view?usp=sharing)]
        - Johannes Weertman, Julia R. Weertman, [Elementary Dislocation Theory](https://www.amazon.com/Elementary-Dislocation-Theory-Johannes-Weertman/dp/0195069005), 1992

- Advanced-level:

        - Peter M. Anderson, John P. Hirth, Jens Lothe, [Theory of Dislocations](https://www.amazon.com/Theory-Dislocations-Peter-M-Anderson/dp/0521864364), 3rd edition, 2017

Some Google Drive links above are private. You may request access. To learn all kinds of defects in crystals, read [the website by Föll](https://www.tf.uni-kiel.de/matwis/amat/def_en/index.html) and/or [the book by Cai and Nix](https://www.cambridge.org/highereducation/books/imperfections-in-crystalline-solids/3A193C8DEF36073F9E2EF07EEA6A5D96#overview).

When you are ready to run simulations, download four files to a local directory `local_peierls` on your local computer. The first three files can be downloaded from this GitHub repository, including

- `lmp_peierls.batch`, which is for job submission
- `lmp_peierls.data`, which is the LAMMPS data file, containing a screw dislocation on the {112} plane
- `lmp_peierls.in`, which is the LAMMPS input file

The fourth file is

- `MoNbTi_A_atom.eam.alloy`, which is the interatomic potential file and can be downloaded from [this page](https://github.com/wrj2018/Intermetallics_2020)

Then on Pod, create a new directory, `pod_peierls`, in your `$HOME`, by typing

`mkdir pod_peierls`

then hit Return. Then upload, via Filezilla, the four files from your local computer to `pod_peierls` on Pod. 

Then, in your terminal emulator, type

`cd pod_peierls`

then hit Return. Then submit the job by typing

`sbatch lmp_peierls.batch`

then hit Return.

<a name=""LSR""></a>After the job is finished, you will find a new file called `strain-stress`. The first and second columns of this file, respectively, are the _yz_ components of the strain tensor and stress tensor of the simulation cell. The strain is unitless and the stress is in units of MPa. Download `strain-stress` to your local computer, plot it, and you will see a point at which the stress-strain relation starts to deviate from linearity. Let's call it P1.

To visualize the dislocation core, download dump files to the same directory on your local computer. You do not need to download all of them at once, just selected ones, e.g., dump.0.load, dump.50.load, dump.100.load, ..., dump.500.load. Open any of them in OVITO by File --> Load File --> select the file --> Open. Then, Add modification --> Dislocation analysis (DXA), and change the ""input crystal type"" to ""Body-centered cubic (BCC)"". The blue and white atoms, respectively, are in BCC and disordered local structures. The green line is the dislocation line. White atoms exist in three locations: top layer, bottom layer, and center of the simulation cell. Those in the center are atoms in the dislocation core. Select one white atom using the [crosshair button](https://www.ovito.org/docs/current/data_inspector.particles.php).

Next, go through all dump files frame by frame in OVITO and pay attention to between which two frames the dislocation core starts to move along the positive _x_ direction. Why is this important? Because when the applied stress surpasses the Peierls stress, the dislocation line should [move from one Peierls valley to another](https://www.tf.uni-kiel.de/matwis/amat/def_en/kap_5/backbone/r5_3_1.html). Therefore, if the dislocation moves between one dump file and the next one, the Peierls stress is between the two stresses associated with these two dump files.

How do we determine whether the dislocation moves? Usually one of the two criteria is used: (i) does any white/blue atom become blue/white? (ii) does the green line move by a non-negligible distance? The keyword here is ""non-negligible"". Regardless of whether the Peierls stress has been reached, the green line may move a little bit between any two frames, especially when the dislocation is an edge dislocation. However, this may be because the entire simulation cell is sheared and so are all atoms within. If, from dump file A to dump file B, the dislocation moves a little bit, and from dump file B to dump file C, the dislocation moves by a longer distance, then likely the Peierls stress is reached somewhere between B and C.

Note: For a screw dislocation, it is important to check whether the dislocation moves within the _xz_ plane. In many cases, the screw dislocation immediately crosses slip to a plane that is not parallel to _xz_. For more on this topic, read [this paper](https://doi.org/10.1016/j.commatsci.2014.03.064). When this happens, the Peierls stress is not calculable. Write this down and move on to the next calculation. Sometimes the screw dislocation moves within the _xz_ plane by a certain distance, and then crosses slip. In this case, the Peierls stress is considered calculable. Note that an edge dislocation does not cross slip, so its Peierls stress should always be calculable.

In the example provided in this GitHub repository, the dislocation moves between `dump.350.load` and `dump.400.load`. Then download `dump.360.load`, `dump.370.load`, `dump.380.load`, and `dump.390.load` from Pod to the same directory (to which all previous dump files were downloaded) on your local computer. Open any dump file again in OVITO, by File --> Load File --> select the file --> Replace selected. Again, go through the newly downloaded dump files frame by frame and identify the two frames between which the dislocation core starts to move. The two frames are `dump.390.load` and `dump.400.load`.

Then download `dump.391.load`, `dump.392.load`, ..., `dump.399.load` to the same local directory. Open any dump file, go through these new dump files and identify the two frames between which the dislocation core starts to move. The two frames are `dump.393.load` and `dump.394.load`.

Then the Peierls stress is the stress of the simulation cell corresponding to `dump.393.load`. The strain and stress of the simulation cell at this point can be found in line 393 of the file `strain-stress`, and the corresponding stress is then the Peierls stress for the anti-twinning direction on the {112} plane in MoNbTi<sub>_A_</sub>, 1174 MPa. In the current case, the critical point associated with the Peierls stress is also P1 which was identified earlier.

In a general case, however,

- The dislocation core may move along the negative _x_ direction, depending on the Burgers vector of the dislocation and the shear direction.
- Sometimes there is more than one point on the stress-strain curve at which the stress-strain relation starts to deviate from linearity. Let's say there are three such points and we call them P1, P2, and P3. Then the point at which the dislocation core starts to move may be one of them, or none of them. In other words, do not assume that any of these points is the critical point associated with the Peierls stress. If the point at which the dislocation core starts to move does not correspond to any turning point identified on the stress-strain curve, go with the former point instead of the latter.

Note: If you use any file from this section in your published work, please cite

- Shuozhi Xu, Yanqing Su, Wu-Rong Jian, Irene J. Beyerlein, [Local slip resistances in equal-molar MoNbTi multi-principal element alloy](http://dx.doi.org/10.1016/j.actamat.2020.10.042), Acta Mater. 202 (2021) 68--79",['shuozhixu'],1,,0.76,0,,,,,,1,,,
264012942,MDEwOlJlcG9zaXRvcnkyNjQwMTI5NDI=,SEM-Lab7,garberadamc/SEM-Lab7,0,garberadamc,https://github.com/garberadamc/SEM-Lab7,"Ten Growth Models - University of California, Santa Barbara",0,2020-05-14 20:01:01+00:00,2020-05-24 01:29:56+00:00,2020-05-24 01:29:54+00:00,,4558,0,0,HTML,1,1,1,1,0,0,16,0,0,0,,1,0,0,public,16,0,0,master,1,,"# SEM-Lab7

Ten Growth Models - University of California, Santa Barbara - Structural Equation Modeling

handout here - https://garberadamc.github.io/project-site/Lab7-ten-growth-models

course materials here - https://garberadamc.github.io/project-site/


![](figures/tidy_workflow_hex.png)
",['garberadamc'],1,,0.78,0,,,,,,1,,,
747953940,R_kgDOLJTfFA,Capstone-Scripps,PSTAT197-F23/Capstone-Scripps,0,PSTAT197-F23,https://github.com/PSTAT197-F23/Capstone-Scripps,Collaboration of UCSB Data Science Capstone students and CalCOFI to generate RShiny App for visualizing CalCOFI marine mammal visual observations and eDNA detections,0,2024-01-25 00:56:04+00:00,2024-12-11 01:27:31+00:00,2024-06-10 18:18:37+00:00,,113032,3,3,Jupyter Notebook,1,1,1,0,0,0,1,0,0,0,mit,1,0,0,public,1,0,3,main,1,1,"# CalCOFI_eDNA_RShiny
Collaboration of UCSB Data Science Capstone students and CalCOFI to generate RShiny App for visualizing the distribution of marine mammal eDNA detections in time and space relative to oceanographic parameters and marine mammal visual observations. 
- app.R is the prototype RShiny App built by MNA to visualize marine mammal detections along CalCOFI grid
- ""CalCOFI_2004-2022_CombinedSightings.csv"" is the dataset of marine mammal visual observations from 2004 - 2022. Each row contains information about a unique sighting.
- ""CalCOFI_2004-2021_Effort_OnTransectOnEffortONLY_MNA.csv"" contains visual survey effort from 2004 - 2021. Each row contains information about location and length of a given transect line.
- ""CalCOFI_species_codes.csv"" contains all of the cetacean (whale, dolphin, and porpoise) species codes present in the dataset.
- ""CalCOFIStationOrder.csv"" contains the locations of each CalCOFI station.
- ""edna.csv"" contains the eDNA sequencing effort and detections. Each row represents eDNA effort at a given station and depth. Columns 10-16 represent species specific eDNA detections, with the detection code also in column 20 (""detection"")

","['kaitlynlee31', 'samguimte', 'koitaku2323', 'luibaraj', 'JustinKim4402', 'Yoobinn', 'm1alksne', 'just5034', 'YoobinW', 'zpys233']",1,,0.76,0,,,,,,0,,,
453907766,R_kgDOGw4VNg,TEMP-repo02-docs-qa,ucsb-cs156-w22/TEMP-repo02-docs-qa,0,ucsb-cs156-w22,https://github.com/ucsb-cs156-w22/TEMP-repo02-docs-qa,Documentation QA site for ucsb-cs156-w22/TEMP-repo02,0,2022-01-31 06:56:09+00:00,2022-01-31 07:06:52+00:00,2022-01-31 07:05:23+00:00,https://ucsb-cs156-w22.github.io/TEMP-repo02-docs-qa,1249,0,0,,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,1,"# TEMPLATE-docs

This repo is a template repo used in the GitHub Actions scripts of several 
repos in this organization.  It forms the initial template for the `-docs` 
and `-docs-qa` repos used with GitHub pages to publish documentation.

You may also need to turn on GitHub pages, like this:

![image](https://user-images.githubusercontent.com/1119017/151720067-00883ce2-944f-4931-8fd3-4961a9c1cc96.png)

","['pconrad', 'phtcon']",1,,0.83,0,,,,,,0,,,
363220930,MDEwOlJlcG9zaXRvcnkzNjMyMjA5MzA=,sams-mapping,ucsb-coast-lab/sams-mapping,0,ucsb-coast-lab,https://github.com/ucsb-coast-lab/sams-mapping,,0,2021-04-30 18:03:42+00:00,2021-10-20 15:24:19+00:00,2021-08-20 17:49:25+00:00,,98905,4,4,JavaScript,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,4,master,1,1,"# SAMS Mapping
This is a utility developed by the UCSB COAST Lab for the ARPA-E SAMS project for visualizing data produced from various autonomous marine vehicles. 

## Build Instructions 

* [Install Rust](https://www.rust-lang.org/tools/install)
* Using `$ cargo run` will start the application on `http://localhost:8000`, which can be navigated to in a web browser.
","['sethvanb', 'quietlychris']",1,,0.85,0,,,,,,2,,,
103815591,MDEwOlJlcG9zaXRvcnkxMDM4MTU1OTE=,ciscocmd1,MichealGarner/ciscocmd1,0,MichealGarner,https://github.com/MichealGarner/ciscocmd1,Run Cisco IOS commands in Python using NetMiko,0,2017-09-17 08:55:12+00:00,2023-04-06 23:38:23+00:00,2017-09-23 08:31:57+00:00,,4,1,1,Python,1,1,1,1,0,0,2,0,0,0,mit,1,0,0,public,2,0,1,master,1,,"# Running Cisco commands with Python using Netmiko

This project was created to test Netmiko with Cisco Switches and Routers.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

This project is based on netmiko.
You will need a working copy of netmiko to use these files.

Installing netmiko:

Netmiko can be found on GitHub at https://github.com/ktbyers/netmiko.

You can install it from source:
```
$ git clone https://github.com/ktbyers/netmiko.git
$ cd netmiko
$ python setup.py install
```
You can also use pip:
```
$ pip install netmiko
```

### Installing

First make a local copy of the files in this repository

```
$ git clone https://github.com/MichealGarner/ciscocmd1
```

## Running the tests

Once you have a local copy of the files, you can use the script as follows:

To run the commands listed in the router_commands.txt file...

Usage:
```
python cmdrunner.py router_commands.txt routers.json
```
add the commands you want to run to the router_commands.txt file.
add the devices you want to run the commands on in the routers.json file.

To run the commands listed in the switch_commands.txt file...

Usage:
```
python cmdrunner.py switch_commands.txt switches.json
```
add the commands you want to run to the switch_commands.txt file.
add the devices you want to run the commands on in the switches.json file.

## Authors

* **Micheal Garner** - https://github.com/MichealGarner


## Acknowledgments

* This script is based entirely on the work of Greg Mueller
https://www.youtube.com/channel/UCsB_qVfDBlkejpg_y3Ltgqw
",['MichealGarner'],0,,0.73,0,,,,,,0,,,
214978980,MDEwOlJlcG9zaXRvcnkyMTQ5Nzg5ODA=,Dynamic-Mode-Decompositions,nibodh/Dynamic-Mode-Decompositions,0,nibodh,https://github.com/nibodh/Dynamic-Mode-Decompositions,Codes to run some Dynamic Mode Decompositions (DMD) algorithms on multiple time-series data with some prebuilt choices of observables and example simulation models in python modules. The one step and N step options refer only to the predictions using the dynamics matrix rather than its estimation itself. Used research at University of California Santa Barbara (UCSB).,0,2019-10-14 07:40:30+00:00,2025-01-07 13:29:22+00:00,2020-09-04 00:17:40+00:00,,1889,9,9,Python,1,1,1,1,0,0,3,0,0,0,,1,0,0,public,3,0,9,master,1,,,['nibodh'],1,,0.64,0,,,,,,1,,,
732832035,R_kgDOK64hIw,ucsb-cs160-compiler,Youngcius/ucsb-cs160-compiler,0,Youngcius,https://github.com/Youngcius/ucsb-cs160-compiler,"UCSB CS160 (Translation of Programming Languages, i.e., Compiler) course projects",0,2023-12-18 00:28:05+00:00,2023-12-18 00:28:05+00:00,2023-12-18 00:28:05+00:00,,5,0,0,,1,1,1,1,0,0,0,0,0,0,apache-2.0,1,0,0,public,0,0,0,master,1,,"# ucsb-cs160-compiler
UCSB CS160 (Translation of Programming Languages, i.e., Compiler) course projects
",['Youngcius'],1,,0.72,0,,,,,,1,,,
253121327,MDEwOlJlcG9zaXRvcnkyNTMxMjEzMjc=,project-s0-t4-new-city,ucsb-cs48-s20/project-s0-t4-new-city,0,ucsb-cs48-s20,https://github.com/ucsb-cs48-s20/project-s0-t4-new-city,,0,2020-04-04 23:53:20+00:00,2020-06-09 17:21:15+00:00,2020-10-13 22:31:22+00:00,,16084,0,0,JavaScript,1,1,1,0,0,0,5,0,0,5,mit,1,0,0,public,5,5,0,master,1,1,"# project-s0-t4-new-city

Ari	Brian	Xilin	Steven

Used to compare different counties in california for people looking for a new home, including different aspects of living standards such as cost of living, crime rates, temperature, and cost/rent of the homes. Our app will allow users to filter according to different parameters and to compare between two different counties. It will also genereate a list of possible candidates according to user's preference. 

A Spring Boot project. 


# Deploy instruction

* [Deployment Instructions](./docs/DEPLOY.md)


# Testing
* Run mvn test
","['briankangcoder', 'Wxl19980214', 'jseong1100', 'aripo99', 'pconrad', 'aripo999', 'btk5h', 'jackkilgore', 'phtcon']",1,,0.84,0,,,,,,1,,,
60924991,MDEwOlJlcG9zaXRvcnk2MDkyNDk5MQ==,sparse-wavelets,arleilps/sparse-wavelets,0,arleilps,https://github.com/arleilps/sparse-wavelets,,0,2016-06-11 19:47:00+00:00,2016-06-11 19:58:35+00:00,2017-10-01 09:17:22+00:00,,3536,0,0,Jupyter Notebook,1,1,1,1,0,0,5,0,0,1,,1,0,0,public,5,1,0,master,1,,"# Graph Wavelets via Sparse Cuts

Implementation of graph wavelets via sparse cuts with some baselines, datasets and evaluation.

Evaluation is performed using python notebooks.

Scalability and approximation experiments:
-----------------------
https://nbviewer.jupyter.org/github/arleilps/sparse-wavelets/blob/master/synthetic-data.ipynb

Compression experiments:
-----------------------
https://nbviewer.jupyter.org/github/arleilps/sparse-wavelets/blob/master/compression-experiments.ipynb

For more details, see the paper:  
[Graph Wavelets via Sparse Cuts ](http://arxiv.org/abs/1602.03320 """")  
Arlei Silva, Xuan-Hong Dang, Prithwish Basu, Ambuj K Singh, Ananthram Swami  
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 2016 (to appear). 

Arlei Silva (arlei@cs.ucsb.edu)

",['arleilps'],1,,0.7,0,,,,,,2,,,
438207391,R_kgDOGh6Dnw,gw170817-eft-eos,LBJ-Wade/gw170817-eft-eos,0,LBJ-Wade,https://github.com/LBJ-Wade/gw170817-eft-eos,,0,2021-12-14 10:18:52+00:00,2021-12-14 10:20:50+00:00,2021-12-14 10:20:33+00:00,,135635,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# GW170817: Stringent constraints on neutron-star radii from multimessenger observations and nuclear theory

**Collin D. Capano<sup>1,2</sup>, Ingo Tews<sup>3</sup>, Stephanie M. Brown<sup>1,2</sup>, Ben Margalit<sup>4,5,6</sup>, Soumi De<sup>6,7</sup>, Sumit Kumar<sup>1,2</sup>, Duncan A. Brown<sup>6,7</sup>, Badri Krishnan<sup>1,2</sup>, Sanjay Reddy<sup>8,9</sup>**

**<sup>1</sup>Albert-Einstein-Institut, Max-Planck-Institut für Gravitationsphysik, Callinstraße 38, 30167 Hannover, Germany**

**<sup>2</sup>Leibniz Universität Hannover, 30167 Hannover, Germany**

**<sup>3</sup>Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM 87545, USA**

**<sup>4</sup>Department of Astronomy and Theoretical Astrophysics Center, University of California, Berkeley, CA 94720, USA**

**<sup>5</sup>NASA Einstein Fellow**

**<sup>6</sup>Kavli Institute for Theoretical Physics, University of California, Santa Barbara, CA 93106, USA**

**<sup>7</sup>Department of Physics, Syracuse University, Syracuse NY 13244, USA**

**<sup>8</sup>Institute for Nuclear Theory, University of Washington, Seattle, WA 98195-1550, USA**

**<sup>9</sup>JINA-CEE, Michigan State University, East Lansing, MI, 48823, USA**

## License

![Creative Commons License](https://i.creativecommons.org/l/by-sa/3.0/us/88x31.png ""Creative Commons License"")

This work is licensed under a [Creative Commons Attribution-ShareAlike 3.0 United States License](http://creativecommons.org/licenses/by-sa/3.0/us/).

## Introduction

This repository is a companion to [Capano et al. (arxiv:1908.10352)](https://arxiv.org/abs/1908.10352). It contains the Livingston glitch-removed gravitational-wave frame data, the equation of state files, and the posterior probability density files from the parameter estimation.

We encourage use of these data in derivative works. If you use the material provided here, please cite the paper using the reference:
```
@article{Capano:2019,
      author         = ""Capano, Collin D. and Tews, Ingo and Brown, Stephanie M. and
                        Margalit, Ben and De, Soumi and Kumar, Sumit and Brown, Duncan
                        A. and Krishnan, Badri and Reddy, Sanjay"",
      title          = ""{GW170817: Stringent constraints on neutron-star radii from
                         mutimessenger observations and nuclear theory}"",
      year           = ""2019"",
      eprint         = ""1908.10352"",
      archivePrefix  = ""arXiv"",
      primaryClass   = ""astro-ph.HE"",
      SLACcitation   = ""%%CITATION = ARXIV:1908.10352;%%""
}
```

## Contents

 * [eos_data](https://github.com/sugwg/gw170817-eft-eos/tree/master/eos_data) contains the equation of state data using chiral effective field theory computed to either nuclear saturation density [nsat](https://github.com/sugwg/gw170817-eft-eos/tree/master/eos_data/nsat) or twice nuclear saturation density [2nsat](https://github.com/sugwg/gw170817-eft-eos/tree/master/eos_data/2nsat). Each realization of an equation of state is provided in a single plain-text file. The three columns in these files correspond to radius (km), mass (solar masses), and dimensionless tidal polarizability (Lambda) for each equation of state.
 * [frame_data](https://github.com/sugwg/gw170817-eft-eos/tree/master/frame_data) contains the glitch-removed Livingston data used for the gravitational-wave parameter estimation.
 * [posterior_data](https://github.com/sugwg/gw170817-eft-eos/tree/master/posterior_data) contains the posteriors for the equations of state computed to either nuclear saturation density [nsat](https://github.com/sugwg/gw170817-eft-eos/tree/master/posterior_data/nsat) or twice nuclear saturation density [2nsat](https://github.com/sugwg/gw170817-eft-eos/tree/master/posterior_data/2nsat). For each of the two families of equations of state, the primary results are available in the directory `uniform_mass_prior`. This directory contains three files: `posterior.hdf` contains the gravitational-wave posterior, `posterior_mthresh.hdf` contains the posterior with the threshold mass cut applied, and `posterior_mthresh_maxmass.hdf` contains the posterior with both the threshold mass cut and maximum neutron star mass cut applied. The directories called `dns_mass_prior` contains the same data for the double neutron star mass prior.

## Reading posterior samples

The posterior samples are in the `samples` group in the posterior data hdf files. These may be read in a python environment using an installation of h5py. For example,
```
>>> import h5py
>>> fp = h5py.File('posterior_data/2nsat/uniform_mass_prior/posterior_mthresh_maxmass.hdf', 'r')
>>> fp['samples/radius_1p4'][:]
array([10.66445588, 10.33877226, 10.81947201, ..., 11.53508902,
     11.22292423, 11.77858514])
```

Provided parameters are:
 * `mass1`: The source-frame mass of the larger object, in solar masses.
 * `mass2`: The source-frame mass of the smaller object, in solar masses.
 * `spin1z`: The dimensionless spin of the larger object.
 * `spin2z`: The dimensionless spin of the smaller object.
 * `eos`: The equation of state index. The corresponding equation of state is
   in the eos directory, with the name of the text file corresponding to the
   index. Note: the eos indices are stored as floats; to find the appropriate
   EOS file, take the integer part. For example, `450.87` corresponds to EOS
   `450`.
 * `tc`: The geocentric GPS time of the signal merger.
 * `inclination`: The inclination of the binary's orbital angular momentum with
   respect to the line of sight, in radians. An inclination of 0 (pi)
   corresponds to a face-on (face-away) orientation.
 * `polarization`: The polarization angle of the gravitational wave.
 * `loglikelihood`: The natural log of the likelihood of each sample.

The following parameters are calculated from the equation of state associated
with each sample. As such, there are only 2000 unique values of the following,
even though the total number of samples may be larger.
 * `lambda1`: The dimensionless tidal polarizability of the larger object.
 * `lambda2`: The dimensionless tidal polarizability of the smaller object.
 * `radius1`: The radius of the larger object, in km.
 * `radius2`: The radius of the smaller object, in km.
 * `radius_1p4`: The radius of a 1.4 solar mass neutron star with the same
   equation of state.
 * `radius_1p6`: The radius of a 1.6 solar mass neutron star with the same
   equation of state.
 * `p1p9`: The pressure in the core of a 1.9 solar mass neutron star with the
   same equation of state, in MeV / cubic fm.
 * `p2nsat`: The pressure at twice nuclear saturation density, as determined
   by the equation of state, in MeV / cubic fm.
 * `p4nsat`: The pressure at four times nuclear saturation density, as
   determined by the equation of state, in MeV / cubic fm.
 * `pmax`: The maximum pressure supported by the equation of state, in
   MeV / cubic fm.
 * `cs_sq_1p9`: The speed of sound in the core of a 1.9 solar mass neutron star
   with the same equation of state.
 * `cs_sq_max`: The maximum speed of sound supported by the equation of state.
 * `max_mass`: The maximum neutron star mass supported by the equation of
   state, in solar masses.

In addition, the threshold mass for prompt collapse is provided
(`threshold_mass`), in solar masses. This is calculated using equation 3 of the
supplementary material. To account for systematic error in that fit, a random
draw from a normal distribution with a standard deviation of 0.05 is added to
each threshold mass sample. As a result, there are more than 2000 unique
values of the threshold mass, even though it is calculated from the equation
of state parameters.


## Acknowledgements

We thank Bruce Allen, Wolfgang Kastaun, and Brian Metzger for valuable discussions.

### Funding

This work was supported by U.S. National Science Foundation grants
PHY-1430152 (SR),
PHY-1707954 (DAB, SD);
U.S. Department of Energy grant DE-FG02-00ER41132 (SR);
NASA Hubble Fellowship grant \#HST-HF2-51412.001-A awarded by the Space Telescope Science Institute, which is operated by the Association of Universities for Research in Astronomy, Inc., for NASA, under contract NAS5-26555 (BM); and the U.S. Department of Energy, Office of Science, Office of Nuclear Physics, under Contract DE-AC52-06NA25396, the Los Alamos National Laboratory (LANL) LDRD program, and the NUCLEI SciDAC program (IT). 
DAB, SD, and BM thank the Kavli Institute for Theoretical Physics (KITP) where portions of this work were completed. KITP is supported in part by the National Science Foundation under Grant No. NSF PHY-1748958. 
Computational resources have been provided by Los Alamos Open Supercomputing via the Institutional Computing (IC) program, by the National Energy Research Scientific Computing Center (NERSC), by the Jülich Supercomputing Center, by the ATLAS Cluster at the Albert Einstein Institute in Hannover, and by Syracuse University. The gravitational-wave data used in this work was obtained from the Gravitational Wave Open Science Center (GWOSC) at [https://www.gw-openscience.org](https://www.gw-openscience.org). GWOSC is a service of LIGO Laboratory, the LIGO Scientific Collaboration and the Virgo Collaboration. LIGO is funded by the National Science Foundation. Virgo is funded by the French Centre National de Recherche Scientifique (CNRS), the Italian Istituto Nazionale della Fisica Nucleare (INFN) and the Dutch Nikhef, with contributions by Polish and Hungarian institutes.

### Authors contributions:
Conceptualization, DAB, CDC, BK, BM, SR, IT;
Data curation, DAB, CDC, IT;
Formal analysis, CDC, SMB, IT, SD;
Funding acquisition: DAB, BK, BM, SR, IT;
Methodology: DAB, CDC, SD, BK, BM, SR, IT;
Project administration: DAB, CDC, BK, IT;
Resources: DAB, BK, IT;
Software: DAB, SMB, CDC, SD, SK, BM, IT;
Supervision: DAB, BK, SR;
Validation: DAB, SMB, CDC, SD, IT;
Visualization: SMB, CDC, BM;
Writing--original draft: DAB, SMB, CDC, IT;
Writing--review and editing: DAB, SMB, CDC, SD, BK, BM, SR, IT.
","['duncan-brown', 'soumide1102']",1,,0.74,0,,,,,,1,,,
38482685,MDEwOlJlcG9zaXRvcnkzODQ4MjY4NQ==,UCSB-Course-Projects,Pyr0mania/UCSB-Course-Projects,0,Pyr0mania,https://github.com/Pyr0mania/UCSB-Course-Projects,Code source files of my UCSB course projects,0,2015-07-03 08:48:32+00:00,2015-07-03 08:48:32+00:00,2015-07-03 08:48:32+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,[],1,,0.76,0,,,,,,0,,,
43609296,MDEwOlJlcG9zaXRvcnk0MzYwOTI5Ng==,INTERNAL-CS189A,sagarsaija/INTERNAL-CS189A,0,sagarsaija,https://github.com/sagarsaija/INTERNAL-CS189A,Team Gigs,0,2015-10-03 18:17:51+00:00,2016-04-05 19:16:07+00:00,2016-02-03 00:33:16+00:00,,1797,0,0,Ruby,1,1,1,1,0,0,0,0,0,2,,1,0,0,public,0,2,0,master,1,,"# Mezzo [![Build Status](https://magnum.travis-ci.com/sagarsaija/INTERNAL-CS189A.svg?token=pQvxcmrbHMs3QsSaUN6U&branch=master)](https://magnum.travis-ci.com/sagarsaija/INTERNAL-CS189A)
#### Finding a _medium_ ground for musicians
#### CS 189A - Senior Capstone Project
###### Instructor: Chandra Krintz (ckrintz@cs.ucsb.edu)
###### TA: Daniel Imberman (dimberman@umail.ucsb.edu)
###### Mentors: *Appfolio* 
- Brynjar Gretarsson (brynjar.gretarsson@appfolio.com)
- Andrew Mutz (andrew.alan.mutz@appfolio.com)
- Daniel Vicory (daniel.vicory@appfolio.com)

### Team Gigs:
- Sagar Saija - Lead Software Developer
- Sahil Bissessur - Software Developer
- Vincent Chang - Software Developer/Scribe
- Mason Levy - Software Developer
- Prithvi Sathiya - Software Developer

## Currently on: Sprint 3
**Goal:** Develop UI, profile, and matching features

###To-do: [PivotalTracker](https://www.pivotaltracker.com/n/projects/1440674)
* Link profiles to users (5)
* Store user location in database (1)
* Create matching page (5)
* ~~Chat messaging system research (C)~~
* User Stories (C)
* UX/UI Feedback (C)

##### 3 Things We're Focusing on This Sprint:
1. We will **go to every scrum and class** (barring sickness).
2. We will **stay updated** with PivotalTracker and log work times.
3. We will **be more open** with our blocks or our problems.
","['Styxx', 'sbissessur', 'masonl93', 'prithvisathiya']",1,,0.88,0,,,,,,5,,,
100515495,MDEwOlJlcG9zaXRvcnkxMDA1MTU0OTU=,ucsb-cs8,Yiluo-pHoton/ucsb-cs8,0,Yiluo-pHoton,https://github.com/Yiluo-pHoton/ucsb-cs8,,0,2017-08-16 17:31:58+00:00,2017-10-02 18:20:37+00:00,2017-10-02 18:19:36+00:00,,15,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# CS8 at UCSB
- Introduction to Python and Linux commands
- Test Driven Development
",['Yiluo-pHoton'],1,,0.84,0,,,,,,1,,,
141270151,MDEwOlJlcG9zaXRvcnkxNDEyNzAxNTE=,Biomedical-Segmentation-with-PyTorch,SleyAI/Biomedical-Segmentation-with-PyTorch,0,SleyAI,https://github.com/SleyAI/Biomedical-Segmentation-with-PyTorch,Biomedical Segmentation with PyTorch and different Convolutional Neural Network Architectures.,0,2018-07-17 09:58:20+00:00,2024-05-24 06:01:29+00:00,2023-05-22 09:48:57+00:00,,5513,18,18,Python,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,18,master,1,,"# Biomedical Segmentation with PyTorch

Pixel-wise segmentation for biomedical images using [Pytorch][Pytorch].
This project was part of my Bachelor Thesis.


### Dataset

[//]: # (Image References)

[images_and_masks]: etc/Images.png

![alt text][images_and_masks]


The code was tested on a biomedical breast cancer dataset which can't be provided due to data privacy.
A very similar dataset can be found at [bioimage.ucsb.edu](https://bioimage.ucsb.edu/research/bio-segmentation)
Note: The images have a different size than the images I'm using. The network achitecture (reshaping of tensors, padding after each convolution) needs to be tuned a little bit to work with the data.


### Architectures

I have implemented the following architecture:

- [x] [U-Net](https://arxiv.org/abs/1505.04597)


### Required packages

```
torch
torchvision
numpy
PIL
pydensecrf
```

The code is based on Python 3.6


### Folder Structure

        .
    ├── data                    # training dataset
    ├── val                     # validation set
    ├── checkpoints             # checkpoints to store the model

Data and Val folder needs to contain .txt files with filenames of the data. The ""create_txt"" script can be used to generate these.


### Usage

There are multiple parameters which can be used:

main.py
```
-e        # number of epochs to train
-l        # learning rate
-g        # use this parameter to utilize your GPU
-c        # load a pretrained model
```

predict.py
```
-m        # path to the pretrained model / checkpoint
-i        # input image to predict
-o        # filename of the output image
-c        # GPU support is enabled by default. Use this parameter to predict on CPU
```

There are some more parameters which can be useful.


### Evaluation

Further evaluation needs to be done in the future.
For now the net reached an Accuracy of 87% (Dice Coefficient of 0.87) on a small validation set.


### Some notes about hardware

I'm using a Nvidia GTX 1070 (8GB VRAM) to train the net. The highest memory usage I could observe was about 5,5GB.
The size of the images is 510x512 which will be downscaled to 255x256. Downscaling even further will lower the memory needed.

Training took about 1 1/2 hours.


[Pytorch]: http://pytorch.org
",['SleyAI'],0,,0.65,0,,,,,,2,,,
500276504,R_kgDOHdGdGA,California-Fire-Weather-Index-Calculations-Python,mariandob/California-Fire-Weather-Index-Calculations-Python,0,mariandob,https://github.com/mariandob/California-Fire-Weather-Index-Calculations-Python,"This python code was used to complete a homework assignment in Geog 288CJ during the Spring 2022 quarter at the University of California, Santa Barbara. In this code we compute and produce related plots for various fire weather indices for two model (WRF) gridpoints in the state of California (USA).",0,2022-06-06 03:17:04+00:00,2022-06-06 03:21:37+00:00,2022-06-06 07:17:39+00:00,,8151,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# California-Fire-Weather-Index-Calculations-Python
This python code was used to complete a homework assignment in Geog 288CJ during the Spring 2022 quarter at the University of California, Santa Barbara. In this code we compute and produce related plots for various fire weather indices for two model (WRF) gridpoints in the state of California (USA).

Here is a link to a Binder with the complete project notebook:
[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/mariandob/California-Fire-Weather-Index-Calculations-Python/HEAD)
",['mariandob'],1,,0.7,0,,,,,,1,,,
102910356,MDEwOlJlcG9zaXRvcnkxMDI5MTAzNTY=,ucsb-cs16-f17.github.io,ucsb-cs16-f17/ucsb-cs16-f17.github.io,0,ucsb-cs16-f17,https://github.com/ucsb-cs16-f17/ucsb-cs16-f17.github.io,Website for UCSB CS16 Fall 2017 (Matni),0,2017-09-08 22:42:22+00:00,2017-10-11 03:53:51+00:00,2017-12-08 02:14:07+00:00,https://ucsb-cs16-f17.github.io/,73567,0,0,HTML,1,1,1,1,1,0,1,0,0,1,mit,1,0,0,public,1,1,0,master,1,1,"# ucsb-cs16-f17.github.io

Website: http://ucsb-cs16-f17.github.io

To test locally:
* One time setup:
    * `git clone` the repo
    * Install rvm (the Ruby version manager)
    * Run `./setup.sh` to install correct ruby version, bundler version, and bundle the gems
* From then on, to test the site locally:
    * Run `./jekyll.sh
    * Point browser to localhost:4000
","['pconrad', 'ziadmatni']",1,,0.92,0,,,,,,0,,,
882033463,R_kgDONJLDNw,nicolelpepper,nicolelpepper/nicolelpepper,0,nicolelpepper,https://github.com/nicolelpepper/nicolelpepper,,0,2024-11-01 18:33:10+00:00,2024-11-21 04:44:16+00:00,2024-11-21 04:44:12+00:00,,13,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"## 👋 Hi there, I'm Nicole Pepper, an Environmental Data Scientist in training.

I'm a graduate student at University of California, Santa Barbara, pursuing a Master’s in Environmental Data Science (MEDS) at the Bren School. My passion lies in leveraging spatial and diverse datasets to tackle pressing environmental challenges and inspire meaningful action. When I'm not learning how to  wrangle data, you'll find me enjoying the great outdoors, especially in the mountains. Take a look around to learn more about my work and the impact I'm striving to make.


- 😄 Pronouns: she/her
- 📫 How to reach me: nicolelpepper@gmail.com


",['nicolelpepper'],1,,0.72,0,,,,,,1,,,
676855353,R_kgDOKFf-OQ,dl-fall-2023,fum-cs/dl-fall-2023,0,fum-cs,https://github.com/fum-cs/dl-fall-2023,Deep Learning Course,0,2023-08-10 07:01:13+00:00,2024-12-01 06:26:39+00:00,2024-12-01 06:26:35+00:00,https://fum-cs.github.io/dl-fall-2023/,7056,2,2,Jupyter Notebook,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,2,main,1,1,"---
layout: home
title: Deep Learning
nav_exclude: true
permalink: /:path/
seo:
  type: Course
  name: Just the Class
---

# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
",['mamintoosi'],0,,0.81,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
252290091,MDEwOlJlcG9zaXRvcnkyNTIyOTAwOTE=,AirPhotos,jonjab/AirPhotos,0,jonjab,https://github.com/jonjab/AirPhotos,Jupyter notebooks associated with UCSB Library partnership with Microsoft AI for Good.,0,2020-04-01 21:24:53+00:00,2023-06-06 00:50:40+00:00,2023-06-06 01:10:23+00:00,,137361,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,,"# Geolocating Aerial Photography

## Find North

The purpose of this Jupyter Notebook is to determine the orientation of two geo-located aerial photographs.  The main function is FindNorth.find_north().  It takes the location of two .tif image files, two tuples describing the lat and long of the centerpoints of those images, and a string (""SIFT"". ""ORB"", or ""BRISK"") which determines which feature descriptor is used to determine the location of keypoints in the input images.  Opencv-python 3.4.2.17 and opencv-contrib-python 3.4.2.17 or earlier are required to run the ""SIFT"" algorithm.

To run the demo script call the function with any two consecutive images found in demo/find_north/images/c-300/.  For images c-300_a-1.tif and c-300_a-2.tif the returned rotations to true north should be 11.33 degrees and 9.78 degrees respectively.


## Topo Compare

The purpose of this Jupyter Notebook is to geolocate images of unknown location using Topography Reconstruction.  This process involves using the COLMAP tool, which is available here: https://colmap.github.io/.

### Running the Demo:

Demonstration data is available under colmap_reconstructions/btm-1954.  The files in this repository can be entered into the TopoCompare.topo_compare() function as shown in the Demo section of the notebook.  Running this demonstration should only take a few minutes as it only searches a small portion of California.  Results (df_min) should be as follows:

          -   | x_pixels | y_pixels | min_value | rotation | best_fit_lat | best_fit_long |
       -------|----------|----------|-----------|----------|--------------|---------------|
       160148 |   141    |   208    |   707.67  |     3.18 |     34.66    |    -119.72    |

### Running Against New Data

1) First select approximately 72 overlapping images from the flight you wish to identify.  These images should be in a more or less rectangular pattern.

2) These images should be converted from .tif to .jpg format by using the TopoCompare.prep_photos() function.  Remove any border from the boundary of the image by specifying *_crop parameters.

3) Use COLMAP to reconstruct the 3-dimensional rendering of the images.  For our project we used COLMAP 3.6-dev.3, but a newer versin may be available now.  We selected Reconstruction > Automatic reconstruction, specified an appropriate work folder and the correct images folder, and left all other parameters as default.  This process took approximately 2 hours on a NVIDIA GTX 1070.

4) Export the points3D.txt file and images.txt file by selecting File > Export model as text.

**!!WARNING!!** This step will take approximately 6 hours to complete on a home desktop.  This time is mostly spent in the pixelwise search.  

5) Direct the mhnc, df_diff, df_min = TopoCompare.topo_compare() function to the correct images_loc and points_loc as just exported from the COLMAP reconstruction.  
- Specify the number of pics in the x direction and y direction. 
- Indicate the scale (i.e. a scale of 1:20000 would have scale = 20000).
- Enter state as ""California"" (the only supported state to search at this time).
- Enter the height and width (in inches) of the cropped images from step (2).
- Specify num_matches if desired (default is 15).
- Ensure that **demo == False**.  This will ensure that all of California is searched.

6) View df_min to see results.


## Pix2pix Generative Adversarial Network

The git repository is not large enough to store all of the training images needed to recreate the GAN models from our paper. However we have included a zipped repository of Jun-Yan Zhu one of the authors of the original pix2pix GAN paper, which is easier to use than Philip Isola’s repo. All the jupyter notebooks and scripts needed to train and test a pix2pix GAN is included in the zip. Recall that pix2pix is a conditional GAN and reqires paired input images, so the zip has a script to join training and target images into a single input file for the pix2pix. For our purposes we joined the aerial images and the matching satellite images. When joining images they need to be the same dimensions (same size, number of channels and, type), so some reformatting may need to be done. Two good options for reformatting images are the Pillow and GDAL packages; Pillow is standard with Anaconda installs and GDAL must be either pip or conda installed.  Some of our images were in unusual formats that Pillow could not open however GDAL was able to handle conversion of these files to more standard formats. To run the join script you will have to first make A and B directories each with train, test, and val sub directories. To make it easy, put the input images into the A folders and the target images into the B folders so that you can train in the AtoB direction.

The training script is capable of running on multiple GPU’s and batching images really helps to speed things up. Using checkpoints will allow you to resume training from your last checkpoint if interrupted. This can be very useful, especially when training cycle GANs as they take quite a bit longer than pix2pix GANs. The models are designed to be trained on either Nvidia GPUs or a CPU but, we have not tried training on CPUs. Even though the GANs were not useful for this project, they are facinating and are worth further investigation.

To recap: steps to train and test a pix2pix GAN

0) Run the requirements.txt file

1) Create directories A and B, each with subdirectories train, test and val

2) Put input images in the A directories and the target images in the B directories
- Names of the paired images in A and B must match
- Images in A and B must be same dimensions and file types

3) Run the combine_A_and_B.py script which will create new train, test and val directories with the paired training and testing images

4) Run the train.py script
- Make sure you are choosing the AtoB direction

5) Run the test.py script
- Generated images as well as the input and target images will all be in a new results directory

","['jfm888', 'pmeleney', 'gnunnelley']",1,,0.62,0,,,,,,1,,,
607798490,R_kgDOJDpE2g,ramirezmichaelp,ramirezmichaelp/ramirezmichaelp,0,ramirezmichaelp,https://github.com/ramirezmichaelp/ramirezmichaelp,Profile,0,2023-02-28 17:42:27+00:00,2023-03-14 03:49:50+00:00,2023-12-13 22:17:52+00:00,,14,1,1,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"

```yaml
# Github profile bio 
-ramirezmichaelp:

Name: Ramirez, Michael

Email: ramirezmichaelp@pm.me

HackerRank: ramirezmichaelp

Location: San Gabriel Valley, CA

Education:
          -University of California, Santa Barbara(UCSB)
                Bachelor of Science, Statistics and Data Science
                
Technical: 
          -Time Series
          -Regression
          -Model Selection
          -Bayesian Data Analysis
          -PCA
          -Anova
          -Exploratory Data Analysis
          -Data Cleaning
          -Story Telling
          
Hobbies:
        -Jiu Jitsu 
        -Sport Psychology
        -Welding and Machining
        -Mycology
        -UX
        
Coding Languages:
                 -R
                 -Python
                 -SAS
                 -Stan
                 -SQL/MySQL
                 
Short Story Publications:
          -Word Magazine
          -Santa Barbara Independent 

```







",['ramirezmichaelp'],1,,0.66,0,,,,,,1,,,
53810595,MDEwOlJlcG9zaXRvcnk1MzgxMDU5NQ==,cs56-github-kohsuke-grading-automation,ucsb-cs56-projects/cs56-github-kohsuke-grading-automation,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-github-kohsuke-grading-automation,-,0,2016-03-13 22:16:36+00:00,2016-09-25 00:53:25+00:00,2016-03-14 00:11:41+00:00,,2376,0,0,HTML,1,1,1,1,0,0,1,0,0,0,mit,1,0,0,public,1,0,0,master,1,1,"# cs56-github-kohsuke-grading-automation

A program that builds an abstraction layer on top of the Kohsuke GitHub library to facilitate the automation of grading for CMPSC 56, a lower division course at UCSB.

Authors:

1. Jonathan Easterman

## Kohsuke GitHub API
http://github-api.kohsuke.org/

Who? - Kohsuke Kawaguchi --> https://github.com/kohsuke

What? - A Java library that offers an object oriented approach to interacting with GitHub's API. Allows programmers to create applications that make API calls to GitHub.com and GitHub enterprise (e.g. github.ucsb.edu), without having to deal with the nitty gritty of HTTP requests. 

When? - Currently in development, current release (as of March 2016) is 1.73. This repo currently includes version 1.73 in the lib folder.

Where? - Check out the official website for examples, important info, and a link to the javadoc --> http://github-api.kohsuke.org/

Why? -- Because, why build a GitHub API from scratch when we can build on top of an already existing, robust library. Seriously, this library is great and fairly easy to use. Once you spend maybe an hour or two reading the javadoc and uncovering the relationships between certain objects, you will realize the potential of the Kohsuke API.

## Current status of this Repo (March 2016)
This repo currently employs a basic object-oriented style. There is an abstract class called Lab that all Labs hosted on github.ucsb.edu inherit from. There are three classes named Lab00, Lab02, Lab03 that are sub-classes of Lab. There is a class called GitHubUCSB that contains a main method for instantiating any one of the 3 above Labs, depending on user input. Finally, there is a class called GitHubAPI, which interacts with github.com and basically showcases the variety of objects defined in the Kohsuke API. It defines a bunch of methods for getting information about issues within a repo, and then also a main method that calls these methods.

## Suggestions for future authors
* Rename Lab to LabUCSB
  * Create a new abstract class with name Lab, and a new abstract class with name LabGit
  * Have LabUCSB and LabGit both inherit from Lab, then labs hosted on github.ucsb.edu would inherit from LabUCSB (i.e. 0 - 3), and labs hosted on github.com would inherit from LabGit
* Create a class for grading Lab01
* Make code in Lab00, Lab02, Lab03 DRYer.
  * There seems to be a lot of repetition in those classes that could be abstracted out to a method in LabUCSB
* Incorporate Bash scripting to programmatically run tests on labs.
  * i.e. use Java code to compile a list of addresses for repos that can be used as input to git clone <repo_address_here>
  * Pipe that list into a bash script that calls git clone on each repo name, runs a test suite, reports % of tests passed, then deletes the repo when finished

## Questions

If you have any questions please feel free to email me at jonathaneasterman@umail.ucsb.edu

",['jaeaster'],1,,0.84,0,,,,,,4,,,
519599388,R_kgDOHvh1HA,m22-ykk,ucsb-csw8/m22-ykk,0,ucsb-csw8,https://github.com/ucsb-csw8/m22-ykk,Summer 2022 (Session B),0,2022-07-30 19:05:41+00:00,2022-07-30 22:43:52+00:00,2022-09-08 05:31:23+00:00,https://ucsb-csw8.github.io/m22-ykk/,1651,0,0,Python,1,1,1,1,1,0,5,0,0,0,mit,1,0,0,public,5,0,0,master,1,1,"---
layout: home
title: Just the Class
nav_exclude: true
permalink: index.html
seo:
  type: Course
  name: Just the Class
---

# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
    - for CSW8, use the previous course repo to minimize the setup time: 
    - W22 ([github](https://github.com/ucsb-csw8/w22) / [web](https://ucsb-csw8.github.io/w22/)) 
    - S22 ([github](https://github.com/ucsb-csw8/s22) / [web](https://ucsb-csw8.github.io/s22/))
1. Update `_config.yml` and `index.md`/`README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.
    - `_config.yml`- update first - its contents are not auto-refreshed like the .md pages do. To see the changes to its contents, stop/restart Jekyll
    - `about.md` - make sure to update the Syllabus and course policies
    - `announcements.md` - skip, if not using the website Announcements
    - `calendar.md` - the information from this file is displayed at the top of the page that lists weekly topics and due dates;
        - if not using reflections, make sure to comment-out that part of the instructions. 
        - The Calendar is populated using the files in the `_modules` folder. These are added semi-automatically, using a script `generate_due_dates.py` that hard-codes start and end dates, etc.
    - `faq.md` - make sure to update the QnA based on your course information. After you update the Syllabus and the Calendar, make sure you address the typical first-week questions and clarify the `#weekly-pattern-and-planning-your-work` section
        - can be omitted if you are short on time or you'd rather answer these repeated questions yourself
    - `index.md` - the front page of the course; some of the info there, like the course title, come from the `_config.yml` file 
    - `jekyll.sh` - no need to change: run it as a shortcut for the `bundle` command
    - `quiz.md` - make sure to update the instructions based on your course quiz structure and policies
        - can be omitted if you are short on time or you'd rather answer these repeated questions yourself
    - `schedule.md` - the information for it is pulled from the `_schedules/weekly.md` --> make sure to update the latter - usually done via a script
        - use the two scripts in `_modules` to automatically generate the weekly modules on the Calendar
        - read the script documentation and the TODOs that are included inside the `.py` files
    - `staff.md` - the information for it is pulled from the `_staffers` and images are in the `assets/images` --> make sure to update them (see the `_example.md` to help you get started with a template; there is a `404.png` for anyone who doesn't want their picture included) 
    - `success.md` - make sure to change the **Roadmap** to align with your course calendar
        - can be omitted if you are short on time 

* For the `ref/` folder, I recommend initially comitting the `goals.md`, since it's referenced in the Syllabus and `keyboard.md` (+ `debug`?); the `ide` shows them how to install Python and is part of the FAQ; the rest of them can be added later, when they become relevant.
    * `data-structures` - a comparison table for strings, lists, tuples and namedtuples, dictionaries
    * `debug` - a good one to release initially as well - contains common errors and troubleshooting tips
    * `goals` - a list of CSW8 learning goals/objectives
    * `ide` - how to set up IDLE + common issues/warnings; include when covering functions/IDE/Gradescope
    * `index` - auto-generated index page for this Category
    * `keyboard` - common keyboard symbols and their names
    * `labtocode` - how to convert lab instructions to code; include when covering functions
* Initial commit should include the following files (if using announcements): `README.md _announcements _config.yml _includes/ _layouts/ _modules/ _sass/  _schedules _staffers about.md announcements.md assets/ calendar.md faq.md index.md jekyll.sh ref/goals.md ref/keyboard.md schedule.md staff.md success.md `
    * include `debug.md`?

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
","['ykharitonova', 'RRuschel', 'ShailjaShailja', 'apurvvarshney', 'saikumarysk']",1,,0.89,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
672438386,R_kgDOKBSYcg,justaclass,hyojoonkim/justaclass,0,hyojoonkim,https://github.com/hyojoonkim/justaclass,,0,2023-07-30 04:53:29+00:00,2023-07-30 04:53:33+00:00,2023-08-15 03:32:57+00:00,,441,0,0,SCSS,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"---
layout: home
title: Just the Class
nav_exclude: true
permalink: /:path/
seo:
  type: Course
  name: Just the Class
---

# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
",['hyojoonkim'],0,,0.79,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
316654195,MDEwOlJlcG9zaXRvcnkzMTY2NTQxOTU=,ucsb-grad-group-31,alxxgaynor/ucsb-grad-group-31,0,alxxgaynor,https://github.com/alxxgaynor/ucsb-grad-group-31,,0,2020-11-28 04:11:58+00:00,2020-12-01 16:43:50+00:00,2020-12-01 16:43:48+00:00,,4,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,# ucsb-grad-group-31,"['alxxgaynor', 'jcvdav', 'carlossimms']",1,,0.81,0,,,,,,2,,,
535900868,R_kgDOH_EyxA,f22,ucsb-cs156/f22,0,ucsb-cs156,https://github.com/ucsb-cs156/f22,,0,2022-09-13 00:39:09+00:00,2022-09-13 01:39:58+00:00,2022-12-02 17:58:31+00:00,https://ucsb-cs156.github.io/f22,19238,0,0,HTML,1,1,1,1,1,0,2,0,0,0,,1,0,0,public,2,0,0,main,1,1,"# F22

https://ucsb-cs156.github.io/f22/

Jekyll based website for UCSB CS156, Fall 2022

Website: <https://ucsb-cs156.github.io/f22/>

The theme currently being used can be find in the jekyll-theme value in `_config.yml`

To test locally:
* One time setup:
    * `git clone` the repo
    * Install rvm (the Ruby version manager)
    * Run `./setup.sh` to install correct ruby version, bundler version, and bundle the gems
* From then on, to test the site locally:
    * Run `./jekyll.sh
    * Point browser to <http://localhost:4000/f22/>

","['pconrad', 'andrewhlu', 'JacquelineMai', 'phtcon', 'scottpchow23', 'kheff16', 'mara-downing', 'ryan8xia', 'bzamora020', 'zsisco', 'meredithxu', 'btk5h', 'yinonrousso', 'oliviagillam', 'dependabot[bot]', 'benye11', 'azolyomi', 'WadeVaresio', 'mlroller', 'kperkins96', 'myuusubi', 'shudaniel', 'CalvinJenkins', 'pingyuanw']",1,,0.86,0,,,,,,0,,,
16676651,MDEwOlJlcG9zaXRvcnkxNjY3NjY1MQ==,cs56-games-minesweeper,ucsb-cs56-projects/cs56-games-minesweeper,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-games-minesweeper,-,0,2014-02-09 21:50:26+00:00,2018-03-21 00:58:22+00:00,2018-03-21 00:58:20+00:00,,42454,0,0,Java,1,1,1,1,0,0,10,0,0,34,mit,1,0,0,public,10,34,0,master,1,1,"cs56-games-minesweeper
======================


Migrated from: https://foo.cs.ucsb.edu/56mantis/view.php?id=0000900 by http://github.com/pconrad

Link to Javadoc: https://jrecinos98.github.io/cs56-games-minesweeper/javadoc/

Code prior to W14: https://foo.cs.ucsb.edu/cs56/issues/0000900/

project history
===============
```
W18 jrecinos98 | Mgla96 | M16 hwangaustin | ije896 | saisrimat | W16 Athielk 4pm | athielk | W14 | calebnelson | andrewberls 4pm | jgee67, davidacevedo | (pconrad) Minesweeper game
```


High-level description
======================

This is a program that runs the game minesweeper. Currently, the game itself is able to be played. The game can be played via GUI or through text, depending on the user's preference. There is a start menu, with seven buttons: new game (with three separate difficulties), help, load, leaderboard, and quit. Selecting new game will start a new game. Selecting help will bring the user to a page with instructions of how to play. Leaderboard will bring the user to the leaderboard containing top 10 scores for each difficulty. Quit exits the program. During a game, the user can choose reset game, exit minesweeper, or main menu the in-game toolbar at the top of the game. Once the game is over, the user gets a message indicating whether he/she won or lost. The user can then choose an option from the toolbar to continue with their game.

Developer Notes/Documentation
=============================

The end game message is currently a JLabel located in StartMenu.java. The variable name for this label is status. To change the text in this label, there is a method in StartMenu.java called setLabel(string s).

StartMenu is a class that creates a menu that the user can see and pick an option. It also initializes the game on call.

Grid is a class that is the foundation for minesweeper, applies mine locations, checks if something is open, makes flags functional, etc.

HelpScreen.java is a panel that displays help messages and a button to return to the start menu. It is displayed only after the user clicks ""Help"" from either the start menu or the pause menu.

MineComponent is a class that sets up the minesweeper Gui, ie. sets up the grid with numbered buttons.

DBConnector is a class that allows the leaderboard to access the database holding high scores or users.

How to Run
==========

First set up your environment variables to connect to your postgrsql database then:

* To run the GuiGame, use ""ant mine"".
* To run the TextGame, use ""ant textmine"".

![Alt Text](https://media.giphy.com/media/5z24YknBcpkmlNqyEk/giphy.gif)

W18 Final Remarks
=================
The underlying logic of the game has been rewritten and optimized for better performance.
The GUI game is completely redone and refactored so now it runs much smoother as well as looks much cleaner and visually pleasing.
The grid cells resemble traditional minesweeper with similar aesthetics and colors. Furthermore we added the traditional minesweeper smiley with a fresh and updated emoji look.

To gain a better understanding of the code I would recommend you look at Grid.java and GameFrame.java first. 
This is where most of the mechanics of the game are held. Make sure to understand the underlying code for how the cells in the grid are selected to be visible.
PathFinder class would be a good place to start to understand the logic.

We would suggest that the next group starts with fixing the over cluttered main menu frame to get a 
a better understanding of how the frames interact with one another. Also there still isn't 100% test coverage so that would be a great way to understand 
how the code works at the same time as tackling an important issue. Only Grid.java has working JUnit tests at the moment, the tests for the GUI 
are broken and require fixing.

F17 Final Remarks
=================

The text game is completely redone and refactored.
There is now a leaderboard display for both versions of the game.
Added images to the GUI version of the game.
There isn't 100% test coverage so that might be good starting block for you to understand how the code works.
One thing that might be benefitial to refactor is the ButtonListener inner class in the GameFrame.

The more complicated part of the code is the database. To the connect to a database do the following steps:
1. Create an account on Heroku
2. Create a new server instance
3. Go to add-ons and search for ""Postgres Heroku""
4. Once you add the database to your app click on it and go to view your database credentials
5. copy sample.env.sh into a new file in the scripts folder called env.sh and replace the filler in it with your database credentials
6. call ```source scripts/env.sh``` from the root directory (this will need to be done on every new shell)

In the future, this process will hopefully be replaced by a server, where the server will handle the environment variables rather than the client

W16 Final Remarks
=================
The coding style was not what I was accustom to so when I was reading through the code, I tabbed and rearranged stuff just so I could read it, however I didn't do that for all the code so beware there are atleast 2 styles here.   

M16 Final Remarks
=================
Depending on the issue being addressed, it was helpful to identify which classes needed changes (adding/removing features). There are a handful of files (some that deal with GUI, another that sets up and modifies the grid/map, etc.) so reading through the code multiple times line by line while running the program will help you to understand what each part of the code is doing and how it needs to be changed to accomodate the issue. Possible features to be added along with potential bugs are listed in the ""Issues"" of the master repo, these include but are not limited to (#30)adding a highscore feature and (#34)exposing all mines on the display when the player loses.

F16 Final Remarks
=================
At first there is a lot going on and hard to understand, Recommend looking at Grid.java and MineComponent.java first. Would be a good idea to refactor code and split up into more than three classes. 

Know that:
1. Grid is the 2D array that holds ONLY mines.
2. Map is the 2D array that holds what the user puts down (whether an entry has been ""opened"" aka clicked on by the user, whether an entry is a flag, etc...)
3. Thus grid and Map interactions make up the game.

The way that the code is written is kind of messy because the naming of the variables is inconsistent from file to file. The functions are scattered. So refactoring would be good. Also remove the commented out code if it doesn't help you. 
","['jrecinos98', 'lar-ryan-nick', 'redbeanblackbean', 'davidacevedo', 'athielk', 'pconrad', 'johnnyzhang295', 'ajhhwang', 'kperkins96', 'calebnelson', 'Mgla96', 'CDLlo', 'jimmylle', 'kjorg50', 'mcaccamo', 'mliou', 'jaeaster', 'hannavigil', 'mastergberry']",1,,0.9,0,,,,,,4,,,
125828408,MDEwOlJlcG9zaXRvcnkxMjU4Mjg0MDg=,Render-Denoise-Paper,StanwieCB/Render-Denoise-Paper,0,StanwieCB,https://github.com/StanwieCB/Render-Denoise-Paper,awesome render denoise paper,0,2018-03-19 08:51:48+00:00,2023-06-06 12:37:25+00:00,2018-05-12 03:21:17+00:00,,4,15,15,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,15,master,1,,"# Paper List 2011 - Present

## 1 Denoising
2015 Recent Advances in Adaptive Sampling and Reconstruction for Monte Carlo Rendering

2015 Denoising Your Monte Carlo Renders: Recent Advances in Image Space-Adaptive Sampling and Reconstruction (course)
http://cgg.unibe.ch/publications/denoising-your-monte-carlo-renders

### 1.1 Filters using Auxiliary Features
2011 On Filtering the Noise from the Random Parameters in Monte Carlo Rendering

2011 Temporal Light Field Reconstruction for Rendering Distribution Effects
http://groups.csail.mit.edu/graphics/tlfr/ (code available)

2012 Reconstructing the Indirect Light Field for Global Illumination.pdf
http://groups.csail.mit.edu/graphics/ilfr/ (code available)

2012 Robust Image Denoising using a Virtual Flash Image for Monte Carlo Ray Tracing
http://sglab.kaist.ac.kr/VFL/ (code available)

2012 SURE-based Optimization for Adaptive Sampling and Reconstruction
http://www.cmlab.csie.ntu.edu.tw/project/sbf/ (code available)

2013 Robust Denoising using Feature and Color Information
http://cgg.unibe.ch/publications/robust-denoising-using-feature-and-color-information
(code e-mail to zwicker@inf.unibe.ch)

2014 Progressive Image Denoising
http://cgg.unibe.ch/publications/progressive-image-denoising

2016 Texture Space Caching and Reconstruction for Ray Tracing
https://software.intel.com/en-us/articles/texture-space-caching-and-reconstruction-for-ray-tracing (code available)

2016 Nonlinearly Weighted First-order Regression for Denoising Monte Carlo Renderings
https://benedikt-bitterli.me/nfor/

2018 Adaptive rendering based on robust principal component analysis

### 1.2 Image Space Denoising Filters
2012 Adaptive Rendering with Non-Local Means Filtering

2013 Removing the Noise in Monte Carlo Rendering with General Image Denoising Algorithms
http://www.ece.ucsb.edu/~psen/PaperPages/removing_MC_noise.html (code available)

2014 Boosting Monte Carlo Rendering by Ray Histogram Fusion

2016 Adaptive Polynomial Rendering
https://www.disneyresearch.com/publication/adaptive-polynomial-rendering/

2017 Low-Rank Matrix Completion to Reconstruct Incomplete Rendering Images

## 2 NN method
2015 A Machine Learning Approach for Filtering Monte Carlo Noise
http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2015_LBF/ (everything available)

2016 Neural Network Ambient Occlusion
http://theorangeduck.com/page/neural-network-ambient-occlusion

2017 Deep Shading: Convolutional Neural Networks for Screen Space Shading
http://deep-shading-datasets.mpi-inf.mpg.de/ (caffe/dataset)

2017 Interactive Reconstruction of Monte Carlo Image Sequences using a Recurrent Denoising Autoencoder
http://research.nvidia.com/publication/interactive-reconstruction-monte-carlo-image-sequences-using-recurrent-denoising

2017 High-Quality Hyperspectral Reconstruction Using a Spectral Prior
http://vclab.kaist.ac.kr/siggraphasia2017p1/index.html (everything)

2017 Kernel-Predicting Convolutional Networks for Denoising Monte Carlo Renderings
http://cvc.ucsb.edu/graphics/Papers/SIGGRAPH2017_KPCN/

2017 Beyond a Gaussian Denoiser Residual Learning of Deep CNN for Image Denoising
https://github.com/cszn/DnCNN

## 3 Evaluation
2017 Analysis of reported error in Monte Carlo rendered images

## 4 CV detail preservation
2016 Deep Edge Guided Recurrent Residual Learning for Image Super-Resolution 
http://www.icst.pku.edu.cn/struct/Projects/DEGREE.html

2016 Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network 
https://github.com/tensorlayer/srgan

2017 EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis
https://github.com/kkkzm2017/Enhancenet
https://webdav.tue.mpg.de/pixel/enhancenet/",['StanwieCB'],0,,0.7,0,,,,,,0,,,
697064947,R_kgDOKYxd8w,LM-Watermark,meiling-fdu/LM-Watermark,0,meiling-fdu,https://github.com/meiling-fdu/LM-Watermark,Survey of watermarking for (large) language models,0,2023-09-27 01:34:24+00:00,2025-02-17 01:32:35+00:00,2023-10-23 03:44:30+00:00,,38,5,5,,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,5,main,1,,"# LM-Watermark
Survey of watermarking for (large) language models

---

## White-Box Watermark

- 2021 **Protect, show, attend and tell- Empowering image captioning models with ownership protection** (Jian Han Lim) Universiti Malaya
  - paper: https://www.sciencedirect.com/science/article/pii/S0031320321004659 (Pattern Recognition 2021) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133977706)
  - code: https://github.com/jianhanlim/ipr-imagecaptioning

- 2022 **An Embarrassingly Simple Approach for Intellectual Property Rights Protection on Recurrent Neural Networks** (Zhi Qin Tan) Universiti Malaya
  - paper: https://aclanthology.org/2022.aacl-main.8.pdf (AACL-IJCNLP 2022)
  - code: https://github.com/zhiqin1998/RecurrentIPR
  
- 2023 **An Effective Framework for Intellectual Property Protection of NLG Models** (Mingjie Li) Shanghai University
  - paper: https://www.mdpi.com/2073-8994/15/6/1287 (Symmetry 2023)
  - code: 

## Black-Box Watermark

### NLU

- 2021 **Robust Black-box Watermarking for Deep Neural Network using Inverse Document Frequency** (Mohammad Mehdi Yadollahi) University of New Brunswick
  - paper: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9730156 (DASC-PICom-CBDCom-CyberSciTech 2021) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133846246)
  - code:

- 2022 **TextBack: Watermarking Text Classifiers using Backdooring** (Nandish Chattopadhyay) Nandish Chattopadhyay
  - paper: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9996658 (25th Euromicro Conference on Digital System Design 2022) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133889992)
  - code:

- 2023 **PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models** ([Peixuan Li](https://solour-lfq.github.io/)) Shanghai Jiao Tong University 
  - paper: https://ojs.aaai.org/index.php/AAAI/article/view/26750 (AAAI 2023) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133929482)
  - code:  

- 2023 **Are You Copying My Model? Protecting the Copyright of Large Language Models for EaaS via Backdoor Watermark** (Peng) USTC
  - paper: https://aclanthology.org/2023.acl-long.423.pdf (ACL 2023)
  - code:

### NLG

- 2023 **GPTs Don’t Keep Secrets: Searching for Backdoor Watermark Triggers in Autoregressive Language Models** (Evan Lucas) Michigan Technological University
  - paper: https://aclanthology.org/2023.trustnlp-1.21.pdf (TrustNLP 2023) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133912304)
  - code: https://github.com/evan-person/findingBackdoorWatermarks


## Non-Box Watermark

### Decoding-Based

- 2023 **A Watermark for Large Language Models** (John Kirchenbauer) University of Maryland
  - paper: https://proceedings.mlr.press/v202/kirchenbauer23a/kirchenbauer23a.pdf (ICML 2023)
  - code: https://github.com/jwkirchenbauer/lm-watermarking

- 2023 **Provable Robust Watermarking for AI-Generated Text** (Xuandong Zhao) UC Santa Barbara
  - paper: https://openreview.net/pdf?id=Bwz0fy9Hc9 (ICML Workshop 2023)
  - code: https://github.com/XuandongZhao/GPTWatermark

### Editing-Based

- 2011 **Watermarking the Outputs of Structured Prediction with an Application in Statistical Machine Translation** （Ashish Venugopal）Google
  - paper: https://aclanthology.org/D11-1126.pdf (EMNLP 2011) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133851863)
  - code: 

- 2022 **Distillation-Resistant Watermarking for Model Protection in NLP** (Xuandong Zhao) UC Santa Barbara
  - paper: https://aclanthology.org/2022.findings-emnlp.370.pdf (EMNLP Findings 2022)
  - code: https://github.com/XuandongZhao/DRW

- 2022 **Protecting Intellectual Property of Language Generation APIs with Lexical Watermark** (Xuanli He) Monash University
  - paper: https://ojs.aaai.org/index.php/AAAI/article/view/21321 (AAAI 2022) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133878949)
  - code: https://github.com/xlhex/NLG_api_watermark

- 2022 **CATER: Intellectual Property Protection on Text Generation APIs via Conditional Watermarks** (Xuanli He) University College London
  - paper: https://openreview.net/pdf?id=L7P3IvsoUXY (NeurIPS 2022) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133946267)
  - code: https://github.com/xlhex/cater_neurips

- 2023 **Protecting Language Generation Models via Invisible Watermarking** (Xuandong Zhao) UC Santa Barbara
  - paper: http://proceedings.mlr.press/v202/zhao23i/zhao23i.pdf (ICML 2023)
  - code: https://github.com/XuandongZhao/Ginsew

- 2023 **A novel watermarking framework for intellectual property protection of NLG APIs** (Mingjie Li) Shanghai University
  - paper: https://www.sciencedirect.com/science/article/pii/S0925231223008238 (NeuroComputing 2023) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133893004)
  - code:

- 2023 **COSYWA: Enhancing Semantic Integrity in Watermarking Natural Language Generation** (Junjie Fang) Xiamen University
  - paper: https://dl.acm.org/doi/abs/10.1007/978-3-031-44693-1_55 (NLPCC 2023) [Crack it in Chinese](https://blog.csdn.net/qq_36332660/article/details/133972765)
  - code:
  

---

## arXiv

- 20221118 **DeepHider: A Covert NLP Watermarking Framework Based on Multi-task Learning** (Dai) Hainan University
  - paper: https://arxiv.org/ftp/arxiv/papers/2208/2208.04676.pdf (arXiv)
  - code: 

- 20230210 **Watermarking Pre-trained Language Models with Backdooring** (Chenxi Gu) Fudan University
  - paper: https://arxiv.org/pdf/2210.07543.pdf (arXiv)
  - code:

- 20230309 **DeepTextMark: Deep Learning based Text Watermarking for Detection of Large Language Model Generated Text** (Travis Munyer) University of Nebraska Omaha
  - paper: https://arxiv.org/pdf/2305.05773.pdf （arXiv）
  - code:

- 20230514 **Watermarking Text Generated by Black-Box Language Models** (Yang) USTC
  - paper: https://arxiv.org/pdf/2305.08883.pdf (arXiv)
  - code: https://github.com/Kiode/Text_Watermark_Language_Models

- 20230522 **Watermarking Text Data on Large Language Models for Dataset Copyright Protection** (Liu) Lehigh University
  - paper: https://arxiv.org/pdf/2305.13257.pdf
  - code: 

- 20230524 **Who Wrote this Code? Watermarking for Code Generation** (Taehyun Lee) Seoul National University
  - paper: https://arxiv.org/pdf/2305.15060.pdf (arXiv)
  - code: 

- 20230525 **Undetectable Watermarks for Language Models** (Miranda Christ) Columbia University
  - paper: https://arxiv.org/pdf/2306.09194.pdf (arXiv)
  - code: 

- 20230529 **Baselines for Identifying Watermarked Large Language Models** (Leonard Tang) Harvard University
  - paper: https://arxiv.org/pdf/2305.18456.pdf (arXiv)
  - code: 

- 20230630 **On the Reliability of Watermarks for Large Language  Models** (John Kirchenbauer) University of Maryland
  - paper: https://arxiv.org/pdf/2306.04634.pdf (arXiv)
  - code: https://github.com/jwkirchenbauer/lm-watermarking

- 20230725 **Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy** (Fu) University of California, Riverside
  - paper: https://arxiv.org/pdf/2307.13808.pdf (arXiv)
  - code: 

- 20320726 **Three Bricks to Consolidate Watermarks for Large Language Models** ([Pierre Fernandez](https://pierrefdz.github.io/)) Centre Inria de l’Universite de Rennes
  - paper: https://pierrefdz.github.io/assets/publis/threebricks/paper.pdf (arXiv)
  - code: 

- 20230728 **Robust Distortion-free Watermarks for Language Models** (Rohith Kuditipudi) Stanford University
  - paper: https://arxiv.org/pdf/2307.15593.pdf (arXiv)
  - code: https://github.com/jthickstun/watermark

- 20230729 **Towards Codable Text Watermarking for Large Language Models** (Liang) WeChat AI,
  - paper: https://arxiv.org/pdf/2307.15992.pdf (arXiv)
  - code: https://github.com/lancopku/codable-watermarking-for-llm

- 20230801 **Advancing Beyond Identification- Multi-bit Watermark for Language Models** (Yoo) Seoul National University
  - paper: http://arxiv.org/pdf/2308.00221 (arXiv)
  - code: 

- 20230802 **A Private Watermark for Large Language Models** (Liu) Tsinghua University
  - paper: https://arxiv.org/pdf/2307.16230.pdf (arXiv)
  - code: https://github.com/THU-BPM/private_watermark

- 20230822 **Evading Watermark based Detection of AI-Generated Content** (Jiang) Duke University
  - paper: https://arxiv.org/pdf/2305.03807.pdf (arXiv)
  - code: https://github.com/zhengyuan-jiang/WEvade 
",['meiling-fdu'],0,,0.71,0,,,,,,0,,,
943571602,R_kgDOOD3Ckg,shiny_sierra_climate_diversity_or_ts_ct,charliethrift/shiny_sierra_climate_diversity_or_ts_ct,0,charliethrift,https://github.com/charliethrift/shiny_sierra_climate_diversity_or_ts_ct,Shiny app exploring climate and biodiversity at the Sierra Nevada Aquatic Research Laboratory (SNARL),0,2025-03-05 23:28:50+00:00,2025-03-05 23:40:21+00:00,2025-03-05 23:40:18+00:00,,5,0,0,R,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# SNARL Diversity
## Shiny app exploring climate and biodiversity at the Sierra Nevada Aquatic Research Laboratory (SNARL)

Authors:  Olivia Ross<sup>1</sup>, Tanvi Shah<sup>1</sup>, and [Charles Thrift<sup>2</sup>](https://orcid.org/0000-0002-4257-6951)

Affiliations: <sup>1</sup>Bren School of Environmental Science & Management, University of California Santa Barbara. <sup>2</sup>Ecology, Evolution, and Marine Biology, University of California Santa Barbara. 

Description: Tool for visualizing the climate, fire history, and biodiversity of flora and fauna at the Sierra Natural Aquatic Research Laboratory (SNARL) in Mammoth Lakes, California
",['charliethrift'],1,,0.83,0,,,,,,1,,,
196315556,MDEwOlJlcG9zaXRvcnkxOTYzMTU1NTY=,hw4,Badri-narayan/hw4,0,Badri-narayan,https://github.com/Badri-narayan/hw4,some assignments from my cs24 data structures class at UCSB,0,2019-07-11 03:46:23+00:00,2019-07-11 03:51:14+00:00,2019-07-11 03:51:12+00:00,,7,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['Badri-narayan'],1,,0.67,0,,,,,,0,,,
438041796,R_kgDOGhv8xA,BIOL456-549,syngnathid/BIOL456-549,0,syngnathid,https://github.com/syngnathid/BIOL456-549,Course Website for Computer Skills for Biologists (BIOL 456/549),0,2021-12-13 22:19:03+00:00,2022-03-01 15:19:48+00:00,2022-03-03 19:27:06+00:00,,6355,0,0,JavaScript,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a set of customizations on top of the popular [Just the Docs](https://github.com/pmarsceill/just-the-docs) theme, which provides a robust and thoroughly-tested foundation that makes it easy to extend for your own special use cases. These foundational features include:

- automatic [navigation structure](https://pmarsceill.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://pmarsceill.github.io/just-the-docs/docs/search/) and page indexing,
- and a small but powerful set of [UI components](https://pmarsceill.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://pmarsceill.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `index.md` with your course information.
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add your content.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([DS1](https://ucsb-ds.github.io/ds1-f20/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). For a few open-source examples, see the following course websites and their source code.

- [CSE 390HA](https://courses.cs.washington.edu/courses/cse390ha/20au/) ([source code](https://gitlab.cs.washington.edu/cse390ha/20au/website)) is an example of a single-page website that centers modules.
- [CSE 143](https://courses.cs.washington.edu/courses/cse143/20au/) ([source code](https://gitlab.cs.washington.edu/cse143/20au/website)) hosts an entire online textbook with full-text search.
- [CSE 373](https://courses.cs.washington.edu/courses/cse373/21su/) ([source code](https://gitlab.cs.washington.edu/cse373-root/21su/website)) is an example of a simple website combining Markdown pages with generated HTML files.

Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

Continue reading to learn how to setup a development environment on your local computer. This allows you to make incremental changes without directly modifying the live website.

### Local development environment

Just the Class is built for [Jekyll](https://jekyllrb.com), a static site generator. View the [quick start guide](https://jekyllrb.com/docs/) for more information. Just the Docs requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler.

1. Follow the GitHub documentation for [Setting up your GitHub Pages site locally with Jekyll](https://help.github.com/en/articles/setting-up-your-github-pages-site-locally-with-jekyll).
1. Start your local Jekyll server.
```bash
$ bundle exec jekyll serve
```
1. Point your web browser to [http://localhost:4000](http://localhost:4000)
1. Reload your web browser after making a change to preview its effect.

For more information, refer to [Just the Docs](https://pmarsceill.github.io/just-the-docs/).
",['syngnathid'],0,,0.75,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
163599542,MDEwOlJlcG9zaXRvcnkxNjM1OTk1NDI=,ucsb-cs111.github.io,ucsb-cs111/ucsb-cs111.github.io,0,ucsb-cs111,https://github.com/ucsb-cs111/ucsb-cs111.github.io,Website: https://ucsb-cs111.github.io,0,2018-12-30 16:00:27+00:00,2020-01-03 19:53:05+00:00,2022-10-06 03:31:24+00:00,,138,0,0,Ruby,1,1,1,1,1,0,0,0,0,4,,1,0,0,public,0,4,0,master,1,1,"# ucsb-cs111.github.io
Website: https://ucsb-cs111.github.io
","['pconrad', 'johnrgilbert']",1,,0.84,0,,,,,,0,,,
564473944,R_kgDOIaUwWA,EDS220_Fall2022_HW2,samanthastevenson/EDS220_Fall2022_HW2,0,samanthastevenson,https://github.com/samanthastevenson/EDS220_Fall2022_HW2,,0,2022-11-10 19:51:39+00:00,2022-11-10 19:58:20+00:00,2022-11-10 19:56:45+00:00,,9,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,1,0,public,0,0,0,main,1,,"# EDS220_Fall2022_HW2
### Information needed for HW2 and final project for EDS 220, Fall 2022

This repository contains useful template information for working on assignments for EDS 220 Working With Environmental Data at UC Santa Barbara (Fall 2021 quarter). 

Contents:
- HW2_template.ipynb: Template Jupyter notebook for use in Homework 2 and final project
- environment.yml: Template environment file for use in creating Binder environment for running Jupyter notebook

Information for Homework 2:
- Due date = **Friday, November 18**
- Deliverables:
   - Jupyter notebook template - complete sections through ""Metadata and Basic Visualization""
   - Any necessary data or supporting files included in the repo
   - README file edited to be appropriate for your project


Information for final project:
- Presentation dates: **Nov 29; Dec 1**
- Final writeup hand-in date: **Dec 5**
- Deliverables (for in-class presentation):
  - Jupyter notebook - all sections completed, initial sections edited to reflect grade feedback
  - Binder environment compiled to allow others to run code easily
  - Group-led presentation on assigned date

- Deliverables (for final writeup):
  - Jupyter notebook, supporting data files, Binder environment, and README in repo
  - Edits reflecting student and instructor feedback can be made until due date
",['samanthastevenson'],1,,0.71,0,,,,,,1,,,
698402533,R_kgDOKaDG5Q,UCSB_CS190I,Seanjie250/UCSB_CS190I,0,Seanjie250,https://github.com/Seanjie250/UCSB_CS190I,,0,2023-09-29 20:47:10+00:00,2023-09-29 20:51:16+00:00,2023-10-14 21:56:10+00:00,,153,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['Seanjie250'],1,,0.73,0,,,,,,1,,,
223463001,MDEwOlJlcG9zaXRvcnkyMjM0NjMwMDE=,fisheries-behavior-change,emlab-ucsb/fisheries-behavior-change,0,emlab-ucsb,https://github.com/emlab-ucsb/fisheries-behavior-change,"All code and data for the manuscript ""Catalyzing sustainable fisheries management through behavior change interventions""",0,2019-11-22 18:33:33+00:00,2024-10-04 12:04:48+00:00,2020-05-04 18:32:11+00:00,,14900,1,1,R,1,1,1,1,0,0,3,0,0,0,,1,0,0,public,3,0,1,master,1,1,"# fisheries-behavior-change
This repository contains the code and data for reproducing McDonald, *et al.* 2019 (Conservation Biology): ""Catalyzing sustainable fisheries management through behavior change interventions"" (https://doi.org/10.1111/cobi.13475).

The DOI for this code and data repository is managed through Zenodo with DOI number 10.5281/zenodo.3635980 (https://doi.org/10.5281/zenodo.3635980).

> **Title**: Catalyzing sustainable fisheries management though behavior change interventions

> **Authors**: Gavin McDonald, Molly Wilson, Diogo Veríssimo, Rebecca Twohey, Michaela Clemence, Dean Apistar, Stephen Box, Paul Butler, Fel Cesar Cadiz, Stuart J. Campbell, Courtney Cox, Micah Effron, Steve Gaines, Raymond Jakub, Roquelito H. Mancao, Pablo T. Rojas, Rocky Sanchez Tirona, Gabriel Vianna


> **Abstract:** Small-scale fisheries are an important livelihood and primary protein source for coastal communities in many of the poorest regions in the world, yet many suffer from overfishing, requiring effective and scalable management solutions. Positive ecological and socioeconomic responses to management typically lag behind immediate costs borne by fishers from fishing pressure reductions necessary for fisheries recovery. These short-term costs challenge the long-term success of these interventions. However, social marketing may increase perceptions of management benefits before ecological and socioeconomic benefits are fully realized, driving new social norms and ultimately long-term sustainable behavior change. Using ecological surveys and community-perceived measures of management support and socioeconomic conditions, we assess the impact of a standardized small-scale fisheries management intervention that was implemented across 41 sites in Brazil, Indonesia, and the Philippines. The intervention combines TURF-reserves (community-based Territorial Use Rights for Fishing coupled with no-take marine reserves) with locally-tailored social marketing behavior change campaigns. Leveraging data across diverse indicators, our results suggest that communities were developing new social norms and fishing more sustainably, even before long- term ecological and socioeconomic benefits of fisheries management had materialized. 

## Repository structure  

```
fisheries-behavior-change 
  |__ data
  |__ output_figures
  |__ r
  |__ output_tables
```

## Software

This analysis was performed in R. The script for fully reproducing the paper analysis can be found in `r/analysis.R`.

## Data

The `data` folder contains four input data files, with full metadata given below:  

* `monitoring_data.csv`: All monitoring data for sites from the Community Support, Sustainable Fishing Practices, Sustainable Ecosystems, or Sustainable Livelihoods impact surveys   
* `site_data.csv`: Descriptive demographics and statistics for each site  
* `survey_question_lookup.csv`: A lookup table that matches specific socioeconomic survey questions from each site to specific indicators     
* `phils_matching_data.csv`: Site attribute scores used for control site selection for the 3 sets of matched impact / control sites for the Philippines sustainable ecosystems and sustainable livelihoods survey  

### `monitoring_data.csv`

Each row contains an individual monitoring observation, with the following schema:

* `country`: Country (Brazil, Indonesia, or Philippines)  
* `site`: 6-letter site code 
* `survey`: Survey (Community Support, Sustainable Fishing Practices, Sustainable Ecosystem, or Sustainable Livelihoods)  
* `before_after`: Binary for before (0) or after (1) the intervention  
* `control_impact`: Binary for control (0) or impact (1) site 
* `replicate`: Replicate for analysis (anonymized indivudal for Community Support, Sustainable Fishing Practices, and Sustainable Livelihoods surveys, and dive site location for Sustainable Ecosystems surveys)  
* `indicator_full`: Full indicator name, breaking community support and sustainable fishing practices indicators out across 6 different behavior changes (Licensing; Catch Reporting; Enforcement; NTZ Compliance; TURF Compliance; Management Participation)  
* `indicator_condensed`: Condensed indicator name, aggregating together community support and sustainable fishing practices indicators across 6 different behavior changes 

### `site_data.csv`  

Each row contains descriptive statistics and demographics for a single site, with the following schema:  

* `country`: Country (Brazil, Indonesia, or Philippines)  
* `site`: 6-letter site code 
* `lat`: Latitude for centroid of site
* `lon`: Longitude for centroid of site
* `site_type`: One of either ""Intervention"" or ""Control""
* `fishers_ff_target_communities`: Number of fishers in Fish Forever target communities  
* `area_current_turfs_ha`: Area of TURFs, as of 2017  
* `area_current_reserves_ha`: Area of reserves (NTZs), as of 2017 


### `survey_question_lookup.csv`

Each row contains the exact survey question that was asked at a particular site, and which survey and indicator the question corresponds to, with the following schema:

* `country`: Country (Brazil, Indonesia, or Philippines)  
* `site_code`: 6-letter site code 
* `survey`: Survey (Community Support, Sustainable Fishing Practices, Sustainable Ecosystem, or Sustainable Livelihoods)  
* `indicator_full`: Full indicator name, breaking community support and sustainable fishing practices indicators out across 6 different behavior changes (Licensing; Catch Reporting; Enforcement; NTZ Compliance; TURF Compliance; Management Participation)  
* `indicator_condensed`: Condensed indicator name, aggregating together community support and sustainable fishing practices indicators across 6 different behavior changes 
* `full_question`: Full survey question, as presented to the survey participant   
* `survey_question_code`: Cleaned version of `full_question` that removes spaces, capital letters, and special characters  
* `response_options`Full survey response options, as presented to the survey participant  

### `phils_matching_data.csv`

Each row contains the attribute score used for base characteristics used during the control site selection for the Philippines sustainable ecosystems and sustainable livelihoods survey, with the following schema:

* `site`: 6-letter site code 
* `control_impact`: Binary for control (0) or impact (1) site 
* `country`: Country (Philippines)  
* `survey`: Survey (Sustainable Ecosystem or Sustainable Livelihoods)  
* `baseline_characteristic`: Name of baseline characteristic  
* `value`: Attribute score (ranked 1 to 5)  

## License

The software code contained within this repository is made available under the [MIT license](http://opensource.org/licenses/mit-license.php). The data and figures are made available under the [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.

**Please note:** To ensure reproducibility and in order to manage package dependencies, we use the `renv` package. When you first clone this repo onto your machine, run `renv::restore()` to ensure you have all correct package versions installed in the project. Please see the `renv` page for more information: https://rstudio.github.io/renv/articles/renv.html.",['gmcdonald-sfg'],1,,0.79,0,,,,,,3,,,
189624637,MDEwOlJlcG9zaXRvcnkxODk2MjQ2Mzc=,2019-summer,UCSBCarpentry/2019-summer,0,UCSBCarpentry,https://github.com/UCSBCarpentry/2019-summer,Summer offerings for UCSB Carpentry,0,2019-05-31 16:20:42+00:00,2024-07-13 00:03:04+00:00,2024-07-13 00:03:01+00:00,https://ucsbcarpentry.github.io/2019-summer/,42,0,0,CSS,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,gh-pages,1,1,"# 2019-summer
Summer offerings for UCSB Carpentry
","['sharonwsolis', 'ilessing', 'josenino95']",1,,0.88,0,,,,,,13,,,
397340581,MDEwOlJlcG9zaXRvcnkzOTczNDA1ODE=,Wang234ucsb,Wang234ucsb/Wang234ucsb,0,Wang234ucsb,https://github.com/Wang234ucsb/Wang234ucsb,Config files for my GitHub profile.,0,2021-08-17 17:32:27+00:00,2021-08-17 17:32:27+00:00,2021-08-17 17:32:28+00:00,https://github.com/Wang234ucsb,0,0,0,,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,[],-1,,0.79,0,,,,,,1,,,
392530486,MDEwOlJlcG9zaXRvcnkzOTI1MzA0ODY=,abarriosvasquez,abarriosvasquez/abarriosvasquez,0,abarriosvasquez,https://github.com/abarriosvasquez/abarriosvasquez,Config files for my GitHub profile.,0,2021-08-04 03:08:51+00:00,2021-11-04 05:03:14+00:00,2022-08-30 03:17:26+00:00,https://github.com/abarriosvasquez,20,0,0,HTML,0,1,1,0,0,0,0,0,0,0,,1,0,0,public,0,0,0,other,1,,"Hi 👋 My name is Auner Barrios Vasquez
======================================

Aspiring Software Engineer
--------------------------

I'm currently a student at College of San Mateo studying Computer Science Applications and Development. I have been coding with programming languages such as Python, HTML & CSS, javascript, swift, and java.

* 🌍  I'm based in the San Francisco Bay Area, CA
* ✉️  You can contact me at [aunerbarrios86@gmail.com](mailto:aunerbarrios86@gmail.com)
* 🧠  I'm learning Java and C++ in order to apply for schools such as UC Berkely, UC Davis, UC Santa Barbara 
* 🤝  I'm open to collaborating on a Simon Says game that is created with java

### Skills 

<p align=""left"">
<a href=""https://www.oracle.com/java/"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/java-colored.svg"" width=""36"" height=""36"" alt=""Java"" /></a>
<a href=""https://www.python.org/"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/python-colored.svg"" width=""36"" height=""36"" alt=""Python"" /></a>
<a href=""https://developer.mozilla.org/en-US/docs/Glossary/HTML5"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/html5-colored.svg"" width=""36"" height=""36"" alt=""HTML5"" /></a>
<a href=""https://www.w3.org/TR/CSS/#css"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/css3-colored.svg"" width=""36"" height=""36"" alt=""CSS3"" /></a>
<a href=""https://www.adobe.com/uk/products/photoshop.html"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/photoshop-colored.svg"" width=""36"" height=""36"" alt=""Photoshop"" /></a>
<a href=""https://www.figma.com/"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/skills/figma-colored.svg"" width=""36"" height=""36"" alt=""Figma"" /></a>
</p>


### Socials

<p align=""left""> <a href=""https://www.github.com/abarriosvasquez"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/github.svg"" width=""32"" height=""32"" /></a> <a href=""https://www.linkedin.com/in/aunerbarriosvasquez/"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/linkedin.svg"" width=""32"" height=""32"" /></a> <a href=""https://www.twitter.com/AunerBarriosVas"" target=""_blank"" rel=""noreferrer""><img src=""https://raw.githubusercontent.com/danielcranney/readme-generator/main/public/icons/socials/twitter.svg"" width=""32"" height=""32"" /></a></p>

### Badges

<b>My GitHub Stats</b>

<a href=""http://www.github.com/abarriosvasquez""><img src=""https://github-readme-stats.vercel.app/api?username=abarriosvasquez&show_icons=true&hide=&count_private=true&title_color=0891b2&text_color=ffffff&icon_color=0891b2&bg_color=1c1917&hide_border=true&show_icons=true"" alt=""abarriosvasquez's GitHub stats"" /></a>

<a href=""http://www.github.com/abarriosvasquez""><img src=""https://github-readme-streak-stats.herokuapp.com/?user=abarriosvasquez&stroke=ffffff&background=1c1917&ring=0891b2&fire=0891b2&currStreakNum=ffffff&currStreakLabel=0891b2&sideNums=ffffff&sideLabels=ffffff&dates=ffffff&hide_border=true"" /></a>

<a href=""http://www.github.com/abarriosvasquez""><img src=""https://activity-graph.herokuapp.com/graph?username=abarriosvasquez&bg_color=1c1917&color=ffffff&line=0891b2&point=ffffff&area_color=1c1917&area=true&hide_border=true&custom_title=GitHub%20Commits%20Graph"" alt=""GitHub Commits Graph"" /></a>

<a href=""https://github.com/abarriosvasquez"" align=""left""><img src=""https://github-readme-stats.vercel.app/api/top-langs/?username=abarriosvasquez&langs_count=10&title_color=0891b2&text_color=ffffff&icon_color=0891b2&bg_color=1c1917&hide_border=true&locale=en&custom_title=Top%20%Languages"" alt=""Top Languages"" /></a>
",['abarriosvasquez'],0,,0.74,0,,,,,,1,,,
357416624,MDEwOlJlcG9zaXRvcnkzNTc0MTY2MjQ=,me169-binder,karthink/me169-binder,0,karthink,https://github.com/karthink/me169-binder,"Pluto notebooks for ME 169, Spring '21 @ UCSB",0,2021-04-13 03:48:32+00:00,2021-05-06 06:58:36+00:00,2021-05-06 06:58:34+00:00,,39,0,0,Julia,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,0,master,1,,"# ME 169 Pluto Notebooks
Pluto.jl notebooks for ME 169, spring 2021 @ UCSB
",['karthink'],1,,0.72,0,,,,,,2,,,
369324806,MDEwOlJlcG9zaXRvcnkzNjkzMjQ4MDY=,us-comm-phd,hongtaoh/us-comm-phd,0,hongtaoh,https://github.com/hongtaoh/us-comm-phd,美国传播学博士项目一览,0,2021-05-20 20:01:53+00:00,2025-03-04 03:18:21+00:00,2024-05-28 05:02:36+00:00,,145,25,25,Shell,1,1,1,1,0,0,3,0,0,0,other,1,0,0,public,3,0,25,master,1,,"# 美国传播学博士项目一览

此文源自我的[同名博客文章](https://hongtaoh.com/cn/2021/01/10/us-comm-phd/)。

相关文章：

- [美国提供全奖的新闻传播学硕士项目（不完全统计)](https://hongtaoh.com/cn/2020/02/01/us-comm-ma/)

- [去读美国的传播学博士几条路](https://hongtaoh.com/cn/2021/05/22/us-phd-comm/)

- [美国的信息学院](https://hongtaoh.com/cn/2021/05/20/us-ischool/)

- [我的美国博士申请之路](https://hongtaoh.com/cn/2021/05/22/my-phd-app/)

- [Computational Social Science: Graduate Programs and Researchers](https://github.com/hongtaoh/CompSocSci)

- [Academic CVs that you can emulate](https://github.com/hongtaoh/cv_emulate)

## 改进与贡献

非常欢迎改进意见！如果你在下面某个项目中就读过，不管是硕士还是博士，欢迎添加该项目的介绍！请直接 Fork 此仓库，修改，然后提交合并请求。如果不知道如何操作，请参考拙文 [How to Make A Pull Request on GitHub](https://hongtaoh.com/en/2020/10/05/github-pull-request/)。

## 版权

Shield: [![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]

本项目采用 《[署名-非商业性使用-相同方式共享4.0 协议 (CC BY-NC-SA 4.0)][cc-by-nc-sa]》进行授权。全文转载、部分引用、二次演绎必须注明署名和链接，禁止商用，禁止以其他协议发布。

[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]

[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh
[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png
[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg

---
![US-Map](https://wallpapercave.com/wp/MbXUy9y.jpg)

以上地图来自 [wallpapercave.com](https://wallpapercave.com/wp/MbXUy9y.jpg)

我会大致按照美国地图的顺序来介绍各州内的传播学博士项目。由北向南，由西向东。

主要参考：

1. [NCA's Doctoral Program Guide](https://www.natcom.org/nca-doctoral-program-guide)
2. [ShanghaiRanking's Global Ranking of Academic Subjects 2020 — Communication](http://shanghairanking.com/Shanghairanking-Subject-Rankings/communication.html)

## 没有博士点的州

- Alaska
- Montana
- Idaho
- Nevada
- Wyoming
- South Dakota
- Arkansas
- Rhode Island
- New Hampshire
- Vermont

## Alaska

NCA 显示[阿拉斯加州内没有传播学博士项目](https://www.natcom.org/nca-doctoral-program-guide?field_docprog_state_value=AK&title=)。我试着搜了下，只找到了 University of Alaska Fairbanks 下的 [Department of Communication and Journalism](https://www.uaf.edu/cojo/)。这个学院有一个硕士项目，可以给硕士生[助教全奖](https://www.uaf.edu/cojo/students/comm-masters-ta-positions/)。官网上只列出了[6位助教](https://www.uaf.edu/cojo/contact-us/index.php#TA)，其中有一位中国女生。

学院只有 [6 位教授](https://www.uaf.edu/cojo/contact-us/index.php#Faculty)，研究方向有两个。一个是偏实践类的摄影（系主任就是教摄影的）和纪录片。学术类的方向是组织传播。这个硕士项目很小，但是不妨碍感兴趣的人试一下。学院在 [Q & A](https://www.uaf.edu/cojo/areas-of-study/degrees/grad.php)中也提到，硕士学习可以帮助学生申请博士项目，所以应该还不错。我看了一下[硕士项目的手册](https://www.uafjournalism.com/docs/RevisedGraduateHandbook8-23-2017.pdf)，必修课（24个学分）里包括了一门理论课和两门方法课。选修课里有组织传播和健康传播的课。作为一个硕士项目，我觉得挺好的了。

根据[软科 2020](http://shanghairanking.com/ARWU2020.html) 的排名，[这所学校](https://uaf.edu/uaf/)全球排名在 601-700, 是阿拉斯加唯一一所进全球前 1000 的学校。

如果你本科出身不好，家里没钱支持你读全自费的学校，专业和摄影、纪录片、组织传播、人际传播相关，并且英语比较好，我建议你试一下。具体申请流程和截止日期[学院网站](https://www.uaf.edu/cojo/areas-of-study/degrees/grad.php)没有列出，只给出了这两个链接 ([1](https://www.uaf.edu/admissions/index.php), [2](https://www.uaf.edu/gradsch/other-resources/calendar/dates-and-deadlines/index.php))，请自己查阅相关信息。因为是助教奖，所以我猜测他们对英语口语要求会比较高，想申请的话，口语尽量要好。

## Washington

华盛顿有两所学校开设传播学博士项目：华盛顿大学 (University of Washington) 和华盛顿州立大学 (Washington State University)。

### 1. [University of Washington, Department of Communication](https://com.uw.edu/)

我们先来看下大名鼎鼎的华盛顿大学。插一句嘴，我一直以为它是私立学校，前几天才知道原来是[公立](https://en.wikipedia.org/wiki/University_of_Washington)的。很厉害。学校实行的是 Quater 制。

传播系的项目是 MA/PhD。MA 是你读博士的时候顺手给你一个，虽然有人会拿硕士走人。

该学院 2020-2021 因为新冠疫情影响，没有招生。官网的原话是 ""In light of the disruptions and uncertainties created by the COVID-19 pandemic, the Department of Communication graduate faculty have voted to suspend admissions to our M.A./Ph.D. and Ph.D. programs for Autumn 2021""。不知道这对 2021-2022 有什么影响。

这个学院申请截止日期非常早，每年都的11月15号截止，感兴趣的同学一定要尽快申请。

在我看来，美国传播学院中有三大专注定性的学校：华盛顿大学、纽约大学和加州圣地亚哥。

一些有用的链接：

- [硕士、博士项目概况](https://com.uw.edu/graduate/ma-phd/ma-phd-overview/)

- [研究方向](https://com.uw.edu/graduate/ma-phd/areas-of-study/)

- [申请指南](https://com.uw.edu/admissions/ma-phd-admissions/)

### 2. [Washington State University, Murrow College of Communication](https://murrow.wsu.edu/)

浙江大学传媒与国际文化学院院长[韦路](https://person.zju.edu.cn/luwei) 在这里拿到的博士学位。

这个学院有两个系，[Strategic Communication](https://murrow.wsu.edu/academics/academic-departments/department-of-strategic-communication/) 和 [Journalism & Media Production](https://murrow.wsu.edu/academics/academic-departments/department-of-journalism-and-media-production/). 前者应该偏科研，后者偏实践。如果我没记错的话，这个学院的 MA 也是给钱的。从学科设置来看，这里的研究应该偏重公关、广告和健康传播。

## Oregon

### 3. [University of Oregon, School of Journalism and Communication](https://journalism.uoregon.edu/)

俄勒冈只有一所学校有博士点：University of Oregon。这个学院有硕士项目也有博士项目，如果对硕士感兴趣，建议你自己问下硕士给不给全奖。

我对这个学院不是非常了解，如果感兴趣，建议你自己把每个老师的研究介绍仔细看一遍。我只知道师从 Jeffrey Hancock 的 [David Markowitz](https://journalism.uoregon.edu/profile/dmark) 从斯坦福博士毕业后去这里任教了。

## Utah

### 4. [University of Utah, Department of Communication](https://communication.utah.edu/)

这里的硕士是给奖的。学院说的很清楚：""The Department strives to fully fund all admitted graduate students who request funding when they apply to the graduate program.""

这个学院我不是特别了解。具体请自己上学院网站获取详情。一些可能有用的链接：

- [Graduate Program](https://communication.utah.edu/graduate/index.php)

- [Prospective Students](https://communication.utah.edu/graduate/prospectivestudents.php)

- [Graduate Handbook](https://communication.utah.edu/_documents/graduate/Department%20of%20Communication%20Graduate%20Handbook%2003%202019.pdf)

## Colorado 

### 5. [University of Colorado, College of Media, Communication and Information](https://www.colorado.edu/cmci/academics/communication)

科罗拉多最近把几个不同的学院合并到了一起，组成了现在这个 College of Media, Communication and Information。我觉得这对学生来说是好事，可以接触到不同的内容，开阔视野，合作机会多。

这个 College 有以下几个方向，每个方向都有博士点：

- [Advertising, Public Relations, and Media Design](https://www.colorado.edu/cmci/academics/advertising-pr-and-media-design), 博士点是 PhD in Strategic Communication

- [Communication](https://www.colorado.edu/cmci/academics/communication)

- [Critical Media Practices](https://www.colorado.edu/cmci/dcmp), PhD in Emergent Technologies and Media Arts Practices

- [Information Science](https://www.colorado.edu/cmci/infoscience)

- [Intermedia Art, Writing and Performance (PhD)](https://www.colorado.edu/cmci/academics/iawp)

- [Journalism](https://www.colorado.edu/cmci/academics/journalism)

- [Media Studies](https://www.colorado.edu/cmci/academics/media-studies)

请自己了解吧，我不是特别清楚。

### 6. [University of Denver, Department of Communication](http://www.du.edu/ahss/schools/comn/index.html)

这个学院在传播学领域几乎没有什么存在感。有一个 M.A. in Communication Studies, 和 PhD in Communication Studies。请自己问下硕士是否给钱。这个学院不是一个很好的博士选择，但如果学院给硕士生钱，你的研究方向正好也是人际传播之类的，我觉得去这里读硕士是个很好的选择。

这里只有[三个教授](https://www.du.edu/ahss/comn/faculty-staff/index.html)，Mary Claire, Elizabeth A. Suter, 和 Erin K. Willer，都研究 Interpersonal & Family communication。

请自己了解。

### 7. [Colorado State University, Department of Journalism & Media Communication](https://journalism.colostate.edu)

PhD in Public Communication & Technology

我了解的都不多，请自己了解。

### 8. [Colorado State University, Department of Communication Studies](https://communicationstudies.colostate.edu/)

我了解的都不多，请自己了解。

## Arizona

### 9. [University of Arizona, Department of Communication](http://comm.arizona.edu/)

这所学校的硕士是给全奖的。强烈推荐。

这所学校的人际传播、家庭传播、公关是强项。可带学生的教授有14位，其中两位是中国人。具体情况请自行了解。

- [可以带硕士、博士生的老师](https://comm.arizona.edu/peo-faculty) (进去后选择 Research Faculty)

- [申请指南](https://comm.arizona.edu/graduate-program-apply)

### 10. [Arizona State University, Hugh Downs School of Human Communication](http://humancommunication.clas.asu.edu/)

我不是特别了解。请自行翻阅。

- [Ma & PhD Degrees](https://humancommunication.asu.edu/degrees/graduate)

- [Graduate admission](https://humancommunication.asu.edu/admission/graduate-admission)

- [Research areas](https://humancommunication.asu.edu/node/1800)

- [Faculty](https://humancommunication.asu.edu/node/1798)

## New Mexico 

### 11. [University of New Mexico, Department of Communication & Journalism](http://www.unm.edu/~cjdept/)

有硕士也有博士项目。这个学院的[硕士项目](http://cjdept.unm.edu/graduate/ma-in-communication.html)是给全奖的。

这个学院的项目我了解的不多。请自行了解。

- [学位项目概况](http://cjdept.unm.edu/graduate/index.html)

- [申请流程](http://cjdept.unm.edu/graduate/application-procedures.html)

- [学院教授](http://cjdept.unm.edu/people/faculty/index.html)

## North Dakota 

### 12. [North Dakota State University, Department of Communication](http://www.ndsu.edu/communication/)

硕士给全奖。

这所学校我不了解。

- [硕士项目简介](https://www.ndsu.edu/communication/programs/masters_program/)

- [博士项目简介](https://www.ndsu.edu/communication/programs/doctoral_program/)

- [教授](https://www.ndsu.edu/communication/faculty/)

### 13. [University of North Dakota, Department of Communication](http://arts-sciences.und.edu/communication/)

貌似没有硕士项目。

这所学校我不了解。

- [Ph.D. in Communication](https://und.edu/programs/communication-phd/index.html)

- [Faculty & Staff](https://arts-sciences.und.edu/academics/communication/faculty-staff.html)

## Nebraska

### 14. [University of Nebraska, Department of Communication Studies](https://comm.unl.edu/)

这所学校的强项在人际传播和健康传播。目前（2021-05-18）研究生、博士生中[一个中国人都没有](https://comm.unl.edu/current-grad-students)。

我了解的不多。

- [人际、健康传播宣传手册](https://comm.unl.edu/documents/IFH_Flyer.pdf)

- [硕士项目简介](https://comm.unl.edu/master-arts-communication-studies)

- [博士项目简介](https://comm.unl.edu/doctor-philosophy-communication-studies)

- [Graduate Handbook, 2018-2019](https://comm.unl.edu/Graduate%20Handbook%202018-2019.pdf)

## Kansas

### 15. [University of Kansas, Department of Communication Studies](http://coms.ku.edu/)

不太了解，硕士生也许给全奖。定量方面，[研究的重点在人际、跨文化、组织传播](http://coms.ku.edu/overview)。请自行了解。

- [MA](http://coms.ku.edu/ma-overview) & [2019 Masters Program Prifile](http://coms.ku.edu/sites/coms.ku.edu/files/files/Masters%20Program%20Profile%202019.pdf)

- [Ph.D.](http://coms.ku.edu/overview)

- [Communication Studies Graduate Student Handbook](http://coms.ku.edu/sites/coms.ku.edu/files/docs/FINAL%202019%20COMS%20Graduate%20Handbook.pdf)

- [申请指南](http://coms.ku.edu/ma-admissions)

## Oklahoma

### 16. [University of Oklahoma, Gaylord College of Journalism & Mass Communication](http://www.ou.edu/gaylord)

有硕士也有博士。硕士也许会给全奖。我了解的不多，请自行查阅。

- [Graduate Programs](https://www.ou.edu/gaylord/graduate)

- [Application](https://www.ou.edu/gaylord/graduate/application-process)

- [Faculty](https://www.ou.edu/gaylord/people/faculty)

### 17. [University of Oklahoma, Department of Communication](https://ou.edu/cas/comm/)

有硕士，有博士。硕士生[应该会有助教全奖](https://ou.edu/cas/comm/academics/graduate/graduate-assistantship)。

我了解的不多。请自行查阅。

- [Graduate programs](https://ou.edu/cas/comm/academics/graduate)

- [Graduate handbook](https://ou.edu/cas/comm/academics/graduate/graduate-student-handbook/_jcr_content/contentpar/download/file.res/Grad%20Handbook%20August%202020%20V2.pdf)

- [Graduate admission](https://ou.edu/cas/comm/academics/graduate/admission)

- [Faculty](https://ou.edu/cas/comm/about/people/faculty)

## Minnesota

### 18. [University of Minnesota, Department of Communication Studies](http://www.comm.umn.edu/)

定量方面强在人际传播。没有硕士项目，只有[五年的博士项目](https://cla.umn.edu/comm-studies/phd-communication-studies)。

- [PhD program overview](https://cla.umn.edu/comm-studies/phd-communication-studies)

- [How to apply](https://cla.umn.edu/comm-studies/graduate/how-apply)

- [Faculty](https://cla.umn.edu/comm-studies/faculty)

### 19. [University of Minnesota - Hubbard School of Journalism](https://hsjmc.umn.edu/)

这个学院很有钱。硕士生给全奖。广告、健康传播是强项。

- [All graduate programs](https://hsjmc.umn.edu/graduate/degree-programs/explore-programs)

- [MA in Mass Communication](https://hsjmc.umn.edu/graduate/degree-programs/ma-mass-communication)

- [PhD in Mass Communication](https://hsjmc.umn.edu/graduate/degree-programs/phd-mass-communication)

- [How to apply](https://hsjmc.umn.edu/graduate/degree-programs/how-apply-graduate-program)

- [Faculty](https://hsjmc.umn.edu/people/faculty)

## Iowa

### 20. [University of Iowa, Department of Communication Studies](http://clas.uiowa.edu/commstudies/)

只有博士项目，虽然偶尔有学生被录取到硕士项目或者学生觉得博士不适合自己就拿硕士走人 (""The graduate program is primarily a doctoral program, though occasionally students are admitted for the master’s or choose to leave with a master’s. "")。定性研究很强。定性研究有两个方向，[媒体历史与文化](https://clas.uiowa.edu/commstudies/node/176) 和 [Rhetoric, Culture, Engagement](https://clas.uiowa.edu/commstudies/node/177)。定量重在[人际传播](https://clas.uiowa.edu/commstudies/node/175)。

- [申请指南](https://clas.uiowa.edu/commstudies/graduate-program/prospective-graduate-students)

- [教授](https://clas.uiowa.edu/commstudies/people)

## Missouri

### 21. [University of Missouri, Department of Communication](http://communication.missouri.edu/)

- [Graduate program overview](https://communication.missouri.edu/graduate-program)

- [Research areas](https://communication.missouri.edu/focus-areas)

- [Faculty](https://communication.missouri.edu/people/faculty)

- [申请指南](https://communication.missouri.edu/grad/graduate-admissions-and-degree-requirements)

## Louisana

### 22. [Louisiana State University, Department of Communication Studies](http://www.lsu.edu/hss/cmst/)

有硕士也有博士。硕士可能会给全奖。有定性也有定量。定量强在人际传播。

- [Graduate handbok](https://www.lsu.edu/hss/cmst/graduate/202021graduatehandbook.pdf)

- [项目简介](https://www.lsu.edu/hss/cmst/graduate/prospective_students.php)

- [申请信息](https://www.lsu.edu/hss/cmst/graduate/app-reqs.php)

- [教授](https://www.lsu.edu/hss/cmst/people/faculty/1facultylist.php)

## Wisconsin

### 23. [University of Wisconsin, Department of Communication Arts](http://bit.ly/2WiO1kA)

有定性也有定量。有硕士项目，官网数据2022年硕士全奖100%覆盖，每月平均2419刀，录取率约为17%。

- [Graduate program overview](https://commarts.wisc.edu/graduate/)

- [Graduate handbook](https://commarts.wisc.edu/graduate/graduate-handbook/)

- [Faculty](https://commarts.wisc.edu/people/)

### 25. [University of Wisconsin, Ph.D. Program in Mass Communications](https://masscommphd.wisc.edu/)

[PhD in Mass Communications](https://masscommphd.wisc.edu/) 由 [ Department of Life Sciences Communication](http://lsc.wisc.edu/) 和 [School of Journalism and Mass Communication](http://journalism.wisc.edu/) 联合授课。很老牌的学校和专业。录取率大约33%，国际生比例较高。

### 26. [University of Wisconsin-Milwaukee, Department of Communication](https://uwm.edu/communication/)

有硕士也有博士。硕士也许会给助教全奖，我不确定。

我了解的不多，请自行查阅。

- [MA program](https://uwm.edu/communication/graduate/ma-program/)

- [PhD program](https://uwm.edu/communication/graduate/phd-program/)

- [Faculty](https://uwm.edu/communication/our-people/faculty-lecturers/)

## Illinois

### 27. [Northwestern University, Department of Communication Studies](https://communication.northwestern.edu/)

西北大学的传播学和宾夕法尼大学的传播学在我看来都属于美国传播学院的「异类」，属于「西邪」一派。我说它俩异类是因为那里的大部分老师都不是传播学出身。我在 [2020 年去西北大学参加 MTS 博士项目面试](https://hongtaoh.com/cn/2020/03/01/northwestern-compus-visit/)时，负责人说 [MTS ](https://mts.northwestern.edu/) 项目的老师没有一个有传播学的博士学位。

西北传播学院分为[五个系](https://communication.northwestern.edu/departments/)，我只了解其中的 传播学系：[Department of Communication Studies](https://communication.northwestern.edu/communication-studies/)，所以我只介绍它。

传播学系我只了解它的博士项目，所以我不介绍硕士的。它有三个博士项目：MTS, TSB 和 Communication Studies。最后一个我了解很有限，所以只介绍 MTS 和 TSB。

#### MTS 

MTS 全称是 [The PhD in Media, Technology, and Society](https://mts.northwestern.edu/)。这个项目的[老师研究方向](https://mts.northwestern.edu/faculty/)差别很大，但基本上以定量为主，也有定性的，比如 Jeremy Birnholtz。有两个老师研究 Network Science: Noshir Contractor 和 Ágnes Horvát。Ellen Wartella 老师是研究孩童与媒体的权威。总之这里的老师都很厉害。

这个学院给的钱很多，2020 年我参加面试时，负责人 Aaron Shaw 老师说学生每年获得的补助超过三万美元（税前），实在是很高。南加大比这个应该还高一些，但那是因为洛杉矶房价高。

这个学院给我的震撼很大，因为他们的组织和科研方式很像理工科，每个老师都有自己的实验室。学院不缺钱，老师的背景多样。在这里读五年博士我觉得是一件很享受很奢侈的事。希望你有这个机会！

更多具体情况请上 [MTS 官网](https://mts.northwestern.edu/faq/)自行了解。

#### TSB

TSB 的全称是 [PhD in Technology and Social Behavior](https://tsb.northwestern.edu/)。这是一个传播学+计算机科学双学位项目，超级好。这个方向就更像理工科了。老师的科研以项目为主导，所以学生有很多获得 RA (Research Assistanships) 的机会。

更多详情，请上 [TSB 官网](https://tsb.northwestern.edu/)了解。

### 28. [Southern Illinois University, Department of Communication Studies](http://cola.siu.edu/communicationstudies/index.php)

有博士有硕士。硕士可能会给全奖。这个项目我不了解。

### 29. [University of Illinois-Chicago, Department of Communication](https://comm.uic.edu/)

请自行了解。

### 30. [University of Illinois, Department of Communication](https://communication.illinois.edu/)

传统名校，强势项目。[M.A.、 M.S.、Ph.D. 一应俱全](https://communication.illinois.edu/academics/ma-phd-program)。自行了解。

- [MA/PhD program](https://communication.illinois.edu/academics/ma-phd-program)

- [M.S. in Health Communication](https://communication.illinois.edu/academics/ma-phd-program)

- [Graduate faculty research areas](https://communication.illinois.edu/research/research-areas)

- [Graduate admissions](https://communication.illinois.edu/admissions/apply-graduate-program)

- [Faculty](https://communication.illinois.edu/directory/faculty)

### 31. [University of Illinois, Institute of Communications Research](https://media.illinois.edu/icr)

很老牌的项目，请自行了解。

- [PhD admissions](https://media.illinois.edu/institute-communications-research/admission-requirements)

- [Faculty](https://media.illinois.edu/phd-program/faculty)

## Mississippi

### 32. [University of Southern Mississippi, Department of Communication Studies](https://www.usm.edu/communication/index.php)

我不了解，自行查阅。

## Michigan

### 33. [Michigan State University, The Department of Media and Information](https://comartsci.msu.edu/academics/academic-departments/advertising-public-relations-journalism-media-information/graduate)

老牌项目，自行了解。我只知道中国学生申请提交成绩单很麻烦。

[waitingdo](https://github.com/waitingdo) 补充到：

>MSU的 Information and Media PhD 并非来自 Media and Information 部门，而是由Advertising + Public Relations （广告）, Journalism （新闻）, Media and Information （游戏、人机交互） 三个部分合办的。说起来很奇怪，虽然这是一个跨学科项目，但实际上这几个部门是各自招生，学生申请的时候也需要明确自己申请的是哪个部门。如果有时间的话，可以联系项目tailor自己的计划、设计一个跨部门的track，比如ADPR+Journalism。MSU的风险传播（健康、科学、环境）很强，偏定量，最近一两年招了很多新老师。

### 34. [Michigan State University, Department of Communication](https://comartsci.msu.edu/academics/academic-departments/communication/graduate/phd-communication)

老牌项目，自行了解。我只知道中国学生申请提交成绩单很麻烦。

### 35. [University of Michigan, Department of Communication and Media](https://lsa.umich.edu/comm)

非常好的学校，非常好的项目。请自行了解。

- [Program Overview](https://lsa.umich.edu/comm/graduates/prospective-students/program-overview.html)

- [How to apply](https://lsa.umich.edu/comm/graduates/prospective-students/how-to-apply.html)

- [Faculty](https://lsa.umich.edu/comm/people/regular-faculty.html)

### 36. [Wayne State University, Department of Communication](http://comm.wayne.edu/)

我了解有限，请自行查阅。我只知道 [Stephanie Tong](http://comm.wayne.edu/profile/fe2816) 老师很厉害。

## Indiana

### 37. [Indiana University, The Media School](https://mediaschool.indiana.edu/index.html)

终于说到自己的母校了。

IU Media School 的好处是几乎所有的硕士都是给全奖的，不管是 [MA](https://mediaschool.indiana.edu/academics/graduate/media-arts-sciences/index.html) 还是 [MS](https://mediaschool.indiana.edu/academics/graduate/ms-media/index.html)。硕士的工资和博士是一样的。目前，每年的工资（一年发 10 个月），税前是 $15,700。刨去税，一个月大概到手 $1,300 左右，在 Bloomington 是够了。

学院的老师分布在四个方向：Cinema and Media Studies, Communication Science, Journalism, 和 Media Arts and Production。如果你是走学术路线的话，[Communication Science](https://mediaschool.indiana.edu/people/faculty/?class=1&unit=2) 和 [Journalism](https://mediaschool.indiana.edu/people/faculty/?class=1&unit=3) 是最相关的。Journalism 方向，有老师是做公关和广告的，比如 Sung Un Yang、Minjeong Kang、Nicholas Browning。Comm Science 方向的老师绝大部分是定量的。

我在这里读的 MA，我觉得真的挺好的。学校很漂亮，生活舒适，课程设置也不错，老师人都很好，至少我碰到的都还不错，很乐意帮学生。这里有很多机会，就看你怎么利用。当然，这篇帖子上列出的所有学校都有很多机会，重点在于你是否能够挖掘。我在这里的两年，上了 [John Kruschke](https://jkkweb.sitehost.iu.edu/) 老师的[贝叶斯统计入门课](https://jkkweb.sitehost.iu.edu/jkkteach/P533/index.html) （我基本没听懂，虽然最后也是拿的 A，只能骗别人了）、[安用烈](http://yongyeol.com/)老师的[数据可视化](https://yyahn.com/dviz-course/)、[Dong-Chul Seo](https://publichealth.indiana.edu/research/faculty-directory/profile.html?user=seo) 老师的 B650 Quantitative Methods for Public Health Research。这些课都让我受益匪浅，帮我转专业申请到了[威斯康星的计算机博士项目](https://www.cs.wisc.edu/)。所以，不管去哪所学校，关键在于你是否能利用好你现有的资源和机会。

- [教授](https://mediaschool.indiana.edu/people/faculty/index.html)

- [硕、博士项目](https://mediaschool.indiana.edu/academics/graduate/index.html)

- [申请指南](https://mediaschool.indiana.edu/admissions/graduate.html)

### 38. [Purdue University, Brian Lamb School of Communication](https://cla.purdue.edu/academic/communication/index.html)

我只知道这个学院很有钱。硕士是给全奖的，但是要求托福口语到 27，这是一条死规定，没有回旋余地。

我了解不多，请自行了解。

- [硕、博士项目简介](https://cla.purdue.edu/academic/communication/graduate/index.html)

- [项目宣传单](https://cla.purdue.edu/academic/communication/documents/2014grad%20brochure%20CLA-14-5091_COMGrad3.pdf)

- [教授](https://cla.purdue.edu/academic/communication/directory/index.html)

### 39. [IUPUI, Department of Communication Studies](https://liberalarts.iupui.edu/comm/pages/graduate-folder/index.php)

有硕士有博士。自行了解。

- [Faculty](https://liberalarts.iupui.edu/comm/pages/directory-folder/index.php)

## Kentucky

### 40. [University of Kentucky, College of Communication & Information](https://ci.uky.edu/grad/)

有硕士有博士，硕士貌似是可以给全奖的。请自行确认。

这个学院我了解的不多，请自行了解。

- [Admission](https://ci.uky.edu/grad/admission)

- [How to apply](https://ci.uky.edu/grad/how-apply)

- [Specializations](https://ci.uky.edu/grad/specializations)

- [PhD in Communication](https://ci.uky.edu/grad/phd-communication)

- [Faculty](https://ci.uky.edu/grad/contact)

## Tennessee

### 41. [University of Tennessee, School of Communication Studies](http://cmst.cci.utk.edu/)

有硕士有博士。硕士可能会给全奖。具体请自己了解。

### 42. [University of Memphis, Department of Communication](https://www.memphis.edu/communication/index.php)

硕士可能会给全奖。这个项目我了解不多，请自行查阅。

## Alabama

### 43. [University of Alabama, College of Communication & Information Sciences](https://cis.ua.edu/)

有硕士有博士，硕士或许可以给全奖。很老牌的项目。请自行了解。

- [Master's program](https://cis.ua.edu/masters-programs/)

- [PhD program](https://cis.ua.edu/cis-doctoral-program/)

- [Graduate Faculty](https://cis.ua.edu/people/graduate-faculty/)

## New Jersey

### 44. [Rutgers University, School of Communication & Information](http://comminfo.rutgers.edu/)

2021 年我申请了这个学校，先是被放到了候补名单，之后一个人拒了 offer 后，我在三月初收到 offer。学校很有钱，一年给我三万刀。真的是闷声发大财的学校。不过我猜那里的房租应该不便宜。我之前不知道，参加了学校的介绍会才知道那里里费城非常近。

这个学院有三个硕士项目，一个博士项目。博士项目叫做 [Ph.D. Program in Communication, Information and Media](https://comminfo.rutgers.edu/graduate-and-professional-programs/phd-program)。我参加学院的介绍会，感觉这里的老师都挺好的，特别是博士项目主管 [Jennifer Theiss](https://comminfo.rutgers.edu/theiss-jennifer)，人看上去很温和。感觉这里像是家一样，很温馨。但这只是我参加远距离 Zoom 会议的初步印象，具体怎么样，我就不知道到了，因为我没有体验过。

上面那个博士项目链接有各种信息，感兴趣的话请自行查阅。

## North Carolina

### 45. [University of North Carolina, Department of Communication Studies](https://comm.unc.edu/)

很好的学校。给的钱和印第安纳差不多 ($15,700)。定性的老师老师很多，定量主要集中在人际传播和组织传播。请自行了解。

- [Phd program](https://comm.unc.edu/graduate-studies/)

- [Faculty](https://comm.unc.edu/people/)

### 46. [University of North Carolina, Hussman School of Journalism and Media](http://hussman.unc.edu/)

这个学院的博士项目貌似有些赶。它让学生在博士第三年完成资格考试、通过博士论文开题、写完论文。这三件事一般情况下需要至少2-3年才能完成。不过学院提到，有学生呆四年（那也有点赶啊。。）

很好的学校,项目也很好。我了解的不多，只知道这里的 [Deen Freelon](http://dfreelon.org/) 老师很厉害。

具体情况请自行了解：

- [PhD program](http://hussman.unc.edu/phd)

- [Faculty](http://hussman.unc.edu/phd/faculty)

- [Admission](http://hussman.unc.edu/phd/admissions)

- [FAQ](http://hussman.unc.edu/phd/faq)

### 47. [North Carolina State University, Department of Communication](https://communication.chass.ncsu.edu/)

有[硕士 (MS)](https://communication.chass.ncsu.edu/academics/graduate/)、有[博士](https://crdm.chass.ncsu.edu/)。硕士[也许可以给全奖](https://communication.chass.ncsu.edu/academics/graduate/prospective/gssp.php)。博士项目的全称是 [The Ph.D. Program in Communication, Rhetoric, and Digital Media](https://crdm.chass.ncsu.edu/)。请自行了解。

- [申请流程](https://crdm.chass.ncsu.edu/prospective-students/application-process.php)

- [教授](https://chass.ncsu.edu/group/crdm/crdm-faculty/)

## Maryland

### 48. [University of Maryland, Department of Communication](https://communication.umd.edu/)

很好的学校。很好的项目。有硕士，有博士。强在广告、公关、健康传播。现在才知道这里居然有[口译](https://communication.umd.edu/academics/graduate/MPS-translation)、[笔译](https://communication.umd.edu/academics/graduate/MPS-translation)的硕士学位！

自行了解：

- [Communication PhD](https://communication.umd.edu/academics/graduate/PHD)

- [Admissions FAQ](https://communication.umd.edu/academics/graduate/admissions)

- [Graduate faculty](https://communication.umd.edu/academics/graduate/PHD/faculty)

## Hawaii

### 49. [University of Hawaii at Manoa, Communication & Information Sciences](https://www.hawaii.edu/cis/)

项目全名叫 [Communication and Information Sciences (CIS) PhD program](https://www.hawaii.edu/cis/about-us/overview/)。这是一个交叉学科项目，由四个学院/系联合：communication, computer science, library studies, 以及 management information systems。

看起来还不错，请自行了解。

- [官网](https://www.hawaii.edu/cis/)

- [申请指南](https://www.hawaii.edu/cis/prospective_students/application/)

- [教授](https://www.hawaii.edu/cis/people/faculty/)

- [研究方向](https://www.hawaii.edu/cis/focus-areas/)

- [学位信息](https://www.ics.hawaii.edu/welcome/academics/graduate-degree-programs/ph-d-in-cis/)

- [申请相关问答](https://www.hawaii.edu/cis/prospective_students/faq/)

## Massachusetts

### 50. [University of Massachusetts, Department of Communication](www.umass.edu/communication/)

这个学院定性很强，四分之三的教授做定性研究 （学院的原话是：""About three-fourths of our faculty specialize in qualitative methods, which is an unusually high proportion among Departments of Communication in the US.""）。虽说如此，做定量的老师也应该挺强的。这毕竟是一个好学校。

请自行了解。

- [Graduate program](https://www.umass.edu/communication/graduate)

- [Grad Program FAQs](https://www.umass.edu/communication/node/857)

- [Research areas](https://www.umass.edu/communication/research)

- [Faculty](https://www.umass.edu/communication/people/faculty)

### 51. [Boston University, College of Communication](http://www.bu.edu/com/)

硕士学位挺多，博士有一个，[PhD in Emerging Media Studies](http://www.bu.edu/com/academics/emerging-media-studies/phd-in-emerging-media-studies/)。项目很小很精致，只有 [6 位老师](http://www.bu.edu/com/profiles/faculty/?discipline=emerging-media)， 但都挺强的，其中有两位中国人，其余四位分别毕业于斯坦福、华盛顿大学、印第安纳大学、罗格斯大学。专注定量。地理位置好，毕竟在波士顿。

详情请自行了解。

### 52. [MIT, Media Lab](https://www.media.mit.edu/)

不多解释，牛人请自便。学院之前只承认雅思不认托福，不过好在这几年开始接受托福了。

- [Information for Applicants](https://www.media.mit.edu/graduate-program/apply/)

- [Research groups](https://www-prod.media.mit.edu/research/?filter=groups)

## South Carolina

### 53. [University of South Carolina, School of Journalism and Mass Communications](https://sc.edu/study/colleges_schools/cic/journalism_and_mass_communications/index.php#.YKVk2OspDBJ)

有硕士有博士，请自行了解。我只知道 OSU 毕业的 [Jacob Long](https://jacob-long.com/) 在这里任教，他编程很强。

- [Mass Communication - Ph.D.](https://sc.edu/study/colleges_schools/cic/academic_programs/phd/mass_communication_phd/index.php)

- [MA program](https://sc.edu/study/colleges_schools/cic/academic_programs/masters/journalism_and_mass_communication/master_of_arts/index.php)

- [Graduate faculty](https://sc.edu/study/colleges_schools/cic/academic_programs/phd/mass_communication_phd/faculty.php)

- [PhD admission guidelines](https://sc.edu/study/colleges_schools/cic/academic_programs/phd/mass_communication_phd/admission_guidelines.php)

## District of Columbia

### 54. [American University, School of Communication](https://www.american.edu/soc/)

有硕士（还挺多的），有博士。博士项目就一个：[PhD in Communication](https://www.american.edu/soc/communication-studies/phd/index.cfm)。我了解不多，请自行查阅。

### 55. [Howard University, Cathy Hughes School of Communications](https://communications.howard.edu/)

这个学院有四个系，提供博士学位的只有 [Communication, Culture and Media Studies](https://communications.howard.edu/index.php/ccms/)。博士项目为：[in Communication, Culture and Media Studies (CCMS)](https://gs.howard.edu/graduate-programs/communication-culture-and-media-studies)。这个项目貌似只有 6 位老师，很小的项目。请自行了解。

## West Virginia

### 56. [West Virginia University, Department of Communication Studies](communicationstudies.wvu.edu)

这个学院很奇葩地有一个一年制的硕士项目：[M.A. in Theory and Research](https://communicationstudies.wvu.edu/students/graduate-students/m-a-in-theory-and-research)。有一个博士项目：[Ph.D. in Communication Studies](https://communicationstudies.wvu.edu/students/graduate-students/ph-d-in-communication-studies)。

这里的[老师人不多](https://communicationstudies.wvu.edu/faculty-and-staff)，但有几位被引量很高：[Matthew Martin](https://communicationstudies.wvu.edu/faculty-and-staff/faculty-directory/matthew-martin) 、[Scott Myers ](https://communicationstudies.wvu.edu/faculty-and-staff/faculty-directory/scott-a-myers)、 [Alan Goodboy](https://communicationstudies.wvu.edu/faculty-and-staff/faculty-directory/alan-goodboy)（好个性的名字！)。

请自行了解。

## Virginia

### 57. [George Mason University, Department of Communication](http://communication.gmu.edu/)

有硕士，有博士。自行了解。

### 58. [Regent University, School of Communication & the Arts](https://www.regent.edu/program/ph-d-in-communication/)

我都不知道有这个大学，从来没听过，查了一下才知道中文名是「[瑞金大学](https://baike.baidu.com/item/%E7%91%9E%E9%87%91%E5%A4%A7%E5%AD%A6/530622)」。请自行查阅，我完全不熟悉。

## Maine

### 59. [University of Maine, Department of Communication & Journalism](http://cmj.umaine.edu/)

系很小，有硕士有博士。网站上信息列的很清楚。自行了解。

- [Graduate program overview](https://cmj.umaine.edu/graduate/)

- [MA in Communication](https://cmj.umaine.edu/graduate/master-of-arts-in-communication/)

- [PhD in Communication](https://cmj.umaine.edu/graduate/interdisciplinary-ph-d-in-communication/)

- [Faculty](https://cmj.umaine.edu/faculty-staff/)

- [Graduate program FAQ](https://cmj.umaine.edu/graduate/graduate-program-faq/)

## Delaware

### 60. [University of Delaware, Department of Communication](https://www.communication.udel.edu/)

有硕士有博士，硕士每年 2 万美元，博士 2.1 万。比较难的是要求 GRE 写作分数到 4.5。自行了解。

- [MA application](https://www.communication.udel.edu/grad-program/prospective-ma-students/application-information-and-resources)

- [PhD application](https://www.communication.udel.edu/grad-program/prospective-phd-students/admission-policy)

- [Faculty](https://www.communication.udel.edu/people/faculty)

- [Graduate program FAQ](https://www.communication.udel.edu/grad-program/prospective-grad-students/faq)

## Connecticut

### 61. [University of Connecticut, Department of Communication](https://comm.uconn.edu/)

有[硕士](https://comm.uconn.edu/grad/masters/)也有[博士](https://comm.uconn.edu/grad/phd/)，硕士可能给全奖。[托福口语要求到 27 分](https://comm.uconn.edu/grad-admissions/)。

这个项目挺好的，[研究方向](https://comm.uconn.edu/research/)挺新潮的，VR, HCI等。定量研究为主。[老师](https://comm.uconn.edu/faculty/)挺多的。符合要求的请自行查阅吧。

## Ohio

### 62. [Ohio State University, School of Communication](https://comm.osu.edu/)

上海交大排第二的大牛校，不多解释。硕士也会给全奖。2019 年我没申请，但是知道那年 12 月 1 号申请截止，同月 9 号就发了录取。这速度实在惊艳。需要指出的是，[申请指南](https://comm.osu.edu/sites/default/files/Application%20instructions_3.pdf) 中提到的托福口语到 28 这个要求不是死的。想要你的话，他们不会用这一条来卡你。

### 63. [Ohio University, School of Communication Studies](https://www.ohio.edu/scripps-college/comm-studies)

[博士项目](https://www.ohio.edu/scripps-college/comm-studies/phd)有三个科研方向：人际和组织传播、健康传播、说服与文化。自行了解。

### 64. [Bowling Green State University, School of Media and Communication](https://www.bgsu.edu/arts-and-sciences/media-and-communication/graduate.html)

有硕士有博士，硕士可能给全奖。自行了解

- [PhD program](https://www.bgsu.edu/arts-and-sciences/media-and-communication/graduate/phd-program.html)

- [MA program](https://www.bgsu.edu/arts-and-sciences/media-and-communication/graduate/masters-program.html)

- [Application information](https://www.bgsu.edu/arts-and-sciences/media-and-communication/graduate/application-information.html)

- [Faculty](https://www.bgsu.edu/arts-and-sciences/media-and-communication/faculty-and-staff.html)

### 65. [Kent State University, College of Communication & Information](https://www.kent.edu/cci)

有[很多硕士项目](https://www.kent.edu/cci/academics/graduate)，有一个博士项目：[PhD in Communication & Information](https://www.kent.edu/cci/academics/doctoral)。

自行了解。

## New York

### 66. [Syracuse University, S.I. Newhouse School of Public Communications](http://newhouse.syr.edu/)

有很多[硕士项目](https://newhouse.syr.edu/academics/programs/masters)，博士项目有一个：[Mass Communications Ph.D.](https://newhouse.syr.edu/academics/mass-communications/)。2018 年的时候我被录取了。它说这是三年的博士项目，但我猜你多呆一两年应该没啥（只是我猜啊，我不确定）。很老牌的项目。自行查阅吧，没必要我多说。

- [Faculty](https://newhouse.syr.edu/academics/mass-communications/faculty/)

- [Graduate admissions](https://newhouse.syr.edu/admissions/graduate/)

### 68. [New York University, Department of Media, Culture & Communication](https://steinhardt.nyu.edu/departments/media-culture-and-communication)

这个项目很好，学生就业很好。主要是定性研究。不多说，自行了解。

- [PhD in Media, Culture, and Communication](https://steinhardt.nyu.edu/degree/phd-media-culture-and-communication)

### 69. [Cornell University, Department of Communication](https://communication.cals.cornell.edu/)

没啥好说的，大牛校，学生就业很好。

### 70. [University at Albany-SUNY, Department of Communication](http://www.albany.edu/communication/index.php)

有[硕士](https://www.albany.edu/communication/programs/ma-communication)，有[博士](https://www.albany.edu/communication/programs/phd-communication)。请自行了解。

### 71. [Rensselaer Polytechnic Institute, Department of Communication & Media](https://hass.rpi.edu/communication-media)

没有硕士，只有博士：[Ph.D. in Communication and Rhetoric](https://hass.rpi.edu/communication-and-media/communication-and-rhetoric)。请自行了解。

- [Research](https://hass.rpi.edu/communication-and-media/research)

- [Faculty](https://hass.rpi.edu/departments-communication-and-media/communication-and-media-faculty)

### 72. [University at Buffalo-SUNY, Department of Communication](http://www.buffalo.edu/content/cas/communication.html)

有硕士有博士。2018 年我申请了这个硕士，貌似被录取了，但是没给钱，所以我就忘了。这个博士项目挺不错了，可以试试。自行了解。

- [PhD program overview](http://www.buffalo.edu/cas/communication/graduate/doctoral-program.html)

- [Faculty](http://www.buffalo.edu/cas/communication/faculty.html)

## Pennsylvania

### 73. [University of Pennsylvania, Annenberg School for Communication](https://www.asc.upenn.edu/)

这个根本不用我介绍。大牛请便。

### 74. [Pennsylvania State University, Department of Communication Arts & Sciences](http://cas.la.psu.edu/)

有硕士有博士，[硕士也给全奖](https://cas.la.psu.edu/graduate/prospective-students-1)。自行了解。

### 75. [Pennsylvania State University, Donald P. Bellisario College of Communications](http://comm.psu.edu/)

无须我解释，很好的项目。自行查阅。

### 76. [Temple University, Klein College of Media & Communication](https://klein.temple.edu/)

有很多硕士项目，有一个 [Media and Communication Doctoral Program](https://klein.temple.edu/academics/media-and-communication-doctoral-program)，挺不错的。详情自己查阅。

### 77. [Drexel University, Department of Communication](https://drexel.edu/coas/academics/graduate-programs/communication-culture-media/)

有硕士 (Master of Science)、有博士。博士项目为 [Doctorate in Communication, Culture & Media](https://drexel.edu/coas/academics/graduate-programs/communication-culture-media/doctorate/)。详情请自己了解。

### 78. [University of Pittsburgh, Department of Communication](www.comm.pitt.edu)

有硕士有博士，详情自己了解。

### 79. [Duquesne University, Department of Communication & Rhetorical Studies](http://www.duq.edu/academics/schools/liberal-arts/academic-programs/communication-and-rhetorical-studies/graduate-programs)

我没怎么太听说过这个学校。有硕士有博士。博士项目叫 [Ph.D. in Rhetoric](https://www.duq.edu/academics/schools/liberal-arts/academics/departments-and-centers/communication-and-rhetorical-studies/graduate-programs/phd-in-rhetoric)，看名字是纯定性的，貌似不适合大部分中国人。自己查阅。

## California

### 80. [Stanford University, Department of Communication](https://comm.stanford.edu/)

不解释，牛人请自便。

### 81. [University of Southern California, Annenberg School of Communication & Journalism](https://annenberg.usc.edu/)

这个也不需要我解释。给的钱很多，但洛杉矶生活也贵。这个学院是托福、GRE 控。想被录取的话就拼命刷分。

### 82. [University of California-Santa Barbara, Department of Communication](www.comm.ucsb.edu/)

曾经是我的梦校！不需要我解释什么，非常好的项目。UCSB 有一个福利是给第一年的博士生提供廉价住宿，如果没记错每个月才 500 多刀（如果记错请更正）。

自己查阅。

### 83. [University of California Davis, Department of Communication](https://communication.ucdavis.edu/)

UC Davis 的传播学院很年轻，但是发展势头强劲。学院貌似把赌注押在了计算传播学方向。2021 年我被录取了，学院介绍会上，7个学生中，有 6 个是对计算方法 (Computational methods) 感兴趣的。学院有很多老师从事计算社会科学 (Computational social science) 研究。

我觉得这个学院挺有前景的。离湾区也近。

不过每年只给两万二美元的工资，不是很高。

### 84. [University of California-San Diego, Department of Communication](communication.ucsd.edu)

专注定性。自行查阅。

### 85. [University of California-Los Angeles, Department of Communication](https://comm.ucla.edu/)

这是个十分小众的项目，好像是 2021 年才刚刚成熟。小众、很新，所以容易被忽视，在 NCA 网上都没有被列出。但是学校好啊！感兴趣一定要试一试。没有单独的硕士学位。如果博士被录取，最后读不下去或者想决定拿硕士走人，学院会给你一个 Master of Science。当然，读博士的过程中，也可以拿 MS。具体看介绍。

[老师](https://comm.ucla.edu/people/faculty/professors/)挺少的。有[三个科研方向](https://comm.ucla.edu/graduate/research-areas/)：传播与认知、政治传播、计算传播。详情自己查询。

- [项目简介](https://comm.ucla.edu/graduate/program/)

- [申请流程](https://comm.ucla.edu/graduate/admissions/)

- [课程设置](https://comm.ucla.edu/graduate/courses/)

## Texas

### 86. [The University of Texas at Austin, Moody College of Communication](https://moody.utexas.edu/)

有四个系，Communication Studies, RTF, Journalism and Media, Advertising & Public Relations，每个系都有自己的博士项目。

请自己了解详情。

### 87. [Texas Tech University, College of Media & Communication](https://www.depts.ttu.edu/comc/)

有硕士有博士。硕士也许会给全奖。不过每学期五千刀的工资真不高。详情请自己了解。

- [Graduate programs](https://www.depts.ttu.edu/comc/graduate/)

### 88. [Texas Tech University, Department of English](https://www.depts.ttu.edu/english/programs_degrees/phd/tcr/index.php)

我不了解。

### 89. [Texas Tech University, Department of Agricultural Education and Communications](https://www.depts.ttu.edu/aged/grad/gen_info.php)

有一个 PhD in agricultural communications and education。小众，我不了解。请自己查阅。

## Georgia

### 90. [University of Georgia, Department of Communication](https://comm.uga.edu/)

有[硕士也有博士](https://comm.uga.edu/degree-plan-options)，[硕士也许也给全奖](https://comm.uga.edu/assistantship-opportunities)。

有定性也有定量。定性专注 Rhetorical studies, 定量专注人际传播和健康传播。十五个[老师](https://comm.uga.edu/directory/graduate-faculty)，[Jiaying Liu](https://comm.uga.edu/directory/people/jiaying-liu) 老师有 NIH 资助的项目，招博士生，给[四年的 Research assistantships](https://comm.uga.edu/assistantship-opportunities)（2021 年 5 月我看的时候还有，什么结束我不知道，最新信息请自己向学校询问），方向是健康传播，感兴趣可以试试。挺好的项目。详情自己关注。

- [申请流程](https://comm.uga.edu/apply-now)

### 91. [University of Georgia, Grady College of Journalism and Mass Communication](https://grady.uga.edu/)

有[硕士](https://grady.uga.edu/academics/ma-degree/)，有[博士](https://grady.uga.edu/academics/ph-d-degree-program/)。硕士方向有很多。博士项目每年招 [5-8 个人](https://grady.uga.edu/forms/graduate/ph-d-degree-program.pdf)。这个博士项目有点赶，只给[三年的钱](https://grady.uga.edu/graduate_studies/prospective-students-faqs/)，逼着学生[三年毕业](https://grady.uga.edu/forms/graduate/ph-d-degree-program.pdf): ""The Ph.D. degree in mass communication typically takes three years to complete.""

[老师不少](https://grady.uga.edu/faculty/?pf%5Bemployee_type%5D%5B%5D=faculty)。广告、公关方向很强。我只了解这里的 [Sun Joo Ahn](https://grady.uga.edu/faculty/sun-joo-grace-ahn/) 老师，她从斯坦福毕业后去这里任教，研究虚拟现实。

详情自己了解。

- [申请信息](https://grady.uga.edu/apply/)

### 92. [Georgia State University, Department of Communication](https://communication.gsu.edu/)

[有硕士有博士](https://communication.gsu.edu/graduate/)，硕士有三个方向，可以申请助教全奖。[博士项目](https://cas.gsu.edu/program/communication-studies-phd/)为 Ph.D. Public Communication。博士有两个方向：媒体与社会、说服与政治。项目为 4-5 年。详情自己关注。

- [博士申请信息](https://cas.gsu.edu/program/communication-studies-phd/#admissions-requirements)

- [教授](https://communication.gsu.edu/directory/?wpvrole=faculty&wpv_aux_current_post_id=5266&wpv_view_count=326-TCPID5266)

## Florida

### 93. [University of Florida, College of Journalism & Communications](www.jou.ufl.edu/)

博士项目很有钱，[老师很多](https://www.jou.ufl.edu/home/about/faculty-staff-directory/doctoral-faculty-directory/)，[简介](https://www.jou.ufl.edu/graduate/phd/)中说给学生提供四年自主，每年两万七到三万五美元。土豪啊!

自己查阅详情。

- [博士项目](https://www.jou.ufl.edu/graduate/phd/)

- [申请流程](https://www.jou.ufl.edu/graduate/admissions/phd-how-to-apply/)

- [教授](https://www.jou.ufl.edu/home/about/faculty-staff-directory/doctoral-faculty-directory/)

### 94. [University of Miami, School of Communication](https://com.miami.edu/)

这个博士项目也很有钱，具体给多少我不知道。在迈阿密上四年学应该也是个挺好的经历。

详情自己了解。

- [Communication PhD program](https://com.miami.edu/phd-communication/)

- [Faculty](https://com.miami.edu/directory/faculty/) （这些老师中哪些能招博士我不知道，请自己问）

### 95. [University of South Florida, Department of Communication](communication.usf.edu)

有[硕士也有博士](https://www.usf.edu/arts-sciences/departments/communication/graduate/index.aspx)，硕士[也可能给助教全奖](https://www.usf.edu/arts-sciences/departments/communication/graduate/teaching-assistantships.aspx)。详情自己查阅。

- [Graduate programs](https://www.usf.edu/arts-sciences/departments/communication/graduate/index.aspx)

- [Admissions](https://www.usf.edu/arts-sciences/departments/communication/graduate/admissions.aspx)

- [Graduate handbook](https://www.usf.edu/arts-sciences/departments/communication/documents/handbook2020-21-oct-update.pdf)

- [Faculty](https://www.usf.edu/arts-sciences/departments/communication/people/index.aspx)

### 96. [Florida State University, School of Communication](https://comm.cci.fsu.edu/)

有[硕士也有博士](https://comm.cci.fsu.edu/graduate-programs/)。2018 年我申请了这里的硕士，被录取，但不给钱。详情自己了解。

- [Graduate programs](https://comm.cci.fsu.edu/graduate-programs/)

- [Graduate admissions](https://comm.cci.fsu.edu/graduate-programs/graduate-admissions/)

- [Faculty research](https://comm.cci.fsu.edu/faculty-research/faculty-research/)

- [Faculty](https://comm.cci.fsu.edu/faculty-research/faculty-research/)

### 97. [University of Central Florida, Nicholson School of Communication and Media](https://communication.ucf.edu/)

有[四个硕士项目、一个博士项目](https://communication.ucf.edu/graduate/)。硕士项目也许可以给助教全奖。博士项目全名为 [Strategic Communication Ph.D.](https://communication.ucf.edu/degree/strategic-communication-ph-d/)

详情自己了解。

- [Communication M.A.](https://communication.ucf.edu/degree/communication/)

- [Strategic Communication Ph.D.](https://communication.ucf.edu/degree/strategic-communication-ph-d/)

- [Faculty](https://communication.ucf.edu/faculty-staff/) （这些老师中哪些能招博士我不知道，请自己问）











","['hongtaoh', 'daoyuanw']",0,,0.63,0,,,,,,3,,,
2602304,MDEwOlJlcG9zaXRvcnkyNjAyMzA0,UCSBGeoTrackrGPS,grantdmckenzie/UCSBGeoTrackrGPS,0,grantdmckenzie,https://github.com/grantdmckenzie/UCSBGeoTrackrGPS,,0,2011-10-18 21:45:11+00:00,2014-08-20 09:44:03+00:00,2012-03-31 02:03:17+00:00,,331,1,1,Java,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,1,master,1,,,['grantdmckenzie'],0,,0.81,0,,,,,,1,,,
728003671,R_kgDOK2R0Vw,LED-Checkerboard,archqn/LED-Checkerboard,0,archqn,https://github.com/archqn/LED-Checkerboard,Beginner Arduino project,0,2023-12-06 02:48:53+00:00,2024-05-27 23:10:57+00:00,2023-12-07 22:54:18+00:00,,15,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# LED-Checkerboard
Beginner Arduino project - checkerboard that tracks the last piece moved and lights up the square it moved from and the new square it was moved to.

First year undergraduate project for ECE 5 - Introduction to Electrical & Computer Engineering at University of California Santa Barbara.

~4 week project. Approximate start date: 11/02/2023. Approximate completion date: 12/05/2023

Table of Contents:
- Code Final:
    final code used for the Arduino checkerboard project
- Design Timeline:
    week by week process for constructing the board
- Future improvements:
    potential improvements and future directions for the project
- Hardware and logic:
    outline of the hardware design and explanation of the final code
- Test code for LED:
    code used for testing just the LEDs
- Test code for switches:
    code used for testing one column of the reed switches
    

",['archqn'],1,,0.77,0,,,,,,1,,,
313394183,MDEwOlJlcG9zaXRvcnkzMTMzOTQxODM=,publications-with-rmarkdown,DanOvando/publications-with-rmarkdown,0,DanOvando,https://github.com/DanOvando/publications-with-rmarkdown,A short introduction demonstrating some specific tricks for using R Markdown to write scientific publications,0,2020-11-16 18:37:29+00:00,2021-03-11 20:09:24+00:00,2020-11-17 20:32:52+00:00,,1318,4,4,HTML,1,1,1,1,1,0,11,0,0,0,mpl-2.0,1,0,0,public,11,0,4,main,1,,,['DanOvando'],0,,0.63,0,,,,,,2,,,
235936037,MDEwOlJlcG9zaXRvcnkyMzU5MzYwMzc=,ECE181B,kennyhn/ECE181B,0,kennyhn,https://github.com/kennyhn/ECE181B,Introduction to computer vision,0,2020-01-24 03:54:53+00:00,2020-04-01 14:13:18+00:00,2020-04-01 14:09:21+00:00,,62250,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# ECE 181B - Introduction to computer vision
Made by Kenny Hoang Nguyen. Course taken at University of California, Santa Barbara for winter quarter 2020.

Did some parts of the course in MATLAB so not complete set of codes are here.",['kennyhn'],1,,0.7,0,,,,,,1,,,
113585164,MDEwOlJlcG9zaXRvcnkxMTM1ODUxNjQ=,Java-Project-UC-Santa-Barbara,raymondlingxiao/Java-Project-UC-Santa-Barbara,0,raymondlingxiao,https://github.com/raymondlingxiao/Java-Project-UC-Santa-Barbara,"Hi! Here is the last course project for Adavanced Application Programming, which I took in UCSB. This project contains certain software architecture designs part in developing the 'Library information System'.",0,2017-12-08 14:53:02+00:00,2017-12-09 05:04:16+00:00,2017-12-08 15:24:28+00:00,,1476,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Java-Project-UC-Santa-Barbara
Hi! Here is the last course project for Adavanced Application Programming, which I took in UCSB. 

Total Lines > 1800

This project contains certain software architecture design patterns in developing the 'Library information System', the details can be seen in the 'Programming4.pdf'.

For architechture design part, please view it under the folder ‘UML_DesignPattern’

Thanks for your time :)
",['raymondlingxiao'],1,,0.76,0,,,,,,0,,,
258905312,MDEwOlJlcG9zaXRvcnkyNTg5MDUzMTI=,deep-illusion,metehancekic/deep-illusion,0,metehancekic,https://github.com/metehancekic/deep-illusion,"Adversarial attack toolbox for Pytorch, Tensorflow, and Jax",0,2020-04-26 00:45:12+00:00,2024-06-15 04:55:28+00:00,2021-05-08 01:46:34+00:00,,26307,7,7,Python,1,1,1,1,0,0,1,0,0,0,mit,1,0,0,public,1,0,7,master,1,,"![alt text][logo]

[logo]: https://github.com/metehancekic/deep-illusion/blob/master/figs/confused-ai.png

# Adversarial Machine Learning

With the advent of more powerful parallel computation units and huge data, we are able to train much more complex and expressive deep neural networks. That is said, deep neural nets (DNN) found its use in a wide variety of fields, ranging from computer vision to game playing agents. They are performing better on some tasks than even human experts in those fields. Despite their incredible success, it is by now well known that they are susceptible to small and carefully designed perturbations which are imperceptible to humans. The fact that DNN's can easily be fooled is a great problem since they are also used in security critical applications such as self-driving cars. Recently, research community has put a great effort to robustify neural networks against these adversarial examples. Despite great attention of research community, there is not a powerful defense mechanism found, and it is shown that defending against adversarial examples are not an easy goal. 

As another group working on this field, we share our attack codes as a library. This library is a side product of our research, and since we use this in our research as well, we made sure it works correctly and as mentioned in the original papers. To sum up, deepillusion contains easy to use and properly implemented adversarial methods.

We are open to suggestions ""metehancekic@ucsb.edu"".

# Deep Illusion #

Deep Illusion is a toolbox for adversarial attacks in machine learning. Current version is only implemented for Pytorch models. DeepIllusion is a growing and developing python module which aims to help adversarial machine learning community to accelerate their research. Module currently includes complete implementation of well-known attacks (PGD, FGSM, R-FGSM, CW, BIM etc..). All attacks have an apex(amp) version which you can run your attacks fast and accurately. We strongly recommend that amp versions should only be used for adversarial training since it may have gradient masking issues after neural net gets confident about its decisions. All attack methods have an option (Verbose: False) to check if gradient masking is happening. 

All attack codes are written in functional programming style, therefore, users can easily call the method function and feed the input data and model to get perturbations. All codes are documented, and contains the example use in their description. Users can easily access the documentation by typing ""??"" at the and of the method they want to use in Ipython (E.g FGSM?? or PGD??). Output perturbations are already clipped for each image to prevent illegal pixel values. We are open to contributers to expand the attack methods arsenal.

We also include the most effective current approach to defend DNNs against adversarial perturbations which is training the network using adversarially perturbed examples. Adversarial training and testing methods are included in torchdefenses submodule. 

Current version is tested with different defense methods and the standard models for verification and we observed the reported accuracies.

Maintainers:
    [WCSL Lab](https://wcsl.ece.ucsb.edu), 
    [Metehan Cekic](https://www.ece.ucsb.edu/~metehancekic/), 
    [Can Bakiskan](https://wcsl.ece.ucsb.edu/people/can-bakiskan), 
    [Soorya Gopal](https://wcsl.ece.ucsb.edu/people/soorya-gopalakrishnan),
    [Ahmet Dundar Sezer](https://wcsl.ece.ucsb.edu/people/ahmet-sezer) 


## Dependencies #

> numpy                     1.16.4\
> tqdm                      4.31.1

**torchattacks**
> pytorch                   1.4.0\
> apex                      0.1  (optional)

**tfattacks**
> tensorflow                   

**jaxattacks**
> jax

## Installation #

The most recent stable version can be installed via python package installer ""pip"", or you can clone it from the git page.

```bash
pip install deepillusion
```
or 
```bash
git clone git@github.com:metehancekic/deep-illusion.git
```

## Example Use #

As mentioned earlier, our adversarial methods are functional instead of modular type. Therefore, all you need to get the perturbations is feeding input data and its labels along with the attack parameters. 

To standardize the arguments for all attacks, methods accept attack parameters as a dictionary named as attack_params which contains the necessary parameters for each attack. Furthermore, attack methods get the data properties such as the maximum and the minimum pixel value as another dictionary named data_params. These dictinaries make function calls concise and standard for all methods.

Following code snippets show PGD and FGSM usage.

```python
from deepillusion.torchattacks import PGD, FGSM, RFGSM

##### PGD ######
data_params = {""x_min"": 0., ""x_max"": 1.}
attack_params = {
    ""norm"": ""inf"",
    ""eps"": 8./255,
    ""step_size"": 2./255,
    ""num_steps"": 7,
    ""random_start"": False,
    ""num_restarts"": 1}
    
pgd_args = dict(net=model,
                x=data,
                y_true=target,
                data_params=data_params,
                attack_params=attack_params,
                verbose=False,
                progress_bar=False)               
perturbs = PGD(**pgd_args)
data_adversarial = data + perturbs

##### FGSM #####
data_params = {""x_min"": 0., ""x_max"": 1.}
attack_params = {""norm"": ""inf"",
                 ""eps"": 8./255}
fgsm_args = dict(net=model,
                 x=data,
                 y_true=target,
                 data_params=data_params,
                 attack_params=attack_params)
perturbs = FGSM(**fgsm_args)
data_adversarial = data + perturbs
```

Analysis tools come handy when one needs to evaluate his/her model against adversarial examples.
Whitebox and blackbox test functions are inside analysis can be used as follow.


```python
from deepillusion.torchattacks import PGD, FGSM, RFGSM, BIM, PGD_EOT
from deepillusion.torchattacks.analysis import whitebox_test, substitute_test

##### PGD ######
data_params = dict(x_min= 0., 
                   x_max=1.)
                   
attack_params = dict(norm=""inf"",
                     eps=0.3,
                     alpha=0.4,
                     step_size=0.01,
                     num_steps=100,
                     random_start=False,
                     num_restarts=1,
                     EOT_size=20)

attack_args = dict(data_params=data_params,
                   attack_params=attack_params,
                   loss_function=""cross_entropy"",
                   verbose=False)

adversarial_args = dict(attack=PGD,
                        attack_args=attack_args)

whitebox_test_args = dict(model=model,
                          test_loader=test_loader,
                          adversarial_args=adversarial_args,
                          verbose=True,
                          progress_bar=True)

attack_loss, attack_acc = whitebox_test(**whitebox_test_args)

substitute_test_args = dict(model=model,
                            substitute_model=another_model,
                            test_loader=test_loader,
                            adversarial_args=adversarial_args,
                            verbose=True,
                            progress_bar=True)

attack_loss, attack_acc = substitute_test(**substitute_test_args)
```

Last but not least, you can check if the perturbations are legal by using get_perturbation_stats:

```python
from deepillusion.torchattacks.analysis import get_perturbation_stats

get_perturbation_stats_args = dict(clean_data=clean_data, 
                                   adversarial_data=adversarial_data, 
                                   epsilon=epsilon, 
                                   norm=""inf"", 
                                   verbose=True)

perturbation_properties = get_perturbation_stats(**get_perturbation_stats_args)
```

## Update #

Deepillusion is a growing and developing library, therefore we strongly recommend to upgrade deepillusion regularly:

```bash
pip install deepillusion --upgrade
```

## Current Version #


0.3.2

## Module Structure #

In case investigation of the source codes are needed, this is how our module is structured:

```
deep-illusion
│   README.md
│
|───deepillusion
|   |   _utils.py               Utility functions
|   |
|   |───torchattacks
|   |   │   _fgsm.py                     Fast Gradient Sign Method
|   |   │   _rfgsm.py                    Random Start + Fast Gradient Sign Method
|   |   │   _pgd.py                      Projected Gradient Descent
|   |   │   _bim.py                      Basic Iterative Method
|   |   │   _soft_attacks.py             Soft attack functions
|   |   │ 
|   |   |───amp
|   |   |   │   _fgsm.py                     Mixed Precision (Faster) - Fast Gradient Sign Method
|   |   |   │   _rfgsm.py                    MP - Random Start + Fast Gradient Sign Method
|   |   |   │   _cw.py                       MP - Carlini Wagner Linf
|   |   |   │   _pgd.py                      MP - Projected Gradient Descent
|   |   |   |   _soft_attacks.py             MP - Soft attack functions
|   |   |
|   |   └───analysis
|   |       │   _perturbation_statistics     Perturbations statistics functions
|   |       │   _evaluate                    Whitebox, blackbox evaluations codes (test functions)
|   |       │   
|   |       └───plot 
|   |           │   _loss_landscape.py       loss landscape plotter
|   |           │   
|   |
|   |───torchdefenses
│   |   |   _adversarial_train.py       Adversarial Training - Adversarial Testing
│   |   |   _trades_train.py            Trades Training - Trades Loss
|   |   │   
|   |   └───amp
|   |       │   _adversarial_train.py     MP (Faster) - Adversarial Training - Adversarial Testing 
|   |
|   |───tfattacks
|   |   |
|   |
|   └───jaxattacks
|       |
|
└───tests
    |   test_....py                         Test functions

```
## Sources #

- [PyPi page for the code](https://pypi.org/project/deepillusion/)

- [Git repo for the code](https://github.com/metehancekic/deep-illusion)

","['metehancekic', 'canbakiskan']",1,,0.69,0,,,,,,2,,,
564510012,R_kgDOIaW9PA,homework-2-mac,EDS220-Fall2022-org/homework-2-mac,0,EDS220-Fall2022-org,https://github.com/EDS220-Fall2022-org/homework-2-mac,homework-2-mac created by GitHub Classroom,0,2022-11-10 21:48:38+00:00,2022-11-10 21:48:44+00:00,2022-12-05 04:10:04+00:00,,1058,0,0,Jupyter Notebook,1,1,1,1,0,0,1,0,0,1,,1,0,0,public,1,1,0,main,1,1,"# EDS220_Fall2022_HW2

## Using Microsoft Planetary Computer Datasets to Examine Fire and Snow in California

Microsoft's Planetary Computer (MPC) combines a catalog of global environmental data with intuitive APIs, a flexible scientific environment that allows users to answer global questions about that data, and applications that put those answers in the hands of conservation stakeholders.

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/EDS220-Fall2022-org/homework-2-mac/HEAD)

#### Authors
- Meagan Brown, UC Santa Barbara, meagan_brown@ucsb.edu
- Andre Dextre, UC Santa Barbara, adextre@ucsb.edu
- Carlo Broderick, UC Santa Barbara, carlobroderick@ucsb.edu

#### Contents:
- finalproject_MAC.ipynb: this file outlines the project and give a more thorough summary of the project. 
- environment.yml: Template environment file for use in creating Binder environment for running Jupyter notebook

#### Datasets:
- [landsat](https://www.nasa.gov/mission_pages/landsat/overview/index.html)
- [MODIS Snow Cover 8-day](https://planetarycomputer.microsoft.com/dataset/modis-10A2-061)
- [MODIS Thermal Anomalies/Fire 8-Day](https://planetarycomputer.microsoft.com/dataset/modis-14A2-061)

#### References:
- Giglio, L., Justice, C. (2021). <i>MODIS/Terra Thermal Anomalies/Fire 8-Day L3 Global 1km SIN Grid V061</i> [Data set]. NASA EOSDIS Land Processes DAAC. Accessed 2022-11-29 from https://doi.org/10.5067/MODIS/MOD14A2.061
- Hall, D. K. and G. A. Riggs. (2021). MODIS/Terra Snow Cover 8-Day L3 Global 500m SIN Grid, Version 61 [Data Set]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. https://doi.org/10.5067/MODIS/MOD10A2.061. Date Accessed 11-29-2022.
- Landsat Collection 2 Level-2 (2022), NASA and US Geological Survey, Date Accessed 2022-11-29 from https://www.usgs.gov/landsat-missions/landsat-collection-2-level-2-science-products

#### Resources:
- geoJSON tutorial: https://www.youtube.com/watch?v=Kr658rFToOs
- geopandas tutorial : https://www.youtube.com/watch?v=vSk-CfqKRpw&list=PL-2EBeDYMIbRppDpfO5osdSeUFIOuZz-2&index=4
- STAC API: https://stacspec.org/en

## How to create a Microsoft Planetary Computer account and access the Hub

- Step 1: Go to: [the 'Hub' tab at the top of the Microsoft Planetary Computer website](https://planetarycomputer.microsoft.com)

- Step 2: Sign up for a Microsoft Account or choose ""other log in options"" and sign in using your GitHub account

- Step 3: Click 'Request Access' 

- Step 4: You are sent an email that indicates your access request has been approved, from the email you can click the [Hub](https://planetarycomputer.microsoft.com/compute) link 

- Step 5: Clone [our Repo](https://github.com/EDS220-Fall2022-org/homework-2-mac) into [the Hub](https://planetarycomputer.microsoft.com/compute)
","['meaganbrown', 'CarloBroderick', 'andredextre', 'github-classroom[bot]']",1,,0.76,0,,,,,,2,,,
331126974,MDEwOlJlcG9zaXRvcnkzMzExMjY5NzQ=,cs291a_project2_template,Justin-Nilsen/cs291a_project2_template,0,Justin-Nilsen,https://github.com/Justin-Nilsen/cs291a_project2_template,,0,2021-01-19 22:29:39+00:00,2021-01-19 22:29:46+00:00,2021-01-19 22:29:42+00:00,,1,0,0,Ruby,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Project 2 Template

## Initial Set up

The following steps should only need to be done once:

### Set Environment Variable

Add the following to your `.bash_profile` script, or similar for your shell:

```sh
# If your ucsb email is user@ucsb.edu, then YOUR_ACCOUNT_NAME is user
#
# Note: If you have an underscore in your account name, please replace with a hypen.
export CS291_ACCOUNT=YOUR_ACCOUNT_NAME
```

### Install `gcloud` tool

Follow the instructions here:
https://cloud.google.com/sdk/docs/#install_the_latest_cloud_tools_version_cloudsdk_current_version

### Authenticate with Google

Make sure you select your `@ucsb.edu` account when authenticating.

```sh
gcloud auth login
```

### Verify the above works

```sh
gcloud projects describe cs291a
```

The above should produce the following output:

```
createTime: '2020-12-29T18:55:55.506Z'
lifecycleState: ACTIVE
name: cs291a
parent:
  id: '254441457261'
  type: folder
projectId: cs291a
projectNumber: '318955983951'
```

### Create Application Default Credentials

Again, make sure you select your @ucsb.edu account when authenticating.

```sh
gcloud auth application-default login
```

### Install Docker

Follow the instructions here: https://www.docker.com/products/docker-desktop

### Link Docker and Gcloud

```sh
gcloud auth configure-docker us.gcr.io
```

## Develop Locally

The following commands are intended to be run from within the directory
containing your project (e.g., your copy of this repository).

Edit your `app.rb` file however you want then follow the next two steps to test your
application:

### Build Container

```sh
docker build -t us.gcr.io/cs291a/project2_${CS291_ACCOUNT} .
```

### Run Locally

```sh
docker run -it --rm \
  -p 3000:3000 \
  -v ~/.config/gcloud/application_default_credentials.json:/root/.config/gcloud/application_default_credentials.json \
  us.gcr.io/cs291a/project2_${CS291_ACCOUNT}
```

### Test Using CURL

```sh
curl -D- localhost:3000/
```

The default application should provide output that looks like the following:

```http
HTTP/1.1 200 OK
Content-Type: text/html;charset=utf-8
X-XSS-Protection: 1; mode=block
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
Content-Length: 12

Hello World
```

## Production Deployment

Each time you want to deploy your application to Google Cloud Run, perform the
following two steps:

### Push Container to Google Container Registry

```sh
docker push us.gcr.io/cs291a/project2_${CS291_ACCOUNT}
```

### Deploy to Google Cloud Run

```sh
gcloud beta run deploy \
  --allow-unauthenticated \
  --concurrency 80 \
  --image us.gcr.io/cs291a/project2_${CS291_ACCOUNT} \
  --memory 128Mi \
  --platform managed \
  --project cs291a \
  --region us-central1 \
  --service-account project2@cs291a.iam.gserviceaccount.com \
  --set-env-vars RACK_ENV=production \
  ${CS291_ACCOUNT}
```

The last line of output should look similar to the following:

```
Service [{ACCOUNT_NAME}] revision [{ACCOUNT_NAME}-00018] has been deployed and is serving 100 percent of traffic at https://{ACCOUNT_NAME}-66egyap56q-uc.a.run.app
```

### View Logs

1. Browse to: https://console.cloud.google.com/run?project=cs291a

2. Click on the service with your ACCOUNT_NAME

3. Click on ""LOGS""

4. Browse logs, and consider changing the filter to ""Warning"" to find more pressing issues.

## Resources

- https://cloud.google.com/run/docs/quickstarts/build-and-deploy
- https://googleapis.dev/ruby/google-cloud-storage/latest/index.html

## Possible Errors

### invalid reference format

Re-run the `export` command.
",['Justin-Nilsen'],1,,0.83,0,,,,,,1,,,
236874501,MDEwOlJlcG9zaXRvcnkyMzY4NzQ1MDE=,lab04-sssaaaaaarrra,ucsb-cs56-w20/lab04-sssaaaaaarrra,0,ucsb-cs56-w20,https://github.com/ucsb-cs56-w20/lab04-sssaaaaaarrra,,0,2020-01-29 00:36:16+00:00,2020-01-30 00:43:09+00:00,2020-01-30 00:43:06+00:00,,368,0,0,Java,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,1,"# STARTER_lab04

Starter code for: <https://ucsb-cs56.github.io/w20/lab/lab04/>

* Sara Mandic sssaaaaaarrra
* github:<https://github.com/ucsb-cs56-w20/lab04-sssaaaaaarrra/>
* javadoc:<https://ucsb-cs56-w20.github.io/lab04-sssaaaaaarrra/apidocs/>
* javadoc tests: <https://ucsb-cs56-w20.github.io/lab04-sssaaaaaarrra/testapidocs/>

",['pconrad'],1,,0.79,0,,,,,,0,,,
704081354,R_kgDOKfdtyg,Yifanz,YifanZhang714/Yifanz,0,YifanZhang714,https://github.com/YifanZhang714/Yifanz,"Yifan Zhang, Graduated from University of California, Santa Barbara in FMS major, is attending the MSBA program in Brandeis International Business School",0,2023-10-12 13:52:19+00:00,2023-10-14 01:40:47+00:00,2023-10-14 01:52:45+00:00,,4,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Yifanz
# Zhaoyi Xie


#Here is my update
#Yifan Zhang, who graduated from the University of California, Santa Barbara, with three internships in GanZhou Aluminum， Plum Adventure, and JP Morgan & Co, is attending the MSBA program at Brandeis University International Business School.

#Zhaoyi Xie, who graduated from Colorado University Boulder, is attending the MSBA program at Brandeis University International Business School.
","['YifanZhang714', 'JoeyXie-SZSR']",1,,0.71,0,,,,,,1,,,
144201218,MDEwOlJlcG9zaXRvcnkxNDQyMDEyMTg=,sparkjava-01,ucsb-cs56-pconrad/sparkjava-01,0,ucsb-cs56-pconrad,https://github.com/ucsb-cs56-pconrad/sparkjava-01,,0,2018-08-09 20:36:36+00:00,2021-09-06 20:29:54+00:00,2018-10-10 20:12:20+00:00,,1909,1,1,Java,1,1,1,1,1,0,95,0,0,1,mit,1,0,0,public,95,1,1,master,1,1,"# sparkjava-01

The simplest possible SparkJava web app (Hello World)

* [javadocs](https://ucsb-cs56-pconrad.github.io/sparkjava-01/apidocs/index.html)
* [web page generated by Maven (NOT THE WEB APP)](https://ucsb-cs56-pconrad.github.io/sparkjava-01/index.html).  This is simply documentation automatically generated by Maven, not the actual running web app.


# To use

| To do this | Do this |
| -----------|-----------|
| run the program | Type `mvn exec:java`.  Visit the web page it indicates in the message |
| check that edits to the pom.xml file are valid | Type `mvn validate` |
| clean up so you can recompile everything  | Type `mvn clean` |
| edit the source code for the app | edit files in `src/main/java`.<br>Under that the directories for the package are `edu/ucsb/cs56/pconrad`  |
| edit the source code for the app | edit files in `src/test/java`.<br>Under that the directories for the package are `edu/ucsb/cs56/pconrad`  |
| compile    | Type `mvn compile` |
| run junit tests | Type `mvn test` |
| build the website, including javadoc | Type `mvn site-deploy` then look in either `target/site/apidocs/index.html`  |
| copy the website to `/docs` for publishing via github-pages | Type `mvn site-deploy` then look for javadoc in `docs/apidocs/index.html` |	
| make a jar file | Type `mvn package` and look in `target/*.jar` |

| run the main in the jar file | Type `java -jar target/sparkjava-demo-01-1.0-jar-with-dependencies.jar ` |
| change which main gets run by the jar | Edit the `<mainClass>` element in `pom.xml` |
",['pconrad'],1,,0.81,0,,,,,,1,,,
475616070,R_kgDOHFlTRg,just-the-class,martinsolent/just-the-class,0,martinsolent,https://github.com/martinsolent/just-the-class,,0,2022-03-29 20:52:27+00:00,2022-03-29 21:41:27+00:00,2022-10-24 13:34:04+00:00,https://martinsolent.github.io/just-the-class/,44,0,0,HTML,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"---
layout: home
title: Just the Class
nav_exclude: true
permalink: index.html
seo:
  type: Course
  name: Just the Class
---

# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([DS1](https://ucsb-ds.github.io/ds1-f20/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
",['martinsolent'],1,,0.85,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
663388825,R_kgDOJ4qCmQ,UCSB-Bite----Redesign,LuckDuracell/UCSB-Bite----Redesign,0,LuckDuracell,https://github.com/LuckDuracell/UCSB-Bite----Redesign,,0,2023-07-07 07:24:13+00:00,2023-07-07 07:24:29+00:00,2023-07-07 07:24:23+00:00,,2408,0,0,Swift,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,['LuckDuracell'],0,,0.75,0,,,,,,1,,,
42734478,MDEwOlJlcG9zaXRvcnk0MjczNDQ3OA==,extract-chi,jdunic/extract-chi,0,jdunic,https://github.com/jdunic/extract-chi,,0,2015-09-18 16:41:01+00:00,2015-09-18 16:43:42+00:00,2015-09-18 16:43:41+00:00,,140,0,0,R,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# extract-chi

This repository contains code that allows cumulative human impact values to be extracted from geotiffs. More information about the dataset can be found here: [https://www.nceas.ucsb.edu/globalmarine](https://www.nceas.ucsb.edu/globalmarine). 
",['jdunic'],0,,0.72,0,,,,,,1,,,
914583694,R_kgDONoNwjg,eds-232-discussion,silkieMoth/eds-232-discussion,0,silkieMoth,https://github.com/silkieMoth/eds-232-discussion,All discussion assignments for eds 232 at UCSB.,0,2025-01-09 22:08:27+00:00,2025-03-04 23:27:35+00:00,2025-03-04 23:27:32+00:00,,2360,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# eds-232-discussion
All discussion assignments for eds 232 at UCSB.
",['silkieMoth'],1,,0.72,0,,,,,,1,,,
693865872,R_kgDOKVuNkA,d18O_lags,devinrand/d18O_lags,0,devinrand,https://github.com/devinrand/d18O_lags,,0,2023-09-19 21:48:44+00:00,2025-01-22 19:26:25+00:00,2025-01-22 19:26:16+00:00,,252736,1,1,MATLAB,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,1,master,1,,"**Package to calculate benthic d18O lags using methodology published in Rand et al., (2024). This package can be used to calculate lags between:** 
  1. radiocarbon and benthic d18O age models
  2. radiocarbon and synthetic d18O age models (Gebbie, 2012)
  3. benthic d18O stacks (using a Bayesian inversion).

To reproduce results from Rand et al., (2024) or Rand, (2024) enter the number 1-8 on line 20 of main.m. The corresponding run is indicated in the comments on line 10-17.

**BIGMACS_inputs and BIGMACS_outputs contain the BIGMACS input/output files for the:**
  1. Brazil Margin (Rand et al., 2024)
  2. Atlantic compilation (Rand, 2024)
  3. Iberian Margin vs Equatorial Pacific (Rand, 2024) 

**Description of functions saved in the scripts folder:**
  1. NaN_check: removes time-slices if the percentage of MCMC samples that require extrapolation are greater than the specified critical value.
  2. Analytical: Applies Bayesian inversion to calculate lag between two stacks drawn with a Gaussian process regression (described in Rand, 2024).
  3. calc_lag_diff: finds difference between 2 lag stacks
  4. calc_lag_stack: calculates average of multiple lag time-series
  5. calculate_lag: finds the age difference between radiocarbon and d18O age models by interpolating and subtracting MCMC samples.
  6. calculate_lag_gebbie: calculates time difference between the aligned synthetic d18O and model time.

**Citations:**

Rand, D., L. E. Lisiecki, T. Lee, C. W. Lawrence, and G. Gebbie. ""Quantifying benthic δ18O lags across Termination 1: A probabilistic approach based on     radiocarbon and benthic δ18O chronologies."" Geochemistry, Geophysics, Geosystems 25, no. 2 (2024): e2023GC011068.

Lee, Taehee, Devin Rand, Lorraine E. Lisiecki, Geoffrey Gebbie, and Charles Lawrence. ""Bayesian age models and stacks: combining age inferences from radiocarbon and benthic δ 18 O stratigraphic alignment."" Climate of the Past 19, no. 10 (2023): 1993-2012.

Rand, Devin Scott. ""Ocean Sediment Core Age Models, Stacks, and Benthic Foraminiferal δ18O Lags."" PhD diss., UC Santa Barbara, 2023.

Gebbie, Geoffrey. ""Tracer transport timescales and the observed Atlantic‐Pacific lag in the timing of the Last Termination."" Paleoceanography 27, no. 3 (2012).
Harvard        

",['devinrand'],1,,0.65,0,,,,,,2,,,
43238892,MDEwOlJlcG9zaXRvcnk0MzIzODg5Mg==,UCSB,ravikumarsureshbabu/UCSB,0,ravikumarsureshbabu,https://github.com/ravikumarsureshbabu/UCSB,Code done @ UCSB,0,2015-09-27 07:54:46+00:00,2015-09-27 08:14:41+00:00,2015-09-27 08:14:40+00:00,,124,0,0,C,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# UCSB
",[],1,,0.81,0,,,,,,1,,,
923599180,R_kgDONw0BTA,PNAS-WBGT-fertility-Nigeria,nbrooks09/PNAS-WBGT-fertility-Nigeria,0,nbrooks09,https://github.com/nbrooks09/PNAS-WBGT-fertility-Nigeria,"Replication code for ""Humid-heat shifts conceptions and increases pregnancy termination risks in Nigeria"" published in PNAS 2025.",0,2025-01-28 14:39:34+00:00,2025-02-12 19:18:18+00:00,2025-02-12 19:18:14+00:00,,44,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# PNAS-WBGT-fertility-Nigeria
Replication code for ""Humid-heat shifts conceptions and increases pregnancy termination risks in Nigeria"" published in PNAS 2025.

The materials in this repository includes public data and the scripts used to produce the figures and tables appearing in the main text and supplementary information of the paper.

If you find errors in the code or have questions or suggestions, please contact Nina Brooks at nrbrooks@bu.edu.

## Organization of repository
To replicate the analysis your directory should be structured as followed:

data/raw: stores raw DHS data (see note below)

data/clean: stores clean data files for analysis

scripts/: scripts for cleaning, merging data, and analyzing data.

figures/: stores pdf figures output by analysis script.

tables/: stores latex tables produced by analysis script.

## Data
### DHS
We used Nigeria DHS data extracted from [IPUMS DHS](https://www.idhsdata.org/idhs/). DHS data is publicly available, with a registered user account. To replicate this analysis, you must first register for a DHS account and if you wish to use IPUMS DHS to extract the data, also register for an IPUMS DHS account (both free). Both IPUMS and the DHS have extensive guides and tutorials on working with the data. The [IPUMS Climate Change and Health Research Hub](https://tech.popdata.org/dhs-research-hub/) also has resources on how to import IPUMS  data into R using the `ipumsr` package. Once you have accounts, this analysis utilizes the 2008 and 2018 surveys with the fertility calendar module and the complete births history from the 1990, 2003, 2008, 2018 waves. In addition to demographic, fertility, and conceptrceptive use variables, you must also obtain access to the GPS data (which requires specific permission). 

### Heat
We estimate daily maximum shaded wet bulb globe temperature (WBGTmax) for Nigeria DHS clusters from 1983 - 2016 using CHIRTS-daily. The raw CHIRTSdaily heat record is publicly available from the University of California, Santa Barbara Climate Hazards Center at https://data.chc.ucsb.edu/products/CHIRTSdaily/. The approach to produce the WBGTmax from CHIRTSdaily is described in C Tuholske, et al., Global urban population exposure to extreme heat. *Proc. Natl. Acad. Sci.* 118, e2024792118 (2021) and the output is available at https://data.chc.ucsb.edu/people/cascade/UHE-daily/wbgtmax/. This repository contains code to extract the WBGTmax data for the Nigeria DHS clusters.

## Scripts
There are 8 scripts to reproduce the data cleaning and analysis for this paper. Note that some are python scripts and some are Rmd files.

`setup.R`: this script loads necessary R packages and defines custom functions that will be used in the subsequent scripts. 

`01_extractWBGT.py`: this code extracts the daily WBGTmax record in 5km buffer zones around each Nigeria DHS cluster.

`02_annual_avg_wbgtmax.ipynb`: this code produces the annual average WBGTmax across Nigeria used to create Figure 1.

`03_prepare_WBGTdata.Rmd`: creates monthly and annual WBGTmax (from daily record) for each DHS cluster.

`04_import_clean_DHS.Rmd`: imports IPUMS DHS data (from `data/raw`) and cleans variables for analysis. Creates woman-level data, woman-month (from calendar), and the unbalanced panel of births and saves them to `data/clean'.

`05_merge_heat_DHS.Rmd`: merges WBGTmax with all dhs datasets. specifically, merges heat and woman-month calendar data to create survival structured data for discrete-time analysis, merges heat with woman-month calendar to create annual pregnancy-level data, merges heat with birth panel to create annual births datasets.

`06_makeFig1_Nigeria_AvgHeat83-2016.ipynb`: this script creates the map of annual average WBGT and change across Nigeria from 1983-2016.

`07_run_analysis_heat_fertility.Rmd`: runs all analysis, including supplementary analysis, and outputs figures and tables from main paper and SI.
","['nbrooks09', 'cascadet']",0,,0.61,0,,,,,,1,,,
464328179,R_kgDOG60V8w,ultimate_Cache,markoristicc/ultimate_Cache,0,markoristicc,https://github.com/markoristicc/ultimate_Cache,Final Project for W21 CS190A: Algorithmic Decision Making @ UCSB,0,2022-02-28 03:43:15+00:00,2022-02-28 19:49:49+00:00,2022-03-08 13:21:47+00:00,,76,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# ultimate_Cache
Final Project for W21 CS190A: Algorithmic Decision Making @ UCSB
","['alexandersrioudom', 'markoristicc']",1,,0.85,0,,,,,,1,,,
491694349,R_kgDOHU6pDQ,thesis,resultsmayterry/thesis,0,resultsmayterry,https://github.com/resultsmayterry/thesis,senior thesis for ucsb econ,0,2022-05-12 23:16:19+00:00,2022-05-12 23:16:19+00:00,2022-05-12 23:16:20+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,[],1,,0.58,0,,,,,,1,,,
490344349,R_kgDOHToPnQ,asm-2022_shiny-workshop,njlyon0/asm-2022_shiny-workshop,0,njlyon0,https://github.com/njlyon0/asm-2022_shiny-workshop,Repo for All Scientists' Meeting (ASM) R Shiny workshop,0,2022-05-09 15:38:46+00:00,2024-08-22 20:17:05+00:00,2024-08-13 16:20:19+00:00,https://njlyon0.github.io/asm-2022_shiny-workshop/,17161,4,4,SCSS,1,1,1,1,1,0,0,0,0,0,cc-by-sa-4.0,1,0,0,public,0,0,4,main,1,,"# All Scientists' Meeting - R Shiny Workshop

### Team led by [Gabe De La Rosa](https://www.gabrieldelarosa.com/), [Francisco J Guerrero](https://github.com/guerrero-fj) & [Nick J Lyon](https://njlyon0.github.io/)

This repository includes all of the content for the workshop entitled **""[Shiny App for Sharing Science](https://2022lterasm.sched.com/event/13kyO/22x053-shiny-app-for-sharing-science)""** to be presented at the 2022 LTER [All Scientists' Meeting](https://lternet.edu/2022-all-scientists-meeting/).

To supplement this repository, we have created a [repository to house all of our example Shiny apps](https://github.com/njlyon0/asm-2022_shiny-workshop-examples) that we'll be coding with you all in the workshop. You can visit that repository to use the apps that are embedded in the code chunks of this website (this saves you from needing to copy/paste each code chunk into a new script yourself).

## Workshop Abstract:

R Shiny applications are a powerful way to let users explore scientific data in a curated environment. Shiny is a flexible platform that allows users to create both intricate apps and simple interfaces for sharing data with collaborators. After this workshop, attendees will be able to (1) define the fundamental structure of a Shiny app, (2) implement different user interface elements, (3) write and format useful labels and headers, and (4) learn to partition Shiny app components to create clean, concise, and easy-to-navigate apps. Workshop participants follow a guided coding session to create a demo shiny app, with an emphasis on creating an app to share and interact with scientific data. We will leverage pre-written ""example apps"" to facilitate attendees writing their own apps. Please bring a laptop computer. There will also be time set aside throughout the workshop to discuss issues and share best practices so whether you're a veteran Shiny user or have never heard of it, we welcome your participation.

## Acknowledgment

The development of this training material is supported through the Long Term Ecological Research Network Office (LNO) (NSF award numbers 1545288 and 1929393) and the National Center for Ecological Analysis and Synthesis, UC Santa Barbara.

**Citation:** Nick Lyon, Gabe De La Rosa, and Francisco J Guerrero. 2023. Shiny Apps for Sharing Science.

<br>
<hr>

<p align=""center"">
<a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/""><img alt=""Creative Commons License"" style=""border-width:0"" src=""https://i.creativecommons.org/l/by/4.0/88x31.png"" /></a><br />This work is licensed under a <a rel=""license"" href=""http://creativecommons.org/licenses/by/4.0/"">Creative Commons Attribution 4.0 International License</a>.
</p>
","['njlyon0', 'gdlr', 'guerrero-fj']",1,,0.68,0,,,,,,1,,,
14595231,MDEwOlJlcG9zaXRvcnkxNDU5NTIzMQ==,ucsb_code,manuelfs/ucsb_code,0,manuelfs,https://github.com/manuelfs/ucsb_code,Utilities to handle cfA ntuples,0,2013-11-21 17:59:32+00:00,2013-12-16 06:12:25+00:00,2013-12-16 06:12:23+00:00,,492,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"ucsb_code
==========

Utilities to handle cfA ntuples.

Code may be compiled with ./compile.sh. Executables and scripts are stored in scripts directory 
and are all intended to be run from the root ucsb_code directory (i.e. not from within the scripts directory).

Repository is setup with the assumption that (assuming the repository is locally called ucsb_code) 
there is a directory ucsb_code/../data. This directory is intended to store cfA-style .root files 
containing data from cfA needed in the analysis. The directory can be filled (but not created) by running 
./scripts/make_skims.sh.
",[],1,,0.81,0,,,,,,2,,,
9265037,MDEwOlJlcG9zaXRvcnk5MjY1MDM3,cs56-games-pong,ucsb-cs56-projects/cs56-games-pong,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-games-pong,-,0,2013-04-06 19:03:18+00:00,2018-02-16 01:21:53+00:00,2018-03-21 22:24:05+00:00,,928,2,2,Java,1,1,1,1,0,0,12,0,0,17,,1,0,0,public,12,17,2,master,1,1,"Pong
==============

This is an implementation of the classic game Pong, with cooperative multiplayer support.

To compile and run: ""ant run"" in the main directory

There are seven game mode options that correspond to the size of the window when playing.

How To Play:
Player 1 (on the left)
  ""W"" -- Move up
  ""S"" -- Move down
  ""a"" -- grab ball (hold to grab)

Player 2 (on the right)
  up arrow -- Move up
  down arrow -- Move down
  left arrow -- grab ball (hold to grab)

Instructions:
  When the ball is stopped, Press the spacebar to activate motion.
  Try to not let the ball hit your side of the screen or you will lose a life.
  The player who wins the round, receives the total number of hits added to their score.
  Each Player has 3 lives.
  The Winner is whoever has the most lives at the end, their name will be prompted.
  If their score is in the top 5 of the High Score, then it will be saved to the High Score.


  ![](http://i.imgur.com/NAKKNhR.jpg)
  ![](http://i.imgur.com/jdCMrej.jpg)

TODO: maybe add a few more tickets, most of the existing ones wouldn't take much time to implement.  Other than that it builds and runs fine (David Coffill)

project history(Newest remarks to oldest)
===============

### Fall 2017 final remarks

`F17 Andrew Polk, Victoria Sneddon, 2PM lab`

* What the code does:
  * allows users to choose which mode of the game ""pong"" they want to play and the colors of the ball and paddles
* Features to be added:
  * AI opponent
  * Change y ball velocity when ball hits paddle
* Bugs:
  * issues with screen size for some of the modes
  * ball can get stuck behind paddle and wall collisions
  * pause text doesn't automatically show up always
* Opportunities for Refactoring:
  * code can still be better organized, neater
* Advice:
  * program for extensible
  * think about the poor future students that will have to fix your code 

### Winter 2016 final remarks

`W16: Angel Ortega, Ben Patient, 4PM lab`

* What the code does:
  * The code is a simple game of Pong for two players, with scores.
* Features that could be added:
  * AI for the paddle
  * Multiple ball modes
  * Unit-tests
* What bugs exist:
  * Pausing does not pause the paddles
* Opportunities for refactoring:
  * Make variables private, prefer to use nonstatic variables
  * Remove coupling
  * Consider builder pattern for GUI creation

### Fall 2016 final remarks
TODO:
* Add instructions for the ball grabbing feature, we implemented it so that holding ""a"" when the ball is within close range of the left paddle grabs the balls, and ""left arrow"" grabs the balls when they are in range of the right paddle.

* Fix the ball colliding with the top/bottom wall when grabbing the ball with paddle (play around with this and you will clearly see the issue)
* Fix how the game recognizes pausing when the ball is attached
* Integrate two balls with all the difficulty modes and extra balls

How To Play:
Player 1 (on the left)
  ""W"" -- Move up
  ""S"" -- Move down
  ""a"" -- grab ball (hold to grab)

Player 2 (on the right)
  up arrow -- Move up
  down arrow -- Move down
  left arrow -- grab ball (hold to grab)
  SUGGESTIONS
  Integrate grab paddle with thread so that it when the user presses either ""a"" or ""left arrow"", the game processes it right as the ball and paddle collide. (right now we are using distance which allows you to grab the ball while it isn't touching the paddle)
  Refactor how the two balls is implemented so that multiple balls will be easier to work with (in the code)

### Winter 2014 remarks
```
 W14 | bronhuston 4pm | sarahdarwiche,benjaminhartl | An implementation of the classic game Pong, with cooperative multiplayer support.
```

An implementation of the classic game Pong, with cooperative multiplayer support.

To Compile and Run:
""ant run"" in the main directory

The three difficulty options correspond to the size of the window when playing.

How To Play:
Player 1 (on the left)
  ""W"" -- Move up
  ""S"" -- Move down

Player 2 (on the right)
  up arrow -- Move up
  down arrow -- Move down

When the ball is stopped, Press the spacebar to activate motion.
Try to not let the ball hit your side of the screen or you will lose a life.
The player who wins the round, receives the total number of hits added to their score.
Each Player has 3 lives.
The Winner is whoever has the most lives at the end, their name will be prompted.
If their score is in the top 5 of the High Score, then it will be saved to the High Score.
","['joyoyoyoyoyo', 'benjaminhartl', 'bkhanijau', 'vsneddon', 'jdum66', 'joelbagan', 'zhanchengqian', 'sanchitg94', 'gonfunko', 'Lingampalli56', 'xingxinggeng', 'millanbatra1234', 'iamSamuelFu', 'kjorg50', 'dcoffill', 'pconrad', 'brianslee', 'bronhuston', 'hannavigil', 'mastergberry']",1,,0.75,0,,,,,,2,,,
110172436,MDEwOlJlcG9zaXRvcnkxMTAxNzI0MzY=,lab00-anacapa-student,anacapa-dev-class/lab00-anacapa-student,0,anacapa-dev-class,https://github.com/anacapa-dev-class/lab00-anacapa-student,,0,2017-11-09 22:16:29+00:00,2017-11-09 22:17:10+00:00,2017-11-09 22:24:08+00:00,,2,0,0,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,1,"# Practice with C++ control flow

##THIS IS CHANGED 2
This comes from the following assignment in submit.cs:

https://submit.cs.ucsb.edu/form/project/627

![screenshot](/images/2.png)

![screenshot](/images/3.png)

![screenshot](/images/4.png)

![screenshot](/images/5.png)

![screenshot](/images/6.png)

![screenshot](/images/7.png)
","['wpeery', 'anacapa-student']",1,,0.76,0,,,,,,1,,,
181051070,MDEwOlJlcG9zaXRvcnkxODEwNTEwNzA=,R-Software-Carpentry-Workshop,mei-me-i/R-Software-Carpentry-Workshop,0,mei-me-i,https://github.com/mei-me-i/R-Software-Carpentry-Workshop,"UCSB R workshop, Apr 12 2019",0,2019-04-12 17:09:00+00:00,2019-04-12 23:37:19+00:00,2019-04-12 23:37:18+00:00,,38,0,0,R,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# R-Software-Carpentry-Workshop
UCSB R workshop, Apr 12 2019
/n is this a new line?
",['mei-me-i'],1,,0.83,0,,,,,,0,,,
783352270,R_kgDOLrEBzg,sotu-ngrams,groegercesg/sotu-ngrams,0,groegercesg,https://github.com/groegercesg/sotu-ngrams,A Rust N-gram model to create synthetic State of the Union addresses,0,2024-04-07 16:50:52+00:00,2024-05-04 16:09:14+00:00,2024-05-04 16:08:37+00:00,,1839,1,1,Rust,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"# State of the Union N-grams

The following repo implements a N-gram language model in Rust and uses it to generate synthetic exerpts from hypothetical Presidential ""State of the Union"" address. Below are some samples:

> And the whole world looks to us for protection.
>
> Industry is always necessary to keep economies in balance.
> 
> Everything is a possibility.
> 
> We will continue along the path toward a balanced budget.
>
> This Administration will be remembered for support of the workers who are not truly disabled.

*(Generated using the entire SOTU corpus, a Quad-gram model and the Probabilistic text generation mode.)*

## What is a ""State of the Union""?

A ""State of the Union"" (SOTU) address is a speech delivered annually by the President of the United States to Congress. Typically, the president outlines their administration's achievements from the previous year and goals for the coming one. It's an important event, serving as a demonstration of the President's priorities and focus for the coming year.

The N-gram model uses 244 SOTU addresses from the American Presidency Project by [UC Santa Barbara](https://www.presidency.ucsb.edu/documents/presidential-documents-archive-guidebook/annual-messages-congress-the-state-the-union).

## N-Gram Language Models

N-gram language models are statistical models commonplace in NLP and lingustics settings. They use the frequency of words (grams) to predict future text. These rely on the independence assumption, that the probability of a word **only** depends on a fixed number of previous words (history).

This implementation allows the history size, the number of grams used, to be varied -hence it's an N-gram model. For this implementation the following sources have been heavily relied on:

- Speech and Language Processing. Daniel Jurafsky & James H. Martin, 2023. [Link](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
- Foundations of Natural Language Processing, N-gram language models. Alex Lascarides, 2020. [Link](https://www.inf.ed.ac.uk/teaching/courses/fnlp/lectures/03_slides.pdf)

## Text Samples

The repository also includes the following sample texts, used for tests and debugging:

- `shakespeare_alllines.txt`: [Shakespeare Plays](https://www.kaggle.com/datasets/kingburrito666/shakespeare-plays?select=alllines.txt)
- `biden_sotu_2024.txt`: [Joe Biden State of the Union, 2024](https://www.whitehouse.gov/briefing-room/speeches-remarks/2024/03/07/remarks-of-president-joe-biden-state-of-the-union-address-as-prepared-for-delivery-2/)
- `biden_sotu_2022.txt`: [Joe Biden State of the Union, 2022](https://gist.github.com/fzliu/973bb1d659a740b1d78a659f90be4a02)
",['groegercesg'],1,,0.6,0,,,,,,1,,,
107893890,MDEwOlJlcG9zaXRvcnkxMDc4OTM4OTA=,website,whatevery1says/website,0,whatevery1says,https://github.com/whatevery1says/website,WE1S website design,0,2017-10-22 18:57:51+00:00,2022-12-02 14:33:05+00:00,2018-08-02 20:02:57+00:00,http://we1s.ucsb.edu/,66558,1,1,PHP,1,1,1,1,0,0,0,0,0,1,mit,1,0,0,public,0,1,1,master,1,1,"# WE1S Website: Themes, Plugins, and Media for the WE1S Website

http://we1s.ucsb.edu

The WE1S website is a WordPress site using the [Sydney](https://wordpress.org/themes/sydney/) theme, with a child theme called `we1s`.


### Development Notes

see internal document: Log and Description of WE1S WordPress Website Development
","['scottkleinman', 'jeremydouglass', 'ayliu', 'lcthomas']",1,,0.84,0,,,,,,3,,,
249031375,MDEwOlJlcG9zaXRvcnkyNDkwMzEzNzU=,wwuc,JohnMcCann/wwuc,0,JohnMcCann,https://github.com/JohnMcCann/wwuc,,0,2020-03-21 17:56:28+00:00,2021-12-22 13:53:18+00:00,2021-12-22 13:52:14+00:00,,35,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Worldwide Unix Configuration
## My personal configuration for unix machines
### John McCann UCSB ([mccann@ucsb.edu](mailto:mccann@ucsb.edu))

Current release summary
-----------------------
Null
",[],1,,0.76,0,,,,,,1,,,
843530756,R_kgDOMkdCBA,logan-melgoza,logan-melgoza/logan-melgoza,0,logan-melgoza,https://github.com/logan-melgoza/logan-melgoza,,0,2024-08-16 18:09:02+00:00,2024-08-16 18:56:55+00:00,2024-08-16 18:56:52+00:00,,2,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"<h1 align=""center"">Hi 👋, I'm Logan Melgoza</h1>
<h3 align=""center"">A CS major having fun coding :)</h3>



- 🌱 I’m currently learning **HTML, CSS, and JavaScript**

- 📫 How to reach me **loganmelgoza@ucsb.edu**

- ⚡ Fun fact **Sports and Anime are my thing ;)**

<h3 align=""left"">Resume:</h3>
<p align=""left"">
<a href=""https://docs.google.com/document/d/1EIGGspVZPq7hnvJvTBXud-iDfGOIKaJ0/edit?usp=sharing&ouid=106921002943483697670&rtpof=true&sd=true"" target=""blank""><img align=""center"" src=""https://github.com/user-attachments/assets/056f86b2-a97e-4aa3-abd2-4e86231b395c"" width=""40"">

<h3 align=""left"">Connect with me:</h3>
<p align=""left"">
<a href=""https://linkedin.com/in/loganmel"" target=""blank""><img align=""center"" src=""https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg"" alt=""loganmel"" height=""30"" width=""40"" /></a>
<a href=""https://instagram.com/logan.melgoza"" target=""blank""><img align=""center"" src=""https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/instagram.svg"" alt=""logan.melgoza"" height=""30"" width=""40"" /></a>
</p>

<h3 align=""left"">Languages and Tools:</h3>
<p align=""left""> <a href=""https://www.w3schools.com/cpp/"" target=""_blank"" rel=""noreferrer""> <img src=""https://raw.githubusercontent.com/devicons/devicon/master/icons/cplusplus/cplusplus-original.svg"" alt=""cplusplus"" width=""40"" height=""40""/> </a> <a href=""https://www.w3schools.com/css/"" target=""_blank"" rel=""noreferrer""> <img src=""https://raw.githubusercontent.com/devicons/devicon/master/icons/css3/css3-original-wordmark.svg"" alt=""css3"" width=""40"" height=""40""/> </a> <a href=""https://www.w3.org/html/"" target=""_blank"" rel=""noreferrer""> <img src=""https://raw.githubusercontent.com/devicons/devicon/master/icons/html5/html5-original-wordmark.svg"" alt=""html5"" width=""40"" height=""40""/> </a> <a href=""https://www.python.org"" target=""_blank"" rel=""noreferrer""> <img src=""https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg"" alt=""python"" width=""40"" height=""40""/> </a> </p>
",['logan-melgoza'],1,,0.81,0,,,,,,1,,,
588676350,R_kgDOIxZ8_g,name-alignment-tool-showcase,jtmiller28/name-alignment-tool-showcase,0,jtmiller28,https://github.com/jtmiller28/name-alignment-tool-showcase,,0,2023-01-13 17:57:47+00:00,2023-01-13 17:57:47+00:00,2023-01-18 16:52:46+00:00,,147,0,0,,1,1,1,1,0,0,0,0,0,0,cc0-1.0,1,0,0,public,0,0,0,main,1,,"---
### replace uri to point to the name resource you'd like to align
# a url without scheme like https:// (e.g., ```url: foodorganisms.txt```) 
# is assumed to be a local file in working directory
datasets:
    - url: names.csv 
      type: text/csv
#   - url: https://example.org/data.tsv
#     type: text/tab-separated-values
#    - url: https://serv.biokic.asu.edu/ecdysis/content/dwca/UCSB-IZC_DwC-A.zip
#      type: application/dwca
#    - url: https://example.org/rss.xml
#      type: application/rss2+xml
# edit list below to select taxonomies you'd like to work with
taxonomies:
    - id: itis
      name: Integrated Taxonomic Information System
    - id: ncbi
      name: NCBI Taxonomy
    - id: discoverlife
      name: Discover Life Taxonomy
#    - id: batnames
#      name: Bat Names 
#    - id: col
#      name: Catalogue of Life
#    - id: gbif
#      name: GBIF Backbone Taxonomy
#    - id: globi
#      name: GloBI Taxon Graph
#    - id: indexfungorum
#      name: Index Fungorum
#    - id: ott
#      name: Open Tree of Life Taxonomy
#    - id: plazi
#      name: Plazi Treatments
#    - id: tpt
#      name: Terrestrial Parasite Tracker Taxonomies
#    - id: wfo
#      name: World of Flora Online
---

# Name Alignment

[![Name Alignment by Nomer](../../actions/workflows/align.yml/badge.svg)](../../actions/workflows/align.yml)

To find your automatically created name alignment report, click on ""Name Alignment by Nomer"" above, click on a workflow run, and  download the `alignment-report` artifact.

:bulb: note that only logged-in GitHub users with access can download the alignment report generated by GitHub Actions.

## Background


Aligning taxonomic names is a common task in biodiversity informatics. 

This template repository offers an automated method to align scientific names in csv/tsv files and darwin core archive with common taxonomic name lists like Catalogue of Life, NCBI Taxonomy, Integrated Taxonomic Information System (ITIS), and GBIF Backbone taxonomy.

## Getting Started

1. create your own repository using this repository as a template
2. edit the README.md and add the urls / filenames to the resources you'd like to review. Note that only the following types are supported at time of writing (June 2022): ```text/csv```, ```text/tab-separated-values```, ```application/dwca```, and ```application/rss+xml```. Also, delete any taxonomy entries that you are not interested in: the fewer taxonomies to align with, the faster the review. 
3. edit taxonomies list in the README.md [front-matter](https://jekyllrb.com/docs/front-matter/) to select those you are interested to work with. Many are configured by default, and you can customize to make the configuration work best for your names.  
4. for now only names in column ""scientificName"" (tsv/csv), and ""http://rs.tdwg.org/dwc/terms/scientificName"" (DwC-A) will be aligned 
5. commit the changes to github
6. inspect results of name alignment in ""Github Actions"" (e.g., [sample results](https://github.com/globalbioticinteractions/name-alignment-template/raw/main/img/name-alignment-review-2022-11-14.log))
)
7. download name alignment report from the ""artifacts"" section 
8. to re-create/re-run results, change your name list in github or select [""re-run jobs"" in Github Actions](https://docs.github.com/en/actions/managing-workflow-runs/re-running-workflows-and-jobs).

# Origin

This repository was conceived on 2022-03-08 during the [Alien CSI Hack-a-thon](https://github.com/alien-csi/alien-csi-hackathon) in Romania by Christina, Quentin, Jorrit, Jasmijn, .... For more information see https://github.com/alien-csi/alien-csi-hackathon . 

## Contributors


name | affiliation | orcid 
--- | --- | ---
Jorrit Poelen | GloBI; Ronin Institute | https://orcid.org/0000-0003-3138-4118
your name | your affiliation | your orcid


# Feedback / issues

This repository uses scripts in https://github.com/globalbioticinteractions/globinizer. These script use commandline tools like [GloBI](https://globalbioticinteractions.org)'s [nomer](https://github.com/globalbioticinteractions/nomer), cut, sed, etc. 

# Misc Notes


install nomer java8 / java11 - 

https://github.com/globalbioticinteractions/nomer 

e.g., Carl Boettiger taxondb R package


Print names and add a tab in front, to prepare for nomer. 

```
cat foodorganisms.txt | sed 's/^/\t/g' > foodorganisms.tsv
```

Nomer expects the format to be:

[id][tab][name]

e.g.,
id\tname
NCBI:9606\tHomo sapiens


Print names to screen and append itis taxonomic interpretation, and write/redirect to a file 'name-itis.tsv'

```
cat foodorganisms.tsv | nomer append itis > name-itis.tsv
```

open in LibreOffice Calc

Repeat with 'gbif' instead of 'itis'

## Provenance of DwC-A Names

The name context of names extracted from DwC-A are captured in a funny looking text:

```
line:zip:hash://sha256/fe63af46ed66abd253ee148e383fb51da6695ce3848d0bde39af18aa77d364fb!/occurrences.csv!/L10
```

extracted from a generated ```names-aligned.tsv```:

```
$ cat names-aligned.tsv | grep hash | grep occurrence | head -n1
line:zip:hash://sha256/fe63af46ed66abd253ee148e383fb51da6695ce3848d0bde39af18aa77d364fb!/occurrences.csv!/L10        Lasioglossum        SAME_AS        line:zip:hash://sha256/fe63af46ed66abd253ee148e383fb51da6695ce3848d0bde39af18aa77d364fb!/occurrences.csv!/L10        Lasioglossum                                                                HAS_ACCEPTED_NAME        COL:5B4P        Lasioglossum        genus                Biota | Animalia | Arthropoda | Insecta | Hymenoptera | Apoidea | Halictidae | Halictinae | Halictini | Lasioglossum        COL:5T6MX | COL:N | COL:RT | COL:H6 | COL:HYM | COL:625GP | COL:625H4 | COL:JMV | COL:KV7 | COL:5B4P        unranked | kingdom | phylum | class | order | superfamily | family | subfamily | tribe | genus        https://www.catalogueoflife.org/data/taxon/5B4P        
```

This text identifies the row from which the name was extracted. In this case, line 10, from file ```occurrences.csv``` contained in the zip file with content id ```hash://sha256/fe63af46ed66abd253ee148e383fb51da6695ce3848d0bde39af18aa77d364fb``` . If you retain the tracked dataset (in this case UC Santa Barbara Invertebrate Zoology Collection accessed on 2022-06-30) provided in the data/ folder of the name aligment archive,  you can use [Preston](https://preston.guoda.bio) to dig up the original record using:

```
$ preston cat 'line:zip:hash://sha256/fe63af46ed66abd253ee148e383fb51da6695ce3848d0bde39af18aa77d364fb!/occurrences.csv!/L10' 
881449,UCSB,IZC,,b03a3f0c-bfa5-4e02-b5d3-56ff38626302,PreservedSpecimen,a8a4f8b1-38f1-4e10-9b75-b2e86ac196fc,UCSB-IZC00038312,,Animalia|Arthropoda|Hexapoda|Insecta|Pterygota|Neoptera|Hymenoptera|Apocrita|Aculeata|Apoidea|Halictidae|Halictinae|Halictini,Animalia,Arthropoda,Insecta,Hymenoptera,Halictidae,Lasioglossum,186125,""Curtis, 1833"",Lasioglossum,,,,,Genus,""EEMB/ENV S 96"",24-May-2022,,,,,,""Sophie Cameron"",,2022-04-26,2022,4,26,116,,,,""Newly restored salt marsh"",PAN2,,,,,,,""on flower of Eschscholzia californica"",,,Adult,Female,1,Pinned,""United States"",California,""Santa Barbara"",,""University of California Santa Barbara North Campus Open Space"",,34.42174,-119.87186,WGS84,10,,,,GPS,,,,,,,,,,,,""2022-05-31 10:52:55"",http://creativecommons.org/publicdomain/zero/1.0/,""The Regents of the University of California"",https://www.ccber.ucsb.edu/collections/databases-searching-specimen-data-and-images,urn:uuid:a8a4f8b1-38f1-4e10-9b75-b2e86ac196fc,https://serv.biokic.asu.edu/ecdysis/collections/individual/index.php?occid=881449
```

which links to a preserved specimen with occurrenceId b03a3f0c-bfa5-4e02-b5d3-56ff38626302 and landing page at https://serv.biokic.asu.edu/ecdysis/collections/individual/index.php?occid=881449 . Also see [screenshot made on 2022-06-30](./img/UCSB-IZC00038312_b03a3f0c-bfa5-4e02-b5d3-56ff38626302.png). 

With this context, you can trace the origin and context of the name in great detail. This detail can be used to troubleshoot bugs in the name alignment process, or provide granular feedback to those that maintain the dataset or taxonomy.  



",['jtmiller28'],1,,0.63,0,,,,,,1,,,
69165648,MDEwOlJlcG9zaXRvcnk2OTE2NTY0OA==,angr-doc-ja,ntddk/angr-doc-ja,0,ntddk,https://github.com/ntddk/angr-doc-ja,,0,2016-09-25 13:21:50+00:00,2022-02-18 05:45:40+00:00,2016-10-30 07:32:09+00:00,http://ntddk.github.io/angr-doc-ja,9565,10,10,HTML,1,1,1,1,1,0,2,0,0,0,,1,0,0,public,2,0,10,master,1,,"これは[Angr Documentation](https://docs.angr.io/)の非公式翻訳です．

# 怒る (angry) ために

本書は，angrにまつわるドキュメントの集積です．
これを読めば，あなたはangrのプロとして，バイナリを思うがままに叩きのめせるようになりますよ．

私たちはangrを可能な限り苦痛なく利用できるように取り組んできました――私たちの目的は，ただiPythonを起動して，少ないコマンドを入力するだけで高度なバイナリ解析技術を試せるような，ユーザーフレンドリーなバイナリ解析スイートをつくることにあるのです．
とはいえ，バイナリ解析は複雑で，したがってangrも複雑にならざるを得ません．
そういうわけで，本稿は，系統立った解説を通じて，angrとその設計思想を理解する一助となるべく執筆されました．

## さあ始めよう

インストール手順は[こちら](./INSTALL.md)で読むことができます．

angrの機能を概括的に把握するには，[トップレベルメソッド](./docs/toplevel.md)から始めるか，[概要](./docs/overview.md)を通読するとよいでしょう．

検索可能な本書のHTML版は[ntddk.github.io/angr-doc-ja](http://ntddk.github.io/angr-doc-ja)に掲載されています．さらに，HTML
版APIリファレンスは[angr.io/api-doc](http://angr.io/api-doc/)にあります（英語）．

## angrを引用する

学術的な著作でangrを用いる場合は，元になった論文を引用してください：

```bibtex
@article{shoshitaishvili2016state,
  title={SoK: (State of) The Art of War: Offensive Techniques in Binary Analysis},
  author={Shoshitaishvili, Yan and Wang, Ruoyu and Salls, Christopher and Stephens, Nick and Polino, Mario and Dutcher, Andrew and Grosen, John and Feng, Siji and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
  booktitle={IEEE Symposium on Security and Privacy},
  year={2016}
}

@article{stephens2016driller,
  title={Driller: Augmenting Fuzzing Through Selective Symbolic Execution},
  author={Stephens, Nick and Grosen, John and Salls, Christopher and Dutcher, Andrew and Wang, Ruoyu and Corbetta, Jacopo and Shoshitaishvili, Yan and Kruegel, Christopher and Vigna, Giovanni},
  booktitle={NDSS},
  year={2016}
}

@article{shoshitaishvili2015firmalice,
  title={Firmalice - Automatic Detection of Authentication Bypass Vulnerabilities in Binary Firmware},
  author={Shoshitaishvili, Yan and Wang, Ruoyu and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
  booktitle={NDSS},
  year={2015}
}
```

## サポート

angrのヘルプを得たければ，下記の場所で質問するとよいでしょう：

- メーリングリスト： angr@lists.cs.ucsb.edu
- IRCチャンネル： [freenode](https://freenode.net/)の**#angr**
- 適切なgithubリポジトリのissue

## もっと先へ：

angrの内部構造，アルゴリズム，要素技術の一部を解説した[論文][paper]を読めば，内部で起きていることをより理解できます．

[paper]: https://www.cs.ucsb.edu/~vigna/publications/2016_SP_angrSoK.pdf
","['zardus', 'rhelmot', 'ltfish', 'kereoz', 'ntddk', 'Manouchehri', 'P1kachu', 'NickStephens', 'domenukk', 'ronnychevalier', 'salls', 'antoniobianchi333', 'sciencemanx', 'ocean1', 'ekse', 'giovannivigna', 'symeonp', 'ercoppa', 'Owlz', 'dipanjan', 'xoreaxeaxeax', 'ctfhacker', 'nescio007', 'iamahuman', 'berney', 'WGH-', 'riyadparvez', 'r-jenish', 'nebirhos', 'holycrap872', 'subwire', 'chuckleberryfinn', 'tunz', 'chaws', '0xBUGSPRAY']",1,,0.73,0,,,,,,0,,,
69515568,MDEwOlJlcG9zaXRvcnk2OTUxNTU2OA==,locamotor,scalableinternetservicesarchive/locamotor,0,scalableinternetservicesarchive,https://github.com/scalableinternetservicesarchive/locamotor,[UCSB],0,2016-09-29 00:41:31+00:00,2023-01-28 20:57:25+00:00,2016-12-05 19:08:28+00:00,,15734,0,0,Ruby,1,1,1,0,0,0,0,1,0,3,,1,0,0,public,0,3,0,master,1,1,"# README

Our application will allow users to become lenders and borrowers of vehicles of all types including cars, bicycles, and skateboards. Lenders will be able to post their vehicle with parameters such as price, time availability, as well as pickup and drop-off zones. Borrowers will be able to instantly book vehicles that fit their needs or can attempt to schedule trips ahead of time that may not fit lender parameters exactly. In this case we will attempt to match a series of trips that fit the lenders parameters and chain together borrowers so the vehicle is returned to the proper location, at the proper time.

Team Members:

Joel Daniel Dick

![picture to come](super_cool_pictures/Joel.png)

Aaron Magat

![picture to come](super_cool_pictures/AaronM.png)

Shane Masuda

![picture to come](super_cool_pictures/Shane2.png)

Aaron Zakhor

![picture to come](super_cool_pictures/AaronZ.png)
","['ajmagat', 'joelddick', 'aaronzak']",1,,0.74,0,,,,,,4,,,
801098500,R_kgDOL7_LBA,proj-gauchoride-s24-5pm-7,ucsb-cs156-s24/proj-gauchoride-s24-5pm-7,0,ucsb-cs156-s24,https://github.com/ucsb-cs156-s24/proj-gauchoride-s24-5pm-7,,0,2024-05-15 15:32:04+00:00,2024-06-10 02:53:58+00:00,2024-06-10 02:53:54+00:00,https://ucsb-cs156-s24.github.io/proj-gauchoride-s24-5pm-7/,15079,0,0,JavaScript,1,1,1,0,1,0,0,0,0,19,,1,0,0,public,0,19,0,main,1,1,"# proj-gauchoride

# Deployments

| Type | Link       | 
|------|------------|
| prod | <https://gauchoride.dokku-00.cs.ucsb.edu/> | 
| qa | <https://gauchoride-qa.dokku-00.cs.ucsb.edu/>  | 

# W24 Production Deployments


| Team | Link       | 
|------|------------|
| w24-7pm-1 | <https://gauchoride.dokku-13.cs.ucsb.edu/> | 
| w24-7pm-2 | <https://gauchoride.dokku-14.cs.ucsb.edu/>  | 
| w24-7pm-3 | <https://gauchoride.dokku-15.cs.ucsb.edu/>  | 
| w24-7pm-4 | <https://gauchoride.dokku-16.cs.ucsb.edu/>  | 

# W24 QA Deployments


| Team | Link       | 
|------|------------|
| w24-7pm-1 | <https://gauchoride-qa.dokku-13.cs.ucsb.edu/> | 
| w24-7pm-2 | <https://gauchoride-qa.dokku-14.cs.ucsb.edu/>  | 
| w24-7pm-3 | <https://gauchoride-qa.dokku-15.cs.ucsb.edu/>  | 
| w24-7pm-4 | <https://gauchoride-qa.dokku-16.cs.ucsb.edu/>  | 

# Setup before running application

Before running the application for the first time,
you need to do the steps documented in [`docs/oauth.md`](docs/oauth.md).

Otherwise, when you try to login for the first time, you 
will likely see an error such as:

<img src=""https://user-images.githubusercontent.com/1119017/149858436-c9baa238-a4f7-4c52-b995-0ed8bee97487.png"" alt=""Authorization Error; Error 401: invalid_client; The OAuth client was not found."" width=""400""/>

# Getting Started on localhost

* Open *two separate terminal windows*  
* In the first window, start up the backend with:
  ``` 
  mvn spring-boot:run
  ```
* In the second window:
  ```
  cd frontend
  npm install  # only on first run or when dependencies change
  npm start
  ```

Then, the app should be available on <http://localhost:8080>

If it doesn't work at first, e.g. you have a blank page on  <http://localhost:8080>, give it a minute and a few page refreshes.  Sometimes it takes a moment for everything to settle in.

If you see the following on localhost, make sure that you also have the frontend code running in a separate window.

```
Failed to connect to the frontend server... On Dokku, be sure that PRODUCTION is defined.  On localhost, open a second terminal window, cd into frontend and type: npm install; npm start;
```

# Accessing swagger

To access the swagger API endpoints, use:

* <http://localhost:8080/swagger-ui/index.html>


# To run React Storybook

* cd into frontend
* use: npm run storybook
* This should put the storybook on http://localhost:6006
* Additional stories are added under frontend/src/stories

* For documentation on React Storybook, see: https://storybook.js.org/

# SQL Database access

On localhost:
* The SQL database is an H2 database and the data is stored in a file under `target`
* Each time you do `mvn clean` the database is completely rebuilt from scratch
* You can access the database console via a special route, <http://localhost:8080/h2-console>
* For more info, see [docs/h2-database.md](/docs/h2-database.md)

On Heroku:
* The SQL database is a postgres database provisioned automatically by Heroku
* You can reset it with `heroku pg:reset --app app-name-goes-here`
* More info and instructions for access the SQL prompt are at [docs/postgres-database.md](/docs/postgres-database.md)
","['pconrad', 'phtcon', 'Mohamed-Elfouly', 'SophiaWeiler', 'Ze-el', 'gretchenlam', 'Kanagawa-okiNamiUra', 'zachmiller-ucsb', 'andrewpengucsb', 'btk5h', 'jamespflaging', 'abcdefucsb', 'Daoyijiucsb', 'ru1nw', 'gracefeng05', 'cherylstanley', 'Aasish-Virjala', 'cjyu81', 'ameymwalimbe', 'owenjpark', 'aneeshtheplug', 'liamlizard', 'adilahmed2', 'katelarrick', 'andrewhlu', 'mike-k999', 'koraykondakci', 'jtmnguyen', 'adityapatil834', 'strongani', 'ColinBaylis', 'sebastiananvari', 'sethvanb', 'scottpchow23', 'vChase42', 'AnikaArora', 'AlejandroRR16', 'bzamora020', 'JamesEllenstein', 'seannoh', 'whuang602', 'sanilkatula']",1,,0.88,0,,,,,,0,,,
208666325,MDEwOlJlcG9zaXRvcnkyMDg2NjYzMjU=,DS-Progress-Journal,parkervg/DS-Progress-Journal,0,parkervg,https://github.com/parkervg/DS-Progress-Journal,,0,2019-09-15 22:37:39+00:00,2024-09-17 00:15:31+00:00,2019-10-23 04:51:20+00:00,,632,2,2,Jupyter Notebook,1,1,1,1,0,0,25,0,0,0,,1,0,0,public,25,0,2,master,1,,"[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/parkervg/DS-Progress-Journal/master)
# DS-Progress-Journal

Template for a beginner project in the UCSB Data Science Club.

Allows members to log progress in an interactive visualization using Jupyter Notebook, Pandas, Matplotlib, and mplcursors.

## Overview 

Being in an academic club like the Data Science Club is very appealing to potential employers. However, one issue with the large number of people listing ""UCS Data Science Club"" on their resumé is that it can be difficult to quantify the amount of progress made or knowledge gained in this extracurricular club.

This short project intends to help those motivated and driven members of the club to track their weekly progress in a matplotlib visualization, while in the process also gaining knowledge of git commands.

The final result is an interactive visualization like this:
![example](https://github.com/parkervg/DS-Progress-Journal/blob/master/resources/example.png)

## Create Github Repository
We'll be using this [Git Cheat Sheet](https://github.github.com/training-kit/downloads/github-git-cheat-sheet.pdf) to help us out. 

### 1. Create GitHub account (if you haven't already) 
### 1(a) If you are using windows, follow [this link](https://git-scm.com/download/win) to install Git 
### 2. Link GitHub account to terminal/shell
  - In the future, we want to be able to interact with our GitHub scripts through our terminal. In order to do this, we need to point git (the programming language upon which GitHub is based on) to our account.
  - Run `git config --global user.name ""Your name here""` and `git config --global user.email ""Your email here""` in your terminal.
  - To ensure these config commands worked, run `git config user.name`  
### 3. Fork this repository 
  - Forking is the process of copying a repo. To do so, click the ""Fork"" button at the top right of this screen, next to ""Watch"" and ""Star"".
### 4. Create a local clone
  - Cloning allows us to have a local copy of all the files in the repo which we can make changes to.
  - Hit the profile button in the top right of this page. From that drop-down, select ""My Repositories"" and find the ""DS-Progress-Journal"" repo you just cloned.
  ![helpful image](https://github.com/parkervg/DS-Progress-Journal/blob/master/resources/my_profile.png)
  ![helpful image](https://github.com/parkervg/DS-Progress-Journal/blob/master/resources/your_repositories.png)
  - Copy the url of your forked repo. It should be https://github.com/YOUR_USERNAME/DS-Progress-Journal
  - In your terminal, navigate to a local directory where you want to store this project. For example, if you have a folder on your desktop called ""DataScienceClub"", you would type `cd desktop/DataScienceClub` for Macs, and `cd C:\Users\MyName\Desktop\DataScienceClub` for Windows.
  - Once in your desired local directory, enter `git clone https://github.com/YOUR_USERNAME/DS-Progress-Journal`. Make sure you don't just copy and paste that command and actually use your updated username.
### 5. Edit repo and push changes
  - Now, you're ready to do work in the local repo you just cloned. In the future, you're going to need to update the Github version of the repo to the version on your computer.
  - Once you've made certain changes, it's typically a 3-step process to push changes (update) the Github repo:
      1. `git add -A`                 adds all changes, deletions and insertions made to the repo locally 
      2. `git commit -m ""YOUR-MESSAGE""`         adds a custom commit message where you describe the changes that have been made
      3. `git push`                 pushes all staged commits
  - **IMPORTANT:** In future collaborative work done on Github, you have the potential to make people very angry by pushing directly to master. Read up on [branches](https://help.github.com/en/articles/about-branches) and experiment on your own time within a personal repo with creating and merging branches.
  
  
  
## Install Dependencies 
### 1. Navigate to the directory where the repo is stored locally to your computer 
### 2. Type `pip install -r requirements.txt`. 
  - What's happening with this command is that, line-by-line, the neccessary modules for completing this project are being installed. Depending on your local python setup, you may need to specify `pip3` instead of just plain pip.

## Open Jupyter Notebook
For this section, check out [this guide](https://jupyter.readthedocs.io/en/latest/install.html) on installing Jupyter Notebook. It's reccomended that, if you are a beginner, you install Anaconda as a package manager. 
### 1. On your terminal, change your directory to where you stored the DS-Progress-Journal repo
### 2. Type `jupyter notebook` to start a new notebook session
### 3. Click the 'ProgressJournal.ipynb' file to open and begin working.
  - If, for whatever reason, the first cell importing all the dependencies fails, contact a Data Science Officer to help get everything set up right.



## Troubleshooting
* If you are using Windows and Anaconda and get an SSLerror when installing with `pip install -r requirements.txt`, follow [this link](https://docs.telerik.com/teststudio/features/test-runners/add-path-environment-variables) to add the following PATH variables:
  - D:\Anaconda3
  - D:\Anaconda3\Scripts
  - D:\Anaconda3\Library\bin
  
* If `pip install -r requirements.txt` returns something like ""pip not found"", make sure you have Python 3.6 or 3.7 installed. pip comes with all versions past 3.4

* If you are having any other specific problems, slack me (Parker Glenn). I realize there may be more compatibility issues, especially with Windows.
",['parkervg'],1,,0.74,0,,,,,,1,,,
112424178,MDEwOlJlcG9zaXRvcnkxMTI0MjQxNzg=,Compiler,ShadowAries/Compiler,0,ShadowAries,https://github.com/ShadowAries/Compiler,UCSB CS160 Final Project,0,2017-11-29 03:57:31+00:00,2021-01-31 02:12:24+00:00,2015-12-12 09:14:54+00:00,,1055,0,0,C++,0,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Compiler
UCSB CS160 Project #6
",['maxkohne'],1,,0.79,0,,,,,,1,,,
55166698,MDEwOlJlcG9zaXRvcnk1NTE2NjY5OA==,CS20-S16-lab00,UCSB-CMPTGCS20-S16/CS20-S16-lab00,0,UCSB-CMPTGCS20-S16,https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab00,https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab00,0,2016-03-31 16:41:57+00:00,2016-03-31 16:41:57+00:00,2016-03-31 16:46:16+00:00,,6,0,0,,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,1,"# CS20-S16-lab00
https://github.com/UCSB-CMPTGCS20-S16/CS20-S16-lab00

CMPTGCS 20, S15, lab00:  Hello World in Python 2.7

For this lab, there is one goal: write a Python 2.7 program that prints the string `Hello, World!` as its output.

In this sense, we are following a long tradition: for 
[more than 40 years](https://en.wikipedia.org/wiki/%22Hello,_World!%22_program)
it has been a tradition to make printing `Hello, World!` be the first
thing you do when learning a new programming language.

In Python, this program is very short.  It looks like this:

```Python
print 'Hello, World!'
```

That's it!   Now, you can also add, on the first line, a *comment* with your name, and information about the course, for example:

```Python
# Chris Gaucho, for CMPTGCS 20, S16
print 'Hello, World!'
```

You are encouraged to do that, because it helps someone looking at your code know that *you* wrote it.  But, other than that, it isn't necessary.  In general, in computer programming, a *comment* is something that is intended only for human readers of the code, and is otherwise ""ignored by the system"".   Nearly every programming language has some way to express comments, though the exact rules for formatting of comments--that is, the *syntax* of comments--differs from one language to another.

In Python, a `#` starts a comment.  Everything from the `#` to the end of that line is part of the comment.

Now, how will you create this bit of code?  Assuming you have a laptop in front of you, the best way is to use a piece of software called IDLE, which is part of the download for Python 2.7.11.  Let's explore that option first.

# Downloading Python 2.7.11 (including IDLE) for your system.

These instructions assume <b>you are working with a Windows or Mac system.</b>  

* <b>If you are running Linux</b>, it is assumed that you already have some system administration skills (otherwise, you'd be running Windows or Mac.   In particular, we assume you know how to install software for your distribution of Linux with an appropriate package manager, e.g. apt-get, yum, dpkg, etc.    If you are on Linux, install Python 2.7.11 in whatever way is appropriate for your distribution of Linux.  That's all the help we can provide.

For Windows or Mac, you can install Python 2.7.11 by visiting: http://python.org and clicking the Downloads link.

## Be sure you get Python 2, not Python 3

* BE SURE YOU GET PYTHON 2.7.11 (or a later version on the 2.7 branch.)  
* FOR THIS COURSE, YOU DO NOT WANT ANY VERSION OF PYTHON STARTING WITH 3.

If you already have a version of Python 3 on your system, that's ok.  

Supposedly, Python 2 and Python 3 can happily co-exist.   What's this all about?  We'll explain in lecture, but if you missed the lecture, or want to learn more, here's some information: https://wiki.python.org/moin/Python2orPython3

As for why we are using Python 2 rather than 3 in this course, the answer is:
* The [textbook we are using (Guttag,2013)](https://mitpress.mit.edu/books/introduction-computation-and-programming-using-python-0).  I haven't found a Python 3 based book that is as good as this particular Python 2 book.  Any benefits of using Python 3 vs. Python 2 are far overshadowed by the range of Computer Science depth that this book provides, in a relatively affordable, portable, lightweight book. 
* Web applications with Flask and Heroku.   We'll be able to do some cool stuff with putting our applications on the web if we stick with Python 2.7.    It's much tougher to do this with Python 3 at the moment.

As a side note, the College of Engineering Python course, CMPSC 8, uses Python 3.    I say that only ""FYI"".  Fortunately, that isn't a constraint on this course.   If you decide to switch to Python 3 later, the transition is easy.  

# Once you've downloaded Python 2.7.11, Start up Idle and enter your hello.py program

You should have gotten a program along with your Python 2.7.11 download called ""Idle"".

Idle is a program that allows you to create and modify Python programs.   It also allows you to check the program for formatting errors (syntax errors) and then run the program and see what it does.      

I'll demonstrate the use of Idle in lecture, since its much easier to just follow along than to try to explain everything in a text document.   But if you need a demonstration, you can find one on YouTube.  For example: http://www.youtube.com/watch?v=Cdk20r2dgFU

We are going to put our hello.py into Idle, and run it.

# Uploading your program to submit.cs

Next, we'll try submitting our program to submit.cs, which is an autograder system used by many Computer Science department courses at UCSB.    

As this is a CCS course, we aren't really concerned about ""grades"", per se, so perhaps ""autograder"" is a misnomer in our case.  Rather, this is a system where we can check the correctness of our solution, and thereby check our understanding of what we are trying to learn.

# Creating your submit.cs account

You may have already done the steps in this section--an email was sent out through Gauchospace inviting you to do so.   If you have, you may skip this section.

Otherwise, to create your submit.cs account, please take the following steps:

1. Navigate to the following website: https://submit.cs.ucsb.edu
1. Click on the ""Create User"" button, and enter your Umail address.
1. Check your umail for a message with additional instructions—follow the instruction in the email to select a password and activate your account.
1. Go back to the website: https://submit.cs.ucsb.edu and login with your account.
1. Select ""Join Class"", and click on the link for CCS_CMPTGCS_20_s16

At that point, you should be good to go.

# Navigate to the page for submitting lab00

The page for submitting lab00 is here: https://submit.cs.ucsb.edu/form/project/452/submission

Navigate to that page, and upload your `hello.py` file.

Note that if you try to upload a file with a name that does not match EXACTLY the name `hello.py`, the system will not allow you to do it.  The name cannot be, for example, `Hello.py`, or `HelloWorld.py`, or `hell0.py` (note the zero as in '007' instead of the letter 'o' as in octopus.)  Only `hello.py` is permitted.   This will always be the case with submit.cs: it is very picky about the filename that it wants.

Once you upload it, you should get a page that shows your submission is pending.

Refresh that page, and you should get one that indicates with either red, or green, whether the test cases for your code passed or failed.

If you got all green, and 100 points, then you passed, and you are finished with lab00!

",['pconrad'],1,,0.63,0,,,,,,1,,,
846552933,R_kgDOMnVfZQ,182fa24,berkeleyljj/182fa24,0,berkeleyljj,https://github.com/berkeleyljj/182fa24,Local copy of C182 website for fa24 term,0,2024-08-23 13:01:08+00:00,2024-08-23 13:09:15+00:00,2024-08-23 13:08:38+00:00,,323346,0,0,HTML,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a set of customizations on top of the popular [Just the Docs](https://github.com/pmarsceill/just-the-docs) theme, which provides a robust and thoroughly-tested foundation that makes it easy to extend for your own special use cases. These foundational features include:

- automatic [navigation structure](https://pmarsceill.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://pmarsceill.github.io/just-the-docs/docs/search/) and page indexing,
- and a small but powerful set of [UI components](https://pmarsceill.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://pmarsceill.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `index.md` with your course information.
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add your content.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([DS1](https://ucsb-ds.github.io/ds1-f20/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). For a few open-source examples, see the following course websites and their source code.

- [CSE 390HA](https://courses.cs.washington.edu/courses/cse390ha/20au/) ([source code](https://gitlab.cs.washington.edu/cse390ha/20au/website)) is an example of a single-page website that centers modules.
- [CSE 143](https://courses.cs.washington.edu/courses/cse143/20au/) ([source code](https://gitlab.cs.washington.edu/cse143/20au/website)) hosts an entire online textbook with full-text search.
- [CSE 373](https://courses.cs.washington.edu/courses/cse373/21su/) ([source code](https://gitlab.cs.washington.edu/cse373-root/21su/website)) is an example of a simple website combining Markdown pages with generated HTML files.

Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

Continue reading to learn how to setup a development environment on your local computer. This allows you to make incremental changes without directly modifying the live website.

### Local development environment

Just the Class is built for [Jekyll](https://jekyllrb.com), a static site generator. View the [quick start guide](https://jekyllrb.com/docs/) for more information. Just the Docs requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler.

1. Follow the GitHub documentation for [Setting up your GitHub Pages site locally with Jekyll](https://help.github.com/en/articles/setting-up-your-github-pages-site-locally-with-jekyll).
1. Start your local Jekyll server.
```bash
$ bundle exec jekyll serve
```
1. Point your web browser to [http://localhost:4000](http://localhost:4000)
1. Reload your web browser after making a change to preview its effect.

For more information, refer to [Just the Docs](https://pmarsceill.github.io/just-the-docs/).
","['kevinlin1', 'young-geng', 'erickim555', 'zhangmarvin', 'smilli', 'addcninblue', 'berkeleyljj', 'akindofyoga', 'ykharitonova']",0,,0.78,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
742250142,R_kgDOLD3Wng,UCSBusy,amorifusa/UCSBusy,0,amorifusa,https://github.com/amorifusa/UCSBusy,2024 UCSB Data Science Project,0,2024-01-12 04:05:24+00:00,2024-05-02 06:31:00+00:00,2024-05-02 06:30:57+00:00,,815,0,0,Python,1,1,1,0,0,0,1,0,0,0,,1,0,0,public,1,0,0,main,1,,"# UCSBusy
2024 UCSB Data Science Project
","['quinnkos', 'amorifusa', 'boiwertz']",1,,0.82,0,,,,,,1,,,
69179876,MDEwOlJlcG9zaXRvcnk2OTE3OTg3Ng==,cs56-rational-ex03,ucsb-cs56-pconrad/cs56-rational-ex03,0,ucsb-cs56-pconrad,https://github.com/ucsb-cs56-pconrad/cs56-rational-ex03,See: https://ucsb-cs56-pconrad.github.io/tutorials/rational_ex03/,0,2016-09-25 17:38:22+00:00,2018-06-16 19:40:28+00:00,2018-06-16 19:40:26+00:00,,279,0,0,Java,1,1,1,1,1,0,10,0,0,0,mit,1,0,0,public,10,0,0,master,1,1,"This repository is part of a [series of Java tutorials for a Rational class](https://ucsb-cs56-pconrad.github.io/tutorials/rational/) written by [Phill Conrad](https://www.cs.ucsb.edu/~pconrad) for [CMPSC 56](ucsb-cs56-pconrad.github.io), a Java course taught in the [Dept. of Computer Science](https://www.cs.ucsb.edu) at [UC Santa Barbara](https://www.ucsb.edu).

# For detailed instructions, see:

* https://ucsb-cs56-pconrad.github.io/tutorials/rational/
* https://ucsb-cs56-pconrad.github.io/tutorials/rational_ex03/

| Previous Repo | This Repo | Next Repo
|-|-|-|
|[cs56-rational-ex02](https://github.com/UCSB-CS56-pconrad/cs56-rational-ex02)|[cs56-rational-ex03](https://github.com/UCSB-CS56-pconrad/cs56-rational-ex03)|[cs56-rational-ex04](https://github.com/UCSB-CS56-pconrad/cs56-rational-ex04)

| Previous Lesson | This Lesson | Next Lesson |
|-|-|-|
| [rational_ex02](https://ucsb-cs56-pconrad.github.io/tutorials/rational_ex02/) | [rational_ex03](https://ucsb-cs56-pconrad.github.io/tutorials/rational_ex03/) | [rational_ex04](https://ucsb-cs56-pconrad.github.io/tutorials/rational_ex04/) |


# Quick start

Once you clone this repo, these commands show how to compile and run the code inside.  You need  `ant` to following these instructions;  refer to [cs56-rational-ex02](https://github.com/UCSB-CS56-pconrad/cs56-rational-ex02) and the article on [`ant`](http://ucsb-cs56-pconrad.github.io/topics/ant/) for more information.

The `build.xml` file in this repo is set up to produce a jar file:

To run this new target, we use:

```
ex03 pconrad$ ant jar
Buildfile: /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03/build.xml

compile:
    [javac] Compiling 2 source files to /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03

jar:
      [jar] Building jar: /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03/build/rational.jar

BUILD SUCCESSFUL
Total time: 0 seconds
ex03 pconrad$ 
```

We can then run the file with this command:

```
ex03 pconrad$ java -jar build/rational.jar 
r.getNumerator()=5
r.getDenominator()=7
ex03 pconrad$ 

```

To compile:

```
ex03 pconrad$ ant compile
Buildfile: /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03/build.xml

compile:
    [javac] Compiling 3 source files to /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03

BUILD SUCCESSFUL
Total time: 0 seconds
ex03 pconrad$ 
```

To run the JUnit tests in the repo:

```
ex03 pconrad$ ant test
Buildfile: /Users/pconrad/github/UCSB-CS56-M16/cs56-rational-example/ex03/build.xml

compile:

test:
    [junit] Testsuite: RationalTest
    [junit] Tests run: 4, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.059 sec
    [junit]

BUILD SUCCESSFUL
Total time: 0 seconds
ex03 pconrad$ 
```
","['pconrad', 'hiranya911']",1,,0.73,0,,,,,,9,,,
810877844,R_kgDOMFUDlA,ULD,UCSB-NLP-Chang/ULD,0,UCSB-NLP-Chang,https://github.com/UCSB-NLP-Chang/ULD,Implementation of paper 'Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference' [NeurIPS'24],0,2024-06-05 14:15:54+00:00,2025-01-08 06:26:36+00:00,2024-06-14 21:00:16+00:00,,2509,16,16,Python,1,1,1,0,0,0,0,0,0,1,mit,1,0,0,public,0,1,16,main,1,1,"# Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference
[![License: MIT](https://img.shields.io/badge/License-MIT-g.svg)](https://opensource.org/licenses/MIT)
[![Arxiv](https://img.shields.io/badge/arXiv-2406.08607-B21A1B)](https://arxiv.org/abs/2406.08607)
[![Hugging Face Transformers](https://img.shields.io/badge/%F0%9F%A4%97-Transformers-blue)](https://github.com/huggingface/transformers)
[![GitHub Stars](https://img.shields.io/github/stars/UCSB-NLP-Chang/ULD?style=social)](https://github.com/UCSB-NLP-Chang/ULD/stargazers)

This is the implementation for the paper [*Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference*](https://arxiv.org/abs/2406.08607).

## Install
```bash
conda create -n uld python=3.10 -y
conda activate uld
conda install pytorch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 pytorch-cuda=11.8 -c pytorch -c nvidia
conda install -c ""nvidia/label/cuda-11.8.0"" cuda-toolkit -y
pip install flash-attn==2.5.6 --no-build-isolation
pip install deepspeed
pip install -e .
```

## Training

### ULD Training
```bash
python scripts/hf_forget_train.py \
    data=[tofu|harry] \
    data.dataset.split=${DATASPLIT} \
    model=[tofu-llama-2|mistral] \
    model_mode=uld \
    model_mode.num_layer=8 \
    unlearn_loss=remember+uniform \
    trainer.strategy=ddp \
    OUTPUTMODELDIR=${OUTPUTMODELDIR}
```
For more detailed training options, please refer to `bashes/tofu/uld_train_eval.sh` and `bashes/harry/uld_train_eval.sh`. This would save the assistant model to `${OUTPUTMODELDIR}`.

### Offset Training
```bash
python scripts/hf_forget_train.py \
    data=[tofu|harry] \
    data.dataset.split=${DATASPLIT} \
    model=[tofu-llama-2|mistral] \
    model_mode=offset \
    unlearn_loss=${UNLEARN_LOSS} \
    trainer.strategy=deepspeed \
    OUTPUTMODELDIR=${OUTPUTMODELDIR}
```
For more detailed training options, please refer to `bashes/tofu/offset_train_eval.sh` and `bashes/harry/offset_train_eval.sh`. This would save the assistant model to `${OUTPUTMODELDIR}`.


### Other Training
```bash
python scripts/hf_forget_train.py \
    data=[tofu|harry] \
    data.dataset.split=${DATASPLIT} \
    model=[tofu-llama-2|mistral] \
    model_mode=base \
    unlearn_loss=${UNLEARN_LOSS} \
    trainer.strategy=deepspeed \
    OUTPUTMODELDIR=${OUTPUTMODELDIR}
```
For more detailed training options, please refer to `bashes/tofu/base_train_eval.sh` and `bashes/harry/base_train_eval.sh`. This would save the unlearned model to `${OUTPUTMODELDIR}`.

## Evaluation

```bash
python scripts/eval_tofu.py \
    data=[tofu|harry] \
    model=[tofu-llama-2|mistral] \
    model_mode=[base|uld|offset] \
    ckpt_path=${CHECKPOINT_DIR} \
    data.dataset.split=${DATASPLIT} 
```
For more detailed options, please refer to `bashes/tofu/tofu_eval.sh` and `bashes/harry/harry_eval.sh`.


## Development

We also implement several other unlearning methods employed in previous works, including:
* [Offset Unlearning for Large Language Models](https://arxiv.org/abs/2404.11045)
* [Negative Preference Optimization: From Catastrophic Collapse to Effective Unlearning](https://arxiv.org/abs/2404.05868)
* [TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/abs/2401.06121)

You can follow the guide below to implement other unlearning methods.

### Code Structure
* `scripts/`: scripts for training and evaluation
* `uld/data/`: data processing and dataloader
* `uld/models/`: model definition
* `uld/trainer/`: unlearn trainer and unlearn losses. 

### Add other dataset
* Add dataset to `uld/data/` and register it in `uld/data/__init__.py`
* Implement new dataset class by inheriting `TrainDataModule` class, reference implementation for ToFU dataset is in `uld/data/tofu.py`. Typically, you need to implement the logic to load *forget data* and *retain data*. 

### Add other unlearn loss
* Add unlearn loss to `uld/trainer/unlearn_losses.py` and add it in `configs/unlearn_loss`.
* Implement new unlearn loss class by defining the `forget_loss_func` and `retain_loss_func` for `ForgetRetainLoss` class, reference implementation is in `create_unlearn_loss` function.



## Citation
If you find this work useful, please consider cite our paper:
```bibtex
@article{ji2024reversing,
  title   = {Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference},
  author  = {Jiabao Ji and Yujian Liu and Yang Zhang and Gaowen Liu and Ramana Rao Kompella and Sijia Liu and Shiyu Chang},
  year    = {2024},
  journal = {arXiv preprint arXiv: 2406.08607}
}
```

## Acknowledgement
Huge thanks for following repos that greatly help our implementation:
* https://github.com/licong-lin/negative-preference-optimization
* https://github.com/OPTML-Group/SOUL
* https://github.com/locuslab/tofu
* https://github.com/EleutherAI/lm-evaluation-harness
* https://github.com/voidism/dola
",['Question406'],1,,0.83,0,,,,,,2,,,
413988758,R_kgDOGKz3lg,cs291a_project2,abbywysopal/cs291a_project2,0,abbywysopal,https://github.com/abbywysopal/cs291a_project2,,0,2021-10-05 21:49:03+00:00,2021-10-08 00:45:07+00:00,2021-10-08 00:45:04+00:00,,76,0,0,Ruby,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Project 2 Template

## Initial Set up

The following steps should only need to be done once:

### Set Environment Variable

Add the following to your `.bash_profile` script, or similar for your shell:

```sh
# If your ucsb email is user@ucsb.edu, then YOUR_ACCOUNT_NAME is user
#
# Note: If you have an underscore in your account name, please replace with a hypen.
export CS291_ACCOUNT=YOUR_ACCOUNT_NAME
```

### Install `gcloud` tool

Follow the instructions here:
https://cloud.google.com/sdk/docs/#install_the_latest_cloud_tools_version_cloudsdk_current_version

### Authenticate with Google

Make sure you select your `@ucsb.edu` account when authenticating.

```sh
gcloud auth login
```

### Verify the above works

```sh
gcloud projects describe cs291a
```

The above should produce the following output:

```
createTime: '2020-12-29T18:55:55.506Z'
lifecycleState: ACTIVE
name: cs291a
parent:
  id: '254441457261'
  type: folder
projectId: cs291a
projectNumber: '318955983951'
```

### Create Application Default Credentials

Again, make sure you select your @ucsb.edu account when authenticating.

```sh
gcloud auth application-default login
```

### Install Docker

Follow the instructions here: https://www.docker.com/products/docker-desktop

### Link Docker and Gcloud

```sh
gcloud auth configure-docker us.gcr.io
```

## Develop Locally

The following commands are intended to be run from within the directory
containing your project (e.g., your copy of this repository).

Edit your `app.rb` file however you want then follow the next two steps to test your
application:

### Build Container

```sh
docker build -t us.gcr.io/cs291a/project2_abbywysopal .
```

### Run Locally

```sh
docker run -it --rm \
  -p 3000:3000 \
  -v ~/.config/gcloud/application_default_credentials.json:/root/.config/gcloud/application_default_credentials.json \
  us.gcr.io/cs291a/project2_abbywysopal
```

### Test Using CURL

```sh
curl -D- localhost:3000/
```

```sh
curl -D- -X POST localhost:3000/
```

The default application should provide output that looks like the following:

```http
HTTP/1.1 200 OK
Content-Type: text/html;charset=utf-8
X-XSS-Protection: 1; mode=block
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
Content-Length: 12

Hello World
```

## Production Deployment

Each time you want to deploy your application to Google Cloud Run, perform the
following two steps:

### Push Container to Google Container Registry

```sh
docker push us.gcr.io/cs291a/project2_abbywysopal
```

### Deploy to Google Cloud Run

```sh
gcloud beta run deploy \
  --allow-unauthenticated \
  --concurrency 80 \
  --image us.gcr.io/cs291a/project2_abbywysopal \
  --memory 128Mi \
  --platform managed \
  --project cs291a \
  --region us-central1 \
  --service-account project2@cs291a.iam.gserviceaccount.com \
  --set-env-vars RACK_ENV=production \
  abbywysopal
```

The last line of output should look similar to the following:

```
Service [{ACCOUNT_NAME}] revision [{ACCOUNT_NAME}-00018] has been deployed and is serving 100 percent of traffic at https://{ACCOUNT_NAME}-66egyap56q-uc.a.run.app
```

### View Logs

1. Browse to: https://console.cloud.google.com/run?project=cs291a

2. Click on the service with your ACCOUNT_NAME

3. Click on ""LOGS""

4. Browse logs, and consider changing the filter to ""Warning"" to find more pressing issues.

## Resources

- https://cloud.google.com/run/docs/quickstarts/build-and-deploy
- https://googleapis.dev/ruby/google-cloud-storage/latest/index.html

## Possible Errors

### invalid reference format

Re-run the `export` command.
",['abbywysopal'],1,,0.82,0,,,,,,1,,,
453160177,R_kgDOGwKs8Q,2022-01-webpub,apandas/2022-01-webpub,0,apandas,https://github.com/apandas/2022-01-webpub,2022 Jan 28 UCSB Carpentry Workshop drafting site,0,2022-01-28 17:38:23+00:00,2022-01-28 19:16:00+00:00,2022-02-01 00:53:54+00:00,https://apandas.github.io/2022-01-webpub/,224,0,0,HTML,1,1,1,1,1,0,0,0,0,0,cc0-1.0,1,0,0,public,0,0,0,main,1,,"# 2022-01-webpub
2022 Jan 28 UCSB Carpentry Workshop drafting site

This is a **markdown file** that (may eventually) contains metadata about the repository.

# Workshop Web Page

This repo is for *learning* how to make websites with jekyll.

This curriculumn comes from [Carpentries](https://carpentries.org/).  
Other Carpentries lessons include...

- Software Carpentry
- Data Carpentry
- Library Carpentry

##    Another second level heading

Some text under that second level heading that includes an [link](https://carpentries.org/) and ~~strikethrough text~~ .

    grey box
",['apandas'],1,,0.83,0,,,,,,1,,,
10085306,MDEwOlJlcG9zaXRvcnkxMDA4NTMwNg==,cs56-games-client-server-v2,ucsb-cs56-projects/cs56-games-client-server-v2,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-games-client-server-v2,-,0,2013-05-15 18:32:53+00:00,2017-10-04 23:33:02+00:00,2017-12-07 06:08:03+00:00,,251,1,1,Java,1,1,1,1,0,0,5,0,0,7,,1,0,0,public,5,7,1,master,1,1,"cs56-games-client-server
========================
A simple client-server program that allows people to play iconic online games like Tic-tac-toe and Gomoku. Chat and observation functions are included.

How to Run
==========
After compiling, use ""ant run-client"" and ""ant run-server"" to start a client or a server respectively.
Only 1 server is necessary, but many clients can be created to play and spectate in the server ran lobby.Currently, this project is only runnable on one computer. In the future, we will expand functionality to be able to play on multiple csil computers.

Project history
===============
Fall 2017, Hong Wang & David Roster:
A new version of cs56-games-client-server that is identical on the outside, but substantially refactored inside to have better MVC separation.

Refactored JavaClient and other complex classes to create a more easily understood code while maintainingfunction. Javdoc descriptions have been added for every class and nearly every method. These descriptions will provide helpful insight when deciphering this beauty of a beast project.

We also changed the structure of classes by having a client, server, and games directory with their respected Views, models, and controller directories inside. THis can be made very clear by typing ""tree"" into our root directory called v2 (cs56/cs56-games-client-server-v2/src/edu/ucsb/cs56/games/client_server/v2). WE believed this would help with future user understanding.

v2: The version from Spring 2013.


Tips
==============
The code works great and does it's job to near perfection. However, it can be difficult to understand all the mechanisms of the class due to large complexity and number of classes. The main classes that handle this project are JavaClient (and its respected helper classes recently refactored) and JavaServer (which will be refactored shortly).

Since there is a lot of classes some basic commands provided here can help display useful info.
-> type ""tree"" into command line and it will illustrate the tree-like pattern of classes from that repo a	nd on
-> type ""grep -Irne 'whatever string value you want to search for' "" .This command will present all files 	that include that string on your terminal command with line numbers and color coded
-> type ""cat 'filename' "" to print whatever file you want to on the command line. You can print multiple files as well because cat stands for concatinate. 

Breakdown of Basic Repo Names
=================================
*Both the main client and server repo's have these sub directories because they keep code cleaner and follow the MVC design pattern. Here's a link that will explain more ... https://www.tutorialspoint.com/design_pattern/mvc_pattern.htm

3 main directories:
-games -> controls the game function for our application
-client -> handles the client side 
-server -> handles server side

Controller -> This stands for Logic which means that most of our logic handling 	functions and raw code are in here... have fun

Model -> This is where the data of our actual game is processed and sent between 	controllers for processing.

Views -> This provides both our GUI application for Server and Client. Server is 	able to run on the command line but that's not as cool.  

F17 Final Remarks
=======================
Explaination of the refactorization of JavaClient and JavaServer:
JavaClient gained 3 helper files. MyCellRenderer and RefreshThread used to be parralel classes inside JavaClient.java, and now they are in their own files. MessageHandler is a helper class that provides helper methods for handleMessage() method from JavaClient.
JavaServer was split into two parts. JavaServer now extends a new abstract class named JavaServerTemplate, which stores the basic methods and variable declarations for JavaServer.

Breakdown of abstract class design:
In certain packages(directories), such as games, there is one or more abstract classes that other classes extend from. For example, each of the subdirectories of Games (ClientController, Models, ServerCobtroller, Views) has an abstract class that each of the other classes implement. These abstract classes are respectively ""TwoPlayerGameController, TwoPlayerGameModel, TwoPlayerGameController, TwoPLayerGameViewPanel"". The reason for creating these abstract classes are it provides a correct layout for creating other games such as possibly chess. When creating a new game such as chess, you would need to make 4 classes minimum (not including any refactored classes or additional helper classes) that EXTEND these abstarct classes.

From our testings, we did not observe any bugs. We did however observe that we created some complex methods such as checkWinner() in our Gomoku Game. This might need refactorization if the Conrad or the TA's deem it necessary. A resource to use to check how your code is (kinda like a report card) is codeClimate. Just submit your open source github files to it and it will relay back possible improvements to make. 
","['wanghharrisonh', 'davidroster', 'sean-shelton', 'pconrad', 'ashedden', 'mastergberry']",1,,0.8,0,,,,,,2,,,
131165209,MDEwOlJlcG9zaXRvcnkxMzExNjUyMDk=,UCSB2018,mahidhar/UCSB2018,0,mahidhar,https://github.com/mahidhar/UCSB2018,,0,2018-04-26 14:08:17+00:00,2018-05-04 01:29:15+00:00,2018-05-04 01:29:14+00:00,,5812,5,5,,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,5,master,1,,"# UCSB2018
",['mahidhar'],1,,0.75,0,,,,,,3,,,
36413455,MDEwOlJlcG9zaXRvcnkzNjQxMzQ1NQ==,crypto,johnolos/crypto,0,johnolos,https://github.com/johnolos/crypto,Cryptographic Engineering - UCSB,0,2015-05-28 03:53:35+00:00,2015-06-11 17:57:18+00:00,2015-06-11 18:48:23+00:00,,408,0,0,TeX,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Cryptographic Engineering - UCSB
",['johannesolier'],1,,0.81,0,,,,,,2,,,
525477636,R_kgDOH1InBA,D-UCSB,Atahualpa-Ayala/D-UCSB,0,Atahualpa-Ayala,https://github.com/Atahualpa-Ayala/D-UCSB,,0,2022-08-16 17:23:10+00:00,2022-08-16 17:23:10+00:00,2022-08-16 17:23:10+00:00,,0,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,,[],-1,,0.74,0,,,,,,1,,,
35979784,MDEwOlJlcG9zaXRvcnkzNTk3OTc4NA==,crawl-e,rrengamani/crawl-e,0,rrengamani,https://github.com/rrengamani/crawl-e,Crawler code,0,2015-05-20 23:32:03+00:00,2015-08-20 20:27:15+00:00,2015-05-20 23:34:36+00:00,,204,0,0,Python,1,1,0,0,0,0,0,0,0,1,bsd-3-clause,1,0,0,public,0,1,0,master,1,,"Authors
---------------------
Bryce Boe (bboe _at_ cs.ucsb.edu)
Christo Wilson (bowlin _at_ cs.ucsb.edu)

About
---------------------
CRAWL-E was designed to crawl the web fast fast as possible with as little
development time as possible. It is only a framework, and requires the
development of a Handler module in order to function properly.

The CRAWL-E developers are very familiar with how TCP and HTTP works and using
that knowledge have written a web crawler intended to maximize TCP throughput.
This benefit is realized when crawling web servers that utilize persistent HTTP
connections as numerous requests will be made over a single TCP connection thus
increasing the throughput.

Other features of CRAWL-E are multiple HTTP request method support, the most
basic being GET, POST, PUT, DELETE, HEAD.

Installation
---------------------
Requirements: python >= python2.5
Run: python setup.py install
Note: You will probably need to be a root user to install the package.

Running
---------------------
Check out the page downloader in the examples folder. The script run_it.sh
should be sufficient to get you started.

The heart of CRAWL-E relies on extending the Crawle.Handler, in which one
must implement a process function. This function is where all the magic can
happen. We say can happen because it's entirely up to you what to do in this
function. Some possibilities are parsing links to add to the queue, simply
saving the contents of the page, or both!
",['bboe'],1,,0.82,0,,,,,,0,,,
40386220,MDEwOlJlcG9zaXRvcnk0MDM4NjIyMA==,Angr,MrMugiwara/Angr,0,MrMugiwara,https://github.com/MrMugiwara/Angr,"angr is a framework for analyzing binaries. It focuses on both static and dynamic symbolic (""concolic"") analysis, making it applicable to a variety of tasks.",0,2015-08-08 00:28:38+00:00,2015-10-10 20:03:49+00:00,2015-08-08 00:31:38+00:00,,136,1,1,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,,"<h1 style=""font-size: 2em; margin: 0.67em 0px; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr</h1>
<pre style=""overflow: auto; font-family: monospace, monospace; font-size: medium; padding-left: 1em; padding-right: 1em; color: #000000; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><span class=""pyprompt"" style=""color: #aaaaaa;"">&gt;&gt;&gt;</span> <span class=""pyinput"" style=""font-weight: bold;"">import angr</span>
<span class=""pyprompt"" style=""color: #aaaaaa;"">&gt;&gt;&gt;</span> <span class=""pyinput"" style=""font-weight: bold;"">proj = angr.Project('./fauxware-amd64')</span>
<span class=""pyprompt"" style=""color: #aaaaaa;"">&gt;&gt;&gt;</span> <span class=""pyinput"" style=""font-weight: bold;"">cfg = proj.analyses.CFG(); cfg.function_manager.functions</span>
<span class=""pyoutput"" style=""color: #333333;"">{4195600L: &lt;Function sub_400510 (0x400510)&gt;,
 4195616L: &lt;Function sub_400520 (0x400520)&gt;,
 4195632L: &lt;Function sub_400530 (0x400530)&gt;,
 4195648L: &lt;Function sub_400540 (0x400540)&gt;,
 4195664L: &lt;Function sub_400550 (0x400550)&gt;,
 4195680L: &lt;Function sub_400560 (0x400560)&gt;,
 4195696L: &lt;Function sub_400570 (0x400570)&gt;,
 4195712L: &lt;Function _start (0x400580)&gt;,
 4195940L: &lt;Function authenticate (0x400664)&gt;,
 4196077L: &lt;Function accepted (0x4006ed)&gt;,
 4196093L: &lt;Function rejected (0x4006fd)&gt;,
 4196125L: &lt;Function main (0x40071d)&gt;}</span>
<span class=""pyprompt"" style=""color: #aaaaaa;"">&gt;&gt;&gt;</span> <span class=""pyinput"" style=""font-weight: bold;"">ex = proj.surveyors.Explorer(find=0x4006ed).run()</span>
<span class=""pyprompt"" style=""color: #aaaaaa;"">&gt;&gt;&gt;</span> <span class=""pyinput"" style=""font-weight: bold;"">ex.found[0].state.posix.dumps(0)</span>
<span class=""pyoutput"" style=""color: #333333;"">'\x00\x00\x00\x00\x00\x00\x00\x00\x00<strong style=""font-weight: 700;"">SOSNEAKY</strong>\x00'</span>
</pre>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">What is angr?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr is a framework for analyzing binaries. It focuses on both static and dynamic symbolic (""concolic"") analysis, making it applicable to a variety of tasks.</p>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">What's it made of?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr is made up of several subprojects, all of which are<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr"">open-source!</a></p>
<ul style=""padding-left: 3em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">
<li>an executable and library loader,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/cle"">CLE</a></li>
<li>a library describing various architectures,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/archinfo"">archinfo</a></li>
<li>a Python wrapper around the binary code lifter VEX,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/pyvex"">PyVEX</a></li>
<li>a VEX simulation engine,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/simuvex"">SimuVEX</a></li>
<li>a data backend to abstract away differences between static and symbolic domains,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/claripy"">Claripy</a></li>
<li>the full-program analysis suite itself,<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/angr"">angr</a></li>
</ul>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">How has it been used academically?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">If you have used angr or its sub-components in research, please cite the paper that it was developed for:</p>
<pre style=""overflow: auto; font-family: monospace, monospace; font-size: medium; padding-left: 1em; padding-right: 1em; color: #000000; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">@article{shoshitaishvili2015firmalice,
  title={Firmalice - Automatic Detection of Authentication Bypass Vulnerabilities
         in Binary Firmware},
  author={Shoshitaishvili, Yan and Wang, Ruoyu and Hauser, Christophe
          and Kruegel, Christopher and Vigna, Giovanni},
  year={2015}
}</pre>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">You can also<span class=""Apple-converted-space"">&nbsp;</span><em>read</em><span class=""Apple-converted-space"">&nbsp;</span>the paper<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""http://www.internetsociety.org/doc/firmalice-automatic-detection-authentication-bypass-vulnerabilities-binary-firmware"">here</a>!</p>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">And non-academically?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr was one of the underpinnings of Shellphish's Cyber Reasoning System for the DARPA Cyber Grand Challenge, enabling them to qualify for the CGC finals!</p>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">Whom can I contact?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">If you have questions with a subcomponent of angr, please open an issue on github (or send us a pull request!). If you have questions or comments, drop us a line at the mailing list at<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""mailto:angr@lists.cs.ucsb.edu"">angr@lists.cs.ucsb.edu</a>.</p>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">Who works on angr?</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr is worked on by several researchers in the<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""http://seclab.cs.ucsb.edu/"">Computer Security Lab at UC Santa Barbara</a>. Major contributers (arbirtrarily, 1000+ lines of code!) include:</p>
<ul style=""padding-left: 3em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">
<li>Yan Shoshitaishvili</li>
<li>Andrew Dutcher</li>
<li>Ruoyu (Fish) Wang</li>
<li>Christophe Hauser</li>
<li>John Grosen</li>
<li>Chris Salls</li>
</ul>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">angr owes its existence to research sponsored by DARPA under agreement number<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""http://www.darpa.mil/program/vetting-commodity-it-software-and-firmware"">N66001-13-2-4039</a>!</p>
<h2 style=""margin-top: 1.5em; margin-bottom: -0.3em; color: #000000; font-family: sans-serif; font-style: normal; font-variant: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">How can I help</h2>
<p style=""padding-left: 1em; padding-right: 1em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">There are many ways to participate! Here are some ideas:</p>
<ul style=""padding-left: 3em; color: #000000; font-family: sans-serif; font-size: medium; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: normal; orphans: auto; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: auto; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">
<li>Report bugs. We know they exist, but it's not always clear where they are!</li>
<li>Write documentation. An analysis system like angr can be a bit overwhelming. If you're using it, and could send a pull request for our<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/angr-doc"">documentation repo</a>, we would be eternally grateful! This includes examples -- if you use angr for something cool, send us a pull request with an example!</li>
<li>Implement more environment support. We use the concept of ""function summaries"" in angr to model the environment of operating systems (i.e., the effects of their system calls) and library functions. Extending this would be greatly helpful in increasing angr's utility. These function summaries can be found<span class=""Apple-converted-space"">&nbsp;</span><a style=""background-color: transparent;"" href=""https://github.com/angr/simuvex/tree/master/simuvex/procedures"">here</a>.</li>
</ul>
",['hacker404'],1,,0.7,0,,,,,,1,,,
132953467,MDEwOlJlcG9zaXRvcnkxMzI5NTM0Njc=,benmo,ije896/benmo,0,ije896,https://github.com/ije896/benmo,"Contains work for CS171 Final Project, S18 UCSB",0,2018-05-10 20:56:08+00:00,2018-07-03 18:37:55+00:00,2018-07-03 18:37:54+00:00,,44,0,0,Python,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# benmo
An implementation of Paxos, used to determine the next entry in a distributed ledger (blockchain) amongst multiple nodes.
",['ije896'],1,,0.74,0,,,,,,2,,,
339542485,MDEwOlJlcG9zaXRvcnkzMzk1NDI0ODU=,nvsim-merged,lpentecost/nvsim-merged,0,lpentecost,https://github.com/lpentecost/nvsim-merged,An extended and modified version of NVSim (https://github.com/SEAL-UCSB/NVSim) for use with the broader eNVM DSE framework (https://nvmexplorer.seas.harvard.edu).,0,2021-02-16 21:59:16+00:00,2025-02-09 23:32:52+00:00,2023-06-05 20:48:19+00:00,,119,8,8,C++,1,1,1,1,0,0,3,0,0,0,,1,0,0,public,3,0,8,main,1,,"Modified/Extended version of NVSim for use in broader eNVM DSE framework;
Please see nvmexplorer.seas.harvard.edu for more details
Added support for FeFET, CTT memory cells
Added support for MLC sensing for CTT, FeFET, ReRAM
+Note: MLC relies on power-of-two scaled capacity values
+Note: Can specify both nLvl for # programmed levels per MLC and nFingers to dictate the size (&resulting reliability) of MLC SA

For additional details, please see [https://arxiv.org/abs/2106.11757 and nvmexplorer.seas.harvard.edu]

Below are more details from NVSim README

NVSim - A performance, energy and area estimation tool
for non-volatile memory (NVM)



======================================================

Sections

    1. Overview
    2. Compiling NVSim
    3. Running NVSim
    4. Configuring NVSim
    5. Hacking NVSim
    6. README Changelog

------------------------------------------------------  

1. Overview

    NVSim models the area, timing, dynamic energy and 
    leakage power of Phase-Change Memory (PCM), Spin-
    Torque-Transfer RAM (STT-RAM), Resistive RAM
    (ReRAM) or memristor, Floating Body Dynamic RAM
    (FBDRAM) and Single-Level Cell NAND Flash.
*** Added: Support for CTT, FeFET cell definitions
*** Added: Support for MLCs for CTT, FeFET, ReRAM
    NVSim uses the same modeling principles as the
    well-known CACTI, but it starts from scratch on
    the basis of a brand-new frame work with more
    flexibility in terms of bank/mat/subarray
    organization and periphral circuitry design. Such
    flexibility is necessary for emerging non-volatile
    memory technologies as the current status of most 
    emerging NVMs is unknown. Thanks for trying NVSim!


------------------------------------------------------

2. Compiling NVSim

    NVSim is programmed under GNU C++, and it can be 
    compiled on both Unix-like OSes and Microsoft 
    Windows 

    2a. Under Linux

        The tool can be built using make:

        $ make

        Running through make will automatically set 
        the compile flags needed.


------------------------------------------------------

3. Running NVSim


    If no .cfg file is specified, NVSim will load the 
    default configuration file (nvsim.cfg)

    $ ./nvsim

    Actually, users can specify their own configurations
    by passing the "".cfg"" argument.

    $ ./nvsim <custom>.cfg
    

------------------------------------------------------

4. Configuring NVSim


    NVSim can be configured using the configuration files.
    Several example configuration files can be found in
    the root directory of the source code. Note that most
    of the configuration files are specified with small
    capacity (< 128MB) as the current version of NVSim 
    only models a single-bank. Multi-bank cache/memory is
    in the to-do list of NVSim 2.0.

    For example, 
    sample_STTRAM_cache.cfg - A 8MB STT-RAM cache (both 
    data and array) configured for design space exploration
    sample_PCRAM.cfg - A 16MB PCM macro with fixed bank 
    organization (H-tree, internal sensing)
    sample_RRAM.cfg - A 2MB ReRAM macro with fixed bank
    organization (bus-manner routing, external sensing)
    A more detailed listing of configuration parameter 
    names and potential values are on the NVSim wiki page.


------------------------------------------------------

5. Hacking NVSim


    As mentioned in the overview, NVSim is meant to 
    be flexible. Another level of flexibility is 
    enabled when experts in NVM design Write their own
    sense amplifier, voltage plane, charge pump
    circuiitry etc. This can be done by creating a new
    C++ file with a new class and instantiate the new
    class in corresponding component. 


------------------------------------------------------


6. README changelog

    09/16/2013 - Created first README (shared template
    with NVMain)


------------------------------------------------------

Please refer to the following paper for a general
introduction of the tool,
""NVSim: A Circuit-Level Performance, Energy and Area
Model for Emerging Nonvolatile Memory"", IEEE TCAD 2012

At the mean time, we are working on the documentation
of a detailed technical report. If you have any comments,
questions, or suggestions please contact us via email.

Cong Xu <czx102@cse.psu.edu>
Xiangyu Dong <xydong@cse.psu.edu>


",['lpentecost'],0,,0.71,0,,,,,,2,,,
80098750,MDEwOlJlcG9zaXRvcnk4MDA5ODc1MA==,Buzmo-Social-Web-App,JBLanier/Buzmo-Social-Web-App,0,JBLanier,https://github.com/JBLanier/Buzmo-Social-Web-App,UCSB CS 174A - Database Systems Final Project,0,2017-01-26 08:52:34+00:00,2021-04-02 18:47:48+00:00,2017-01-26 09:20:20+00:00,,553,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# BuzMo Social Network

To compile, you should have Oracle JDK 8 installed and have `JAVA_HOME`
set to its directory. The `java` and `javac` commands should likewise be configured
for JDK 8 (Java 1.8).

To build `cd` to the repo directory then:

    mvn clean package

To run:

    java -jar target/BuzMo.jar server config/local.yaml

Try visiting `/api/hello` (the sample HelloResource) or `/admin/healthcheck` (part of
Dropwizard) or `/` (the frontend).

When running `add_demo_data.sql` from SQLPlus make sure to enter into the prompt:

    set define off

before running:

    @add_demo_data.sql


To setup and run the frontend:

    cd src/main/resources/frontend
    npm install
    npm run


","['bsandler', 'JBLanier']",1,,0.76,0,,,,,,1,,,
943514794,R_kgDOODzkqg,home,texbouja/home,0,texbouja,https://github.com/texbouja/home,Site web pour maths aux prépas,0,2025-03-05 20:41:39+00:00,2025-03-05 21:19:32+00:00,2025-03-05 21:19:29+00:00,,32,0,0,SCSS,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"---
layout: home
title: Maths en Prépas
nav_exclude: true
permalink: /:path/
seo:
  type: Cours
  name: Maths en Prépas
---

# Maths en prépas

Maths en prépas est un site web dédié aux mathématiques en classes préparatoires. Il contient des cours, des séries d'exercices avec solutions et des sujets des concours corrigés dans une présentation simple mais moderne et efficace. Le site s'adapte au support utilisé pour la consultation. 

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
",['texbouja'],-1,,0.74,,,,,,,,,,
464607529,R_kgDOG7FZKQ,STARTER-team04-cows,ucsb-cs156-w22/STARTER-team04-cows,0,ucsb-cs156-w22,https://github.com/ucsb-cs156-w22/STARTER-team04-cows,,0,2022-02-28 18:59:40+00:00,2022-02-28 20:23:15+00:00,2022-03-01 20:33:05+00:00,,3656,0,0,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,1,"# HappyCows/HappierCows

[![codecov](https://codecov.io/gh/ucsb-cs156-w22/HappierCows/branch/main/graph/badge.svg?token=cu7LTPXZh1)](https://codecov.io/gh/ucsb-cs156-w22/HappierCows)


This is a full rewrite of the application HappyCows, a project sponsored by [Mattanjah de Vries, Distingished Professor of Chemistry at UC Santa Barbara](https://www.chem.ucsb.edu/people/mattanjah-s-de-vries).


The application is a simulation game that gives players (typically students in Prof. de Vries' courses) an opportunity to learn about the [Tragedy of the Commons](https://en.wikipedia.org/wiki/Tragedy_of_the_commons).

This rewrite uses the new tech stack being developed for [CMPSC 156](https://ucsb-cs156.github.io).    This tech stack uses:
* Spring Boot (Java) for the backend
* React (JavaScript) for the frontend
* Spring Security plus Google OAuth for authentication/authorization
  - This last point is what distinguishes this tech stack from the one currently in use (as S21) for the three legacy code apps in
    CMPSC 156: the current apps use Auth0 with JWTs as the authentication/authorization mechanism.

Storybook is here:
* Production: <https://happycows.github.io/HappierCows-docs/>
* QA: <https://happycows.github.io/HappierCows-docs-qa/>


The GitHub actions script to deploy the Storybook to QA requires some configuration; see [docs/github-actions.md](docs/github-actions.md) for details.

If these repos are not yet setup, see the setup steps in [`docs/storybook.md`](docs/storybook.md).

# Game Play for Developers

A description of how the game is played and what scheduled actions are run are given under [`docs/gamePlay.md`](docs/gamePlay.md)

# Setup before running application

Before running the application for the first time,
you need to do the steps documented in [`docs/oauth.md`](docs/oauth.md).

Otherwise, when you try to login for the first time, you 
will likely see an error such as:

<img src=""https://user-images.githubusercontent.com/1119017/149858436-c9baa238-a4f7-4c52-b995-0ed8bee97487.png"" alt=""Authorization Error; Error 401: invalid_client; The OAuth client was not found."" width=""400""/>

# Getting Started on localhost

* Open *two separate terminal windows*  
* In the first window, start up the backend with:
  ``` 
  mvn spring-boot:run
  ```
* In the second window:
  ```
  cd frontend
  npm install  # only on first run or when dependencies change
  npm start
  ```

Then, the app should be available on <http://localhost:8080>

If it doesn't work at first, e.g. you have a blank page on  <http://localhost:8080>, give it a minute and a few page refreshes.  Sometimes it takes a moment for everything to settle in.

If you see the following on localhost, make sure that you also have the frontend code running in a separate window.

```
Failed to connect to the frontend server... On Heroku, be sure that PRODUCTION is defined.  On localhost, open a second terminal window, cd into frontend and type: npm install; npm start"";
```

# Getting Started on Heroku

On Heroku, you'll need to set the following configuration variable:

* Using the Heroku CLI:
  ```
  heroku config:set PRODUCTION=true --app <heroku app name>
  ```
* Or set it on the Heroku Dashboard:
  ![image](https://user-images.githubusercontent.com/1119017/149855768-7b56164a-98f7-4357-b877-da34b7bd9ea4.png)

You'll also need to follow the OAuth set up instructions here: [`docs/oauth.md`](docs/oauth.md).

If you get the following message on Heroku, it probably means that you failed to setup the `PRODUCTION` environment variable.

```
Failed to connect to the frontend server... On Heroku, be sure that PRODUCTION is defined.  On localhost, open a second terminal window, cd into frontend and type: npm install; npm start"";
```

# Accessing swagger

To access the swagger API endpoints, use:

* <http://localhost:8080/swagger-ui/index.html>


# To run React Storybook

* cd into frontend
* use: npm run storybook
* This should put the storybook on http://localhost:6006
* Additional stories are added under frontend/src/stories

* For documentation on React Storybook, see: https://storybook.js.org/

# Accessing Database Console

* On localhost only: <http://localhost:8080/h2-console>  See also: [docs/h2-console.md](docs/h2-console.md)
* On Heroku, with CLI:
  - Use: `heroku psql --app app-name-here` 
  - Note that this requires that you have the psql CLI tool installed on your system.  
  - This does work on CSIL, but you may need `heroku login -i` in order to login on CSIL
  - Example:
   
    ```
    [pconrad@csilvm-03 ~]$ heroku psql --app demo-spring-react-example
    ›   Warning: heroku update available from 7.59.1 to 7.59.2.
    --> Connecting to postgresql-tapered-84555
    psql (13.4, server 13.5 (Ubuntu 13.5-2.pgdg20.04+1))
    SSL connection (protocol: TLSv1.3, cipher: TLS_AES_256_GCM_SHA384, bits: 256, compression: off)
    Type ""help"" for help.

    demo-spring-react-example::DATABASE=> 
    ```
* On Heroku, without CLI: 
  - Upper right of dashboard, select ""More"" then ""Run Console""
    
    <img alt=""Heroku Dashboard; More; Run Console"" src=""https://user-images.githubusercontent.com/1119017/150204550-a1027ab8-6ce7-4770-b566-a43928f5c3a0.png"" width=""300"" />
  - Enter `psql $DATABASE_URL` and click `Run`
   
    <img alt=""Enter psql $DATABASE_URL and click Run"" src=""https://user-images.githubusercontent.com/1119017/150206174-43193825-1afd-49f4-aeaf-cfadf0c0c6f3.png"" width=""400"" />
* Cheatsheet of `psql` commands: <https://www.geeksforgeeks.org/postgresql-psql-commands/>","['pconrad', 'btk5h']",1,,0.88,0,,,,,,0,,,
454203825,R_kgDOGxKZsQ,spring2022,Brown-CS2952N/spring2022,0,Brown-CS2952N,https://github.com/Brown-CS2952N/spring2022,Website for Brown CSCI2952N Advanced Topics in Deep Learning,0,2022-01-31 23:27:19+00:00,2022-01-31 23:27:59+00:00,2022-05-10 19:17:32+00:00,,183,0,0,HTML,1,1,1,1,1,0,3,0,0,0,mit,1,0,0,public,3,0,0,main,1,1,"# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a set of customizations on top of the popular [Just the Docs](https://github.com/pmarsceill/just-the-docs) theme, which provides a robust and thoroughly-tested foundation that makes it easy to extend for your own special use cases. These foundational features include:

- automatic [navigation structure](https://pmarsceill.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://pmarsceill.github.io/just-the-docs/docs/search/) and page indexing,
- and a small but powerful set of [UI components](https://pmarsceill.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://pmarsceill.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `index.md` with your course information.
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add your content.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([DS1](https://ucsb-ds.github.io/ds1-f20/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). For a few open-source examples, see the following course websites and their source code.

- [CSE 390HA](https://courses.cs.washington.edu/courses/cse390ha/20au/) ([source code](https://gitlab.cs.washington.edu/cse390ha/20au/website)) is an example of a single-page website that centers modules.
- [CSE 143](https://courses.cs.washington.edu/courses/cse143/20au/) ([source code](https://gitlab.cs.washington.edu/cse143/20au/website)) hosts an entire online textbook with full-text search.
- [CSE 373](https://courses.cs.washington.edu/courses/cse373/21su/) ([source code](https://gitlab.cs.washington.edu/cse373-root/21su/website)) is an example of a simple website combining Markdown pages with generated HTML files.

Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

Continue reading to learn how to setup a development environment on your local computer. This allows you to make incremental changes without directly modifying the live website.

### Local development environment

Just the Class is built for [Jekyll](https://jekyllrb.com), a static site generator. View the [quick start guide](https://jekyllrb.com/docs/) for more information. Just the Docs requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler.

1. Follow the GitHub documentation for [Setting up your GitHub Pages site locally with Jekyll](https://help.github.com/en/articles/setting-up-your-github-pages-site-locally-with-jekyll).
1. Start your local Jekyll server.
```bash
$ bundle exec jekyll serve
```
1. Point your web browser to [http://localhost:4000](http://localhost:4000)
1. Reload your web browser after making a change to preview its effect.

For more information, refer to [Just the Docs](https://pmarsceill.github.io/just-the-docs/).
",['jesu9'],0,,0.76,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
234821863,MDEwOlJlcG9zaXRvcnkyMzQ4MjE4NjM=,Rate-My-UCSB-Profs,CallistaTai/Rate-My-UCSB-Profs,0,CallistaTai,https://github.com/CallistaTai/Rate-My-UCSB-Profs,,0,2020-01-19 01:27:56+00:00,2020-01-19 01:30:55+00:00,2020-01-19 01:29:02+00:00,,3,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['CallistaTai'],1,,0.78,0,,,,,,1,,,
287357237,MDEwOlJlcG9zaXRvcnkyODczNTcyMzc=,MiniRayTracerPBR,undersilence/MiniRayTracerPBR,0,undersilence,https://github.com/undersilence/MiniRayTracerPBR," Multithread RayTracer(Cook-Torrance BRDF model, metallic workflow) implemented by C++",0,2020-08-13 18:52:03+00:00,2023-04-19 10:24:13+00:00,2022-06-20 11:12:48+00:00,,6326,4,4,C++,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,4,master,1,,"# MiniRayTracerPBR
$$
L_o(p, \omega_o) = L_e(p, w_o) + \int_{\Omega}f(p, \omega_i\rightarrow\omega_o)L_i(p, \omega_i)\cos\theta\mathrm{d}\omega_i
$$

  Multithread RayTracer(Cook-Torrance BRDF model, metallic workflow) implemented by C++.

  The basic code frame comes from [GAMES101.2020](https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html) Assignment7.

## Features
+ Cook-Torrance BRDF model
+ metallic workflow(material can be adjusted by [albedo, roughness, metallic], I've defined three materials(copper, silver, gold) in main.cpp as example)
+ importance sampling microfacet-based BSDF for GGX NDF(normal distribution function)
+ speed up intersection detection of triangle mesh with BVH
+ implement anti-aliasing by create random ray inside one pixel.(not by filter)
## Results
| spp16 | spp32 |
| :------: | :------: |
|![pic1](image/784x784_16spp_1597337087.png)|![pic2](image/784x784_32spp_17s.png)

|spp128| spp512 |
| :------: | :------: |
|![pic3](image/784x784_128spp_1597341889.png)|![pic4](image/784x784_512spp_1597342583_261s.png)|

|spp512 rough metal| spp512 marble floor|
| :------: | :------: |
|![pic5](image/784x784_512spp_1597344327.png)|![pic6](image/784x784_512spp_1597432985.png)

## Bugs
+ **SOLVED** ~~Rarely there will be particularly bright noise pointer, I think it's caused by dividing very small float(some pdf could be), maybe just spp is not high enough or algorithm's limitation?~~

## Future work
+ random number generation is very expensive
+ the implementation of Multi-threading needs to be improved(divide into blocks)
+ the code is untidy and needs cleaning
+ support common types of textures(normal map, albedo/roughness/metallic map..)
+ support transparent/anisotropic materials

## References
+ https://learnopengl.com/PBR/Theory
+ http://jcgt.org/published/0007/04/01/paper.pdf
+ https://agraphicsguy.wordpress.com/2015/11/01/sampling-microfacet-brdf/
+ https://schuttejoe.github.io/post/ggximportancesamplingpart1/
+ https://computergraphics.stackexchange.com/questions/7656/importance-sampling-microfacet-ggx
+ https://sites.cs.ucsb.edu/~lingqi/teaching/resources/GAMES101_Lecture_16.pdf
+ https://sites.cs.ucsb.edu/~lingqi/teaching/resources/GAMES101_Lecture_17.pdf
+ https://github.com/Bly7/OBJ-Loader

## Tips
+ please run the program in release mode, make sure you are not in debug mode when testing your high spp result(otherwise it will be a disaster).
+ It takes about 270 seconds to complete the rendering(mingw-w64/gcc) when spp=512 with cpu i7-9750H(2.60GHz,6c12t)
",['undersilence'],1,,0.75,0,,,,,,1,,,
422962085,R_kgDOGTXjpQ,ucsb_amenities,ucsb-codepath-team5/ucsb_amenities,0,ucsb-codepath-team5,https://github.com/ucsb-codepath-team5/ucsb_amenities,An iOS app to find bathrooms and study locations.,0,2021-10-30 18:34:33+00:00,2021-12-04 01:51:55+00:00,2021-12-04 01:51:52+00:00,,3012,0,0,Swift,1,1,1,1,0,0,0,0,0,11,,1,0,0,public,0,11,0,main,1,1,"# User Story Milestone 3
As a developer, I would like to be able to periodically add new locations to the locations and restroom tableviews

# Discussion 
We will use the Parse backend from back4apps to store the information of new locations as new classes with strings and doubles for the information relating to the locations

# Acceptance Criteria
- [x] User can see locations added to the map
- [x] Developers can add new object instances to the backend DB server


# Implementations To-Do's
- [x] Set up new classes in parse
- [x] Change the tableview to take in data from parse 

# UCSB AMENITIES

## Table of Contents
1. [Overview](#Overview)
1. [Product Spec](#Product-Spec)
1. [Wireframes](#Wireframes)
2. [Schema](#Schema)

## Overview
### Description
Help UCSB students locate some important amenities on campus, which are bathrooms and study rooms. 

### App Evaluation
[Evaluation of your app across the following attributes]
- **Category:** Utility/Productivity
- **Mobile:** Maps and navigation apps work well on mobile. Mobile is view only, uses location of user to showcase  
- **Story:** Allows users to quickly find study spots and bathrooms when needed in a pinch.  
- **Market:** UCSB students - over 20,000 students
- **Habit:** Study spots and bathrooms are places students need to go to every day
- **Scope:** We want to start with study locations and bathrooms using a map, but may be expanded to other useful locations in the future. 

## Product Spec

### 1. User Stories (Required and Optional)

**Required Must-have Stories**

* *Stream*: scrolling list view of locations (possibly ordered closest to user?)
* *Maps*: map with color-coded pins that mark locations 

**Optional Nice-to-have Stories**

* *Detail*: if a student clicks on the list/pin on the map, it goes to another screen that expands on more detail of location, e.g any features the study area might have (outlets, whiteboards, etc..) or what time a bathroom is locked or closed 

### 2. Screen Archetypes

* [Home screen]
   * List of amenities (bathroom and study rooms) maybe instead of just a home page there can be two pages, as described below
* [Map of UCSB]
   * contains color codded pins on where the bathroom and study room are on UCSB campus
* [Restrooms]
   * list view of restrooms, with a search feature
* [Study locs]
   * list view of study locations, with overview for each location 
* [Settings]
   * settings tab to change gender preferences and other things to change the priority ordering/ filtering for study locations and bathrooms

### 3. Navigation

**Tab Navigation** (Tab to Screen)

* Home: List view of locations, e.g bathrooms
* Map: Map view, has color-coded pins that mark the location 
* Study locs 
* Restrooms
* Settings

**Flow Navigation** (Screen to Screen)
* Study locs -> map tab
* Restrooms -> map tab 
* Settings -> Toggle settings

## Wireframes
https://www.figma.com/file/mgLcVCt9nYRo9E1Gi4T3gR/Amenities?node-id=0%3A1

<img src=""https://i.imgur.com/ThtzkIP.png"" width=800><br>

Interactive Demo: https://www.figma.com/proto/mgLcVCt9nYRo9E1Gi4T3gR/Amenities?node-id=1%3A2&scaling=scale-down&page-id=0%3A1&starting-point-node-id=18%3A20

<img src=""https://i.imgur.com/yNd0qXs.gif"" width=200><br>

## Schema 
### Models
#### User Info

   | Property      | Type     | Description |
   | ------------- | -------- | ------------|
   | username      | String   | username for an account |
   | password        | String| login info |
   | gender         | String     | user's preferred gender for restrooms |
#### Location Reviews
   | Property      | Type     | Description |
   | ------------- | -------- | ------------|
  | objectId      | String   | unique id for the user post (default field) |
   | author        | Pointer to User| image author |
   | rating         | Integer     | rating of location |
   | review | String | quick description of the location |

#### Location Info 
   | Property      | Type     | Description |
   | ------------- | -------- | ------------|
  | objectId      | String   | location name |
   | reviews        | Double| average rating of location |
   | tags         | String array     | Array of labels relating to the location (quietness, size, etc) |



### Networking
#### List of network requests by screen
   - Home Feed Screen
      - (Read/GET) Query all posts where user is author
         ```swift
         let query = PFQuery(className:""Ratings"")
         query.whereKey(""author"", equalTo: currentUser)
         query.order(byDescending: ""createdAt"")
         query.findObjectsInBackground { (ratings: [PFObject]?, error: Error?) in
            if let error = error { 
               print(error.localizedDescription)
            } else if let ratings = ratings {
               print(""Successfully retrieved \(ratings.count) ratings."")
            }
         }
         ```
      - (Create/POST) Leave a rating or change a rating
      - (Delete) Delete existing rating

#### [OPTIONAL:] Existing API Endpoints
##### An API Of Ice And Fire
- Base URL - [http://www.anapioficeandfire.com/api](http://www.anapioficeandfire.com/api)

   HTTP Verb | Endpoint | Description
   ----------|----------|------------
    `GET`    | /characters | get all characters
    `GET`    | /characters/?name=name | return specific character by name
    `GET`    | /houses   | get all houses
    `GET`    | /houses/?name=name | return specific house by name

##### Google Maps API 
- Base URL - https://www.google.com/maps/embed/v1/place
  ?key=YOUR_API_KEY
  
- Website -https://developers.google.com/maps/documentation/embed/embedding-map 

- Parameters -
    
![](https://i.imgur.com/6f0kgd8.png)
![](https://i.imgur.com/G2lVnmD.png)
![](https://i.imgur.com/ekGYnZx.png)


","['brian-w-ai', 'irdinaharris']",1,,0.86,0,,,,,,0,,,
93258068,MDEwOlJlcG9zaXRvcnk5MzI1ODA2OA==,ExploitCTF2017,pietrobiondi/ExploitCTF2017,0,pietrobiondi,https://github.com/pietrobiondi/ExploitCTF2017,,0,2017-06-03 15:49:12+00:00,2017-06-21 20:55:02+00:00,2017-09-07 10:54:06+00:00,,41012,1,1,Python,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,1,master,1,,"# ExploitCTF2017 CuredPin
Exploit for VM :  Crowdsourcing Evil 2015.

Using the ucsb icttf 2015 VM.

[iCTF 2015 VM Download](https://ictf.cs.ucsb.edu/archive/2015/vms/ictf2015.services.tpxz)

### Service avaiable in this repo
| Service name | Port | Description | Flag description |
|-----------------|-------|-------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| pirate_map | 20038 | Pirate map -- find correct map and get pirate treasure! | Flags are indentified by treasure name. |
| hanoiFones | 20040 | OnlineAuction platform | Flags are identified by the auction IDs. |
| nadmozg | 20067 | google translate killer | private dictionary name |
| FHM-Maintenance | 20111 | Password-protected web storage for secrets in C. | Flags are identified by the username. |
| ropeman | 20129 | An interesting ropeman/hangman game binary program. Password-protected note storage service in C. | Flags are identified by the note name.The flags are the status field in a txt file for a registered user |
| hacker_diary | 20130 | Keeps a private log of how your exploits work, with timestamps and hashes you can share, so you can prove you exploited something without sharing how | A flag_id is an entry id which corresponds to a detailed, prehashed description of an exploit. http: //<hostname>: <port>/entries/<flag_id> should yield an entry with the flag |
",['pietrobiondi'],0,,0.78,0,,,,,,0,,,
854397887,R_kgDOMu0Tvw,chesapeake-bay-nutrient-pollution-python,linusghanadan/chesapeake-bay-nutrient-pollution-python,0,linusghanadan,https://github.com/linusghanadan/chesapeake-bay-nutrient-pollution-python,,0,2024-09-09 05:17:12+00:00,2024-10-26 21:24:44+00:00,2024-10-26 21:24:40+00:00,,4900,1,1,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"## Time Series Analysis of Nutrient Concentration in Chesapeake Bay

### [Link to Blog (includes Python code, code output, and written analysis)](https://linusghanadan.github.io/blog/2024-8-20-post/chesapeake-bay-python.html)

### Repository Contents
    chesapeake_bay_nutrient_pollution_python
    └───images
        │   STL visualization for nitrogen: nitrogen.png
        │   STL visualization for phosphorus: phosphorus.png
    │   README.md
    │   .ipynb

### Context

For this final project in my master’s statistics course at UC Santa Barbara, I worked independently to find data, pose a question, and carry out analysis using statistical modeling and Python.

### Central Question

Over the ten years that followed the onset of new regulations in 2010, what linear trends best capture how average nitrogen and phosphorus concentrations have changed in the Chespeake Bay?

### Summary of Analysis

Proposed statistical question on possible underlying linear trends in average nitrogen and phosphorus concentrations across the Chesapeake Bay since 2010 (when new Clean Water Act regulations were implemented for the Bay) and found appropriate data for answering the question (over 43,000 samples from the Bay’s tidal regions). Constructed two Seasonal-Trend using LOESS (STL) decomposition models to conduct time series analysis of nitrogen and phosphorus concentrations (selected length of seasons based on autocorrelation). For each pollutant, visualized model parameters comparatively and ran regressions of parameters (to determine proportion of variation attributable to seasonality and 95% confidence interval for 10-year linear trend component).

### Datasets
- 2010-2019 Chesapeake Bay Program (CBP) Traditional Partner Tidal XLSXs

### Data References
- Chesapeake Bay Program DataHub. n.d. “Traditional Partner Tidal (Tier 3) Data.” https://datahub.chesapeakebay.net/FileDownloads.
",['linusghanadan'],1,,0.59,0,,,,,,1,,,
428782630,R_kgDOGY60Jg,group-15-ucsb-grad,Marco-Puzumbo/group-15-ucsb-grad,0,Marco-Puzumbo,https://github.com/Marco-Puzumbo/group-15-ucsb-grad,ESM206 Assignment 5 task 3,0,2021-11-16 19:10:14+00:00,2021-11-18 22:56:09+00:00,2021-11-18 22:56:06+00:00,,7,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# group-15-ucsb-grad
ESM206 Assignment 5 task 3
",['Marco-Puzumbo'],1,,0.75,0,,,,,,1,,,
10537111,MDEwOlJlcG9zaXRvcnkxMDUzNzExMQ==,cs8,pconrad/cs8,0,pconrad,https://github.com/pconrad/cs8,"CMPSC 8 at UC Santa Barbara, Instructor: Phill Conrad <pconrad@cs.ucsb.edu>",0,2013-06-06 21:44:42+00:00,2013-12-22 04:10:36+00:00,2013-06-06 21:44:42+00:00,,108,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"cs8
===

CMPSC 8 at UC Santa Barbara, Instructor: Phill Conrad &lt;pconrad@cs.ucsb.edu>
",['pconrad'],1,,0.78,0,,,,,,1,,,
53469795,MDEwOlJlcG9zaXRvcnk1MzQ2OTc5NQ==,cs56-android-games-pacman,ucsb-cs56-projects/cs56-android-games-pacman,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-android-games-pacman,-,0,2016-03-09 05:07:09+00:00,2022-03-07 10:40:43+00:00,2017-10-26 00:44:36+00:00,,12121,3,3,Java,1,1,1,1,0,0,13,0,0,12,,1,0,0,public,13,12,3,master,1,1,"# PacmanAndroid
A mobile version of the of Pacman game on Android

Authors: Kevin Lee, Jimmy Le

## Running the game
1. Load the project on Android Studio
2. Connect your device to your computer using a usb cable
3. Press ""Run"" (Shift + F10 on Windows)
4. Choose the device you wish to run it on such as your phone or the Android Studio emulator
5. The game should run on your device

##Screenshots
###Title Screen

![] (http://i.imgur.com/uM2tITF.png)

###How to Play

![](http://i.imgur.com/8koRTPe.png)

###Settings

![](http://i.imgur.com/KTMnEkE.png)

###Starting a new game

![](http://i.imgur.com/tYzTmNB.png)

###Gameplay

![](http://i.imgur.com/7BPCeaK.png)

###Pause Menu

![](http://i.imgur.com/VNNbl3o.png)

###Game Over

![](http://i.imgur.com/yZDJ8Ve.png)









## Current progress (Already Done)
* Title screen
* Three buttons on the screen (New Game, Settings, and How to Play)
* New Game button takes you to a screen with the map layout and pacman
* How to play button leads to the how to play screen
* You can move pacman around by swiping in the direction you wish to go
* Pacman will eat the pellets.
* Pacman dies when he touches the ghost.
* The game can be paused.
* The High Score and the Current Score are displayed at the top of the screen during the game.
* Eating pellets increases the current score.
* If the current score surpasses the high score, the high score updates accordingly.
* There is background music that starts and stops appropriately.

## User Stories (Implementation Tasks/Goals):
1. ~~As a user, I can see the introduction screen when I open the app so that I can know it has sucessfully opened.~~ (100pts)
2. ~~As a user, I can see a play button and a help button and a high score button so that I can click on them.~~ (50pts)
3. ~~As a user, I can click on the help button so that I can know how to play.~~ (50pts)
4. ~~As a user, I can click on the play button so that I can start the actual game.~~ (50pts)
5. ~~As a user, I can see the game board so that I know the game is about to start.~~ (150pts)
6. ~~As a user, I can see my character on the gameboard so that I know where I start.~~ (50pts)
7. ~~As a user, I can move my character so that I see myself move across the game board.~~ (250pts)
  * ~~The character should animate.~~ (50 pts)
  * ~~The character should be able to move up down, left and right.~~(25 pts)
  * ~~The character should move based on user input (swipe gestures).~~ (75 pts)
  * ~~The character stops moving when it reaches a wall.~~ (100 pts)
8. ~~As a user, I can see the pellets on the board so I know where to move.~~ (50pts)
9. ~~As a user, I can see my score to see how well I've played.~~ (50pts)
10. ~~As a user, I can move my character to eat pellets so that I can get points.~~ (150pts)
 * ~~The pellet should dissapear when the character moves over it.~~ (100 pts)
 * ~~The score should increase when the pellets get eaten.~~ (50 pts)
11. ~~As a user, I can pause the game so that I can continue later on.~~ (50pts)
12. ~~As a user, I can unpause/resume the game so that I can continue where I left off.~~ (50pts)
13. ~~As a user, I can see enemy ghosts on the board so that I know where they spawn.~~ (50pts)
14. As a user, I can see enemy ghosts move so that I know where NOT to move. (250pts)
 * ~~The ghosts should animate.~~ (50 pts)
 * The ghosts should move according to unique personalities/behaviors. (200pts)
   * [Ghost AI Movement](http://gameinternals.com/post/2072558330/understanding-pac-man-ghost-behavior)
 * There is more than one ghost in the game. (200pts)
15. ~~As a user, I can keep track of my highest score so I can strive to beat it.~~ (50pts)
16. ~~As a user, I can hear Pacman background music so I can get HYPED.~~ (150pts)
 * ~~The music shoud start when the user opens the app.~~ (25pts)
 * ~~The music should stop when the app is not in focus.~~ (50pts)
 * ~~The music should be shared across all screens so there is no overlap.~~ (75pts)
17. As a user, I can see a mute button so that I have the ability to mute the music. (50pts)
18. As a user, I can click on the mute button to mute the music. (100 pts) 
19. As a user, I can set different difficulties so that I can make it easier or harder for myself. (200pts)
20. As a user, I can change the colors of the game so I can set things to my color preference. (100pts)
21. As a user, I can pause and continue the game using a pause button. (100pts)
22. As a user, I can start a new game after losing the previous game so that I can play again.
23. As a user, I can use the mega-pellet so that I can kill ghosts.
24. As a user, I can respawn the ghosts so that they come back after dying.
25. As a user, I can save settings so that preferences are set.


##W16 Final Remarks##
For future students, If you have no prior experience in android programming then it is highly recommended you at least go through the android tutorial [here](https://github.com/UCSB-CS56-Projects/cs56-android-getting-started). There are a couple of things that you should also be very familiar with which include: [Drawing/Animation](http://developer.android.com/guide/topics/graphics/2d-graphics.html), [Activities](http://developer.android.com/guide/components/activities.html), [Intents](http://developer.android.com/reference/android/content/Intent.html), [Touch Events](http://developer.android.com/reference/android/view/MotionEvent.html), [Bitmaps](http://developer.android.com/training/displaying-bitmaps/index.html), [Supporting multiple screens](http://developer.android.com/guide/practices/screens_support.html).

Next you are encouraged to look through DrawingView.java first as this is where the bulk of the code is including the animation, wall collision, points, etc. It may seem very overwhelming at first, and it is, but smart students like yourselves will understand it in no time. Right now the code is pretty messy especially in the DrawingView.java because we haven't refactored the code out to different classes for specific things like pacman or ghosts. That could possibly be one of the things you guys can do for points. 

Right now the core of the game is mostly done. The things that are currently working are the Main Menu Screen, Help Screen, Music, Pause/Resume, pacman animation using swipes, eating pellets, score system. The things that you guys should probably fix are the ghost AI (it kind of works but it has alot of bugs), making it so that when pacman and the ghosts touch each other pacman dies, centering the map without messing up the wall collisions (this may seem easy and even trivial however, keep in mind that since this is on android, the game will have to support multiple screen sizes and dimensions of a huge variety and this causes complicaitons with the wall collision), and make it so that when you finish eating all the pellets you go to the next level. By the way there should be a java file called BackgroundMusicService.java and note this is NOT the way music was implemented in the program, the way music was implemented in the program is using a static [mediaplayer](http://developer.android.com/guide/topics/media/mediaplayer.html) that could be accessed across all activities of the program. The way BackgroundMusicService implemented music is through [services](http://developer.android.com/guide/components/services.html) which you may choose to do if you like.

New features that you may like to add include settings that allow the user to change the difficulty, color of pacman/ghost, and allow users to choose their own music. Also I highly recommend that you guys add a mute button for the music because the music gets pretty annoying after a while (Note: it will get stuck in your head after you hear it for even a little bit). Perhaps you can also add another game mode and try to make it adhere to Google's [material design standard](https://www.google.com/design/spec/material-design/introduction.html#) if you have time. Well that's about it, I know this is a lot of information especially if you're new to android but trust me, it gets better and it's so much more fun and exciting once you get the hang of it. There is alot of good documentation about most of the things you need to know about android and Google is your friend.

##M16 Final Remarks##
For future students, if you have no prior android programming experience, then it is highly recommended that you go through the android tutorial links above.

To review, the code for each ""screen"" of the game, which handles the buttons/widgets is located under cs56-android-games-pacman/app/src/main/res/layout/(""screen"" you want to work on). From there, each widget's methods that are called are located in their corresponding class underthe first, /app/src/main/java/com.example.jimmyle.pacmanandroid./(""screen"" you want to work on)  For example, the code for the Main layout is located in MainActivity.java. This should provide a basic knowledge foundation on where to look for things in the game.

We fixed one of the issues that the W16 class had which was the refactoring of the DrawingView class into seperate classes that could handle their own behavior. So far we created a BitmapImages class for getting bitmap images of pacman, the ghost and the world objects. We created to character objects Pacman and Ghost which would allow them to be a fully encapsulated class. We added a Movement class for handling the movement of the characters, one thing you could improve would be changing the methods to be static so new ghosts could be added. Also, we have a PlayerDeathException class that throws an exception when a ghost touches a player which could be improved upon if new ghosts are added.

A new feature we added is the ability to select levels through the Settings page. At the handled by the Global variable ""levelSelector"", which is set in SettingsActivity.java and later called in DrawingView.java, which is the class used to draw the map. If you wish to add new levels, simply create a new multi-dimensional array of bitmaps in LevelGenerator.java and add in the case in LevelGenerator.java's getMap(int level) method.

Another new feature we added is the ability to mute the music from the Settings page. This is handled in SettingsActivity.java.

We refactored DrawingView into smaller classes and objects, but there is still a long way to go before it is a single drawing class. You can take all of the methods that run the game a put them into a game controller in order to have seperate classes and behaviors. 

##F16 Final Remarks##
For future students, if you have no prior android programming experience, then it is highly 
recommended that you go through the android tutorial links above. There are a couple of things 
that you should also be very familiar with which include: Drawing/Animation, Activities, Intents, 
Touch Events, Bitmaps, Supporting multiple screens.

The game's current and completed issues are listed above.
We've added screenshots to show what the game and its menus look like. 
There are some instances that cause the game to crash but otherwise the game runs fine.

The classes are stored in app/src/main/java/com/example/jimmyle/pacmanandroid.

The classes that end in Activity hold the code for the menus. The code for the buttons and related widgets in the menus are stored in the .xml files in app/src/main/res/layout. 
The images are stored in app/src/main/res/drawable. The BitmapImages class loads these images.
The Gameconditions class holds the conditions that are run per instance of the game. 
The Globals class holds the values that exist outside of the game such as high score. 
The Movement class holds the movement behavior the ghosts and pacman. There are four copies of 
ghost movement methods for each ghost. 
The UserInterface class holds the draw methods for the elements of the user class.
There are currently three levels in the game and the code for those levels is stored in the LevelGenerator class.
The DrawingView class instantiates the map, draws the figures, and runs the game. 

Drawing View has been refactored to separate the draw methods, game conditions, and entity movements.
A pause button and a mute button have been added to the game. More ghosts have been added to the game. The difficulty buttons now change color when selected.

Some issues future students can focus on are giving each ghost a unique behavior, adding more levels to expand the scope of the game, adding powerups (http://pacman.wikia.com/wiki/Power-Ups), adding sound effects such as the wakka noise, and adding animations such as the death animation.
## Project History
```
M16 | Kevin Chan, Cole Rogers | W16 | Kevin Lee, Jimmy Le | F16 | Austin Dorotheo, Miclos Lobins | CS56 Conrad | 4PM Section
```
","['jimmylle', 'KevinLee00', 'mlobins', 'colerogers', 'kevinchanucsb', 'Tektonbuilds', 'johnnyzhang295', 'kvnloo', 'pconrad', 'adorotheo', 'Justin-Nilsen', 'scottpchow23', 'ashedden', 'MicLob', 'ntpincus']",1,,0.77,0,,,,,,5,,,
162784733,MDEwOlJlcG9zaXRvcnkxNjI3ODQ3MzM=,CompositeStrength,amilworks/CompositeStrength,0,amilworks,https://github.com/amilworks/CompositeStrength,Predicts effective yield strength of a composite given its 3D microstructure,0,2018-12-22 05:37:44+00:00,2023-04-20 00:29:24+00:00,2023-04-20 00:24:55+00:00,https://bisque2.ece.ucsb.edu/,24569,0,0,Python,1,1,1,1,1,0,0,0,0,21,,1,0,0,public,0,21,0,master,1,,"![github-yieldstrength](https://user-images.githubusercontent.com/22850980/233224946-c83341e1-55d4-4747-a878-fe1b15113d90.svg)

# **Composite Strength Module**
### Amil Khan, Marat Latypov | Version 2

[__Read the Paper__](https://link.springer.com/article/10.1007/s40192-019-00128-5) | [__Demo__](https://bisque2.ece.ucsb.edu/module_service/Composite_Strength/)

## Description
This module implements a surrogate model that predicts effective yield strength of a composite given its 3-D microstructure. The model is developed for composites with strength contrast of 5: strength of hard phase $s2/s1 = 5$. The model works best on periodic 3-D microstructures. Calibration of the model is done by finite element simulation data by multivariate polynomial regression between principal component scores of 2-point statistics (representing microstructure) and effective yield strength (property). 

![Workflow](https://bisque2.ece.ucsb.edu/module_service/Composite_Strength/public/marat_workflow.png)

## BisQue Platform

BisQue is a free, open source web-based platform for the exchange and exploration of large, complex datasets. It is being developed at the Vision Research Lab at the University of California, Santa Barbara. BisQue specifically supports large scale, multi-dimensional multimodal-images and image analysis. Metadata is stored as arbitrarily nested and linked tag/value pairs, allowing for domain-specific data organization. Image analysis modules can be added to perform complex analysis tasks on compute clusters. Analysis results are stored within the database for further querying and processing. The data and analysis provenance is maintained for reproducibility of results. BisQue can be easily deployed in cloud computing environments or on computer clusters for scalability. BisQue has been integrated into the NSF Cyberinfrastructure project CyVerse.


## Getting Started

Here is a preview of a logged in [BisQue](https://bisque.ece.ucsb.edu/client_service/) user, me. Don't judge me too much. 

![bisque](https://github.com/amilworks/BisQue_CompositeStrength/blob/master/public/interface.png)

Next, to see the module in all its glorious action, click on __Analyze__ at the top, find and select __Composite Strength__. You should arrive at a page that looks like this. 

To run your analysis, upload your HDF5 file, select either your own `Reducer` and `Predictor`, or our calibrated ones. 

Note: If your file needs Dream3D, we gotchu. Head over to the Dream3D module and upload the pipeline and your Dream3D file. Hit run, get your output HDF5, and run it through Composite Strength.

Another Note: I am making the huge assumption that you are familiar with Material Science or know what you're doing.

## Results 

![bisque](https://github.com/amilworks/BisQue_CompositeStrength/blob/master/public/composite_strength_GUI2.png)

Once your run is complete, you will see the results in the block below. If your input was a dataset, you would see results for each table. Therein, you can go through each table to make sure everything makes sense.
",['amilworks'],1,,0.7,0,,,,,,0,,,
387015316,MDEwOlJlcG9zaXRvcnkzODcwMTUzMTY=,lizard-guts-naxos,katekathrynkat/lizard-guts-naxos,0,katekathrynkat,https://github.com/katekathrynkat/lizard-guts-naxos,,0,2021-07-17 18:45:10+00:00,2021-10-12 22:10:18+00:00,2021-10-12 22:10:14+00:00,,33217,0,0,HTML,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,master,1,,"# lizard-guts-naxos

Lizard prey selection on Naxos (Greek Cyclades)

View analyses at https://katekathrynkat.github.io/lizard-guts-naxos/

## Directory structure

    .
    ├── data_raw         # Raw data files
        ├── field            # Field/lab measurements
        ├── literature       # Data compiled from the literature
        └── spatial          # Maps and other spatial files
    ├── docs             # Website HTML files (rendered from R_markdowns)
    ├── output           # Figures (.png) and data (.csv) generated during analyses
    ├── R_markdowns      # Code for analyses (.Rmd)
    ├── R_scripts        # Scripts containing source code, functions, etc. (.R)
        └── archive          # Unorganized snippets of ill-fated code (view at your own risk)
    ├── renv             # Package management with renv
    ├── reports          # Standalone HTML reports (rendered from R_markdowns)
    └── README.md        # You are here

-----

**Contact:** Kate Culhane, kathrynculhane@ucsb.edu
",['katekathrynkat'],1,,0.84,0,,,,,,1,,,
635600958,R_kgDOJeKAPg,Almond-Yield-Anomaly,aksandhu23/Almond-Yield-Anomaly,0,aksandhu23,https://github.com/aksandhu23/Almond-Yield-Anomaly,,0,2023-05-03 03:38:20+00:00,2023-05-03 04:16:55+00:00,2023-05-03 04:13:57+00:00,,612,1,1,R,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,1,main,1,,"<h1 align=""center""> Calculate Almond Yield and Create a Profit Model<h1>

![image](https://github.com/aksandhu23/Assignment2/blob/main/Almonds.jpg)

## Project Motivation

For this assignment provided in our EDS 230 Environmental Modeling class, the goals were to:

- Implement a simple model of almond yield anomaly response to climate.
  - Draw a diagram to represent your model - how it will translate inputs to outputs, with parameters that shape the relationship between inputs and outputs. 
  - Implement your diagram as an R function.

- Develop a profit model for your almond yield.
  - Do a simple informal sensitivity analysis of almond yield profit using at least 2 parameters.
  - Create a single graph of the results.
  
 ## This repository contains the following files: 
 ### Files:
- HW2.Rmd: Read in the climate data to test the almond yield function
- HW3.Rmd: An example of how to use the profit model containing plots of the results
- almond_yield_function.R: Almond yield as a function to calculate the anomaly in acres per ton
- profit_model.R: Profit model function for almond yield anomaly
- clim.txt: The dataset used to conduct analysis
- EDS230_Diagram.pdf: An initial diagram of the almond yield anomaly model
  
  ## Collaborators 
If you have any questions, comments, or concerns, please reach out to a team member using the information below:
##### Elise Gonzales,    Github: efgonzales,       Email: efgonzales@bren.ucsb.edu

##### Amrit Sandhu,      Github: @aksandhu23,       Email: aksandhu@bren.ucsb.edu
",['aksandhu23'],1,,0.63,0,,,,,,1,,,
112038021,MDEwOlJlcG9zaXRvcnkxMTIwMzgwMjE=,ucsb-cs56-w18.github.io,ucsb-cs56-w18/ucsb-cs56-w18.github.io,0,ucsb-cs56-w18,https://github.com/ucsb-cs56-w18/ucsb-cs56-w18.github.io,"Website for UCSB CS56, W18 (https://ucsb-cs56-w18.github.io)",0,2017-11-25 22:14:28+00:00,2018-08-10 17:25:55+00:00,2018-03-27 16:43:37+00:00,,2438,1,1,JavaScript,1,1,1,1,1,0,2,0,0,0,,1,0,0,public,2,0,1,master,1,1,,"['pconrad', 'rhelmot', 'scottpchow23', 'seemantasaha']",1,,0.76,0,,,,,,1,,,
228068309,MDEwOlJlcG9zaXRvcnkyMjgwNjgzMDk=,GPPCA,MengyangGu/GPPCA,0,MengyangGu,https://github.com/MengyangGu/GPPCA,Code for generalized probabilistic principal component analysis of correlated data,0,2019-12-14 18:16:35+00:00,2025-01-28 07:01:39+00:00,2019-12-14 18:58:02+00:00,,1237,5,5,R,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,5,master,1,,"# GPPCA
Code for Generalized Probabilistic Principal Component Analysis of Correlated Data

Mengyang Gu and Weining Shen (2019)

Journal of Machine Learning Research, In Press

arXiv preprint arXiv:1808.10868

This software is distributed under the terms of the GNU GENERAL PUBLIC LICENSE Version 2, April 2013.

This folder contains data and code reproduce the numerical results from the paper.

There are 5 folders.

src -- It contains the needed functions in C++ code to perform fast computing. In the code of R software, we use Rcpp and RcppEigen to call these functions. 
Demonstration -- The code to reproduce Figure 1 and Figure 2 in Example 1.
Simulation -- The code to reproduce all the simulation results in Section 4. 
Real_example_1 -- The code and data to reproduce Table 5 and Figure 8 in Section 5.1
Real_example_2 -- The code and data to reproduce Table 6, Figure 8 and Figure 9 in Section 5.2


Mengyang Gu
Department of Statistics and Applied Probability
University of California, Santa Barbara

Email: mengyang@pstat.ucsb.edu
",['MengyangGu'],1,,0.65,0,,,,,,2,,,
479898803,R_kgDOHJqssw,cart-pole-control,gschaffner/cart-pole-control,0,gschaffner,https://github.com/gschaffner/cart-pole-control,Cart-pole balance control for PHYS CS 15C in S21.,0,2022-04-10 03:04:14+00:00,2023-12-20 11:53:29+00:00,2022-04-10 03:05:58+00:00,,61869,1,1,Python,0,0,1,0,0,0,1,1,0,0,,1,0,0,public,1,0,1,squash,1,,"# Inverted Pendulum (Cart-Pole) Control
PHYS CS 15C, Spring 2021

Ganden Schaffner, Pierre Thibodeaux, Richard Yang

College of Creative Studies

University of California, Santa Barbara


# Introduction
![cart-pole](https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Cart-pendulum.svg/256px-Cart-pendulum.svg.png)

[Krishnavedala, CC0, via Wikimedia Commons]

The inverted pendulum is an illustrative dynamical system useful for studying nonlinear behavior and control methods for underactuated nonlinear systems. While a standard pendulum has a center of mass below its pivot point, an inverted pendulum has a center of mass below its pivot point. Thus, while a standard pendulum has a natural stable equilibrium when the center of mass is directly below the pivot point, the inverted pendulum has an unstable equilibrium when the center of mass is directly above the pivot point. Any perturbation away from this equilibrium is amplified, causing the pendulum to fall away from the usntable equilibrium.

In order to balance the pendulum upright, we need a controller that applies force/torque to the system in response to displacement from equilibrium. In our system, the pivot is attached to a cart which we move with a motor to provide this force. We can read the angular position of the pendulum and feed that measurement to a controller to determine how to move the cart to keep the pendulum upright. We implemented this using Python 3 and a Raspberry Pi 4.


# List of Components
### Hardware
* 0.75 x 3.5 in x R/L ft poplar
* 0.25 x 5.5 in x 2 ft poplar board
* 0.25 x 1.8 in x 2 ft poplar strip
* 1m Linear rails + sliding carts
* GT2 Timing Belt + 5mm teeth pulleys wheels
* 8mm bore diameter ball bearing pillow block
* 6mm diameter ball bearing
* M6 x 80 mm partially threaded bolt
* M3, M4, M5 bolts and nuts
* Rotary tool
* Super glue
* Wood glue
* Panel saw
### Electronics
* Raspberry Pi 4
* HEDS-5505 Rotary Encoder
* NEMA-17 Stepper Motor
* Stepper Motor Bracket
* BIQU A4988 Motor Driver
* ALITOVE DC 12V 10A Power Supply
* Breadboard
* 1m Female-to-Male breadboard jumper wires
* Ring wire connectors
* 100 uF capacitor
* 3-prong power cord


# Design
## Cart-Pole Hardware Design
The hardware design for our cart-pole came primarily from [this Instructable](https://www.instructables.com/Inverted-Pendulum-Control-Theory-and-Dynamics/), though with large modifications.

There needs to be a cart, from which the pendulum pivots. This cart moves back and forth on a rail, being moved by a belt attached to the motor. Here is a preliminary design of the rail system:

![rail system](images/1_3.jpg)

The cart needs to have a wall to accomodate the pivot of the pendulum. The friction in the pivot is reduced by a ball bearing, through which the axle/shaft is fed. Using a thick wall with multiple contact points reduces torque on the system. On the inside wall, the encoder is fixed to measure the angular position of the pendulum. Here is a preliminary design of the pivot:

![pivot system](images/1_4.jpg)

Here is an early, rudimentary 3D model of the whole system. The foreground version is truncated, with the pendulum removed, for visibility:

![model of system](images/Screen%20Shot%202021-04-06%20at%2011.07.30%20PM.png)

This model can be explored in 3D [here](https://www.tinkercad.com/things/0iKo4K6oQAa-inverted-pendulum-cart-simple-design). The cart design and overall design were modified, as will be evident in the result of the Building process section.

## Software Design
We chose to use a single-board computer (Raspberry Pi 4) for control rather than a microcontroller. A few factors went into this decision. First, we all had preexisting familiarity with Python but not with the Arduino language. While a microcontroller could provide a faster response time, there are many documented instances of working cart-pole balance controllers running on Raspberry Pi's, so the lower response time was not a major concern. More important to us was the speedup we would have from not having to learn a new language.

Our software consists of three main pieces:
* Our simulation of the system.
* Our controllers. These are not hardware controllers—they are controllers in the control theory sense. They are are boxes that take in state and output a float.
* Our hardware control code, the part that interacts with the physical circuitry.

Desired interoperability between these pieces also factored into our decision to write everything in Python. We wanted each controller to be modular so that it could be run on either simulation or on the actual hardware. We ended up adhering to this philosophy for one of our controllers, but the second was integrated directly into hardware control code since it would not have been feasible to test it on our existing simulation; more on this later.

## Circuit Design
The general circuit design is as follows:

![circuit design](images/Screen%20Shot%202021-06-02%20at%2011.40.58%20PM.png)

The rotary encoder is connected to the RPI 5V and GND. Its Channel A, B outputs are sent to two GPIO pins to serve as inputs, specified in the code (here, 23 and 24).

The motor driver mediates the outputs from the RPI and translates it into motor movement. The motor driver STEP and DIR inputs are connected to the RPI through GPIO pins specified in the code (here 27 and 22), which respectively control the speed and direction of the motor. The driver is also connected to the ground and 5V pins of the RPI, to drive the logic inputs (STEP, DIR). Sleep and RESET on the driver are connected. The motor is connected to the driver at A1,B1,A2,B2. The driver is given DC power input from the power supply, which converts wall outlet AC voltage to usable DC voltage and steps it down to a useable voltage (120AC to 12DC). A capacitor is placed across the power supply voltage and its ground to prevent discharge when the system is disconnected, and to limit the current going into the motor.

An implementation is depicted here:

![breadboard](images/breadboard.jpg)


# Building Process
**Step 1: Linear rails**

The two ends of the linear rails are fixed to a large wooden block with mounting screws. The two linear rails must be parallel to each other so that the pendulum-cart assembly can freely slide. The distance between the two linear rails is 70 mm from end to end. Use a rotary tool to drill appropriate holes on the wooden blocks, and fix the rails on top with screws. See picture below.

![linear_rail](images/linear_rail.jpg)

**Step 2: Idle pulley and stepper motor mounting**

The idle pulley and stepper motor need to be at approximately the height as the metal carts, on which the pendulum is mounted. Slide the metal carts onto the rails and measure the height from the wooden block at the end of the rail to the top of the cart. This determines how much the pulley and/or stepper motor needs to be elevated. For our apparatus, a block of wood with a height of about 20 mm is placed between the idle pulley and the end wooden block. The stepper motor does not need any elevation.

A timing pulley wheel is used on both the shaft of the stepper motor and the idle pulley. For the stepper motor, the timing pulley directly locks onto its shaft. The idle pulley is constructed by putting a M4\*20 bolt through a pulley wheel with a nut locked on the other side. The nut is then fitted snugly into the pillow bearing block. See pictures for details.

![idle_pulley_separate](images/idle_pulley_separate.jpg)

![idle_pulley](images/idle_pulley.jpg)

The stepper motor is mounted with a stepper motor bracket onto the linear rails. A large rectangular piece of wood is cut out from the wood plank to give enough room for the motor to be placed with its timing pulley wheel in between the two rails. See picture for details.

![stepper_motor_mounting](images/stepper_motor_mounting.jpg)

**Step 3: Pendulum-cart assembly**

The pendulum is made by fixing the end of a 70mm long M6 shaft through one end of a long wooden strip. Use a rotary tool to drill a hole of suitable diameter for the shaft to fit in and make sure the hole is centered along the midline of the strip.

The shaft passes through two vertical side pieces. Cut out two rectangular pieces from the plank of wood with dimensions 70mm x 60 mm. Drill a whole in the center of each piece so that a M6 bearing can be embedded inside. See picture below for detail.

![side_piece](images/side_piece.jpg)

On the left side of the picture is the encoder base plate; in the middle is a side piece in the process of drilling a hole through it, and on the right is a finished side piece.

The two side pieces rest on top of a platform, which is in turn locked onto the rail carts. Cut out a 140 mm x 70 mm rectangle from the plank of wood for the platform. Drill a slit on the midpoint of the platform's longer side. This is where the timing belt will pass through in the later part.

The rotary encoder is super glued on one of the side pieces with the pendulum shaft passing through its optical disk. Make sure the shaft can pass freely through the side piece and the encoder. Be very careful with locking the rotary encoder onto the shaft! The rotary encoder is typically not designed to be dismounted from the shaft, which means you should lock the encoder after checking all parts of the pendulum-cart assembly are in place. Always check the datasheet and other information provided by the manufacturer before use. See schematics for details:

![pendulum_schematic](images/pendulum_schematic.jpg)

Use wood glue to attach the two sides pieces onto the platform. One side piece sits on a shorter side of the platform, and the other side piece is 30 mm inward and in parallel with the first one. Make sure the shaft can fit through the two side pieces and is in good orientation before applying wood glue to the side pieces.

Slide in the shaft through the two sides pieces and leave the entire threaded part outside (see schematics above). Lock the rotary encoder onto the shaft following the instructions provided by its manufacturer.

**Step 4: Putting everything together**

Slide the two rail carts onto the rails and mount the pendulum-cart assembly on top with screws. Wind the timing belt around the two pulleys and into the two slits of the platform. Next, mount the pendulum on the threaded part of the shaft. A washer and a nut should sandwich on either side of the pendulum. The hardware is assembled!

![hardware_frontview](images/hardware_frontview.jpg)

![hardware_topview](images/hardware_topview.jpg)


# Simulation and Control Theory
_N. B._ This section is written to accompany [derivation.pdf](derivation.pdf) (i.e. [derivation.tex](derivation.tex)), parts of which should be considered as part of this README. As we go through this, I will note when you should tab over to [derivation.pdf](derivation.pdf) to read a section there.

## Equation of Motion and Simulation
As simulation of the system was implemented based on a derivation of the cart-pole system's equation of motion. The equation of motion included terms for the control force `u(t)` applied to the cart. See the ""Equation of Motion"" section of [derivation.pdf](derivation.pdf) for this derivation. The first part of [derive.py](src/derive.py) also performs the last step of this derivation symbolically. It is not important that you read the entire ""Equation of Motion"" section of [derivation.pdf](derivation.pdf), but you should understand the equation of motion as written in manipulator form:

![](images/equations/EoM-2D.png)

This equation was quite important in the development of a linear-quadratic regulator for the system, as we will describe soon.

Simulation of motion based on this derivation was implemented in [sim.py](src/sim.py), which relies primarily on `scipy.integrate.solve_ivp`. [sim.py](src/sim.py) can also render animations of the simulated system.

## Considered Types of Controllers
For balance control, we want a controller that minimizes the error vector

![](images/equations/error-vec.png)

with some meaningful definition of ""minimizes."" We considered two major controller types for balance control, each with their pros and cons:

* PID controller
    * Con: Can be tedious to tune
        * Up to 3 * N_inputs constant parameters in general.
            * With our error vector, redundancy between integrals and derivatives means that this would be up to 8 parameters to tune. In practice, a few of these would be unimportant and set to zero, so there would be 3–5 parameters to tune.
        * Navigating parameter space can be finnicky when one is trying to tune.
    * Pro: Does not require explicit knowledge of the system's governing differential equation.
        * Widely applicable to many systems.
* Linear-quadratic regulator (LQR)
    * Pro: Much easier to tune
        * Up to N_inputs * (N_inputs + 1) + 1 constant parameters in general.
            * In practice, good controllers need only N_inputs nonzero parameters. For us, this is 5. This is actually effectively only 4, however, since the relative scaling of an LQR's parameters does not affect the resulting controller.
        * The parameter space is ""smoother,"" loosely speaking. It's much less finnicky to navigate than a PID's parameter space usually is.
    * Con: Requires knowledge of the system's (linearized) governing differential equation (the equation of motion, in our case).
        * ⇒ Applicable to fewer systems.

## Deriving a Linear-Quadratic Regulator (LQR)
We decided to try using an LQR for balance control before trying a PID, as we expected an LQR would be much easier to tune than a PID controller. We also already had familiarity with PID's and wanted to take the opportunity to explore something new.

Unlike a PID controller, an LQR requires knowing the system's equation of motion, linearized about the equilibrium that we want the system to balance at. This linearization is detailed extensively in Section 2 of [derivation.pdf](derivation.pdf), with symbolic calculations done in [derive.py](src/derive.py). Here I will just describe the general gist of the derivation.

First, the state vector `s` was used to push the equation of motion down to first order: in block notation,

![](images/equations/EoM-1D.png)

To linearize this about the unstable equilibrium (`s^*`, `u^*`), we then calculated the Jacobians

![](images/equations/A-B-Jacobians.png)

yielding the linearized equation of motion

![](images/equations/EoM-1D-linearized.png)

An LQR then uses the linear control law

![](images/equations/LQR-control-law.png)

to minimize the cost function

![](images/equations/LQR-cost.png)

where `Q`, `R`, and `N` are parameters that one must tune. Note that this cost is a time-integrated quadratic form. Noting that the vector `u` has only one nonzero component, we have 4 * x + 1 + 4 = 21 parameters to tune here.

In practice, however, we don't need all of this generality. Please read the discussion of this at the end of Section 2 of [derivation.pdf](derivation.pdf). The result is that we only have 5 important parameters to choose: the diagonal of `Q`, and a scalar `R`. Each element `Q_{ii}` weights the penalty assigned for error in the component `e_i`, while the scalar `R` penalizes the control and keeps it from being overly large.

The matrix `K` is then calculated by solving the continuous-time algebraic Riccati equation, which can be done numerically. Even though an LQR is actually just a proportional controller, which can have problems with overshooting their set point, the time integral in the LQR's cost function means that the controller will do a good job at preventing overshoot.

## Results of LQR on Simulation
Tuning the parameters for the LQR was incredibly easy. It took only perhaps an hour to find a set of parameters that work very well in simulation, with most of the time during tuning being spent waiting for simulated animations to render. Compare this to how long it has probably taken you to tune PID's in the past.

Furthermore, the performance of the controller did not vary significantly when the LQR parameters were perturbed. This is the aforementioned ""smoothness,"" which is best seen from the fact that LQR parameters are _penalties_ on different types of errors away from equilibrium. A PID's parameters, on the other hand, are coefficients in the actual _response_ of the controller. When tuning a PID controller, one is directly setting coefficients in the controller's response. But LQR takes a step back into a more abstract space, where one tunes _penalties_ for error rather than tuning what the actual _response_ should be itself. This step back into a nicer parameter space is only possible because an LQR has knowledge of the system's equation of motion.

[Here](images/lqr-sim/00-deg,pi-on-2-radps.mp4) is an example of the LQR working in simulation. It works nicely and doesn't overshoot the center of the track too much when returning to the desired set point there.

Note that the lengths, masses, etc. used in simulation match to the dimensions of the hardware we built. Do note, however, that the tip of the pendulum, as displayed in simulated animations, is actually the center of mass of the pendulum. The real pendulum is about twice as long as it naïvely appears to be in the animations.

Let's now look into the performance of the LQR. In particular, let's look at two cases: response to an initial angular displacement (with no angular velocity or cart velocity), and response to an initial angular velocity (with no angular displacement or cart velocity).

## LQR Performance: Initial angular displacement

For each initial angular displacement `theta_0`, we simulated the system with LQR control applied. For each `theta_0`, we took note of the maximum force and the track length that the controller used to stabilize the pendulum.

We found that the controller could stabilize initial angles up to about 75 degrees. This was very impressive—remember, the LQR is has ""knowledge"" of the _linearized_ equations of motion, _linearized_ about the set point. 75 degrees is well out of the `sin(theta) = theta` range, so it's rather incredible that the controller works this far out.

![](images/lqr-sim/force-v-ang.png)

Note that the above plot is linear, except at large `theta_0`. Since the controller is linear, the control applied at `t = 0` is linear in `theta_0`. So a linear plot would occur if the controller was applying the maximum force at `t = 0`. This is in fact the case! This is a sign of a good controller, showing that it doesn't underreact to the initial condition.

In contrast, the nonlinearity that we observe at initial `theta_0` near the limit of what can be controlled means that at large `theta_0`, the controller applies the maximum force at `t > 0`. This isn't good. It means that the controller is underreacting to these large initial angular displacements and allowing the pendulum to continue falling over too quickly. As the pendulum falls over too quickly, the system state becomes ""worse"" than it was initially. The controller then realizes this and has to an apply an even stronger force than it did before. The nonlinearity that we can see at initial angular displacements near the controllable limit is because at these initial conditions, the controller could just barely take control of the system! And note that as `theta_0` increases up to the maximum controllable limit, the plot diverges even farther from linearity. At just above 75 degrees, the controller stops being able to take control of the system entirely—the initial angular displacement is just too extreme.

A similar figure was made showing the track length that the controller used for each initial `theta_0`:

![](images/lqr-sim/tracklen-v-ang.png)

Note that, while the controller can stabilize initial angular displacements of up to about 75 degrees, our actual track is only 1 meter long, allowing only about 20 degrees: [see animation](images/lqr-sim/20-deg,0.0-radps.mp4). This is still pretty good.

## LQR Performance: Initial angular velocity

We also did the same sort of performance analysis for the case of initial angular velocities (without initial angular displacement or cart velocity).

The controller could stabilize initial angular velocities up to about 1300 deg/s, or about 3.6 rev/s. Again, this is quite impressive!

![](images/lqr-sim/force-v-angvel.png)

The above figure is entirely linear, all the way up to the controllable limit (unlike the maximum force figure for initial angular displacements). Linearity indicates that the controller is not underreacting to the initial angular velocity, which is good. But the _lack_ of nonlinearity near the maximum controllable limit is curious, and we haven't come up with an explanation for why there isn't a bit of nonlinearity present near this limit.

A similar figure was made showing the track length that the controller used for each initial `omega_0`:

![](images/lqr-sim/tracklen-v-angvel.png)

This figure is rather interesting, for a few reasons. First, the linearity observed throughout of this track length figure is not something that we have a good physical explanation for! The length of track that the controller uses to stabilize the pendulum is just something that pops out the numerical integrals in our simulation! There doesn't seem to be an explanation for it via something like energy conservation, as the force applied by the controller is variable and depends on the system state, and the displacement over which this force is applied also depends on the system state, which is something with no nice analytic form that we must just numerically integrate for. If you manage to come up with a compelling explanation of this unexpected linearity, please let us know!

In the figure above, the behavior observed at initial `omega_0` near the controllable limit is also interesting. We can see that the track length used to stabilize the pendulum has a peculiar dip, and then it blows up. The dip is not something that we have been able to determine a physical explanation for. The explosion, on the other hand, has a nice interpretation. If one watches the animations of these simulated trials, the explosion is clearly associated with the onset of a huge overshooting of the set-point past some critical-ish value of `omega_0`. That is: if we increase `omega_0` past the threshold seen in the figure above, the pendulum is initially falling to the left very quickly, so the controller pushes the cart left to chase it. The forced cart makes its way under the pendulum in order to begin pushing the pendulum to the right, to catch the pendulum and move back toward the equilibrium at the center of the track. At most `omega_0`, the controller does a good job at this, with minimal overshoot of the track's center when rebounding. But past the critical-ish threshold value of `omega_0`, the controller almost loses control of the system while it pushes the system back to the center of the track. This causes an overshooting of the center. Below `omega_0` of about 1300 deg/s, this overshoot is still recoverable and the controller eventually succeeds at bringing everything back to the center. But above a quite high `omega_0` of around 1300 deg/s, the initial angular velocity is just too extreme for the controller to handle.

The final thing that we would like to note here is that while the controller can stabilize initial angular velocities of up to about 1300 deg/s in simulation, our actual track is 1 meter long, allowing only about 90 deg/s: [see animation](images/lqr-sim/00-deg,pi-on-2-radps.mp4). This is still pretty good.


# Hardware Control Code
## Input/Output
Generally, the design of the code is that we want to take in a reading from the encoder, do some action on that measurement to inform how the motor should move, and then tell the motor how to move that way.

The reading from the motor is handled by the [Encoder library](https://pypi.org/project/Encoder/) which translates the encoders quadrature-encoded signal into a single int, where the magnitude represents angular displacement from the start-up position, and sign represents the net direction of that displacement. This is converted into an angle measurement from equilibrium for use by the controller.

The action is determined by the controller, which takes in the current state of the system and returns an acceleration/force for the motor to perform. This is discussed in the previous section.

The stepper motor moves a finite ""step"" for every time-spaced pulse that is fed to it. Thus by manipulating the number of pulses we feed to the driver in a given time step, we can manipulate how fast the motor spins. The direction the motor should move in is determined by the sign of the intended force, and is fed to DIR. The magnitude is converted into a number of pulses, making sure to limit this number so as not to exceed the maximum torque/speed of the motor. The pulses (and direction) are generated using the [RPi.GPIO Library](https://pypi.org/project/RPi.GPIO/) and manually turned on and off to make the voltage high/lows that move the motor.

## Enumeration of Source Files
* [derive.py](src/derive.py) does symbolic calculations as discussed in [derivation.tex](derivation.tex)
* [sim.py](src/sim.py) generates the simulations and animations used to test the LQR
* [lqr.py](src/lqr.py) implements a LQR for balance control
* [measuremoment.py](src/measuremoment.py) records the (approximately) sinusoidal oscillation behavior of the free-swinging pendulum to calculate the moment of inertia of the pendulum
* [movemotor.py](src/movemotor.py) moves the motor a distance according to user input
* [drivesin.py](src/drivesin.py) moves the pendulum in a sinusoidal pattern to test motor control and to examine resonant behavior
* [encoder2motor.py](src/encoder2motor.py) uses a LQR to drive the system based on the encoder reading
* [encoder2pid.py](src/encoder2pid.py) uses a PID balance controller to drive the system based on the encoder reading


# Testing
As a preliminary testing of the hardware, we supplied the stepper motor with a sinusoidal driving function and recorded the pendulum's oscillation.

![sindrive](images/sindrive.png)

Sinusoidal driving at a random frequency.

![resonance](images/resonance.png)

Sinusoidal driving at the pendulum's measured natural frequency, 0.80 Hz. The system exhibits resonance.

The rotary encoder experiences a drift as the pendulum rotates.

![encoder_drift](images/encoder_drift.png)

The figure above shows significant drifting in angle measurement during free oscillation of the pendulum around 20 degrees. (ignore the units on the y-axis). The figure also suggests that the optical disk tends to be ""stuck"" at one place as the axle of the pendulum rotates.

This is because we dismounted the rotary encoder from a shaft that was used for testing purposes. The actual shaft intended for the encoder was delayed for delivery until week 8 of the quarter. As it turns out, the rotary encoder is designed to be locked permanently to a shaft. The dismounting and reinstalling of the shaft causes the slippage issue between the new shaft and the optical disk inside the encoder.

Our testing also shows that the stepper motor is not able to correct the falling pendulum to within an appreciable amount of initial angular displacement. [Click here](https://drive.google.com/file/d/1BHcrjFQCVGA6YQBz7S_OSBysZSyTQeNV/view?usp=sharing)


# Results/Analysis
Overall, our pendulum controller was able to correctly dictate the action that the motor should perform in order to fix the motion of the pendulum. However, the data we took involved Richard keeping his hands near the pendulum to prevent it from falling too far. As will be discussed, the system is unable to maintain equilibrium on its own. Here we can see a trial using the LQR:

![insert_LQR_plot](src/lab_data/run_0531/2021-05-31_17.44.12_figure.png)

Of note here are the purple and red curves. Purple represents intended motion of the motor, in pulses per timestep, as calculated by the controller. Red represents the approximate velocity of the cart based on the actual pulses delivered to the motor. The blue curve is the angular displacement from t = 0. Since we start the pendulum in its upright position, the blue curve is the angular deviation from the unstable equilibrium, and is the object the controller is trying to minimize. The blue and purple curves are almost always anticorrelated, which shows that the LQR is trying to balance the pendulum.

The difference between the purple and red curve is because we impose a maximum speed of the motor above which the motor ceases to work. We can see that in this plot, the red curve is bounded, but the purple curves exceed these bounds. Thus, we can conclude that the controller is ordering the motor to move above a certain speed that the motor cannot achieve.

This is reinforced in other tests that we performed. In [this video](https://drive.google.com/file/d/1BHcrjFQCVGA6YQBz7S_OSBysZSyTQeNV/view?usp=sharing) it can be seen that the motor has difficulty moving faster than the falling pendulum.

This is a limitation of our hardware. It is possible that using a pendulum with a higher moment of inertia would lessen the effect of this issue, as the pendulum would rotate slower compared to the motion of the motor. We could also use a faster motor, or try to use a larger pulley to translate the same angular velocity into a larger linear velocity of the cart.

Something to note here is that the LQR's theoretical design does not perfectly match our hardware. Ganden developed the LQR controller, but did not realize until too late that our choice to use a stepper motor rather than another type of motor meant that with our system, we actually control the cart's velocity, not the position. For example, if the stepper motor is powered off, the cart does not move freely; it is fixed, and the pendulum becomes a fixed-axis pendulum. Had the project been completed in person rather than with the other two group members unable to physically touch the hardware that Richard built, we would have realized this problem much sooner.

Because the LQR is theoretically flawed for our hardware, we tested a PID controller as well. This would not have solved the hardware issue, but we tried anyway.

![image](src/lab_data/run_0531/2021-05-31_20.29.17_figure.png)

The purple curve is anticorrelated with the blue curve, indicating that the PID controller is basically opposing the position of the pendulum, meaning that it is dictating the motor's motion correctly. However, the system seems to have a noticeable lag, and was ultimately unable to keep the pendulum upright. As expected, the change to the PID was not itself enough to make the system work.


# Issues/Error Analysis/Improvements
The motor does not really move fast enough for simple feedback control. As in, there is a maximum speed of the motor, and this speed is below what is necessary (for the pendulum we used) to correct displacements from equilibrium. The displacements are defaultly positive feedback, so the system needs to be able to react quick enough and move fast enough to outpace this. You could imagine that the bottom of the pendulum needs to move faster than the top of the pendulum in order for it to be returned to an upright position. This is not achievable with our motor. In order to correct this, we would probably want a motor with a higher maximum angular velocity. Using a larger pulley in our belt system could also turn the angular velocity of the motor into a higher linear velocity. It is also possible that a system with a larger moment-of-inertia per mass would move slower, and therefore, our motor would be able to respond quicker in comparison. This would require a pendulum of a different shape.

The rotary encoder experiences drift, as in, moving the encoder moves the angular position of the zero point. This is more profound for larger and more violent angular displacements then for small motions. This might be a consequence of taking apart the rotary encoder, as the HEDS-5505 is not meant to be taken apart, but we did anyways. To overcome this, we would ideally use another rotary encoder that does not have this issue. Using the same flawed encoder, we would want some method to reset the zero point, either manually, or based off of markers of the system (for example, based on the oscilliatory behavior of the system).

The pulse delivery system of the code is imperfect. Manually turning on and off the GPIO outputs might be slow or computationally inefficient, causing the system to react unideally. We would probably want to use the PWM functions in the RPi.GPIO library, though in the course of this project, we could not figure out how to make that work with our devices.

The remote setting of our group also proved to be a challenge for this project. The three members of the group are all in different locations: Isla Vista, San Luis Obispo, and Los Angeles. The hardware was solely constructed in Isla Vista, while the two other group members focused on simulation and coding. This inevitably delayed the construction of apparatus, and made troubleshooting more cumbersome when the system was set up. The lack of physical contact with the apparatus means it was in general harder for the remote members to fully gauge the system's behavior. Coupled with the logistic issue that the shaft of the pendulum was delayed and did not arrive until week 8, the lab apparatus was only constructed on week 8. This left very little time for integrating the hardware with the hardware control code and control (theory) code, testing, troubleshooting, and collecting data.


# Acknowledgements
We'd like to thank Andrew Jayich, Mingyu Fan, and Sean ""Beaks"" Buechele for their suggestions, ideas, and time throughout the quarter.

We'd also like to extend our thank to the authors, contributors, and maintainers of the following open source and/or free software projects:
* the Python language
* NumPy & SciPy
* Matplotlib
* SymPy
* [RPi.GPIO](https://sourceforge.net/projects/raspberry-gpio-python/)
* [Encoder](https://github.com/mivallion/Encoder)
* Black, isort, Flake8, & Flake8-bugbear


# References
* https://www.instructables.com/Inverted-Pendulum-Control-Theory-and-Dynamics/
* https://projekter.aau.dk/projekter/files/243991610/Swing_up_Control_of_an_Inverted_Pendulum.pdf
* https://doi.org/10.1016/j.promfg.2018.06.004
* https://doi.org/10.3182/20110828-6-IT-1002.01985
* https://create.arduino.cc/projecthub/zjor/inverted-pendulum-on-a-cart-199d6f
* https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-832-underactuated-robotics-spring-2009/readings/MIT6_832s09_read_ch03.pdf
",['gschaffner'],1,,0.66,0,,,,,,1,,,
832885963,R_kgDOMaTUyw,UCSB-CS40,Dorayakiee/UCSB-CS40,0,Dorayakiee,https://github.com/Dorayakiee/UCSB-CS40,,0,2024-07-23 23:40:43+00:00,2024-09-07 15:19:19+00:00,2024-08-02 00:55:33+00:00,,73906,1,1,TeX,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"# UCSB-CS40
> Foundations of Computer Science
>
> Summer Session 2024

- All the solutions are written in LaTex.
",['Dorayakiee'],1,,0.71,0,,,,,,1,,,
217761940,MDEwOlJlcG9zaXRvcnkyMTc3NjE5NDA=,VEXRoboticsUCSB,UCSBVexRobotics/VEXRoboticsUCSB,0,UCSBVexRobotics,https://github.com/UCSBVexRobotics/VEXRoboticsUCSB,,0,2019-10-26 19:54:52+00:00,2022-10-29 22:20:25+00:00,2020-03-07 22:03:55+00:00,,50,1,1,C++,1,1,1,1,0,0,2,0,0,2,,1,0,0,public,2,2,1,master,1,1,,"['eduardo-rodas', 'RoryZahedi', 'AHuangHe', 'alexmeigz', 'EdwardJLiu', 'yi-hsien']",1,,0.88,0,,,,,,4,,,
67770180,MDEwOlJlcG9zaXRvcnk2Nzc3MDE4MA==,ai-safety.github.io,ai-safety/ai-safety.github.io,0,ai-safety,https://github.com/ai-safety/ai-safety.github.io,UCSB Graduate Colloquium on Safety and Bias in Machine Learning,0,2016-09-09 05:57:04+00:00,2016-09-09 06:05:21+00:00,2016-12-02 00:03:42+00:00,,3404,0,0,CSS,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,1,"# ai-safety.github.io
UCSB Graduate Colloquium on Safety and Bias in Machine Learning
",['dspoka'],1,,0.72,0,,,,,,1,,,
604877084,R_kgDOJA2xHA,STARTER-lab02,ucsb-cs16-w23/STARTER-lab02,0,ucsb-cs16-w23,https://github.com/ucsb-cs16-w23/STARTER-lab02,,0,2023-02-22 01:10:10+00:00,2023-02-22 01:13:41+00:00,2023-02-23 23:22:13+00:00,,15,0,0,C++,1,1,1,1,0,0,6,0,0,0,,1,0,0,public,6,0,0,main,1,1,"# STARTER-lab02

https://ucsb-cs16.github.io/w23/labs/lab02/
","['pconrad', 'dibamirza', 'RealKaiwenLi', 'tigeryu8900', 'lucasrelic99']",1,,0.87,0,,,,,,0,,,
867770946,R_kgDOM7kiQg,team10AlcTracker,ucsb-cs184-f24/team10AlcTracker,0,ucsb-cs184-f24,https://github.com/ucsb-cs184-f24/team10AlcTracker,,0,2024-10-04 17:28:27+00:00,2024-12-11 07:27:14+00:00,2024-12-11 07:27:10+00:00,,20174,0,0,Kotlin,1,1,1,1,0,0,4,0,0,15,mit,1,0,0,public,4,15,0,main,1,1,"# team10AlcTracker

## Project Name: 
BACTrack

## Project Description: 
An alcoholic drink tracker app which allows users to estimate Blood Alcohol Content. BAC calculation will be based on number and type of drinks, food, etc.

## Members / Github IDs:

Maya Rosenbaum: mayarosenbaum

Kevin Ren: ThatsBadJuju

Madison Long: madisonlong1

Elijah Anderson: ElijahCanderson

Ivan Hernandez: ivan512az

Mariana Rosillo: rosillo-m

Konark Vinod: konarkv

## Tech Stack

For this project, we will be using Android Studio with Kotlin and Jetpack Compose, coupled with Firebase.

## App Funcionality

An alcoholic drink tracker app allows users to estimate their Blood Alcohol Content (BAC) by inputting details such as the number and type of drinks consumed, as well as other factors like food intake. The app will use this information to calculate an estimated BAC, helping users monitor their alcohol consumption and make informed decisions about their drinking. By taking into account variables like drink type and food consumption, the app aims to provide more accurate BAC estimates for responsible and safe drinking. Moreover, you can take a look at your past drinking history as a reference to the different types of alcohol you have consumed. The app will observe all data variables each night and algorithmically generate a standardized “score” (represented by icon/number) so the user can easily track progress based on one simple variable that represents all data.

## User Roles

User will track their alcohol content throughout the night and have options to:
<ol>
  <li>Log drinks</li>
  <li>Manually add custom drinks to the database</li>
  <li>Save common drinks in a separate personal user “common drinks” database</li>
  <li>View current and past alcohol consumption data (BAC, amount of drinks, types of drinks consumed, etc.)</li>
  <li>View generalized “score” based on all data variables that will be displayed in fun/colorful icon/message</li>
</ol>

## Installation 
You will find a zip folder in our release tag named ""v1.0.0"". Inside is an APK to use the app. Download the file and extract the apk. The APK can then be moved to an Android device and installed. Currently, our oldest version tested is Android 12, thus we cannot confirm if BACtrack works on any previous versions.

## Instructions for virtual deployment:
* download android studio from the following link https://developer.android.com/studio
* once installed, got to file, new, and select ""Project From Version Control""
* Paste the following link into the text box: https://github.com/ucsb-cs184-f24/team10AlcTracker.git
* Wait for program to compile
* press the green ""Play"" button at the top of the screen and the project will start up via the default emulator
* Ensure you have conntection to the internet, and select ""Sign in with Github""
* Enter your credntials and use the app!
* See team for details/help bypassing any issues related to private git.ignore files


","['madisonlong1', 'ElijahCanderson', 'rosillo-m', 'mayarosenbaum', 'konarkv', 'ivan512az', 'ThatsBadJuju']",1,,0.73,0,,,,,,1,,,
5083004,MDEwOlJlcG9zaXRvcnk1MDgzMDA0,vuforia-gamekit-integration,Josiastech/vuforia-gamekit-integration,0,Josiastech,https://github.com/Josiastech/vuforia-gamekit-integration,"This project contains Qualcomm's Vuforia SDK and GameKit source, configured to work together to create immersive Augmented Reality applications easily. This integration was put together by UC Santa Barbara's Computer Science Capstone team.",0,2012-07-17 14:31:12+00:00,2019-12-31 20:41:49+00:00,2012-06-26 04:31:08+00:00,,102707,1,1,,0,1,1,1,0,0,9,0,0,0,mit,1,0,0,public,9,0,1,master,1,,"vuforia-gamekit-integration
===========================

This project contains Qualcomm's Vuforia SDK and GameKit source, configured to work together to create immersive Augmented Reality applications easily. This integration was put together by UC Santa Barbara's Computer Science Capstone team.",['airgames'],1,,0.81,0,,,,,,1,,,
70098843,MDEwOlJlcG9zaXRvcnk3MDA5ODg0Mw==,Aerocube,UCSB-CS189-2016-17-Aerospace/Aerocube,0,UCSB-CS189-2016-17-Aerospace,https://github.com/UCSB-CS189-2016-17-Aerospace/Aerocube,Computer vision solution to picosatellite detection and pose estimation,0,2016-10-05 20:57:04+00:00,2024-08-12 19:25:20+00:00,2017-03-14 19:56:26+00:00,,72309,5,5,Python,1,1,1,1,0,0,3,0,0,1,,1,0,0,public,3,1,5,master,1,1,"# AeroCube
## Brief
This repository more-or-less contains all functionality intended to be run on the Jetson TX1 board, and forms the backbone of our application.
## Guide
A breakdown of the folders found at the root-level directory of the repository follows:
* **ImP** - image processing module responsible for scanning an image and returning information about detected AeroCubes; also contains the data structures that represent an AeroCube and its members; contains a module for camera calibration
* **controller** - stateless Controller that, upon receiving events through a TCP connection, calls the appropriate function dependent on the event's signal, returning the results of the function call to the TCP client
* **dataStorage** - handles internal storage on the Jetson (e.g., saving scan information, scanned images)
* **externalComm** - interface to handle external communication, particularly to the Firebase database
* **flaskServer** - more appropriately named the Job Handler, but kept as ""flaskServer"" for legacy/lazy reasons; organizes incoming Jobs that may result from requests to the Flask Server or through a listener on Firebase; processes Jobs by sending events sequentially to the Controller to resolve each event
* **ipcProto** - early prototype to test inter-process communication (between Controller and Flask Server)
* **jobs** - module defining a Job, or a sequence of events that represent a task to be completed (e.g., an ImageUpload job, which consists of scanning an image with ImP and storing it internally and externally); also defines the AeroCubeEvent class -- the instance passed between the Controller and Flask Server -- and the AeroCubeSignals that dictate what action the controller takes for a given event
* **shellScripts** - collection of convenient scripts (e.g., for starting up different parts of the application)
* **systemTests** - collection of system tests, such as the main use case
* **tcpService** - module collecting TCP logic and implementation into one location, allowing Controller and Flask Server to call it concisely


## Reference
For additional information, please see our Wiki page at: <https://github.com/UCSB-CS189-2016-17-Aerospace/Aerocube/wiki>
","['andrewtran1995', 'athielk', 'GusAlejandro', 'joyoyoyoyoyo', 'elswenson']",1,,0.84,0,,,,,,5,,,
780746848,R_kgDOLolAYA,prosperity2024-laobaijinger,Shuai0711/prosperity2024-laobaijinger,0,Shuai0711,https://github.com/Shuai0711/prosperity2024-laobaijinger,Prosperity 2024 Team Laobaijinger Repo,0,2024-04-02 04:45:57+00:00,2024-08-06 13:51:50+00:00,2024-07-30 07:08:12+00:00,,50963,0,0,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# prosperity2024-laobaijinger

This group LAOBAIJINGER in 2024 IMC Prosperity2 challange!

Group members: Shuai Yuan & Jiayue Joyce Chen @ UC Santa Barbara, Xilin Rice Wang @ Brown University, Yutong Elena Li @ U of Chicago, Shuiqing Sophie Han @ U of Michigan Ann Arbor.

We are all undergrads and NEW to algo trading. This is our first ever hands-on experience, and we are doing a decent job (in my opinion) as a first timer haha.

Here is a short description of final strategies used for different sets of products.

R1: `AMETHYSTS` and `STARFRUIT`, Both market making strategies. 

`AMETHYSTS` we always consider fair price at 10000, take all buy/sell order lower/higher than fair price, and the use left positions market make orders 1 better than best ask/bid.

`STARFRUIT` we used similar market making and taking techniques as `AMETHYSTS`, instead using a fixed fair price, we fitted linear regression that use last 4 steps' weighted mid price to calculate next step's fair price.

Both strategies remain stable from round 2-4, around 15k profit per day.

R2: `ORCHIDS`

We failed to do the correct one side market making arbitrage strategy at round2 which gave most teams tons of profit. We discovered that afterwards, which huge backtester profit, but in the end profit very little from round3 and round4 results.

We did not get any progress from trend trading, and failed to construct a signal using humidity and sunlight information.

We basically gave up on `ORCHIDS`

R3: `GIFT_BASKET` and related

We constructed a pair trading strategy with edge = `GIFT_BASKET` - 6 * `CHOCOLATES` - 4 * `STRAWBERRIES` - `ROSES` - 380. Trade when edge exceed margin value = 38 (0.5 * std). 

In general gives a stable 70k profit per day.

R4: `COCONUT` and `COCONUT_COUPON`

Used basic Black-Scholes model, with fixed volatility = 0.0101193. `COCONUT_COUPON` is like a put option of `COCONUT`, since we don't have the call option, we use `COCONUT` to hedge.

We calculate fair price of `COCONUT_COUPON`. When it moved more than margin = 2 from fair price, we take the negative position to trade `COCONUT_COUPON` and trade -delta * position of `COCONUT`.

In round4 this pair gives an amazing 160k profit!

R5: Traders information

After few hours on analysis, we reached an agreement that these information are noises LOL. Decided to keep our original strategies. We looked at each individual traders trading a specific product on a given day, and none of them have a good strategy and a straight, positive PnL. Raj's trades do somehow reflect the long term trend of `COCONUT` but we are not sure that this will be beneficial to our algo so we gave up on all the trader information.

","['Shuai0711', 'elena7111']",1,,0.78,0,,,,,,1,,,
8905954,MDEwOlJlcG9zaXRvcnk4OTA1OTU0,luckyMe,fedhere/luckyMe,0,fedhere,https://github.com/fedhere/luckyMe,"lucky imaging software, designed for the LCOGT LIHSP (Lucky Imaging and High Speed Photometry) systems.",0,2013-03-20 14:20:10+00:00,2023-05-16 21:06:56+00:00,2015-01-19 14:10:05+00:00,,280,4,4,Python,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,4,master,1,,"getlucky
========

lucky imaging software, designed for the LCOGT LIHSP (Lucky Imaging and High Speed Photometry) systems.

at this point, i have only imported the pipeline. instructions and modifications to make it user friendly are needed. But basic help is provided throughout the code.

This code was built as a data reduction package for the LCOGT LIHSP camera data, but it should work with few modifications with YOUR high speed photoemtry data as well. 

Major contributors (other than me) Daniel Kudrow, Scott Hillberry (at the time Undergraduate physics students at UCSB)



",['fedhere'],1,,0.73,0,,,,,,4,,,
213034317,MDEwOlJlcG9zaXRvcnkyMTMwMzQzMTc=,ucsbackup,zerotouchx/ucsbackup,0,zerotouchx,https://github.com/zerotouchx/ucsbackup,,0,2019-10-05 16:39:18+00:00,2019-10-05 19:32:03+00:00,2019-10-05 19:32:02+00:00,,4,0,0,Shell,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# Cisco UCS Backup Automation
This automation script is written with expect. It deletes the previous backup schedule, creates a new one and executes it immediately. Once it is
triggered script also checks the status of the backup. I am not sure if output varies on version of UCS. You can see the sample output of UCS Manager once backup started. 

If backup failed you can get all the details. If everything is Okay. You get 'Backup Success' message with Progress (%): 100

```bash
show backup fsm status <hostname>
```
## On Error

```bash
 Hostname: xxxxx

     FSM 1:
         Remote Result: End Point Failed
         Remote Error Code: ERR DNLD Authentication Failure
         Remote Error Description: Permission denied#
         Status: Backup Fail
         Previous Status: Backup Fail
         Timestamp: 2019-10-02T10:45:47.633
         Try: 1
         Progress (%): 0
         Current Task: internal system backup(FSM-STAGE:sam:dme:MgmtBackupBackup:upload)

```
## On Success 
```bash
 Hostname: xxxxxxx

     FSM 1:
         Remote Result: Not Applicable
         Remote Error Code: None
         Remote Error Description:
         Status: Nop
         Previous Status: Backup Success
         Timestamp: 2019-10-02T12:07:07.907
         Try: 0
         Progress (%): 100
         Current Task:
```

## Caveat
Do not forget to modify the fields '<>' in the **ucsbackup.exp** file with your environment.

## Disclaimer

  <em>**""[The author] assumes no responsibility or liability for any errors or omissions in the content of this site. The information contained in this site is provided on an “as is” basis with no guarantees of completeness, accuracy, usefulness or timeliness…""**</em>",['zerotouchx'],0,,0.71,0,,,,,,1,,,
34473964,MDEwOlJlcG9zaXRvcnkzNDQ3Mzk2NA==,webguide,ucsb/webguide,0,ucsb,https://github.com/ucsb/webguide,Repository for the UCSB WSG Webguide hosted on Github using Jekyll.,0,2015-04-23 18:26:24+00:00,2021-07-06 17:48:23+00:00,2021-05-19 19:07:35+00:00,https://webguide.ucsb.edu,1625,7,7,SCSS,1,1,1,1,1,0,7,0,0,3,bsd-3-clause,1,0,0,public,7,3,7,master,1,1,"### UCSB WSG Webguide

This is the UCSB Web Standards Group webguide which is a static website whose content provides recommendations and best practices for websites hosted within and affiliated with www.ucsb.edu. These recommendations are intended to be broad enough to apply to most any website in any domain -- but an emphasis is placed on Higher Ed web content.

This site has been moved to Github and Jekyll with the goal of increasing social collaboration on the webguide.

## Hosting

The source code for the UCSB Web Standards Guide is stored on GitHub as a repository under the [""UC Santa Barbara"" GitHub organization](https://github.com/UCSantaBarbara) (https://github.com/UCSantaBarbara/webguide). The Guide itself is hosted from this repository using [GitHub Pages](https://pages.github.com/).

## Making a Change to Guide

Changes to the Web Guide should be done by submitting a pull request. Only the two Co-Chairs should have access to accept changes requested on a repository.

If you simply want to **suggest a change** to the web guide, you only need to do the following:

1. Create a **new issue** describing the change (https://github.com/UCSantaBarbara/webguide/issues)

This issue can be used to discuss the change and track work on the proposed change. Feel free to comment on other issues as well.

To actually **make a change** to the web guide:

1. Create a **new issue** describing the change (https://github.com/UCSantaBarbara/webguide/issues)
2. Create a **fork** of the Web Guide repository (https://github.com/UCSantaBarbara/webguide/)
3. On your own fork, create a **branch** with a name that references the issue (e.g. ""responsive-redesign"" or ""broken-link-fix"")
4. Do all of the work associated with the change on this branch
5. When you are finished, create a **pull request** from your branch to the master branch of the Web Guide repository. Reference the issue number in the pull request title or description (e.g. ""fixes #33"")
6. A Co-Chair will **accept** the pull request

Make sure to keep your fork and the branches on your fork in sync with the Web Guide repository by continuously pulling in changes from the master branch of the main repository. This will ensure you can make cleaner merges and pull requests with few conflicts.

For more information on this process, see [GitHub's ""Configuring a remote for a fork""](https://help.github.com/articles/configuring-a-remote-for-a-fork/) and [GitHub's ""Syncing a fork""](https://help.github.com/articles/syncing-a-fork/).

## History

On 4/23/15, a GitHub organization for the UCSB Web Standards Group was created by David Gurba and work started on migrating the Web Standards Guide from its original hosting location on UCSB servers to its new hosting location on GitHub using GitHub Pages. This migration was completed in early May 2015.

Through this migration, the Guide's URL was changed from http://www.ucsb.edu/webguide/ to http://webguide.ucsb.edu/

In February 2018, the repository for the guide was moved from the ""UCSB Web Standards Group"" GitHub organization to the ""UC Santa Barbara"" GitHub organization.

In May 2018 [https://blog.github.com/2018-05-01-github-pages-custom-domains-https/](GitHub began supporting HTTPS for custom domains) by using [https://letsencrypt.org/](Let's Encrypt) which allowed the site to be hosted at https://webguide.ucsb.edu/

## Organization and Repository Management Between Co-Chairs

Each of the two Web Standards Group Co-Chairs should have ""Owner"" permissions over the Web Standards Guide repository.

### License

[The UCSB webguide is released under the BSD Version Clause 3 License](LICENSE.md)
","['loganfranken', 'garster', 'tenken', 'dsaludares', 'BwolfUCSB', 'a3roman', 'dependabot[bot]', 'ilessing', 'UCSB-jcolo', 'rvizena']",1,,0.87,0,,,,,,9,,,
77369798,MDEwOlJlcG9zaXRvcnk3NzM2OTc5OA==,FPGA-Motion-Detector,russellbarnes/FPGA-Motion-Detector,0,russellbarnes,https://github.com/russellbarnes/FPGA-Motion-Detector,Motion detection in both software and in hardware-accelerated OpenCV,0,2016-12-26 08:28:32+00:00,2023-08-28 20:12:34+00:00,2016-12-26 08:38:32+00:00,,1181,12,12,C,1,1,1,1,0,0,4,0,0,1,,1,0,0,public,4,1,12,master,1,,"# FPGA-Motion-Detector

This was my final project for ECE 253 Embedded System Design at UCSB.

![Project hardware](https://github.com/russellbarnes/FPGA-Motion-Detector/raw/master/project_hw.jpeg ""Project hardware"")

The FPGA takes pictures with the camera and performs motion detection in both software and in [hardware-accelerated OpenCV](http://www.wiki.xilinx.com/HLS+Video+Library).

![Block design](https://github.com/russellbarnes/FPGA-Motion-Detector/raw/master/block_design.png ""Block design"")

## System Configuration
- [__Nexys4 DDR__](http://store.digilentinc.com/nexys-4-ddr-artix-7-fpga-trainer-board-recommended-for-ece-curriculum/) development board including a Xilinx Artix-7 FPGA
	- FPGA block design includes AXI IIC, 1-channel GPIO (x2), 16-channel GPIO for LEDs, AXI Quad SPI (x2), AXI VDMA (x2), custom HLS block (included), MIG, interrupt controller, MicroBlaze soft processor, others
- [__ArduCAM-Mini-2MP__](http://www.arducam.com/arducam-mini-released/) camera with both I2C and SPI interfaces connected
- [__240x320 2.2"" TFT display w/ILI9340C__](https://www.adafruit.com/product/1480) by Adafruit
- Memory configuration
	- MicroBlaze is utilizing 128K of BRAM
	- Stack is located in BRAM.  Stack size: 0x800
	- Heap is located in DDR memory via MIG.  Heap size: 0x80000
- Camera SPI @ < 8 MHz, display SPI @ 5 MHz, Camera I2C @ 100 KHz
- SPI chip select signal for camera is *replaced* by single-channel ""spi_dc_1"" GPIO
- Additional spi_dc output for display ""D/C"" signal is single-channel GPIO
- Current camera configuration is for QVGA bitmap output format.  To save to a file, a bitmap header must be added to the beginning (not included - see ArduCAM example code)
- This application configures UART to baud rate 9600 for communication with the host PC.
- Camera driver is based on ArduCAM example code:
	http://www.arducam.com/
	https://github.com/ArduCAM/Arduino

_Also uses UTFT.cpp - Multi-Platform library support for Color TFT LCD Boards.  Copyright (C)2015 Rinky-Dink Electronics, Henning Karlsen. All right reserved._

The OpenCV HLS block should be created with the Xilinx HLS program using the code in __Vivado_HLS_MotionDetect__.  Update the code for desired resolution (QVGA for this project) and validate with corresponding input images.  

![HLS connections](https://github.com/russellbarnes/FPGA-Motion-Detector/raw/master/HLS_IP_block.png ""HLS connections"")

After exporting the hardware design, use Vivado to create the above FPGA block design.  The HLS block requires two AXI VDMA controllers in order to receive the input image streams.  Run the program in __MicroBlaze_SW__ on the FPGA's MicroBlaze processor using Xilinx SDK.

## Known issues:
- Camera SPI occasionally drops a byte (less than 1/20 frames), resulting in distorted color and a false alarm.
- In the program, the hardware motion detection block's VDMA streams are not initialized to supply the whole frame, resulting in a numerical discrepancy between the software and hardware motion detections.  The hardware block can still be thresholded to perform motion detection, but part of the image may be ignored.

## Next Step
The motion detection can be improved by performing edge detection, reducing luminance sensitivity.  This would be more easily implemented in the [hardware block](https://github.com/Xilinx/HLx_Examples/tree/master/Vision/video_edge) than in software.
",['russellbarnes'],1,,0.74,0,,,,,,3,,,
587050764,R_kgDOIv2vDA,mpctools_casadi,cknoll/mpctools_casadi,0,cknoll,https://github.com/cknoll/mpctools_casadi,"Nonlinear Model Predictive Control Tools for CasADi (Python Interface), fork from a bitbucket repo",0,2023-01-09 21:02:21+00:00,2024-04-25 03:26:33+00:00,2023-01-09 21:03:33+00:00,,9341,2,2,Python,1,1,1,1,0,0,1,0,0,0,gpl-3.0,1,0,0,public,1,0,2,main,1,,"

**Note**: This is not the official repository but instead a patched version, published for research purpose only.

The original software can be found here: <https://bitbucket.org/rawlings-group/mpc-tools-casadi/src/master/>




<br>
<br>
<br>


# MPCTools: Nonlinear Model Predictive Control Tools for CasADi (Python Interface) #

Copyright (C) 2017

Michael J. Risbeck and James B. Rawlings.

MPCTools is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by the
Free Software Foundation; either version 3, or (at your option) any later
version.

MPCTools is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the file
COPYING for more details.

## Availability ##

The most recent release of MPCTools is available for download from the
[Downloads][bbdownloads] section. Choose the appropriate version for Python 2
or 3. The development sources are hosted in a Mercurial repository on 
[Bitbucket][bitbucket].

## Installation ##

To use MPCTools, you will need a recent versions of

* Python 3.5+ or 2.7 (see below for Python 2.7 support)
* Numpy
* Scipy
* Matplotlib
* Tkinter (only needed for `*_mpcsim.py` examples)
* CasADi (Version >=3.0; [download here](http://files.casadi.org))

With these packages installed, MPCTools can be downloaded from the
[downloads][bbdownloads] section, and the `mpctools` folder can be manually 
placed in the user's Python path, or the provided setup script
`mpctoolssetup.py` can be used, e.g.,

    python3 mpctoolssetup.py install --user

to install for the current user only, or

    sudo python3 mpctoolssetup.py install

to install systemwide. Note that in these commands, you should use the
appropriate `python` command for the version you downloaded, i.e., `python3`
or `python2`.

Code is used by importing `mpctools` within python scripts. See sample
files for complete examples.

### Python 2.7 Support ###

In older versions of MPCTools, source files were written to be compatible with
Python 2.7, and Python 3 versions were automatically generated using Python's
`2to3` conversion utility. However, as of version 2.4, these roles are reversed.
That is, the source files for MPCTools and the example files are now written to
be compatible with Python 3.5+, and Python 2 versions are generated
automatically. The code has been written so as to require only a minimal set
of changes for Python 2.7 compatibility, but please report any bugs that you
find.

For normal users who use MPCTools fia the [downloads][bbdownloads] link, this
change should be completely transparent, and you can continue to update
MPCTools by re-downloading the approprate `.zip` file. However, for advanced
users who may be using MPCTools directly from a clone of the repository, you
will need to either start using Python 3, or you will have to switch to using
`.zip` files from the [downloads][bbdownloads] section.

Finally, note that [Python 2.7 end of life][py27eol] is Jaunary 1st, 2020.
After this point, Python 2.7 will no longer be supported by the Python
developers. At or before this date, we will stop releasing Python 2 versions
of MPCTools, so you should make plans to upgrade in the near future.

## Documentation ##

Documentation for MPCTools is included in each function. We also
provide a cheatsheet (`doc/cheatsheet.pdf`). See sample files for complete
examples.

## Citing MPCTools ##

Because MPCTools is primarily an interface to CasADi, you should cite CasADi as
described on its [website][casadipubs]. In addition, you can cite MPCTools as

- Risbeck, M.J., Rawlings, J.B., 2015. MPCTools: Nonlinear model predictive
  control tools for CasADi (Python interface).
  `https://bitbucket.org/rawlings-group/mpc-tools-casadi`.

## Bugs ##

Questions, comments, bug reports can be posted on the
[issue tracker][bbissues] on Bitbucket.

Robert D. Mcallister  
<rdmcallister@ucsb.edu>  
University of California-Santa Barbara
Department of Chemical Engineering

[bitbucket]: https://bitbucket.org/rawlings-group/mpc-tools-casadi
[bbissues]: https://bitbucket.org/rawlings-group/mpc-tools-casadi/issues
[bbdownloads]: https://bitbucket.org/rawlings-group/mpc-tools-casadi/downloads
[casadi]: https://casadi.org
[casadipubs]: https://github.com/casadi/casadi/wiki/Publications
[casadidownloads]: https://files.casadi.org
[py27eol]: https://www.python.org/dev/peps/pep-0373

","['mrisbeck', 'tbadgwell', 'cknoll', 'pratyushkumar211', 'gmsanchez', 'tomCTO']",1,,0.76,0,,,,,,2,,,
930491630,R_kgDON3Ys7g,EoYS-2025,joeljaffesd/EoYS-2025,0,joeljaffesd,https://github.com/joeljaffesd/EoYS-2025,Collaborative AlloSphere Project for UCSB MAT EoYS-2025,0,2025-02-10 18:06:55+00:00,2025-02-22 03:00:21+00:00,2025-02-22 03:00:18+00:00,,90,0,0,C++,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# EoYS-2025
Collaborative AlloSphere Project for UCSB MAT EoYS-2025
",['joeljaffesd'],1,,0.85,0,,,,,,2,,,
328624628,MDEwOlJlcG9zaXRvcnkzMjg2MjQ2Mjg=,LifeCycle-,liu-qingzhen/LifeCycle-,0,liu-qingzhen,https://github.com/liu-qingzhen/LifeCycle-,Android Application UCSB ece163,0,2021-01-11 10:18:08+00:00,2021-01-11 12:05:18+00:00,2021-01-11 12:05:16+00:00,,4134,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# LifeCycle-
This is the project repo of UCSB ECE150/ECE251 2019 Spring

Use Android Studio and an Android Phone to run the project

May not work well because of the version of Android Studio

It's an Android applicaiton to help you record your life

You can refer to this playlist

https://www.youtube.com/watch?v=zNsagNprNb8&list=PLnCTl6QmZINAqSRDhCCu72KHCfrUl_JCW
",['liu-qingzhen'],1,,0.79,0,,,,,,1,,,
545913034,R_kgDOIIn4yg,UCSBCS291AProject1,YEthYuan/UCSBCS291AProject1,0,YEthYuan,https://github.com/YEthYuan/UCSBCS291AProject1,,0,2022-10-05 07:35:21+00:00,2022-10-05 07:35:31+00:00,2022-10-06 04:44:36+00:00,,41,0,0,Ruby,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,#ERROR!,['YEthYuan'],1,,0.69,0,,,,,,1,,,
489883627,R_kgDOHTMH6w,GAMES101,ruiwng/GAMES101,0,ruiwng,https://github.com/ruiwng/GAMES101,"The assignments of GAMES101 (Introduction to Computer Graphics) whose instructor is Lingqi Yan, if you are interested, please refer to https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html for more information.",0,2022-05-08 08:10:29+00:00,2024-09-19 16:42:11+00:00,2022-05-27 06:08:38+00:00,,29019,1,1,C,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,1,main,1,,"# GAMES101
The assignments of GAME101 (Introduction to Computer Graphics) whose instructor is Lingqi Yan, if you are interested, please refer to [lecture website](https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html) for more information. this lecture mainly includes four parts: rasterization, geometry, ray tracing and animation. (shown as the following four pictures)

![games101 banner](picture/games101.png)

## Assignment 0: Configure Assignments Environment

### Install Eigen
In the assignemnts of this lecture, Eigen is used for mathematics related calculation, such as dot product, cross product, linear transformation, projection transformation, and so on. so Eigen should be installed beforehand. If you want to know more about Eigen, please go to [Eigen website](https://eigen.tuxfamily.org/index.php?title=Main_Page) for more details. installing Eigen is straightforward. following these steps will be fine:
- Download Eigen. Go to [Eigen offical website](https://eigen.tuxfamily.org/index.php?title=Main_Page), select a latest stable version, and download it.
- Install Eigen. Upzip the package, follow the instructions in the INSTALL file which is under the root directory to install Eigen to the system path. then you can refer to Eigen header files in your code just like this:
```C++
#include<eigen3/Eigen/Core>
#include<eigen3/Eigen/Dense>
```

### Install OpenCV
To show the rendering result, We select OpenCV to do some pixel-level processing, you can go to [OpenCV Documents](https://docs.opencv.org/4.x/d0/db2/tutorial_macos_install.html), and follow these steps listed there to install OpenCV, it may take several minutes to compile the source codes, be patient! after installing OpenCV successfully, you may include the OpenCV header files and enjoy it:
```C++
#include <opencv2/opencv.hpp>
```

### Configure VSCode
On the other hand, using VSCode as our developing environment is highly recommended. the configuration corresponding to VSCode is under the .vscode directory in the root directory of every assignment. I only add the configuration for Mac OS System.(sorry about that)

After installing Eigen and OpenCV, make sure adding the include directory in the CMakeList.txt file, so that your compiler can find the header file.

```
include_directories(/usr/local/include)
include_directories(/usr/local/include/opencv4)
```

Of course, the packages should be added too.

```
find_package(OpenCV REQUIRED)
find_package(Eigen3 REQUIRED)
```

## Assignment 1: Rotation And Projection

In this assignment, we need to implement three basic transformations: rotation about Z-axis, perspective projection and rotation about arbitrary axis passing through origin.

Rotation about Z-axis is straightforward, we just apply rotation to the three basis [1, 0, 0], [0, 1, 0], [0, 0, 1], and fill the three columns of the matrix with these three new basis, then leave the four column of the matrix with translation which is [0, 0, 0].

Computing perspective projection matrix is a little tricky, there are two mistakes it's prone to make, the first one is perspective division, what x- and y-coordinate need to divide is positive z-coordinate, rather than negative z-coordinate, on the other hand, what the camera can see is the coordinate whose z-coordinate is negative, so we need to transform it to a positive one. therefore we need get a homogoneous coordinate whose w is -z after applying the projection transformation, that is to say, the four row of the transformation is [0, 0, -1, 0], instead of [0, 0, 1, 0]. the second one is correctly computing the mapping from [zNear, zFar] to [-1, 1]，we need solve this equation:
```latex
-a * zNear + b = -zNear
-a * zFar + b = zFar
```

To compute a rotation matrix about arbitrary axis passing through origin, you need only follow three steps:
- Transform to the standard orthogonal basis.
- Apply the rotation.
- Transform back.

To compute the matrix which we need to transform to the standard orthogonal basis, we need to build a new orthogonal basis, using the rotation axis as the z-axis, and calculate x-axis and y-axis, there are a lot of them, as long as x-axis, y-axis and z-axis are orthogonal to each other, and then set these three axis as the first three columns of the objective matrix. note that if a matrix is orthogornal matrix, you can calculate its inverse matrix by just transpose it which is fast.

<img src=""assignment1/images/transformation.png"" width =""480"" height=""480"">

## Assignment 2: Triangles And Z-buffering

The architecture provided by this assignment has done a lot for us. what left to us to do is just solving the visibility problem with the help of depth buffer. another problem is to judge whether a given point is in a triangle or not, which can be solved easily by calculating whether the point is all on the same side of the threes lines of the triangle using cross product.

Another point worth mentioning is how to compute the perspective-correct interpolation, although this homework has already handled this problem for us, it's worthwhile to take some time to figure out how it works. such as how the z-coordinate is correctly interpolated, and how the attributes of the vertex is interpolated. If you want to know more, you can refer to ***Mathematics for 3D Game Programming and Computer Graphics, Third Edition***, this book gives a very elegant and easy-to-understand explanation.

SSAA(Super Sampling Anti-Aliasing) implementation is trival, a nice way is to just double the size of the frame buffer and the depth buffer, and after rasterization, down-sample the double-sized frame buffer to a normal size. 

Triangle without and with super sampling:

<img src=""assignment2/images/triangle.png"" width =""480"" height=""480""> <img src=""assignment2/images/super_sampling.png"" width =""480"" height=""480"">

## Assignment 3: Pipeline and Shading

There are three mistakes existing in this assignment:
- In the implementation of blinn-phong shading model, (0, 0, 10) is used as the camera pos, which is wrong, as in the camera coordiniate, the camera pos should be at the origin.
- the essence of dispalcement map is adding some offset to vertex position according to the displacement map, rather than to pixel position.
- In the calculation of TBN transformation, the procedure of computing B is unreasonable. the B and T's direction should be consistent with the direction of U and V of the bump map respectively, only in this way, can the finite difference dU and dV make sense. If you want to know more, [LearnOpenGL](https://learnopengl.com/Advanced-Lighting/Normal-Mapping) gives a correct computation.

Normal visualization and Blinn-Phong shading model:

<img src=""assignment3/images/normal.png"" width =""480"" height=""480""> <img src=""assignment3/images/blinn_phong.png"" width =""480"" height=""480"">

Bump map and Displacement map:

<img src=""assignment3/images/bump_map.png"" width =""480"" height=""480""> <img src=""assignment3/images/displacement_map.png"" width =""480"" height=""480"">

Texture nearest vs bilinear interpolation:

<img src=""assignment3/images/texture_nearest_interpolation.png"" width =""480"" height=""480""> <img src=""assignment3/images/texture_bilinear_interpolation.png"" width=""480"" height=""480"">

## Assignment 4: Bézier Curve

This assignment is trival, it takes only several minutes to implement de Casteljau's algorihtm. the more interesting part is how to achieve anti-aliasing. here I not only assign the specified pixel a color, but also interpolate the surrounding eight pixels with one half the color. Take care not overwrite the ones which already have a value.

Bézier curve without and with anti-aliasing:

<img src=""assignment4/images/bezier_curve.png"" width =""480"" height=""480""> <img src=""assignment4/images/bezier_curve_anti_aliasing.png"" width =""480"" height=""480"">

## Assignment 5: Ray Generation And Intersection With Triangles

Here we use Moller-Trumbore algorithm to judge whether a ray is intersected with a triangle, if intersected, the barycentric coordinate of the intersection point will be given, the three components of the barycentric coordinate should be non-negative, otherwise the triangle is missed. in the process of this algorithm, we need to solve a ***Ax = b*** equation, a general way to solve a low dimensional equation is [Cramer's Rule](https://math.libretexts.org/Bookshelves/Precalculus/Precalculus_(OpenStax)/09%3A_Systems_of_Equations_and_Inequalities/9.08%3A_Solving_Systems_with_Cramer's_Rule), in this rule, the determinants of n + 1 (n is the dimension of ***x***) matrices is needed beforehand. for a 3x3 matrix ***A***[c1 c2 c3] (c1 c2 c3 are the three columns of the matrix), a quick way to compute its determinant is dot(cross(c1, c2), c3).

An error occurred when saving the rendered image to a ppm file in the base code of this assignment, which is triggered by overflow of assigning a unsigned char whose range is (0, 255) to a char whose range is (-127, 128). modifying the conversion from char to unsigned char will solve this issue.

<img src=""assignment5/images/whitted_style_ray_tracer.png"" width=""640"" height=""480"">

## Assignment 6: BVH Acceleration

In this assignment, I have implemented both a naive BVH and a SAH (Surface Area Heuristic) based BVH, after that, I compared both methods' speed on my computer (macOS Big Sur 16GB 2.6GHz 6-Core Intel Core i7) from two dimensions, one is the time to construct BVH tree, the other is the time to render a bunny model using the acceleration structure. the times using naive BVH are 13ms and 784ms respectively, compared to that, It spends both 49ms and 428ms with SAH based BVH. Then we can draw a conclusion that SAH based BVH is much better than the naive one to accelerate intersections.

<img src=""assignment6/images/bvh_acceleration.png"" width=""640"" height=""480"">

## Assignment 7: Path Tracing
Because that it may take a long time to finish rendering an image with path tracing algorithm, you may want to accelerate it. Here are several tips:
- employ 1 spp at the start time.
- decrease the number of meshes.
- keep the ray's bouncing time fewer.

My advice for this assignment is implementing it step by step, The point is to keep the influence factor as less as possible. you may divide the problem into smaller ones just as I do, and conquer them respectively, in order to keep the complexity as low as possible. Make sure the former one works fine, then continue with the next one. Here are the steps when I try to finish the assignment:
- show the intersection's normal as shading point's color, to make sure you correctly compute the intersection with the scene as well as the intersection's information.
- render the light source with no bounce.
- render the direct lighting.
- render the indirect lighting.

you are fate to come across the self-intersection problem when you shoot secondary ray or shadow ray. more precisely, if you shoot a secondary ray from an object you may intersect the object itself because of float-precision issue, or you may intersect the light source itself when you check whether there is a blocker between the shading point and the light source. My solution to the first problem is just offset the start point of the ray across the normal directoin a little bit. and the solution to the second one is to just check if the object intersected is the light source itself, if not, we're certain that there is no blocker between the shading point and the light source.

normal visualization:

<img src=""assignment7/images/normal_visualization.png"" width=""480"" height=""480"">

light with no bounce:

<img src=""assignment7/images/light_no_bounce.png"" width=""480"" height=""480"">

direct lighting:

<img src=""assignment7/images/direct_lighting.png"" width=""480"" height=""480"">

path tracing with 1, 16, 256, 1024 and 50000 spp respectively:

<img src=""assignment7/images/path_tracing_1spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/path_tracing_16spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/path_tracing_256spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/anti_aliasing_1024spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/path_tracing_50000spp.png"" width=""480"" height=""480"">

mirror and glass material with 1, 16, 256, 1024 and 50000 spp respectively:

<img src=""assignment7/images/mirror_glass_material_1spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/mirror_glass_material_16spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/mirror_glass_material_256spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/mirror_glass_material_1024spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/mirror_glass_material_50000spp.png"" width=""480"" height=""480""> 

There are several bugs that I came across worth mentioning here:

- obvious aliases occur at the boundaries of the two boxes. This artifact can be avoided by random sampling in a pixel when shooting a ray into the scene. here are the rendered images without vs with anti-aliasing(both are 1024spp):

<img src=""assignment7/images/no_anti_aliasing_1024spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/anti_aliasing_1024spp.png"" width=""480"" height=""480""> 

- too bright pixels are randomly distributed at the walls. It takes me a lot of time to find out the reason why they are there. when the pdf of a sample is too close to 0.0, we apply this pdf in the rendering equation, we will get a very large radiance, in other words, large variance. This bug can be easily prevented by skipping the samples whose pdf is too small. here are the rendered images with vs without bright pixels(both are 1024spp, you may need to magnify them to see the bright points clearly):

<img src=""assignment7/images/bright_point_1024spp.png"" width=""480"" height=""480""> <img src=""assignment7/images/anti_aliasing_1024spp.png"" width=""480"" height=""480""> 

- generating random float with the provided get_random_float is too slow. this method repeatly creates random_device, mt19937, uniform_real_distribution every time we call it. this is a waste of time, especially that this method is called frequently. using static decorator will be a good choice to prevent from creating these local variables again and again.

- the two spheres with mirror and glass material respsectively are too dark at the grazing angle. imagine that if bsdf is ***Ks***, then according to rendering equation, at the grazing angle, bsdf is fixed, cosine term is very small, leading to small radiance along ***wo*** direction which doesn't make sense. that's the reason why the shading point with specular material at the grazing angle is dark. so the bsdf term of mirror should be ***Ks / dot(N, wi)*** in order to cancel out cosine term, rather than ***Ks***.


## Assignment 8: Mass-Spring System

This assignment is straightforward, the key point is just calculating the direction and magnitude of the force correctly.

explicit Euler and Verlet:

<img src=""assignment8/images/rope_simulation.png"" width=""640"" height=""480"">
",['ruiwng'],1,,0.66,0,,,,,,1,,,
162849139,MDEwOlJlcG9zaXRvcnkxNjI4NDkxMzk=,f18,ucsb-cs56/f18,0,ucsb-cs56,https://github.com/ucsb-cs56/f18,http://ucsb-cs56.github.io/f18,0,2018-12-22 23:25:00+00:00,2019-12-19 23:02:15+00:00,2022-10-06 03:27:50+00:00,http://ucsb-cs56.github.io/f18,10537,0,0,Java,1,1,1,1,1,0,0,0,0,3,,1,0,0,public,0,3,0,master,1,1,"# f18

https://ucsb-cs56.github.io/f18/

Jekyll based website for UCSB CS56, Fall 2018

Website: <https://ucsb-cs56.github.io/f18/>

This version is intended to replace <https://ucsb-cs56-f18.github.io>.

It uses the new Jekyll theme approach to make these sites easier to maintain.

The theme currently being used can be find in the jekyll-theme value
in `_config.yml`

The navigation is set by the values in `_data/navigation.yml`

Jekyll status on Travis-CI: [![Build Status](https://travis-ci.org/ucsb-cs56/f18.svg?branch=master)](https://travis-ci.org/ucsb-cs56/f18)

* Travis-ci: https://travis-ci.org/ucsb-cs56/f18
* To add a status image like this in your README.md, see [these instructions](https://docs.travis-ci.com/user/status-images/)

To test locally:
* One time setup:
    * `git clone` the repo
    * Install rvm (the Ruby version manager)
    * Run `./setup.sh` to install correct ruby version, bundler version, and bundle the gems
* From then on, to test the site locally:
    * Run `./jekyll.sh
    * Point browser to <http://localhost:4000/f18/>

","['pconrad', 'phtcon', 'DennisZZH', 'chan4est', 'zhykoties', 'shao158', 'guanguangua', 'scottpchow23', 'mahnazkoupaee', 'rhelmot', 'omerco1', 'santhameena13', 'nuankw', 'seemantasaha']",1,,0.92,0,,,,,,0,,,
438600200,R_kgDOGiSCCA,UCSB-AIChE-Lab-Reservation,aicheucsb/UCSB-AIChE-Lab-Reservation,0,aicheucsb,https://github.com/aicheucsb/UCSB-AIChE-Lab-Reservation,UCSB AIChE Lab Reservation Backend,0,2021-12-15 11:13:31+00:00,2021-12-30 09:42:29+00:00,2022-04-25 07:22:37+00:00,ucsb-aiche-lab-reservation.vercel.app,352,2,2,JavaScript,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,2,main,1,,"
## Resources Used
* Vercel with NextJS to make serverless functions: https://madewithlove.com/blog/software-engineering/serverless-functions-with-vercel/
* CORS: https://vercel.com/support/articles/how-to-enable-cors#enabling-cors-using-vercel.json and https://stackoverflow.com/questions/65058598/nextjs-cors-issue

This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `pages/index.js`. The page auto-updates as you edit the file.

[API routes](https://nextjs.org/docs/api-routes/introduction) can be accessed on [http://localhost:3000/api/hello](http://localhost:3000/api/hello). This endpoint can be edited in `pages/api/hello.js`.

The `pages/api` directory is mapped to `/api/*`. Files in this directory are treated as [API routes](https://nextjs.org/docs/api-routes/introduction) instead of React pages.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.
",[],1,,0.78,0,,,,,,1,,,
880349190,R_kgDONHkQBg,historiansforharris.github.io,historiansforharris/historiansforharris.github.io,0,historiansforharris,https://github.com/historiansforharris/historiansforharris.github.io,,0,2024-10-29 15:07:36+00:00,2024-11-06 00:06:55+00:00,2024-11-06 00:06:51+00:00,,29,0,0,HTML,1,1,1,1,1,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"As American historians, we are deeply alarmed by the impending election. Since 1789, the nation has prospered under a Constitution dedicated to securing the general welfare, under a national government bound by the rule of law in which no one interest or person holds absolute power. In 1860, an elite interest dedicated to human slavery attempted to shatter the Union rather than accede to the constitutional rule of law by accepting the outcome of the election, plunging the nation into Civil War.

Today, Donald Trump, openly hostile to democracy and to American constitutional customs, seeks to return to office as president. He has flagrantly defied the rule of law. He repeatedly sought to thwart the result of the free and fair election of 2020. His performance has persuaded many of those who worked most closely with him that he is an authoritarian. Now a convicted felon, he has stated his intention to use his power to intimidate, prosecute and imprison his political critics and opponents, whom he designates as “the enemy within.” Given the free hand that he would enjoy today by the Supreme Court’s presidential immunity decision, we take his threats with utmost seriousness as a clear and present danger to American democracy.

Kamala Harris has dedicated her life to affirming the rule of law and democracy. As a prosecutor and California attorney-general, she pursued justice without fear or favor. As U.S. Senator, she confronted those who would aid and abet the malign use of authority. As Vice President, she has worked to find solutions to urgent problems, domestic and foreign. As a presidential candidate, she has called out her opponent as a disgrace to his oath as president to preserve, protect, and defend the Constitution.

We believe, based on our study of the past, that the nation stands at an unprecedented historical as well as a political crossroads. On the outcome of this election, no less than the election of 1860, hangs the fate of both the spirit and the letter of the Constitution. We appeal to our fellow citizens, whether conservative, independent, or liberal, regardless of party affiliation, to vote for Kamala Harris and Tim Walz. We make this call not as partisans but as historians who believe in the pursuit of a more perfect Union—and we urge all Americans to join us.

KAI BIRD

SIDNEY BLUMENTHAL

KEN BURNS

RON CHERNOW

BEVERLY GAGE

EDDIE GLAUDE

JON MEACHAM

SEAN WILENTZ

### _Interested historians are invited to [add their signatures here](https://forms.gle/1BfFBasurdNaj7ne7)._

---

Susan Dunn, Williams College

David Blight, Yale University

Laura Kalman, UC Santa Barbara

Judith A. Miller, Emory University, Dept. of History

Amy Dru Stanley, University of Chicago

Peniel E. Joseph, University of Texas at Austin

Louise W. Knight, Independent Scholar

Timothy Silver, Appalachian State University

Eileen Boris, University of California, Santa Barbara

Jonathan Eig, Author

Amy Bass

Elspeth Whitney, Professor Emerita, University of Nevada, Las Vegas

Adam Arenson

Joanne Meyerowitz, Yale University

Michael J. Pfeifer, John Jay College of Criminal Justice and the Graduate Center, CUNY

Fredrik Logevall, Harvard University

James M. Banner, Jr.

Laura Wexler, Yale University

Hampton Sides, Doubleday

Stacy Schiff, Author

Mary Kupiec Cayton, Miami University

Russell Shorto, The New York Historical Society

Brian Matthew Jordan

Caitlin Rosenthal, UC Berkeley

Judith W Leavitt, Emerita, University of Wisconsin Madison

Chris Fobare, Worcester Polytechnic Institute

Ronald L. Feinman, Florida Atlantic University

Steve Cohen, Tufts University

David Hoillinger, University of California, Berkeley

Adam Shprintzen, Marywood University

Kenneth Pomeranz, University of Chicago

David Brundage, University of California, Santa Cruz

Sara McDougall, CUNY

Megan Marshall, Emerson College

Paul Sparrow, Retired

Jean O'Brien, University of Minnesota

Tim Lehman, Rocky Mountain College

Maurice Isserman, Hamilton College

Rick Shenkman, Founder, History News Network

Anne M. Boylan, University of Delaware

Susan M. Reverby, Wellesley College

Kathryn K. Sklar, Distinguished Professor Emerita, State University of New York

Seth Tannenbaum

Steven A Leibo PhD, Russell Sage College

Harold Holzer, Hunter College, CUNY

Jeff Shesol

Diane Wolfthal, Rice University

Peter W. Williams, Miami University Emeritus

Benjamin L. Carp, Brooklyn College and the Graduate Center, CUNY

Jim Downs, Gettysburg College

James Zarsadiaz

Robert DuPlessis, Swarthmore College

Patricia Harms, Brandon University

Ian Shin, University of Michigan

Matthew Dallek, George Washington University

Jennifer Klein, Yale University

Khalil Gibran Muhammad, Harvard Kennedy School

Geoffrey C. Ward, Independent Scholar

David Grubin, Independent Filmmaker

Brad McKinnon, Heritage Christian University

Mason B. Williams, Williams College

Leigh Ann Wheeler, Binghamton University

Richard Parker, Kennedy School, Harvard University

Grace Peña Delgado, University of California, Santa Cruz

Christopher Sellers, Stony Brook University

M. Colette Plum, UC Berkeley

Adam Hochschild, U.C. Berkeley

Jonathan Eig, Author

Karen Cox, Retired

Stephen Schlesinger, Fellow, Century Foundation

Peter Kolchin, University of Delaware

John Avlon

Ted Widmer, City University of New York

Ann Fabian, Rutgers university, emerita

Tiya Miles, Harvard University

Peter Kornbluh, Historian

Jack Schneider, UMass Amherst

Marc Becker, Truman State University

Ava Jordan

Bruce Gourley

Anne Palazzo, Fort Hamilton HS

Keisha N. Blain, Brown University

Peggy Smith, Democrat

Mark S. Byrnes, Wofford College

Diane Miller Sommerville, Binghamton University, SUNY

Wendy Wall, Binghamton University, SUNY

Ian Buruma, Bard College

David Nasaw, CUNY Graduate Center

Daniel Czitrom, Mount Holyoke College

Alyssa Ritch-Frel, A Ritch History (Genealogist & Historical Researcher)

John W. Quist, Shippensburg University

Malissa Smith, Girlboxing.org

David Avrom Bell, Princeton University

Dan Royles, Binghamton University

James Grossman

Justin Jackson, Bard College at Simon's Rock

Donald Nieman, Binghamton University

Fergus M. Bordewich, Independent Historian

Kenneth R Bowling, retired Co-editor, Documentary History of the First Federal Congress, 1789-1791

Una M. Cadegan, University of Dayton

Diane McWhorter

Maya Soifer Irish, Rice University

David J. Silverman, George Washington University

Naomi Lamoreaux, Yale University

Robert McElvaine, Millsaps College

Daniel Okrent

William Smaldone, Willamette University

James Carroll

Allida Black

Myrna Santiago, Saint Mary's College of California

Ethan Kytle, California State University, Fresno

Linford Fisher, Brown University

Milton Nieuwsma, Retired

Steven Lawson, Rutgers University

Holly Brewer, University of Maryland

Rick Atkinson, Author and Historian

Jonathan Taplin, University of Southern California (Emeritus)

Patricia O'Toole

Sherry Pringle, Democrat

Monica Spencer

Donald L Miller, Emeritus Professor of History, Lafayette College

Amanda Foreman, Chairperson, House of SpeakEasy

Michael Green, UNLV

Ariela Gross, UCLA

Dolph Briscoe IV, Texas A&M University-San Antonio

Lawrence Cleveland, Republican (Voted VP Harris) Texas

James Oakes

Lisa Tendrich Frank, Independent Scholar

Andrew Frank

Bettina Aptheker, Feminist Studies, University of California, Santa Cruz

Leslie Schwalm

Stephenie Ambrose Tubbs, University of Montana Alum.

Sharon Wood, Retired

Peg Collins, Retired

David Myers, UCLA History Department

David Levering Lewis, University Professor Emeritus, NYU

Patrick B. Miller, Dept of History—Northeastern Illinois University

William diGiacomantonio

Patrick B. Miller, History—Northeastern Illinois University

Penny Von Eschen, University of Virginia

David Henkin, University of California, Berkeley

Harriet A. Washington, Columbia University

Thomas Dublin, SUNY Binghamton

Kevin K. Gaines, University of Virginia

Sam Tanenhaus

Alejandra B Osorio, Wellesley College

Kathleen Dalton, Independent Scholar

Elizabeth D. Leonard, Colby College, Waterville, ME

Gail Hershatter, University of California, Santa Cruz

Nell Irvin Painter, Independent Writer

Daniel Horowitz

H. Larry Ingle, Retired, University of Tennessee-Chattanooga

Elena Songster

Matthew Frye Jacobson, Yale University

Woody Register, University of the South

Dayton Duncan

Max Felker-Kantor, Ball State

Virginia Reinburg, Boston College

Cynthia A. Kierner

Eric Foner, Columbia University

Anne Sarah Rubin, University of Maryland, Baltimore County

Harvey J. Kaye, Prof. Emeritus University of Wisconsin-Green Bay

Michael Kazin, Georgetown University

Rebecca L. Davis, University of Delaware

Don H. Doyle, University of South Carolina, Emeritus

Kurt Andersen

Lauren Mancia, Brooklyn College and the Graduate Center, CUNY

Tracy Steffes, Brown University

Jonathan Alter

Carol Groneman, John Jay College of Criminal Justice and the Graduate Center, CUNY

Benjamin Carter Hett, Hunter College and the Graduate Center, CUNY

Anne Marie Wolf, University of Maine - Farmington

Richard H. Kohn, University of North Carolina at Chapel Hill

Craig L Symonds, Emeritus, U.S. Naval Academy

Rose Stremlau, Davidson College

Adam Blackler, University of Wyoming

Raymond H. Dominick III, Professor Emeritus at The Ohio State University

John Stauffer, Harvard University

Helmut Walser Smith, Vanderbilt University

AJ Plotke, Great War Primary Documents Archive

Catherine Clinton, University of Texas in San Antonio

Tyler Anbinder, Professor Emeritus, George Washington University

Marcia M. Gallo, Emerita, University of Nevada Las Vegas

Kenneth D. Ackerman, Independent Writer

Ty Seidule

Jay M. Smith, UNC-Chapel Hill

Zachary S Schiffman, Northeastern Illinois University, Emeritus

Alison Parker, University of Delaware

Kathleen DuVal, Author and Historian

Lisa Lindsay, University of North Carolina - Chapel Hill

James Mann, Author, Johns Hopkins School of Advanced International Studies

Edwin Williams, Independent

C. Morris

Leslie Choquette, Assumption University

Richard Slotkin, Wesleyan University, Retired

Robert K. Brigham, Vassar College

Christopher Morris

Alan Lawson, Professor Emeritus, Boston College

Doug Sackman, University of Puget Sound

Deborah Barton, Université de Montréal

Tim Lacy, Loyola University Chicago/Society for U.S. Intellectual History Co-founder

Melvyn Leffler, University of Virginia Emeritus

Van Gosse, Franklin & Marshall College (emeritus)

Robert Wilson, Independent Scholar

Douglas M. Charles, Penn State University

Mary Kelley, University of Michigan

Nancy Tomes, Stony Brook University

Lou Pérez, University of North Carolina at Chapel Hill

Clara Bingham, Freelance

Mark Peterson, Yale University, Department of History

Lisa Champeau, Journalist

Cheryl Greenberg, Trinity College, Hartford CT

Elaine Weiss, Author

Jonathan Darman

Steven Beller, Independent Scholar

Bridgette Robinson, Prince George's Community College

Nancy A Hewitt, Distinguished Professor Emerita, Rutgers University

John F Marszalek, Giles Distinguished Professor Emeritus of History and Retired Executive Director of the Ulysses S. Grant Presidential Library and U. S. Grant Association, Mississippi State University

Patrick Rael, Bowdoin College

Professor Jennifer Regan-Lefebvre, Trinity College

Adam Hochschild, U.C. Berkeley

Rosemarie Zagarri, George Mason University, History Dept.

Charles Ingrao, Professor Emeritus of History, Purdue University

Ian Reifowitz, SUNY Empire State University

Howard Lawrence Preston

Hasia Diner, New York university

Suzanne E. Smith, George Mason University

Michael O'Malley, George Mason University

Alice Baumgartner, University of Southern California

David Sorkin, Yale University

David Mayers, Boston University

Becky Nicolaides, Huntington-USC Institute on CA & West

Joseph Genetin-Pilawa, George Mason University

Jon Butler, Yale University & University of Minnesota

Andrew W. Robertson, Lehman College and the CUNY Graduate Center, City University of New York

Elizabeth R. Varon

Julia Sweig, Independent historian

Virginia DeJohn Anderson, University of Colorado Boulder (Retired)

Mari Jo Buhle, Brown University, Emerita

Christopher Benfey, Mount Holyoke College

Susan Strasser, Richards Professor Emerita of American History, University of Delaware

Blain Roberts, California State University, Fresno

Paul Freedman, Yale University

Martin Dean, Indpendent Scholar

Katharine Kennedy, Agnes Scott College, Emerita

Doug Haslam, Concerned citizen hoping to preserve our democracy

Kyle Livie, Professor of History, Ohlone College

Joanne Goodwin, UNLV Professor Emerita

Elizabeth Ellis, Princeton University

Meredith Lair, George Mason University

Hayley Negrin, University of Illinois at Chicago

Susan Ware, Independent Scholar

A. Tom Grunfeld, Empire State College/SUNY

Dave Brandt, St. Andrew's Episcopal School

Timothy Patrick McCarthy, Harvard University

Nina Silber, Boston University

Mary C. Cain, Agnes Scott College

Abigail Markwyn, Carroll University

Ellen Schrecker, Yeshiva University (Retired)

Albert Camarillo

Julia Sweig

Sally Charnow, Hofstra University

Jeff Ravel, MIT

Nancy MacLean, Duke University

Barbara Winslow, Professor Emerita Brooklyn College

Clifford A Welch, UNIFESP

Susan Yohn, Hofstra University

Carolyn Eisenberg, Hofstra University

Bonnie Anderson, CUNY

Roger Peace, Independent Scholar

Roger Leisner, Radio Free Maine

Marisa Chappell, Oregon State University

Gary J. Kornblith, Wilson Bruce Evans Home Historical Society

J. Morgan Kousser, Caltech

Mona Siegel, California State University, Sacramento

Guy Alain Aronoff, Cal Poly Humboldt

Ellen Eisenberg, Willamette University

Deborah Cohen, University of Missouri-St. Louis

Shannon Christen, Kent State University

Arlene Avakian, University of Massachusetts Emeritus

Claire Goldberg Moses, University of Maryland (emerita)

Seth Cotlar, Willamette University

Daniel Walkowitz, New York University

Margaret Creighton, Professor Emerita. Bates College

David Gurowsky, New York City Dept. of Education (Retired)

Christopher Brown, Professor of History

Philip Chassler, Univeristy of Massachusetts Boston (Retired)

Tamika Nunley

Sarah Barringer Gordon, University of Pennsylvania

Mark Lincicome, College of the Holy Cross

MJ Maynes, University of Minnesota

Rick Halpern, University of Toronto

Sandra McGee Deutsch, Professor Emerita, University of Texas-El Paso

Christian Miles

Derek N. Buckaloo, Coe College

Hannah Gurman, New York University

Lorraine Chavez, University of Chicago

Wilbur R. Miller, History, SUNY Stony Brook (Emeritus)

John B Boles, Rice University

Julia Mickenberg, University of Texas at Austin (speaking as a private citizen)

Jennifer Frost, Visiting Scholar, University of Washington

Alex Beasley, UT Austin (signed as a private citizen)

Paul Michel Taillon, University of Auckland

Anne Derbes, Hood College

Frima Fox Hofrichter, Professor Emerita, Pratt Institute

Michael W Hassler, Alvernia University

Fred Anderson, Professor Emeritus, University of Colorado Boulder

Andrew Feffer, Professor Emeritus, History, Union College, Schenectady NY

Linda K Kerber, Retired

Peter Gough, California State University Sacramento

Marc Arsell Robinson, California State University, San Bernardino

Pamela Ekstrom, History Lover

Margaret (Peg) Strobel, University of Illinois at Chicago

Jean-Christophe Agnew, Yale University

Jennifer Ritterhouse, George Mason University

Judith Steinhoff

Mary C Wilson, University of Massachusetts

Susan Wladaver-Morgan, Pacific Historical Review, Retired

Al Carroll, Northern Virginia Community College

Elizabeth Schmidt, Loyola University Maryland

Norman Markowitz, Department of History, Rutgers University

Jessica Weiss, California State University, East Bay

Mary Ann Irwin, Author, California History (UC Press)

Louisa A. Burnham, Middlebury College

Walter Greason, Macalester College

Karen Sotiropoulos, Cleveland State University

Sarah Maza, Northwestern University

Kristian Blaich, Agnes Scott College

Claudette Tolson

Elisabeth Sommer

David L. Carlton, Vanderbilt University, Emeritus

Douglas Brinkley, Professor of History and Presidential Historian

Sean Munger, Independent

Ruth M Alexander

Mavis Amundson, Retired journalist, history teacher

Adam J. Davis, Denison University

Kenneth Zimmerman, The History Business

David T. Z. Mindich, Temple University

Sandi Cooper, Professor emerita, City U of New York at Staten Island and The Graduate School

Vernon Burton, Clemson University

Kathy Feeley, University of Redlands

Arun Raja Pookote

Rima Lunin Schultz, University of Illinois Chicago

Derek Larson, The College of St. Benedict + St. John's University (MN)

Leslie Singer Lomas

Marjorie J. Spruill, University of South Carolina Emerita

Andrew Larsen, University of Wisconsin Milwaukee

Allyson Hobbs, Stanford University

Steven Volk, Oberlin College

Margot Canaday, Princeton University

Alison Landsberg, George Mason University

Ross Caputi, UMass

Timothy M. Gay, Author of five books on popular history

Kathy Roberts Forde, University of Massachusetts Amherst

Sid Bedingfield, Hubbard School of Journalism and Mass Communications, University of Minnesota, Twin Cities

William V. Hudon, Bloomsburg University of Pennsylvania

Kitty Krupat, City University of New York (CUNY)

Martha A. Sandweiss, Princeton University

Iris Berger, University at Albany - SUNY

Ronald C. White, Historian and Biographer

Emilio Zamora, University of Texas at Austin

Michael Grossberg, Indiana University, Bloomington

Peter Kuznick, American University

James Borchert, Professor Emeritus Cleveland State University

Amy Kesseman, SUNY New Paltz

Patricia Bonomi, Emerita, New York University

Kristopher Burrell

Matthew H. Sommer, Stanford University

Darcy Buerkle, Smith College, Department of History

Steve Kantrowitz, UW-Madison

David Johnson, Portland State University, emeritus

Ruth Schwartz Cowan, University of Pennsylvania

Kimberly Jensen, Western Oregon University

Martha Hodes, New York University

Bruce Dorsey, Swarthmore College

Matthew S Luckett, California State University Dominguez Hills

Amy Kittelstrom, Sonoma State University

Linda Leavell, Biographers International Organization

Abigail Santamaria, The Dorothy and Lewis B. Cullman Center for Scholars and Writers at the New York Public Library

Justin Spring, Independent

David A. Kaplan

David Allyn

Victoria Phillips, Wilson Center

Caroline Fraser

Amanda Vaill, Independent scholar

Rev. Dr. Phillip A. Bernhardt-House, Research Group on Manuscript Evidence

Laurence Bergreen, Independent historian

Betsy Ennis, Ennis O’Brien and Columbia University alum

Ann Norton Greene, University of Pennsylvania

Alexis Coe, New America

Larry Lockrige, New York University

Trinidad Gonzales

Marjorie Becker, Professor, History and English, University of Southern California

Neal Gabler

Rebecca A. Hunt, University of Colorado, Denver, Emerita

Geoffrey R. Hunt, Ph.D, Professor of History, Emeritus

John Matteson, John Jay College of Criminal Justice, CUNY

Carl E. Kramer, Ph.D., Indiana University Southeast (Retired) and Kramer Associates, Inc.

Rev. Dr. Nancy Koestet, Retired from Luther Seminary, Augsburg College

David S. Dunbar, DKDK Project

Henry Breed

Wes Singletary, Ph.D., Lawton Chiles High School

Ken Krimstein, Author/Graphic Biographer

Mary Ann Wynkoop, UMKC retired

Nigel Hamilton, UMass Boston

William E. Leuchtenburg, William Rand Kenan Prof. Emeritus, UNC Chapel Hill

Marilyn Richardson, Principal, Art + History Consultants

Gary Krist, Independent Scholar

Margaret Bendroth, Retired

Hilliary Turner, Rappahannock Community College and Southern New Hampshire University

Conevery Bolton Valencius, Boston College

Marguerite Renner, Glendale College

Margaret Lavinia Anderson, Historian UC-Berkeley Emerita

Barbara J. Howe

James J. Sheehan, Stanford University

Samuele F.S. Pardini, Elon University

Brian Goldstein, Swarthmore College

Darren Wood

Joshua Kendall, Biographer

Leonard Ortiz, Baker University, Retired

Lara Freidenfelds, Independent Scholar

Jay Turner, Wellesley College

Margo Anderson

Charles Lester, Ohio University

Emily Pawley, Dickinson College

David Greenberg, Rutgers University

Emma Hart, University of Pennsylvania

Gerard E Mayers, Independents

Jinny Turman

Barbara Epstein, History of Consciousness Dept. U.C. Santa Cruz

Susan Kullmann, Retired, CA State Polytechnic Univ., Pomona

Theresa McCulla

Antonia Castaneda, Profesor Emérita

Christopher J. O'Shea, Indiana University

Julian B Carter, California College of the Arts, San Francisco

Amy E.Davis, Retired

Carol Kino, Author, Scribner Books, Double Click: Twin Photographers in the Golden Era of Magazines

Fred L. Johnson III, Ph.D., Hope College

Dawn A. Godfrey-Skeens, Historian

Bill J. Leonard, Wake Forest University

HP Harris, Educator

R Barton Palmer, Clemson University

Brian Lee, McNeese State University

Paul Lubienecki, Boland Center for the Study of Labor and Religion

Jim Hanna, English department, Georgetown College

Mark Clark, The University of Virginia’s College at Wise

Cathal J. Nolan, Smithsonian

Erik Rau

Albert Earle Gurganus, Professor Emeritus, The Citadel

Miriam Cohen, Vassar College

Vivien Sandlund, Hiram College

Kathleen M. Brown, University of Pennsylvania

Eugene Leach, Trinity College, Hartford

Robbie Mahallati

Anthony S. Parent Jr., Wake Forest University

Alex Roland, Duke University

Jim R. McClellan, Dean Emeritus and Professor of History (Ret.), Northern Virginia Community College ia

Elizabeth Blum, Troy University

Christopher Bilodeau, Dickinson College

Peter Pringle, Journalist, Author

Dennis C. Dickerson, Vanderbilt University, Emeritus

Tim Hacsi, University of Massachusetts - Boston

Maureen Fitzgerald, Emeritus William and Mary

Max Perry Mueller, University of Nebraska-Lincoln

Greta Goff

Matthew H. Bernstein, Emory University

Elizabeth Kelly Gray, Towson University

Joseph Gonzlez, Appalachian State University

William Trollinger, University of Dayton

Gary Giddins

Jennifer L. Morgan, New York University

William Carter, Retired

Janet Grojean, Independent and Democrat

William G Morgan, Oral Roberts University (ret.)

Josh Reid, University of Washington

Fred Anderson, University of Colorado at Boulder (Emeritus)

Cynthia E. Grant, Salem College

Deborah Anna Brown, Riverside City College - History

Marilynn S Johnson, Boston College

Richard B. Trask, Danvers Archival Center, Danvers, Massachusetts

Candice Millard

Babette Crowder, Retired

Jeffrey K. Tulis, Professor Emeritus, The University of Texas at Austin

Jeffrey C. Isaac, Indiana University, Bloomington (for ID purposes only)

Jeremi Suri, University of Texas at Austin

Christine Skwiot, Professor of Humanities, Maine Maritime Academy

Annabel Irene Maley, Avid lifetime student of history, practicing lawyer, UVA Law 1990

Mary Nolan, Professor of History emerita NYU

William W. Hagen, University of California, Davis

Robert W. Matson, University of Pittsburgh

Carl E. Prince, New York University (Emeritus)

Donna West, Genealogy and Business History CA and MO

Ian Sikdar, The Tatnall School

Paul Lubienecki, Boland Center for the Study of Labor and Religion

Carolyn Powell, Associate Professor, VSCC

Daniel Mandell, Truman State University

Lori Clune, CA State University Fresno

Alan Kraut, American University

Denver Brunsman, George Washington University

Stanislao Pugliese, Hofstra University

David M Luebke, University of Oregon

Steven Louis Brawley, Public Historian

Geoffrey Kirsch, University of Cambridge

Renee K Harrison, Howard University, School of Divinity

Stephanie A.T. Jacobe, University of Maryland Global Campus

Margaret E Menninger, Texas State University

Mik Larsen, California State University, Long Beach

Elaine Tyler May, University of Minnesota

Lary May, University of Minnesota

Katrin Paehler, Illinois State University

Brendan Julian

Christi Anderson, California State University, Sacramento

Jeffrey K. Wilson, California State University, Sacramento

Maria Quintana, Sacramento State University

Patrick Ettinger, Sacramento State University

Joshua Andy, Winchester Thurston School

Chloe Burke, Sacramento State

Joseph A. McCartin, Georgetown University

Christopher J Castañeda, CSU, Sacramento

Donna Haverty-Stacke, Hunter College

Matthew Shoup, Democrat

Joan E. Cashin, Ohio State University

Aretha Brown, Social Studies Educator

Deborah Holland, History Librarian

John J Thawley, Educator

Jonathan Karp, Binghamton University, SUNY

Katherine Lettieri, Retired Educator

Elissa Bemporad, Queens College and The Graduate Center, CUNY

Mary Ann Baldari, Delta Kappa Gamma

Claudia Webb, Retired public school teacher, Columbus, OH

Phillip Sozansky, Independent Historian & AP U.S. History Instructor

David J. Kent, Lincoln Group of DC and Lincoln Scholar

Akiko Takenaka, University of Kentucky

Joan C. Browning, Freedom Rider Independent Researcher

Lynn Price Robbins

Laura Tabili, Professor Emerita, University of Arizona

Gordon Harris, Ipswich MA town historian, Ipswich Historical Commission

Shirley Wajda, Museum Curator and Public Historian

Jane Marcellus, Middle Tennessee State University

Jonathan Earle, LSU

Tommy Brown PhD, JD

Johann Neem

Marquett Thinn

Heather Clark, University of Huddersfield

Amber Roessner

Katie Foss, Middle TN State University

Chris Magoc, Mercyhurst University

Kevin, New York University

Jerry Gershenhorn, North Carolina Central University

Julius Wayne Dudley, Professor Emeritus of History, Salem State University, Massachusetts

Alexandra Garrett, Saint Michael's College

Danielle McGuire, Independent Scholar

Matthew Basso, University of Utah

Kim Gallon, Brown University

Graham Hodges, Colgate University

Carole Srole, California State University at Los Angeles

Birte Pfleger, California State University Los Angeles

Bryant Simon, Temple University

Carol Sue Humphrey, Retired

Barry Bienstock, Horace Mann School

Robert A. Geake, Public historian, Author

Johann Neem

Lynette Garrett, Northern Virginia Community College

Kendra A. Kennedy

Kathleen Conti, Florida State University

Luella Hobson-Burris, Democrat

Will Kaufman, University of Central Lancashire (Emeritus)

Daniel Rosenberg, Adelphi University

William Smaldone, Willamette University

Melissa Totten, Independent
",['historiansforharris'],0,,0.59,0,,,,,,1,,,
112709275,MDEwOlJlcG9zaXRvcnkxMTI3MDkyNzU=,Speck,merttoka/Speck,0,merttoka,https://github.com/merttoka/Speck,UCSB MAT240C Audio Programming Project,0,2017-12-01 07:31:19+00:00,2020-01-21 20:56:22+00:00,2018-01-10 17:10:25+00:00,,5450,1,1,Processing,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,1,master,1,,"# Speck
**MAT240C *Audio Programming* - Final Project**

*Speck* is a grain sequencer inspired by electronic music notation, granular and image syntheses. Grains can be created by chopping samples and applying an arbitrary envelope. They can be placed onto the canvas by drawing with mouse, and when triggered, the canvas translates spatial pixels into note-like structures whose pitch varies based on the vertical location of the note. 

![ss](docs/ss.png)



### Install and Run

- Install [Processing](https://processing.org/download/)

- Add **Minim** and **ControlP5** libraries to Processing

  - *Sketch* -> *Import Library* -> *Add Libraries*
  - Search the name of the library and click *Install*

- Download / clone the files at:  

  ```git clone https://github.com/merttoka/Speck.git```

- Run `speck.pde` in Processing IDE




### Usage 

<img src=""docs/GIF2.gif"" alt="".."" width=""520""> <img src=""docs/GIF.gif"" alt=""..."" width=""200"">


| Key                                      | Interaction                              |
| ---------------------------------------- | ---------------------------------------- |
| `LEFT CLICK` on *wave shape*             | Sets lower bound of grain selection      |
| `RIGHT CLICK` on *wave shape*            | Sets higher bound of grain selection (reverses sample if *min > max*) |
| `LEFT CLICK` on *envelope*               | Draws bins on envelope                   |
| `0` ... `9`                              | Trigger corresponding grain on the dropdown |
| `LEFT CLICK` on *canvas*                 | Places selected grain on the cell of canvas |
| `RIGHT CLICK` on *canvas*                | Removes item from the cell of canvas     |
| ` SPACE`                                 | Start / stop timer on canvas             |
| `UP`/`DOWN`                              | Increment / decrement playback speed     |
| `i`                                      | Load an image into canvas (image path is in `void setup` function) |
| `s`                                      | Save canvas as an image file             |
| `c`                                      | Clear canvas                             |
| [`SHIFT`] + `LEFT ARROW` or `RIGHT ARROW` | Move timer left or right on canvas (`SHIFT` doubles the speed) |

- You can copy sample files to `speck/samples/` directory to populate the samples list.

- The *resolution* of canvas and *total time* of canvas can be modified with `resolution` (*canvas matrix dimension*) and `maxTime` (*milliseconds*) variables at the top of `speck.pde` 

### TODO:
- [x] Assign keyboard numbers to play grains
- [x] Draw normalized grain wave 
- [x] Reverse sample playback on selection
- [x] Adjustable playback speed
- [x] Image selector
- [x] Labels
- [ ] Save grains and canvas on quit
- [ ] Editing Grains (delete, manipulate)
- [ ] Coloring the grain selection dropdown items
- [ ] Interaction improvements
",['merttoka'],1,,0.67,0,,,,,,1,,,
738811960,R_kgDOLAlgOA,w24,ucsb-cs9/w24,0,ucsb-cs9,https://github.com/ucsb-cs9/w24,"Website for CMPSC 9, W24 taught by Prof K",0,2024-01-04 05:21:25+00:00,2024-02-19 18:18:54+00:00,2024-03-19 01:44:21+00:00,https://ucsb-cs9.github.io/w24/,1055,1,1,JavaScript,1,1,1,1,1,0,7,0,0,3,,1,0,0,public,7,3,1,main,1,1,"# w24
Website for CMPSC 9, W24 taught by Prof K
","['ykharitonova', 'hitomi-nakayama', 'harsha-miryala', 'RyanZanone', 'krushnashah', 'comradez', 'BrennaScholte', 'eshagupta01']",1,,0.85,0,,,,,,3,,,
288258613,MDEwOlJlcG9zaXRvcnkyODgyNTg2MTM=,shellphish.github.io,shellphish/shellphish.github.io,0,shellphish,https://github.com/shellphish/shellphish.github.io,Shellphish web site,0,2020-08-17 18:39:11+00:00,2025-02-03 12:39:30+00:00,2024-09-03 18:21:40+00:00,,220519,3,3,TeX,1,1,1,1,1,0,2,0,0,1,,1,0,0,public,2,1,3,master,1,1,"# shellphish.github.io
Shellphish web site currently a repo for the static HTML

The previous website was done with hugo and housed internally, 
the url was: https://git.seclab.cs.ucsb.edu/shellphish/shellphish.net 

(don't expect to find it here, the path is just relevant for historical purposes)

Moving the website here solves the problem of expiring certificates.

The real url is https://shellphish.net.
","['noah-de', 'giovannivigna', 'mahaloz', 'Lukas-Dresel', 'Cl4sm']",1,,0.8,0,,,,,,12,,,
877751488,R_kgDONFFswA,Secure-Network-Simulation,mirasoldavila13/Secure-Network-Simulation,0,mirasoldavila13,https://github.com/mirasoldavila13/Secure-Network-Simulation,,0,2024-10-24 07:21:00+00:00,2024-10-26 01:20:18+00:00,2024-10-26 01:20:15+00:00,,6364,0,0,,1,1,1,1,0,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# Secure-Network-Simulation

## Overview
This project simulates the setup, configuration, and security of a virtualized network environment as part of the **UC Santa Barbara Professional and Continuing Education Cybersecurity Program**. The objective is to deploy a network that meets a client’s needs within budget and space constraints. Virtual machines (VMs) are used to implement essential components, including firewalls, web servers, DNS servers, and monitoring systems.

This project demonstrates practical skills in deploying, configuring, and securing IT systems. Through troubleshooting, network analysis, and security baselining, this simulation provides hands-on experience in establishing network solutions tailored to operational and budgetary requirements.

---
## Scenario
You have been hired by an **IT company** as an **IT subject matter expert**. The management team has a **client who wants to upgrade their IT systems**, but the client has a **limited budget** and **no more physical space** to install new equipment. 

To solve this issue, you suggest implementing **virtual machines** instead of additional hardware to help **reduce costs** and meet the client’s operational needs. As part of the upgrade, the following components will be installed:
- **Firewall**
- **CEO's PC**
- **Internal Webserver**
- **Internal DNS server**
- **Linux machines** for monitoring and conducting cybersecurity tasks

Once the new network is installed, your task is to **document configurations** and create a **security baseline** by scanning for **open ports**.


---

## Technologies and Tools Used
- **VirtualBox:** Used to create and manage virtual machines.
- **Kali Linux and Other Linux Distributions:** Utilized for security testing, network monitoring, and diagnostic tasks (e.g., ping, FTP).
- **Wireshark:** Used for capturing and analyzing network traffic.
- **VMs Deployed:** Router-FW, DNS Server, Web Server, CEO PC, and Kali Linux (Trusted/Untrusted).

---

## Tasks and Deliverables

### Project Tasks  

1. **Verify Network Connectivity**  
   The CEO PC must be able to access [seclab.net](http://www.seclab.net). If the page fails to load, troubleshoot using Linux commands (e.g., `ping`) to diagnose network issues between machines.

---

#### **Solution: Verify Network Connectivity**

1. **Attempt to Access seclab.net via Firefox**  
   - **Action:** Launched Firefox on the CEO PC and navigated to **`www.seclab.net`**.  
   - **Result:** Firefox displayed a **""Server not found""** error, indicating a potential connectivity issue.  
   ![Firefox Error - Server Not Found](images/ceo-pc/ceo_pc_seclab_not_reachable.png)

2. **Ping the Web Server (10.200.0.12)**  
   - **Action:** Executed `ping 10.200.0.12` from the CEO PC to test connectivity to the web server.  
   - **Result:** Received **""Destination Host Unreachable""**, confirming the web server was not accessible from the CEO PC.  
   ![Ping to Web Server - Unreachable](images/ceo-pc/ceo_pc_web_not_reachable.png)

3. **Ping the DNS Server (10.200.0.11)**  
   - **Action:** Ran `ping 10.200.0.11` to check connectivity with the DNS server.  
   - **Result:** Received **""Destination Host Unreachable""**, indicating that the DNS server was also inaccessible.  
   ![Ping to DNS Server - Unreachable](images/ceo-pc/ceo_pc_dns_server_not_Reachable.png)

4. **Inspect the IP Configuration**  
   - **Action:** Used the command `ip addr` on the CEO PC to review the network interface settings.  
   - **Result:**  
     - The **IP address** was incorrectly set to **203.0.113.69/24**, which does not align with the expected **192.168.0.0/24** trusted network.  
     - This incorrect IP address caused the CEO PC to be isolated from the DMZ and other internal resources.  
   ![Incorrect IP Address](images/ceo-pc/ceopc_incorrect_ip.png)

5. **Analyze and Adjust IP Settings**  
   - **Action:** Checked the **IPv4 settings** of the **Auto eth2** connection.  
   - **Result:**  
     - The **IP address**, **default gateway**, and **DNS server** were incorrectly set within the **203.0.113.0/24 subnet**, preventing proper communication.  
     - According to the **network diagram**:
       - The CEO PC should have an IP address within the **192.168.0.0/24 trusted network**.
       - The **default gateway** should also be within the **trusted network** (192.168.0.x) for correct routing.
       - The **DNS server** should be accessible within the **DMZ (10.200.0.8/29)**, allowing name resolution for internal services.  
   ![Incorrect Network Settings](images/ceo-pc/ceo_pc_edit_ip_Setting.png)

6. **Switch to Automatic DHCP Configuration**  
   - **Decision:**  
     - **Option 1:** Manually assign the correct IP, gateway, and DNS settings to align with the trusted network.  
     - **Option 2:** Switch to **Automatic DHCP** to dynamically receive the appropriate network configuration.

   - **Chosen Solution:**  
     The decision to use **Automatic DHCP** ensured that the CEO PC would receive the correct IP address, gateway, and DNS settings without manual intervention.  
     
     During the import of virtual machines into **VirtualBox**, the option to **""Include all network adapter MAC addresses""** was enabled. This choice guaranteed that each virtual machine, including the CEO PC, would receive a unique MAC address, avoiding potential conflicts.  
     
     Using DHCP reduced the risk of human error and ensured that network settings aligned with the trusted network configuration. This approach provided a more reliable, scalable solution for maintaining proper connectivity across all virtual machines.  
   ![Changed Method to DHCP](images/ceo-pc/ceo_pc_changed_method.png)

7. **Test Connectivity to Web and DNS Servers**  
   - **Action:**  
     - Ran `ping -c6 10.200.0.12` to verify communication with the web server.  
     - Ran `ping -c4 10.200.0.11` to check connectivity with the DNS server.  

   - **Result:** Both pings were **successful**, confirming that communication with the servers had been restored.  
   ![Ping to Web Server - Successful](images/ceo-pc/ceo_pc_web_reachable.png)  
   ![Ping to DNS Server - Successful](images/ceo-pc/ceo_pc_dns_server_reachable.png)

8. **Reopen Firefox and Confirm Access to seclab.net**  
   - **Action:** Launched Firefox again and navigated to **`www.seclab.net`**.  
   - **Result:** The page loaded successfully, confirming the network issue was resolved.  
   ![Successful Access to seclab.net](images/ceo-pc/ceo_seclba_reachable.png)

---

2. **Document IP Configuration**  
   Record the OS version, IP address, subnet mask, default gateway, and DNS server address for the following:
   - CEO PC  
   - Web Server  
   - DNS Server

---

#### **Solution: Document IP Configuration**

> **Note:** The `ip addr` command was used to retrieve the **IP address**, and the `ifconfig` command was used to verify both the **IP address** and **subnet mask** where necessary.

For each system, the following commands were used:
- **OS Version:** `lsb_release -a` or `cat /etc/*rel*` (depending on the OS).
- **IP Address:** `ip addr` or `ifconfig`.
- **Subnet Mask:** Retrieved from `ifconfig`.
- **Default Gateway:** `ip route`.
- **DNS Server:** `cat /etc/resolv.conf`.

### CEO PC  
- **OS Version**:  
  - Command: `lsb_release -a`  
  - **Result**: CentOS 6.4  
  ![CEO PC OS Version](images/ceo-pc/ceo_os_version.png)

- **IP Address**:  
  - Command: `ip addr`  
  - **Result**: `192.168.0.15/24`  
  ![CEO PC IP Address](images/ceo-pc/ceo_new_ip.png)

- **Subnet Mask**:  
  - Command: `ifconfig`  
  - **Result**: IP `192.168.0.15` with Subnet Mask `255.255.255.0`  
  ![CEO PC Subnet Mask](images/ceo-pc/ceo_subnet.png)

- **Default Gateway**:  
  - Command: `ip route`  
  - **Result**: Default Gateway `192.168.0.1`  
  ![CEO PC Default Gateway](images/ceo-pc/ceo_default_gateway.png)

- **DNS Server**:  
  - Command: `cat /etc/resolv.conf`  
  - **Result**: DNS Server `10.200.0.11`  
  ![CEO PC DNS Server](images/ceo-pc/ceo_dns_server_new_ip.png)

---

### Web Server  
- **OS Version**:  
  - Command: `lsb_release -a`  
  - **Result**: Ubuntu  
  ![Web Server OS Version](images/web-server/webserver_os_version.png)

- **IP Address and Subnet Mask**:  
  - Command: `ifconfig`  
  - **Result**: IP `10.200.0.12` with Subnet Mask `255.255.255.248`  
  ![Web Server IP Address](images/web-server/webserver_if_config.png)

- **Default Gateway**:  
  - Command: `ip route`  
  - **Result**: Default Gateway `10.200.0.9`
  ![Web Server Default Gateway](images/web-server/webserver_ip_route.png)
- **DNS Server**:  
  - Command: `cat /etc/resolv.conf`  
  - **Result**: DNS Server `10.200.0.11`
  ![Web Server DNS Server](images/web-server/webserver_dns_server.png)
---

### DNS Server  
- **OS Version**:  
  - Command: `cat /etc/*rel*`  
  - **Result**: CentOS 6.4  
  ![DNS Server OS Version](images/dns-server/dns_server_os_version.png)

- **IP Address and Subnet Mask**:  
  - Command 1: `ip addr`  
    - **Result**: IP `10.200.0.11/29`  
    ![DNS Server IP Address](images/dns-server/dns_server_id_addr.png)

  - Command 2: `ifconfig`  
    - **Result**: IP `10.200.0.11` with Subnet Mask `255.255.255.248`  
    ![DNS Server IP and Subnet Mask](images/dns-server/dns_server_if_config.png)

- **Default Gateway**:  
  - Command: `ip route`  
  - **Result**: Default Gateway `10.200.0.9`  
  ![DNS Server Default Gateway](images/dns-server/dns_server_default_Gateway.png)


---

3. **Download Social Media Security Policy via FTP**  
   From the CEO PC, use FTP to download the policy document from the web server.
---

#### **Solution: Download Social Media Security Policy via FTP**

1. **Initiate FTP Connection**  
   - **Command:** `ftp`  
   - Opened an FTP connection to the **web server** with the command:  
     ```bash
     open 10.200.0.12
     ```
   - Entered the **username:** `jasper` and **password** when prompted.

2. **List Available Files on FTP Server**  
   - **Command:** `ls`  
   - Entered **Passive Mode** and confirmed that the file **Social-Media-Security-Policy** was available:
     ```text
     April 16 2020  Social-Media-Security-Policy
     ```

   ![FTP List Command](images/ceo-pc/social-media-security-policy/ceo_pc_download_social_media_policy.png)

3. **Download the Social Media Security Policy**  
   - **Command:** `get Social-Media-Security-Policy`  
   - The transfer was completed successfully, confirming that the file was downloaded.

4. **Close the FTP Connection**  
   - **Command:** `close`  
     - Response: **221 Goodbye**  
   - **Command:** `exit`  

5. **Verify the Downloaded File**  
   - **Command:** `ls`  
   - Confirmed that the **Social-Media-Security-Policy** file was successfully downloaded to the CEO PC.

   ![Verify Downloaded File](images/ceo-pc/social-media-security-policy/ceo_ls_social_media_security_policy.png)

6. **Open the Social Media Security Policy Document**  
   - Opened the **Social-Media-Security-Policy** file on the CEO PC to verify the content.

   ![Open Social Media Security Policy](images/ceo-pc/social-media-security-policy/ceo_social_media_security_policy.png)
   ### **Summary of the Social Media Security Policy**  
   The **Social Media Security Policy** document is a **draft policy** for **Robot Parts, Inc.** It highlights the company’s strategic use of social media for marketing and business purposes, as well as the importance of protecting the organization from social media threats. Key points from the policy include:

   1. **Importance of Social Media:**  
      - Social media plays a critical role in promoting the company and interacting with customers to build brand awareness.

   2. **Managing Social Media Risks:**  
      - The company acknowledges the growing risks from the **social media threat landscape** and the need to protect its **reputation, customers, and employees** from these risks.

   3. **Commitment to Cybersecurity Best Practices:**  
      - The policy emphasizes adherence to **cybersecurity best practices** and holds the company accountable for responsible social media management.

   4. **Access Management:**  
      - The company will define tools and authorized personnel to manage social media accounts, though further details are to be added in the final version.

   5. **Policy Review and Incident Response:**  
      - The policy requires **annual reviews** and updates by the social media and cybersecurity teams.
      - In the event of a **security incident**, the policy mandates immediate review to identify areas for improvement.


---
4. **Create a New User on the Web Server**  
   Add a new user with a chosen username and password on the web server.
   #### **Solution: Create a New User on the Web Server**

1. **Logged in as Root:**  
   - Already logged in as the `root` user on the web server.

2. **Add New User:**  
   - Executed the command:  
     ```bash
     useradd mirasol
     ```
   - Verified the creation of the user by checking `/etc/passwd` using:  
     ```bash
     cat /etc/passwd
     ```
   - The output showed that the `mirasol` user was successfully created (see the last line).  
     ![New User Created](images/web-server/webserver_created_new_user_mirasol.png)

3. **Set Password, Logout, and Login as New User:**  
   - All the steps for setting the password, logging out from the root session, logging in as the new user `mirasol`, and verifying the login are captured in the following screenshot:
     1. **Set Password:** Used the `passwd mirasol` command to assign a password to the new user.
     2. **Logout:** Logged out of the `root` session.
     3. **Login:** Logged in as `mirasol` with the new credentials.
     4. **Verify:** Executed `whoami` to confirm the current user is `mirasol`.  
   
   ![Logged in as Mirasol](images/web-server/webserver_mirasol_login.png)
---
5. **Perform Port Scans Using Nmap**  
   Use Nmap from a Kali Linux machine to scan the DNS and Web servers. Document all open ports and associated protocols.

   #### **Solution: Perform Port Scans Using Nmap**

1. **Scan on Web Server (10.200.0.12)**  
   - Executed the following command:  
     ```bash
     nmap 10.200.0.12
     ```
   - **Result:** The scan revealed multiple open ports and services running on the web server, such as FTP, HTTP, and SSH.  
     ![Nmap Web Server](images/kali-linux/trusted/nmap/kali_trusted_nmap_webserver.png)

---

2. **Scan on DNS Server (10.200.0.11)**  
   - Executed the following command:  
     ```bash
     nmap 10.200.0.11
     ```
   - **Result:** The scan identified SSH and DNS services running on the DNS server.  
     ![Nmap DNS Server](images/kali-linux/trusted/nmap/kali_trusted_nmap_dns_server.png)



   These scans provide visibility into the services running on the **Web** and **DNS servers**, ensuring they align with expected configurations and highlighting any potential security exposures.
---
6. **Verify that the Trusted network is protected from the Untrusted network.**
   ### **Solution: Verify Network Protection**

   Step 1. **Check IP Address of the Kali Untrusted VM**  
   - Ran the `ifconfig` command on the **Kali Untrusted** virtual machine to confirm the IP address.  
     - The IP address was **172.30.0.10**, which is **within the 172.30.0.0/24 Untrusted Network**, as indicated in the network diagram.

   ![Kali Untrusted IP Address](images/kali-linux/untrusted/kali_untrusted_ifconfig.png)

   Step 2. **Ping from Kali Trusted to Kali Untrusted VM**  
   - From the **Kali Trusted** virtual machine, executed the following command to ping the **Kali Untrusted** machine:
     ```bash
     ping -c5 172.30.0.10
     ```
   - **Result:** The ping was **successful**, indicating that the **Kali Trusted** machine was able to communicate with the **Kali Untrusted** machine, as expected.

   ![Ping from Trusted to Untrusted](images/kali-linux/trusted/kali_trusted_ping_kaliUntrusted.png)

   Step 3. **Ping from Kali Untrusted to Kali Trusted VM**  
   - From the **Kali Untrusted** virtual machine, attempted to ping the **Kali Trusted** machine:
     ```bash
     ping -c5 192.168.0.19
     ```
   - **Result:** The ping was **unsuccessful**, demonstrating that the **Trusted Network** was protected from the **Untrusted Network**.

   ![Unsuccessful Ping from Untrusted to Trusted](images/kali-linux/untrusted/kaliUntrusted_unsucessful_ping_kali_trusted.png)

   Step 4. **Referencing the Network Diagram**  
   - As per the **network diagram**, the **Kali Trusted VM** is part of the **192.168.0.0/24 Trusted Network**, and the **Kali Untrusted VM** belongs to the **172.30.0.0/24 Untrusted Network**.  
   - This configuration confirms the intended **network segmentation**, ensuring that traffic from the untrusted network is blocked from accessing the trusted network’s resources, as designed.
---

7. **Capture FTP Traffic with Wireshark**  
   Use Wireshark on Kali Linux to monitor an FTP session between the CEO PC and the Web Server. Capture the username and password transmitted during the session.
   #### **Solution: Capture FTP Traffic with Wireshark**
   ## Step 1: Initiate FTP Session from CEO PC

      1. On the CEO PC, I used the `ftp` command.
      2. I connected to the Web Server at IP address **10.200.0.12**.
      3. Logged in with the username **jasper**.
      4. Executed the `ls` command to display the available files, confirming the presence of the `Social-Media-Security-Policy`.

   ![FTP session showing file listing](images/kali-linux/trusted/wireshark/wireshark_ftp.png)

   ## Step 2: Download the File and Monitor Traffic

      1. I used the `get Social-Media-Security-Policy` command to download the file.

   ![Downloading Social-Media-Security-Policy](images/kali-linux/trusted/wireshark/whireshark_social_media.png)

   2. In Wireshark, I captured the FTP login sequence, including the USER and PASS commands, revealing the username (jasper) and password (2hard2guess) transmitted in plaintext, followed by the 230 Login successful response.

   ![Captured username, password, and FTP session details](images/kali-linux/trusted/wireshark/kali_trusted_ceo_usr_passwd.png)
---

## Network Diagram  
Below is the network diagram showcasing the design and setup of the virtualized network.

![Network Diagram](images/network-diagram/network_diagram.png)




",['mirasoldavila13'],1,,0.81,,,,,,,,,,
508505788,R_kgDOHk8uvA,shiny-dashboard,UCSB-MEDS/shiny-dashboard,0,UCSB-MEDS,https://github.com/UCSB-MEDS/shiny-dashboard,Infrastructure for the Bren Student Data Explorer,0,2022-06-29 01:25:49+00:00,2024-11-19 00:15:50+00:00,2024-11-19 00:15:47+00:00,https://shinyapps.bren.ucsb.edu/student-data-explorer/,9225,1,1,R,1,1,1,1,0,0,4,0,0,5,,1,0,0,public,4,5,1,main,1,1,"# R Shiny [Bren Student Data Exporer](https://shinyapps.bren.ucsb.edu/student-data-explorer/)

## Purpose
The [Data Explorer](https://shinyapps.bren.ucsb.edu/student-data-explorer/) is an interactive dashboard that showcases the Bren School admissions and career outcomes data of current students and recent alumni. It was developed with the intention of supporting:

* Prospective students in their decision-making as they explore the different degree programs at the Bren School
* Bren departments and staff with their reporting requirements
* All Bren communities and stakeholders from the past, present, and future by upholding data transparency and data integrity principles through an accessible application


## What is here?
    .
    ├── r                              # fxns for building inputs & outputs
    │   ├── admissions_plot.R                  
    │   ├── age_plot .R    
    │   ├── brenNet_stat_valuebox.R                  
    │   ├── diversityDemographics_plot.R                  
    │   ├── domesticPlacement_map.R                  
    │   ├── employmentStatus_stat_valueBox.R                  
    │   ├── geographicComparison_plot.R                  
    │   ├── initialEmployers_table.R 
    │   ├── initPlacementSatisfaction_stat_valueBox.R 
    │   ├── internationalPlacement_table.R 
    │   ├── internationalUniversities_table.R 
    │   ├── ipedsBackgrounds_plot.R 
    │   ├── ipedsCategories_plot.R 
    │   ├── ipedsTrends_plot.R 
    │   ├── jobSource_plot.R 
    │   ├── origins_map.R 
    │   ├── placementStatus_plot.R 
    │   ├── program_radioButtons.R 
    │   ├── programSize_valueBox.R 
    │   ├── race_plot.R 
    │   ├── residency_plot.R 
    │   ├── salary_plot.R 
    │   ├── salaryBySector_plot.R 
    │   ├── salarySpecialization_plot.R 
    │   ├── sectorSatisfaction_plot.R 
    │   ├── sectorTrends_plot.R 
    │   ├── sectorType_radioButtons.R 
    │   ├── sex_plot.R 
    │   ├── urmTrends_plot.R 
    │   └── year_radioButtons.R             
    ├── text                           # markdown and html files that contain text to be included in app
    │   ├── demo_about.md                  # introduces student demographic page
    │   ├── footer.html                    # landing page footer
    │   ├── ipeds_definition.md            # ipeds definition, used on demographics page
    │   ├── ipeds_text.md                  # Race and Background Reporting Defintions (green box on demographics page)
    │   ├── meds_career_about.md           # Welcome tab text on MEDS career page
    │   ├── meds_career_data_info.md       # About the data tab text on MEDS career page
    │   ├── meds_internationalPlacement.md # note about no MEDS international placements yet (takes place of table)
    │   ├── mesm_career_about.md           # Welcome tab text on MESM career page
    │   ├── mesm_career_data_info.md       # About the data tab text on MESM career page
    │   ├── race_ethnicity_text.md         # not currently used anywhere in app (ipeds_text.md used instead in green box)
    │   ├── sector_definitions.md          # sector definitions used as plot caption
    │   ├── undergrad_map_caption.md       # caption for undergrad origin map
    │   ├── urm_definition.md              # urm definition 
    │   ├── welcome_data_text.md           # landing page info about the data used in the app and who created it 
    │   └── welcome_what_text.md           # landing page info introducing the app
    ├── www                           # special directory in shiny for images and logos
    │   ├── logos                        # hex png files
    │   ├── images                       # jpg or png images used in app (e.g. banner image)
    │   ├── .DS_Store                    
    │   └── styles.css                   # CSS styles applied to app `tags$head(tags$link(rel = ""stylesheet"", type = ""text/css"", href = ""styles.css""))`
    ├── global.R                      # data frames, variables, functions, and libraries that are used repeatedly in app
    ├── server.R                      # code needed to build visuals and overall app
    ├── ui.R                          # layout and appearance of app
    ├── shiny-dashboard.Rproj                 
    ├── .gitignore                    # files to ignore when committing project  
    └── README.md

## Contributors
This dashboard was first completed in September 2022 and was presented to the Bren Staff on 13 September 2022. This dashboard will be updated anually by Bren Staff and a MEDS Fellow. 

* [Halina Do-Linh](https://github.com/hdolinh) (Bren R Shiny Developer Fellow 2022)
* [Jamie Montgomery](https://github.com/jamiecmontgomery) (MEDS Program Coordinator)
* [Sam Csik](https://github.com/samanthacsik) (NCEAS Data Training Coordinator)
* [Kristi Birney](https://bren.ucsb.edu/people/kristi-birney) (Bren Career Team)
* [Kristine Duarte](https://bren.ucsb.edu/people/kristine-duarte) (Bren Student Affairs Team)

## Application Updates
* **February 2023, updates by [Sam Csik](https://github.com/samanthacsik):** refactored code base, added career data for MEDS and MESM graduating classes of 2022
* **July 2024, updates by [Sam Csik](https://github.com/samanthacsik), [Jamie Montgomery](https://github.com/jamiecmontgomery), & [Kat Le](https://github.com/katleyq):** added career data for MEDS and MESM graduating classes of 2023, added admissions data for the 2023 entering classes, refactored code for maps (`{tmap}` > `{leaflet}` + removed data wrangling from server to improve loading speeds)
* **October 2024, updates by [Sam Csik](https://github.com/samanthacsik):** redesigned career plots so that they are a bit easier to interpret, added a secondary table of job titles, and continued refactoring code (i.e. simplifying and removing unncessary code)
* **November 2024, updates by [Sam Csik](https://github.com/samanthacsik):** updated demographics tab with 2024 incoming student data
","['hdolinh', 'samanthacsik', 'jamiecmontgomery', 'katleyq']",1,,0.76,0,,,,,,2,,,
85303573,MDEwOlJlcG9zaXRvcnk4NTMwMzU3Mw==,phd,macoj/phd,0,macoj,https://github.com/macoj/phd,A list of resources on how/why to do a PhD,0,2017-03-17 11:16:05+00:00,2025-02-27 14:54:35+00:00,2019-11-18 09:18:46+00:00,,44,355,355,,1,1,1,1,0,0,52,0,0,1,,1,0,0,public,52,1,355,master,1,,"# PhD
A working-in-progress list of resources on how/why to do a PhD. 

# Contents
- [On why (or why not)](#on-why) 
- [On how](#on-how)
  - [Overall](#overall)
  - [Admission](#admission)
  - [Reading a paper](#reading-a-paper)
  - [On writing](#on-writing)
    - [Proposal writing](#proposal-writing)
    - [Thesis writing](#thesis-writing)
    - [Research paper writing](#research-paper-writing)
    - [Grant proposal writing](#grant-proposal-writing)
    - [General writing](#general-writing)
    - [Writing research questions](#writing-research-questions)
    - [Cover letter for journal submission](#cover-letter-for-journal-submission)
  - [Presentations](#presentations)
  - [Poster presentations](#poster-presentations)
  - [Getting an academic job](#academic-job)
    - [Cover letters and CVs](#cover-letters-and-cvs)
  - [Paper reviewing](#paper-reviewing)
- [English](#english)
  - [Collocation](#collocation)
  - [Dictionary](#dictionary)
  - [Thesaurus](#thesaurus)
- [Books](#books)
  - [Science](#science)
  - [Writing Science](#writing-science)
  - [Statistics](#statistics)
- [Nice Wikipedia pages](#nice-wikipedia-pages)
- [Similar lists](#similar-lists)

# On why (or why not) to pursue a Ph.D.
* *The Ph.D Experience* by Mihir Bellare
  * http://cseweb.ucsd.edu/~mihir/phd.html
* *Should I get a Ph.D.?* by Tim Hopper
  * http://shouldigetaphd.com/
* *Notes On The PhD Degree* 
  * https://www.cs.purdue.edu/homes/dec/essay.phd.html
* *Tough love: An insensitive guide to thriving in your PhD* by Chris Chambers
  * http://neurochambers.blogspot.co.uk/2012/05/tough-love-insensitive-guide-to.html
* *The single most practical reason for pursuing a Ph.D. that I can think of (and I've thought a lot about this topic!)* by Philip Guo
  * http://pgbovine.net/practical-reason-to-pursue-PhD.htm
* *Realistic expectations keep you on the path to a PhD*
  * https://www.timeshighereducation.com/news/realistic-expectations-keep-you-on-the-path-to-a-phd/2015739.article
* *“So long, and thanks for the Ph.D.!” a.k.a. Everything I wanted to know about C.S. graduate school at the beginning but didn’t learn until later.* by Ronald T. Azuma
  * https://www.cs.unc.edu/~azuma/hitch4.html


# On how
## Overall 
* *A Survival Guide to a PhD* by Andrej Karpathy
  * http://karpathy.github.io/2016/09/07/phd/
* *How to Be a Good Graduate Student* by Marie desJardins
  * http://www.cs.indiana.edu/how.2b/how.2b.html
* *Ten Lessons I wish I had been Taught* by Gian-Carlo Rota
  * http://alumni.media.mit.edu/~cahn/life/gian-carlo-rota-10-lessons.html
* *Making Key Research Decisions* (excerpt from *500 Tips for Research Students)* by Sally Brown, Liz McDowell and Phil Race
  * https://www.cs.tufts.edu/~nr/students/decisions.txt
* *What Am I Doing Here? A Guide to the Unwritten Rules of Grad School in the Sciences* by Cory Kerens
  * https://www.cs.tufts.edu/~nr/students/clk.html
* *Working with Norman Ramsey: a Guide for Research Students* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/students/guide.pdf
* *Advice for new Ph.D. students* by Philip Guo
  * http://pgbovine.net/early-stage-PhD-advice.htm
* *Some Modest Advice for Graduate Students* by Stephen C. Stearn 
  * http://stearnslab.yale.edu/some-modest-advice-graduate-students
* *Advice for students and junior researchers* by Markus Jakobsson
  * http://www.markus-jakobsson.com/advice-for-students-and-junior-researchers
* *10 easy ways to fail a Ph.D.* by Matt Might
  * http://matt.might.net/articles/ways-to-fail-a-phd/

## Admission
* *How to get admitted to a PhD program* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/students/admit.html
* *CS Grad School Part 1: Deciding to Apply* by Jean Yang
  * http://jxyzabc.blogspot.my/2008/08/cs-grad-school-part-1-deciding-to-apply.html
* *Choosing the Right Grad School* by Danah Boyd
  * http://www.danah.org/GradSchoolAdvice.html
* *FAQ: Applying to Graduate School for Computer Science* by Jean Yang
  * http://jxyzabc.blogspot.my/2012/10/faq-applying-to-graduate-school-for.html
* *Some notes on picking grad schools/advisors* by Jean Yang
  * http://jxyzabc.blogspot.my/2009/02/some-notes-on-picking-grad.html

## Reading a paper
* *How to read a research paper* by Spencer Rugaber
  * http://www.cc.gatech.edu/fac/Spencer.Rugaber/txt/research_paper.txt
* *Thoughts on Reading Research Papers* by Jeff Offutt
  * http://cs.gmu.edu/~offutt/classes/phd/Hints-Read.html
* *How to read a research paper* by Michael Mitzenmacher
  * http://www.imsc.res.in/~meena/mitzenmacher-ReadPaper.pdf
* *How to (seriously) read a scientific paper* by  Elisabeth Pain
  * http://www.sciencemag.org/careers/2016/03/how-seriously-read-scientific-paper
* *Infographic: How to read a scientific paper* by Natalia Rodriguez 
  * https://www.elsevier.com/connect/infographic-how-to-read-a-scientific-paper
* *How to Read an Engineering Research Paper* by William G. Griswold 
  * https://cseweb.ucsd.edu/~wgg/CSE210/howtoread.html
* *How to Read a Paper* by S. Keshav
  * http://ccr.sigcomm.org/online/files/p83-keshavA.pdf
* *How to read a research paper* by Tiffany Barnes
  * http://webpages.uncc.edu/tbarnes2/SeriousGames/papers/ReadingResearchPaper.pdf
* *Reading Scientific Papers* by Robert Siegel
  * http://web.stanford.edu/~siegelr/readingsci.htm
* *How to Read a Scientific Article* by Mary Purugganan and Jan Hewitt
  * http://www.owlnet.rice.edu/~cainproj/courses/HowToReadSciArticle.pdf
* *Strategic Reading, Ontologies, and the Future of Scientific Publishing* by Allen H. Renear and Carole L. Palmer
  * http://science.sciencemag.org/content/325/5942/828
* *How to  Read a Book* by Paul N. Edwards
  * http://pne.people.si.umich.edu/PDF/howtoread.pdf
  
## On Writing
### Proposal writing
* *On Ph.D. thesis proposals in computing science* by H. C. Lauer 
  * http://www.mi.fu-berlin.de/wiki/pub/Mi/PromotionsVerfahren/Lauer75.pdf

### Thesis writing
* *How to write a good PhD thesis and survive the viva* by Stefan Rüger
  * http://people.kmi.open.ac.uk/stefan/thesis-writing.pdf
* *How to Write a PhD Thesis* by Joe Wolfe 
  * http://newt.phys.unsw.edu.au/~jw/thesis.html
* *How To Write a Good (no, Great) PhD Dissertation* by Priya Narasimhan
  * https://www.cs.cmu.edu/~priya/ICSOC-PhDSymp-2006-dist.pdf
* *How to write a Ph.D. thesis* by Reinhard Jahn
  * https://www.uni-goettingen.de/de/document/download/5fb4239f7b0c852ff840df93f2d0fca9-en.pdf/ThesisguidelinesGGNB201604.pdf
* *A Structured Approach to Presenting Thesis* by ChadPerry 
  * http://www.aral.com.au/resources/cperry.pdf
* *Dissertation Advice* by Olin Shivers 
  * https://www.cs.tufts.edu/~nr/students/shivers-thesis.html
* *How To Write A Dissertation or Bedtime Reading For People Who Do Not Have Time To Sleep* by Doug Comer
  * https://www.cs.tufts.edu/~nr/students/dec/essay.dissertation.html
* *Margo's Tips on Writing a Thesis* by Margo
  * http://mis-misinformation.blogspot.com/2012/03/margos-tips-on-writing-thesis.html
* *Design:The Key to Writing (and Advising) a One-Draft Ph.D Dissertation* by John V. Carlis
  * http://www-users.cs.umn.edu/~carlis/one-draft.pdf
* *A GUIDE TO WRITING YOUR MASTERS DISSERTATION*
  * http://www2.hw.ac.uk/sml/postgraduate/downloads/dissertations/dissertationguide.pdf
* *GUIDELINES FOR FORMAT AND CONTENT OF THE DISSERTATION*
  * http://semo.edu/education/images/EduLead_DissertGuide_2007.pdf
* *Mastering Your Ph.D.: Writing Your Doctoral Thesis With Style* By Patricia Gosling, Bart Noordam
  * http://www.sciencemag.org/careers/2007/12/mastering-your-phd-writing-your-doctoral-thesis-style
  
### Research paper writing 
* *11 steps to structuring a science paper editors will take seriously* by Angel Borja 
  * https://www.elsevier.com/connect/11-steps-to-structuring-a-science-paper-editors-will-take-seriously
* *How to write a great research paper* by Simon Peyton Jones
 * https://www.microsoft.com/en-us/research/academic-program/write-great-research-paper/
* *How to Write Your First Paper* by Steven G. Krantz
  * http://www.ams.org/notices/200711/tx071101507p.pdf
* *HOW TO WRITE A GREAT ABSTRACT* by Jari Saramäki
  * https://jarisaramaki.fi/2017/05/04/how-to-write-a-great-abstract/
* *Computer Science Writing Advice* by Renée J. Miller
  * http://dblab.cs.toronto.edu/~miller/index.php?p=resources
* *Common Bugs in Writing* by Henning Schulzrinne
  * http://www.cs.columbia.edu/~hgs/etc/writing-bugs.html
* *Writing Technical Articles* by Henning Schulzrinne
  * http://www.cs.columbia.edu/~hgs/etc/writing-style.html
* *How to get published in Nature (and its sister journals)* by Ed Gerstner
  * http://ord.ntu.edu.tw/tc/includes/GetFile.ashx?mID=253&id=1744&chk=e15262f3-87bf-4a7e-be6a-4103cbc61968

### Grant proposal writing
* *How to write a great research proposal* by Simon Peyton Jones and Alan Bundy
  * https://www.microsoft.com/en-us/research/academic-program/how-to-write-a-great-research-proposal/

### General writing
* *Norman Ramsey's Resources for Writers* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/students/writing.html
* *Learning Technical Writing Using the Engineering Method* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/pubs/learn.pdf
* *Writing Tips for Ph.  D. Students* by John H. Cochrane
  * https://faculty.chicagobooth.edu/john.cochrane/research/papers/phd_paper_writing.pdf
  
### Writing research questions
* *Types of quantitative research question*
  * http://dissertation.laerd.com/types-of-quantitative-research-question.php
* *Developing Research Questions* by Dissertation Recipes
  * http://dissertationrecipes.com/wp-content/uploads/2011/04/Developing-Research-Questions.pdf 
* *Writing a Good Research Question* by Center for Innovation in Research and Teaching
  * https://cirt.gcu.edu/research/developmentresources/tutorials/question
* *Narrowing a Topic and Developing a Research Question*
  * https://libraries.indiana.edu/sites/default/files/Develop_a_Research_Question.pdf
* *Research Questions and Hypotheses*
  * https://www.sagepub.com/sites/default/files/upm-binaries/22782_Chapter_7.pdf

### Cover letter for journal submission
* *Cover letters* by Springer
  * https://www.springer.com/gp/authors-editors/authorandreviewertutorials/submitting-to-a-journal-and-peer-review/cover-letters/10285574
* *I really think you should publish this paper: the cover letter to the editor* by M John
  * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3484622/ 
* *Writing Cover Letters for Scientific Manuscripts*  
  * http://www.biosciencewriters.com/Writing-Cover-Letters-for-Scientific-Manuscripts.aspx
* *Writing the cover letter for a Science Magazine submission* by David F. Raikow
  * https://rivercontinua.wordpress.com/2009/03/02/writing-the-cover-letter-for-a-science-magazine-submission/
* *Submitting your manuscript: Write the right cover letter* by Catarina Sacristán*
  * http://crosstalk.cell.com/blog/submitting-your-manuscript-write-the-right-cover-letter
* *How to write a great cover letter for a scientific manuscript* by Anne Altor
  * http://precisionscienceediting.com/tips/write-great-cover-letter-scientific-manuscript/

## Presentations
* *How to give a great research talk* by Simon Peyton Jones
  * https://www.microsoft.com/en-us/research/academic-program/give-great-research-talk/
* *How to give a technical presentation (how to give a scientific talk)* by Michael Ernst
  * http://homes.cs.washington.edu/~mernst/advice/giving-talk.html
* *Communication in Computer Science: Reviews, Papers, and Talks* by Olivier Danvy
  * http://users-cs.au.dk/danvy/tips-and-tricks.html
* *Oral Presentation Advice* by Mark D. Hill
  * http://pages.cs.wisc.edu/~markhill/conference-talk.html
* *Giving Technical Talks* by Scot Drysdale
  * http://www.cs.dartmouth.edu/~scot/givingTalks/
* *Giving a Good Research Talk* by Nicholas Nethercote
  * http://njn.valgrind.org/good-talk.html
* *Giving a Talk* by Frank R. Kschischang
  * http://www.comm.utoronto.ca/frank/guide/guide0.html
* *The Short Talk* by Charles Van Loan
  * http://www.cs.cornell.edu/cv/ShortTalk.htm
* *How to give a talk* by Bruce Randall Donald
  * http://www.cs.duke.edu/brd/Teaching/Giving-a-talk/giving-a-talk.html
* *How to Give an Academic Talk* by Paul N. Edwards
  * http://pne.people.si.umich.edu/PDF/howtotalk.pdf
* *Tips and Tricks for Giving Talks* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/students/talks.html
* *Maxims for Malfeasant Speakers* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/misc/badtalks.html
* *How to Present a Paper in Theoretical Computer Science: A Speaker’s Guide for Students* by Ian Parberry 
  * https://larc.unt.edu/ian/pubs/speaker.pdf
* *How to Present a Paper:A Speaker’s Guide* by Bob Spillman and Ian Parberry  https://www.sfu.ca/~jeffpell/Ling480/ParberryMembrane.pdf

## Poster presentations
* *Ten Simple Rules for a Good Poster Presentation* by Thomas C Erren and Philip E Bourne
  * https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030102
* *Do's and Don'ts of Poster Presentation* by Steven M. Block
  * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1233841/pdf/biophysj00042-0617.pdf
* *Preparing and Presenting Effective Research Posters* by Jane E. Miller
  * https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1475-6773.2006.00588.x
* *Tips on poster presentations at professional conference* by Scott W. Plunkett 
  * http://www.csun.edu/plunk/documents/poster_presentation.pdf

## Academic job
* *Getting an academic job* by Michael Ernst
  * http://homes.cs.washington.edu/~mernst/advice/academic-job.html
* *Tips for PhD students looking for faculty positions* by Norman Ramsey
  * https://www.cs.tufts.edu/~nr/students/job.html
* *Applying for a postdoc job? Here are 18 tips for a successful application*
  * https://www.theguardian.com/higher-education-network/2015/feb/01/applying-for-a-postdoc-job-here-are-18-tips-for-a-successful-application
* *A foot in the door* by Kendall Powell
  * https://www.nature.com/naturejobs/science/articles/10.1038/nj7281-696a
* *How Do I Apply for a Postdoc Position?*
  * https://med.emory.edu/postdoc/documents/How%20do%20I%20apply%20for%20a%20Postdoc%20Position.pdf
### Cover letters and CVs
* *How to write a killer cover letter for a postdoctoral application* by Bill Sullivan
  * http://www.asbmb.org/asbmbtoday/asbmbtoday_article.aspx?id=48927
* *CVs and Cover Letters* by Office of Career Services - Harvard University 
  * https://ocs.fas.harvard.edu/files/ocs/files/gsas-cvs-and-cover-letters.pdf
* *Writing a winning cover letter* by John K. Borchardt
  * http://www.sciencemag.org/careers/2014/08/writing-winning-cover-letter
* *CV Guide for PhD and Postdoctoral Researchers: Tailoring your CV for the Role.*
  * https://www.ucc.ie/en/media/support/careers/nelie/postdoccvguide/CVGuideforPhDandPostdoctoralResearchers.pdf 
* *How to Write an Academic Cover Letter With Examples* by Alison Doyle
  * https://www.thebalance.com/how-to-write-an-academic-cover-letter-2060155
* *Stanford PhD & Postdoc Career Guide* 
  * https://beam.stanford.edu/sites/default/files/stanfordphd_cg15-161.pdf
* *Documents for the Job Search: Put Your Qualifications in Writing*
  * http://postdocs.cornell.edu/documents-job-search  
* *Cover Letters for Academic Positions* 
  * http://www.grad.illinois.edu/sites/default/files/pdfs/academiccoverletters.pdf 
* *10 Tips to Help You Write a Better Cover Letter*
  * http://www.lifehack.org/articles/work/10-tips-for-better-cover-letter.html
* *How to Write a Cover Letter: 31 Tips You Need to Know*
  * https://www.themuse.com/advice/how-to-write-a-cover-letter-31-tips-you-need-to-know
* *How to write a cover letter people will actually read\*
  * https://www.nytimes.com/2016/10/22/business/how-to-write-a-cover-letter-that-stands-out.html
* *10 Tips for a Better Cover Letter*
  * https://www.jobscan.co/blog/how-to-write-a-cover-letter/
* *How to Write a Cover Letter* by Amy Gallo
  * https://hbr.org/2014/02/how-to-write-a-cover-letter
* *Writing a Successful Cover Letter*
  * http://www.columbia.edu/cu/tat/pdfs/cover%20letter.pdf
  
## Paper reviewing 
* *Accepting an invitation to review* 
  * https://www.springer.com/gp/authors-editors/authorandreviewertutorials/howtopeerreview/accepting-an-invitation-to-review/10286396
* *So you’ve been asked to review a manuscript? – Tips for the novice reviewer* by Chris Parsons* 
  * http://www.southernfriedscience.com/so-youve-been-asked-to-review-a-manuscript-tips-for-the-novice-reviewer/
* *How, when and why to say no to a review request* by Andrew Moore
  * https://hub.wiley.com/community/exchanges/discover/blog/2015/03/12/how-when-and-why-to-say-no-to-a-review-request
* *Tips for first time peer reviewers: Accepting a peer review invitation* by Kakoli Majumde 
  * http://www.editage.com/insights/tips-for-first-time-peer-reviewers-accepting-a-peer-review-invitation 
  
# English
* http://www.bartleby.com/141/index.html
## Collocation
* https://prowritingaid.com/en/Collocation/Dictionary?word=search
* http://www.just-the-word.com/
* http://www.freecollocation.com/
* https://ludwig.guru/
## Dictionary
* http://www.wordhippo.com/
* http://www.roget.org/
## Thesaurus
* http://www.thesaurus.com/
* https://www.merriam-webster.com/

# Books
## Science 
* Chalmers, Alan F. What is this thing called science?. Hackett Publishing, 2013.
* Okasha, Samir. Philosophy of Science: Very Short Introduction. Oxford University Press, 2016.
* Feynman, Richard P. The meaning of it all: Thoughts of a citizen-scientist. Addison-Wesley, 1998.

## Writing Science
* Schimiel, J. (2011). Writing Science: How to Write Papers That Get Cited and Proposals That Get Funded. Oxford University Press. 
* Silvia, P. J. (2007) How to write a lot: A practical guide to productive academic writing. American Psychological Association.
* White, E. B., and Strunk, W. (2014) The elements of style. Pearson Education Limited.

## Statistics
* DeGroot, M. H., & Schervish, M. J. (2012). Probability and Statistics (4th ed.). Addison-Wesley.

# Nice Wikipedia pages
* https://en.wikipedia.org/wiki/Philosophy_of_science
* https://en.wikipedia.org/wiki/List_of_fallacies
* https://en.wikipedia.org/wiki/IMRAD

# Similar lists
* https://www.cs.tufts.edu/~nr/students/
* http://www.ece.ucsb.edu/~yuanxie/Advice.html
",['macoj'],0,,0.61,0,,,,,,13,,,
308226,MDEwOlJlcG9zaXRvcnkzMDgyMjY=,AppBenchmark,suwanny/AppBenchmark,0,suwanny,https://github.com/suwanny/AppBenchmark,appscale benchmark testing tools,0,2009-09-15 21:16:44+00:00,2013-12-19 03:57:45+00:00,2009-09-15 21:22:42+00:00,,4994,2,2,Python,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,2,master,1,,"
1. Agent 
        1.1 How to use 
        ./agent.sh [application]
        ./agent.sh guestbook         // you should have guestbook.properties in etc folder 

2. Proxy 
        2.1 How to use
        ./proxy.sh [script_name]
        ./proxy.sh guestbook // this will generate guestbook.py in script/proxy folder. 

3. Console
        3.1 How to use 
        ./console.sh         // you need XWindow for this since this is GUI application. 

4. Directories
        bin/ 
        bin/agent.sh
        bin/proxy.sh
        bin/console.sh

        etc/
        etc/application.properties

        log/
        log/guestbook/*.log

        scripts/
        scripts/proxy 
        scripts/guestbook.py

5. Data Analysis
  
  - making excel data and statistics input

  ./AppPlot.py data_file name 
  ./AppPlotMulti.py hbase gb_hbase 3 data_appscale-image 5

  - draw chart

  ./AppTransactionPlot.py first > /var/www/hbase_transaction1.png
  ./AppTransactionPlot.py all > /var/www/hbase_transaction.png

  ./AppResponsePlot.py all > /var/www/hbase_response.png
  ./AppResponsePlot.py first > /var/www/hbase_response1.png


6. Collect Data
  scp gb_*.tgz spark@twolves.cs.ucsb.edu:~/Project/Grinder/AppBenchmark/collect

-- JFreeChart
http://downloads.sourceforge.net/project/jfreechart/1.%20JFreeChart/1.0.13/jfreechart-1.0.13.tar.gz?use_mirror=softlayer
http://downloads.sourceforge.net/project/jfreechart/2.%20Documentation/1.0.13/jfreechart-1.0.13-install.pdf?use_mirror=softlayer
",[],0,,0.76,0,,,,,,3,,,
892318128,R_kgDONS-xsA,Vignette-gnn,Capstone-24-25/Vignette-gnn,0,Capstone-24-25,https://github.com/Capstone-24-25/Vignette-gnn,UCSB 2024-2025 Capstone Group 14 - Graph Neural Network,0,2024-11-21 22:20:25+00:00,2024-12-14 06:28:22+00:00,2024-12-14 06:28:18+00:00,,5921,0,0,HTML,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,1,"# Vignette-gnn
Graph Neural Network in Python and Application to Molecule Solubility Prediction (Graph Level Prediction)

### Contributors
- Jaxon Zhang
- Ruizhe Jiang
- Pramukh Shankar

### Abstract
This project aims to implement a **Graph Neural Network (GNN)** in Python and apply it to the prediction of molecule solubility. The dataset used is the [ESOL](https://arxiv.org/abs/1703.00564) dataset that contains 1128 molecules and their solubility values, which is included in the `MoleculeNet` module of `torch_geometric`. A simple GNN is trained on the ESOL dataset and the performance of the GNN is evaluated using the mean squared error (MSE) metric. The GNN is able to achieve a MSE of **xxx** on the ESOL dataset, which is comparable to the performance of other machine learning models on the same dataset.

### Repository Contents

data/ - Folder containing the ESOL dataset; it is also included in the `MoleculeNet` module of `torch_geometric`
img/ - Folder containing images used in the vignette
  img/slides/ - Folder containing images used in the vignette
scripts/ - Folder containing the Python scripts used to implement the GNN and train it on the ESOL dataset
  scripts/draft.ipynb - Jupyter notebook containing the draft code for the GNN implementation
  scripts/model.py - Python script containing the GNN model implementation
  scripts/training.py - Python script containing the training code for the GNN
  scripts/visualization.py - Python script containing the code to visualize the GNN predictions


### Reference List
[A Gentle Introduction to Graph Neural Networks](https://distill.pub/2021/gnn-intro/)
","['JaxonZ2003', 'RuizheJiang', 'PSS128']",1,,0.77,0,,,,,,1,,,
115804638,MDEwOlJlcG9zaXRvcnkxMTU4MDQ2Mzg=,invivo,tiedaoxiaotubie/invivo,0,tiedaoxiaotubie,https://github.com/tiedaoxiaotubie/invivo,,0,2017-12-30 15:13:52+00:00,2017-12-30 15:30:11+00:00,2017-12-31 11:45:28+00:00,,35666,0,0,Python,1,1,1,1,0,0,0,0,0,0,bsd-2-clause,1,0,0,public,0,0,0,master,1,,"angr
====

[![Latest Release](https://img.shields.io/pypi/v/angr.svg)](https://pypi.python.org/pypi/angr/)
[![Build Status](https://travis-ci.org/angr/angr.svg?branch=master)](https://travis-ci.org/angr/angr)
[![License](https://img.shields.io/github/license/angr/angr.svg)](https://github.com/angr/angr/blob/master/LICENSE)
[![Gitbook](https://img.shields.io/badge/docs-gitbook-green.svg)](http://docs.angr.io)
[![API Docs](https://img.shields.io/badge/docs-api-green.svg)](http://angr.io/api-doc)

angr is a platform-agnostic binary analysis framework developed by the Computer Security Lab at UC Santa Barbara and their associated CTF team, Shellphish.

# What?

angr is a suite of python libraries that let you load a binary and do a lot of cool things to it:

- Disassembly and intermediate-representation lifting
- Program instrumentation
- Symbolic execution
- Control-flow analysis
- Data-dependency analysis
- Value-set analysis (VSA)

The most common angr operation is loading a binary: `p = angr.Project('/bin/bash')` If you do this in IPython, you can use tab-autocomplete to browse the [top-level-accessible methods](http://docs.angr.io/docs/toplevel.html) and their docstrings.

The short version of ""how to install angr"" is `mkvirtualenv angr && pip install angr`.

# Example

angr does a lot of binary analysis stuff.
To get you started, here's a simple example of using symbolic execution to get a flag in a CTF challenge.

```python
import angr

project = angr.Project(""angr-doc/examples/defcamp_r100/r100"", auto_load_libs=False)

@project.hook(0x400844)
def print_flag(state):
    print ""FLAG SHOULD BE:"", state.posix.dump_fd(0)
    project.terminate_execution()

project.execute()
```

# Quick Start

- [Install Instructions](http://docs.angr.io/INSTALL.html)
- Documentation as [HTML](http://docs.angr.io/) and as a [Github repository](https://github.com/angr/angr-doc)
- Dive right in: [top-level-accessible methods](http://docs.angr.io/docs/toplevel.html)
- [Examples using angr to solve CTF challenges](http://docs.angr.io/docs/examples.html).
- [API Reference](http://angr.io/api-doc/)
",[],1,,0.69,0,,,,,,0,,,
125886652,MDEwOlJlcG9zaXRvcnkxMjU4ODY2NTI=,iCTF2018,RomanEmelyanov/iCTF2018,0,RomanEmelyanov,https://github.com/RomanEmelyanov/iCTF2018,,0,2018-03-19 16:17:52+00:00,2018-05-25 00:44:25+00:00,2018-03-20 07:37:15+00:00,,31048,2,2,HTML,1,1,1,1,0,0,2,0,0,0,,1,0,0,public,2,0,2,master,1,,"# Tasks from iCTF 2018

See also:
[1] https://ictf2018.net/
[2] https://ictf.cs.ucsb.edu/
[3] https://shellweplayagame.org/
",['RomanEmelyanov'],1,,0.67,0,,,,,,1,,,
743277354,R_kgDOLE2DKg,db-s24,pkirlin/db-s24,0,pkirlin,https://github.com/pkirlin/db-s24,,0,2024-01-14 21:11:01+00:00,2024-04-29 15:22:20+00:00,2024-04-29 15:22:16+00:00,,92591,0,0,HTML,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"---
layout: home
title: Just the Class
nav_exclude: true
permalink: /:path/
seo:
  type: Course
  name: Just the Class
---

# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- [announcements](announcements.md),
- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a template that extends the popular [Just the Docs](https://github.com/just-the-docs/just-the-docs) theme, which provides a robust and thoroughly-tested foundation for your website. Just the Docs include features such as:

- automatic [navigation structure](https://just-the-docs.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://just-the-docs.github.io/just-the-docs/docs/search/) and page indexing,
- and a set of [UI components](https://just-the-docs.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://just-the-docs.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `README.md` with your course information. [Be sure to update the url and baseurl](https://mademistakes.com/mastering-jekyll/site-url-baseurl/).
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add more content pages.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([CSW8](https://ucsb-csw8.github.io/s22/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

### Local development environment

Just the Class requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler. To setup a local development environment, clone your template repository and follow the GitHub Docs on [Testing your GitHub Pages site locally with Jekyll](https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/testing-your-github-pages-site-locally-with-jekyll).
",['pkirlin'],0,,0.77,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
32560805,MDEwOlJlcG9zaXRvcnkzMjU2MDgwNQ==,android_ui_deception,ucsb-seclab/android_ui_deception,0,ucsb-seclab,https://github.com/ucsb-seclab/android_ui_deception,"Source code for our ""What the App is That? Deception and Countermeasures in the Android User Interface"" paper",0,2015-03-20 03:39:57+00:00,2019-03-12 02:55:10+00:00,2015-05-21 20:47:49+00:00,,95689,19,19,Java,1,1,1,0,0,0,7,0,0,0,,1,0,0,public,7,0,19,master,1,1,"# REPOSITORY CONTENT #

This repository contains data and source code about the paper:

""What the App is That? Deception and Countermeasures in the Android User Interface"",
presented at 2015 IEEE Symposium on Security and Privacy (SP)

This repository contains three main folders:

###paper
The pdf file of the paper.

###presentation
The slides and the videos presented at IEEE SP 2015.

###attacks
Source code and videos showing some of the attacks described in the paper.

###android_modifications
The source code of the Android modifications, enabling the proposed on-device, defense.

# HOW TO COMPILE AND USE THE MODIFIED ANDROID #


## Download the Android official source code
Download the Android source code (tag: `android-4.4_r1.2`) as explained [here](https://source.android.com/source/downloading.html).

Use:
```
repo  init -u https://android.googlesource.com/platform/manifest -b android-4.4_r1.2
```
instead of:
```
repo init -u https://android.googlesource.com/platform/manifest
```
to download the correct tag


## Apply the patches
Assume that `<git>` is the folder where this file (`README.md`) is and `<source>` is the folder where Android has been downloaded.

Run:
```
cd <git>/android_modifications
./apply_patches.sh <source>
```


## Compile the code
```
cd <source>
source build/envsetup.sh
lunch 2
make
```
Refer to [the official documentation](https://source.android.com/source/building-running.html) for more information.


## Run the emulator with the correct configuration

The patches have been tested on a device mimicking the appearance of a Nexus 4.

Use the following instructions to run the emulator in the correct configuration.

###Create a correct avd
Open Android AVD Manager 
```
cd <source>/sdk
android avd
``` 
and use it to create a new Nexus 4 avd (named `<avd_name>`).

###Link the avd to the built image
Assuming that `<avd_name>` has been created in `<avd_folder>`, run the following commands:
```
AVD=<avd_folder>
cd <source>
CWD=$(pwd)
ln -s ""$CWD""/out/target/product/generic_x86/cache.img ""$AVD""/cache.img
ln -s ""$CWD""/out/target/product/generic_x86/userdata.img ""$AVD""/userdata.img
ln -s ""$CWD""/out/target/product/generic_x86/userdata-qemu.img ""$AVD""/userdata-qemu.img
ln -s ""$CWD""/prebuilts/qemu-kernel/x86/kernel-qemu ""$AVD""/kernel-qemu
ln -s ""$CWD""/out/target/product/generic_x86/ramdisk.img ""$AVD""/ramdisk.img
ln -s ""$CWD""/out/target/product/generic_x86/system.img ""$AVD""/system.img
```

###Run the emulator
```
cd <source>
source build/envsetup.sh
emulator -avd <avd_name>
```

",['antoniobianchi333'],1,,0.77,0,,,,,,10,,,
16797351,MDEwOlJlcG9zaXRvcnkxNjc5NzM1MQ==,cs56-games-beetle,ucsb-cs56-projects/cs56-games-beetle,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-games-beetle,-,0,2014-02-13 09:02:22+00:00,2016-10-28 00:17:59+00:00,2017-12-03 22:39:58+00:00,,1945,0,0,Java,1,1,1,1,1,0,4,0,0,10,,1,0,0,public,4,10,0,master,1,1,"# cs56-games-beetle

## Authors

* W16 READY Hanna
* F16 Yuanqi Samarth

## Testing the Text-based game
To run the text-based game, you can't use ant at the command line. Instead you have to cd into the build directory and then use the command `java edu.ucsb.cs56.projects.games.beetle.BeetleGame -t`.

## Project Description

This is a dice rolling game in which the user can choose between four levels: Beetle, Ant, Person, and Ladybug. 
The game can be played against the computer or against another person.

This game is played by clicking a ""Roll"" button that randomly rolls a value (1-6) for each play. This value corrensponds to the number on a dice and each number represents a body part of the insect/person trying to be created.
The player must first roll the number representing the ""body"" or ""thorax"" before adding on other parts of the insect/person.
The game is won by being the first player to roll all parts of the insect/person.

## Screenshots

![StartScreen](./gamePictures/StartScreen.png)
![PlayerSelectScreen](./gamePictures/PlayerSelectScreen.png)
![GameScreen](./gamePictures/GameScreen.png)
![GameEndScreen](./gamePictures/GameEndScreen.png)

## F16 Final Remarks

When the game is launched, there is a menu giving the option of which game mode the user wants to choose. After the user selects which game mode they want (Ant, Beetle, Ladybug, or Person) a prompt displays them asking if they want to play with 1 Player or 2. Then it makes them enter in their name(s), and the actual game GUI displays. In this GUI the user(s) can play the game, rolling the die until one of them wins. After they can choose to replay the game or to quit. 

The user can also select to run the text-based version of game by cd-ing into the build directory and then use the command ""java edu.ucsb.cs56.projects.games.beetle.BeetleGame -t"". In this game mode, they do the exact same thing as the normal version, except everything is text-based without a GUI. 

The way the code is set up, nothing needs to be refactored as we took care of that. The entry point to the game is the `BeetleGame` class. `GuiBased` and `TextBased` are the two views of the game using the MVC design pattern. All of the game classes such as `Ant` and `Beetle` extend `Player` so if you want to create more game modes, all you have to do is create new classes extending `Player`.

## W16 Final Remarks

When the game is run, the startGUI window appears with options for the level. When a level is selected, the corresponding GUI is launched and an instance of a Player object for that level is created. The GUI class for each level contains the code for the buttons and text fields while the Player class contains for for handling the rolls and adding parts.

The main feature that can be improved is improving the graphics. It would be nice for the user to see the animal being built as they play the game.

A couple of bugs that exist is that the exit window pops up right when the game ends, which can cause confusion as to who won the game. Also, after a game ends and the user selects a new level, the window for entering a name reappears. These are further explained in the Issues section ing Github.

As of now, each level has its own Player class. However, these Player classes are very similar to each other. There is possibility to combine them all into one generic class or create a parent class that they inherit from in order to keep the code DRY.
","['yuanqili', 'alexanderkang', 'alexk2060', 'hannavigil', 'rammalyala', 'athielk', 'bronhuston', 'lanthony159', 'JNguyen96', 'ashedden', 'erdinckorpeoglu', 'mastergberry']",1,,0.8,0,,,,,,3,,,
493837140,R_kgDOHW9bVA,Java-Programming-Solving-Problems-with-Software,dr-bunsenhoneydew/Java-Programming-Solving-Problems-with-Software,0,dr-bunsenhoneydew,https://github.com/dr-bunsenhoneydew/Java-Programming-Solving-Problems-with-Software,Files related to Duke/UCSB Java Programming Specialization,0,2022-05-18 21:57:32+00:00,2022-05-18 22:02:41+00:00,2022-05-19 20:08:56+00:00,,345,0,0,Java,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"# Java-Programming-Solving-Problems-with-Software
Files related to Duke/UCSB Java Programming Specialization
",['dr-bunsenhoneydew'],1,,0.78,0,,,,,,1,,,
704243122,R_kgDOKfnlsg,nathanjones4323,nathanjones4323/nathanjones4323,0,nathanjones4323,https://github.com/nathanjones4323/nathanjones4323,,0,2023-10-12 21:03:37+00:00,2023-10-12 21:03:38+00:00,2023-10-14 18:32:00+00:00,,27,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"

<h1 align='center'>
  Hi there 👋 I'm Nathan 👨‍💻
</h1>

<p align='center'>
  Data Engineer with a passion for BI, data science, ML.
</p>



<p align='center'>
  
  <a href=""https://www.linkedin.com/in/nathan-jones-8b2b1316b/"">
    <img src=""https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white"" />
  </a>&nbsp;&nbsp;
  
</p>

<p align='center'>
  <a href=""#""><img src=""https://github-readme-stats.vercel.app/api?username=nathanjones4323"" width=""350""></a>
</p>


## 📃 Resume


### Education

📖 **Financial Mathematics and Statistics**\
📆 2016 - 2020\
📍 **University of California, Santa Barbara** - Santa Barbara, California

### Experience

<img align=""right"" src=""https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Metabase-509EE3?style=for-the-badge&logo=metabase&logoColor=fff"" />
<img align=""right"" src=""https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Github-181717?logo=github&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white&style=flat"" />


👨‍💻 **Data Engineer**\
📆 2021 - Current\
📍 **Curri** - Ventura, CA

<img align=""right"" src=""https://img.shields.io/badge/Google%20Sheets-34A853?style=for-the-badge&logo=google-sheets&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Github-181717?logo=github&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white&style=flat"" />

👨‍💻 **Fleet Analyst**\
📆 2020 - 2021\
📍 **Curri** - Ventura, CA

## Contact Me

📫 How to reach me: <a href=""https://www.linkedin.com/in/nathan-jones-8b2b1316b/"">
  <img
    alt=""Linkedin""
    src=""https://img.shields.io/badge/linkedin-0077B5?logo=linkedin&logoColor=white&style=flat""
  />
</a>

## Skills / Tech Stack

#### Databases / BI:
<p>
  <img alt=""PostgreSQL"" src=""https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white"" />
  <img alt=""dbt"" src=""https://img.shields.io/badge/dbt-FF694B?style=for-the-badge&logo=dbt&logoColor=white"" />
  <img alt=""Metabase"" src=""https://img.shields.io/badge/Metabase-509EE3?style=for-the-badge&logo=metabase&logoColor=fff"" />
  <img alt=""Airbyte"" src=""https://img.shields.io/badge/Airbyte-615EFF?logo=airbyte&logoColor=fff&style=for-the-badge"" />
  <img alt=""Fivetran"" src=""https://img.shields.io/badge/fivetran-blue"" />
</p>

#### Development and Programming:
<p>
  <img alt=""Python"" src=""https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white&style=flat"" />
  <img alt=""Jupyter"" src=""https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white&style=flat"" />
  <img alt=""Visual Studio Code"" src=""https://img.shields.io/badge/Visual Studio Code-007ACC?logo=visual+studio+code&logoColor=white&style=flat"" />
  <img alt=""Git"" src=""https://img.shields.io/badge/Git-F05032?logo=git&logoColor=white&style=flat"" />
  <img alt=""GitHub"" src=""https://img.shields.io/badge/GitHub-181717?logo=github&logoColor=white&style=flat"" />
</p>

#### Cloud and Containerization:
<p>
  <img alt=""Docker"" src=""https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white"" />
  <img alt=""Digital Ocean"" src=""https://img.shields.io/badge/Digital_Ocean-0080FF?style=for-the-badge&logo=DigitalOcean&logoColor=white"" />
  <img alt=""AWS"" src=""https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white"" />
</p>

## Commonly Used Packages
<p>
  <img alt=""Matplotlib"" src=""https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black"" />
  <img alt=""Pandas"" src=""https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white"" />
  <img alt=""Numpy"" src=""https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white"" />
  <img alt=""Plotly"" src=""https://img.shields.io/badge/Plotly-239120?style=for-the-badge&logo=plotly&logoColor=white"" />
  <img alt=""Sci-Kit Learn"" src=""https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white"" />
  <img alt=""Streamlit"" src=""https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white"" />
</p>


## Operating System Familiar With
<p>
  <img alt=""MacOS"" src=""https://img.shields.io/badge/MacOS-000000?logo=macos&logoColor=white&style=flat"" />
  <img alt=""Windows"" src=""https://img.shields.io/badge/Windows-0078D6?logo=windows&logoColor=white&style=flat"" />
</p>

<!--## Skills

<img align=""right"" src=""https://img.shields.io/badge/(My)SQL-4479A1?logo=mysql&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/BASH-4EAA25?logo=gnu-bash&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/PHP-777BB4?logo=php&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Go-00ADD8?logo=go&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/C Sharp-239120?logo=c-sharp&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/C++-00599C?logo=c%2B%2B&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/C-A8B9CC?logo=c&logoColor=white"" />

**Programming**

<img align=""right"" src=""https://img.shields.io/badge/Arch-1793D1?logo=arch-linux&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Fedora-294172?logo=fedora&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Debian-A81D33?logo=debian&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Ubuntu-E95420?logo=ubuntu&logoColor=white"" />
<img align=""right"" src=""https://img.shields.io/badge/Windows-0078D6?logo=windows&logoColor=white"" />

**Operating Systems**

<img align=""right"" src=""https://img.shields.io/badge/English-B2-blue?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGlkPSJmbGFnLWljb24tY3NzLWdiLWVuZyIgdmlld0JveD0iMCAwIDY0MCA0ODAiPgogIDxwYXRoIGZpbGw9IiNmZmYiIGQ9Ik0wIDBoNjQwdjQ4MEgweiIvPgogIDxwYXRoIGZpbGw9IiNjZTExMjQiIGQ9Ik0yODEuNiAwaDc2Ljh2NDgwaC03Ni44eiIvPgogIDxwYXRoIGZpbGw9IiNjZTExMjQiIGQ9Ik0wIDIwMS42aDY0MHY3Ni44SDB6Ii8+Cjwvc3ZnPgo="" />
<img align=""right"" src=""https://img.shields.io/badge/Italian-mother tongue-green?logo=data:image/svg%2bxml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGlkPSJmbGFnLWljb24tY3NzLWl0IiB2aWV3Qm94PSIwIDAgNjQwIDQ4MCI+DQogIDxnIGZpbGwtcnVsZT0iZXZlbm9kZCIgc3Ryb2tlLXdpZHRoPSIxcHQiPg0KICAgIDxwYXRoIGZpbGw9IiNmZmYiIGQ9Ik0wIDBoNjQwdjQ4MEgweiIvPg0KICAgIDxwYXRoIGZpbGw9IiMwMDkyNDYiIGQ9Ik0wIDBoMjEzLjN2NDgwSDB6Ii8+DQogICAgPHBhdGggZmlsbD0iI2NlMmIzNyIgZD0iTTQyNi43IDBINjQwdjQ4MEg0MjYuN3oiLz4NCiAgPC9nPg0KPC9zdmc+"" />



<!--
## 📦 Packages
  
  

| Name                 | A short summary                              | Install   | Downloads |
| -------------------- | -------------------------------------------- | --------- | --------- |
| [Slack Exception Send](https://github.com/alexandresanlim/DotNet.Slack.ExceptionSend) | Send exceptions from applications to Slack.  | [![Nuget](https://img.shields.io/nuget/v/Slack.Exception.Send)](https://www.nuget.org/packages/Slack.Exception.Send) | [![Nuget](https://img.shields.io/nuget/dt/Slack.Exception.Send)](https://www.nuget.org/packages/Slack.Exception.Send) |
| [BrazilHolidays.Net](https://github.com/alexandresanlim/BrazilHolidays.Net)   | Work with Brazil holidays on applications.   | [![Nuget](https://img.shields.io/nuget/v/BrazilHolidays.Net)](https://www.nuget.org/packages/BrazilHolidays.Net) | [![Nuget](https://img.shields.io/nuget/dt/BrazilHolidays.Net)](https://www.nuget.org/packages/BrazilHolidays.Net) |
  
-->

<!--
**alexandresanlim/alexandresanlim** is a ✨ _special_ ✨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- 🔭 I’m currently working on ...
- 🌱 I’m currently learning ...
- 👯 I’m looking to collaborate on ...
- 🤔 I’m looking for help with ...
- 💬 Ask me about ...
- 📫 How to reach me: ...
- 😄 Pronouns: ...
- ⚡ Fun fact: ...
-->
",['nathanjones4323'],1,,0.67,0,,,,,,1,,,
448107006,R_kgDOGrWR_g,coms4995-nat-art-neural-nets,samuel-deng/coms4995-nat-art-neural-nets,0,samuel-deng,https://github.com/samuel-deng/coms4995-nat-art-neural-nets,Course website for COMS4995: Natural and Artificial Neural Networks Lab section.,0,2022-01-14 21:04:06+00:00,2022-01-14 21:04:09+00:00,2023-08-30 21:21:58+00:00,,12139,0,0,HTML,1,1,1,1,1,0,0,0,0,0,mit,1,0,0,public,0,0,0,main,1,,"# Just the Class

Just the Class is a GitHub Pages template developed for the purpose of quickly deploying course websites. In addition to serving plain web pages and files, it provides a boilerplate for:

- a [course calendar](calendar.md),
- a [staff](staff.md) page,
- and a weekly [schedule](schedule.md).

Just the Class is a set of customizations on top of the popular [Just the Docs](https://github.com/pmarsceill/just-the-docs) theme, which provides a robust and thoroughly-tested foundation that makes it easy to extend for your own special use cases. These foundational features include:

- automatic [navigation structure](https://pmarsceill.github.io/just-the-docs/docs/navigation-structure/),
- instant, full-text [search](https://pmarsceill.github.io/just-the-docs/docs/search/) and page indexing,
- and a small but powerful set of [UI components](https://pmarsceill.github.io/just-the-docs/docs/ui-components) and authoring [utilities](https://pmarsceill.github.io/just-the-docs/docs/utilities).

## Getting Started

Getting started with Just the Class is simple.

1. Create a [new repository based on Just the Class](https://github.com/kevinlin1/just-the-class/generate).
1. Update `_config.yml` and `index.md` with your course information.
1. Configure a [publishing source for GitHub Pages](https://help.github.com/en/articles/configuring-a-publishing-source-for-github-pages). Your course website is now live!
1. Edit and create `.md` [Markdown files](https://guides.github.com/features/mastering-markdown/) to add your content.

Just the Class has been used by instructors at Stanford University ([CS 161](https://stanford-cs161.github.io/winter2021/)), UC Berkeley ([Data 100](https://ds100.org/fa21/)), UC Santa Barbara ([DS1](https://ucsb-ds.github.io/ds1-f20/)), Northeastern University ([CS4530/5500](https://neu-se.github.io/CS4530-CS5500-Spring-2021/)), and Carnegie Mellon University ([17-450/17-950](https://cmu-crafting-software.github.io/)). For a few open-source examples, see the following course websites and their source code.

- [CSE 390HA](https://courses.cs.washington.edu/courses/cse390ha/20au/) ([source code](https://gitlab.cs.washington.edu/cse390ha/20au/website)) is an example of a single-page website that centers modules.
- [CSE 143](https://courses.cs.washington.edu/courses/cse143/20au/) ([source code](https://gitlab.cs.washington.edu/cse143/20au/website)) hosts an entire online textbook with full-text search.
- [CSE 373](https://courses.cs.washington.edu/courses/cse373/21su/) ([source code](https://gitlab.cs.washington.edu/cse373-root/21su/website)) is an example of a simple website combining Markdown pages with generated HTML files.

Share your course website and find more examples in the [show and tell discussion](https://github.com/kevinlin1/just-the-class/discussions/categories/show-and-tell)!

Continue reading to learn how to setup a development environment on your local computer. This allows you to make incremental changes without directly modifying the live website.

### Local development environment

Just the Class is built for [Jekyll](https://jekyllrb.com), a static site generator. View the [quick start guide](https://jekyllrb.com/docs/) for more information. Just the Docs requires no special Jekyll plugins and can run on GitHub Pages' standard Jekyll compiler.

1. Follow the GitHub documentation for [Setting up your GitHub Pages site locally with Jekyll](https://help.github.com/en/articles/setting-up-your-github-pages-site-locally-with-jekyll).
1. Start your local Jekyll server.
```bash
$ bundle exec jekyll serve
```
1. Point your web browser to [http://localhost:4000](http://localhost:4000)
1. Reload your web browser after making a change to preview its effect.

For more information, refer to [Just the Docs](https://pmarsceill.github.io/just-the-docs/).
",['samuel-deng'],0,,0.77,0,,,,"blank_issues_enabled: false
contact_links:
  - name: Ask a question
    url: https://github.com/kevinlin1/just-the-class/discussions
    about: Ask questions and discuss with other community members
",,1,,,
588673530,R_kgDOIxZx-g,capstone,Tyler-Hattori/capstone,0,Tyler-Hattori,https://github.com/Tyler-Hattori/capstone,,0,2023-01-13 17:48:53+00:00,2024-05-10 00:32:03+00:00,2024-03-01 22:12:19+00:00,,190370,4,4,C,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,4,main,1,,"# F1TENTH VELMA

source code written by the 2022-2023 ucsb f1tenth capstone team

written for ros noetic on ubuntu 20.04.

## Required packages
```
ros-noetic-slam-toolbox
ros-noetic-navigation
ros-noetic-tf2-geometry-msgs
ros-noetic-ackermann-msgs
ros-noetic-map-server
python-is-python3
git libusb-1.0-0-dev g++ build-essential
```

## Usage
```
roslaunch velma velma.launch
```
## Driving Modes
1. Manual Control - 'k'
3. Wall Follow - 'p'
4. Gap Follow - 'g'
5. Return to starting point - 'h'
6. Navigate to selected point on RVIZ map - 'n'
7. Begin to log waypoints of car's path - 'l'
8. Recall and navigate to logged waypoints in sequential order indefinitely - 'r'
9. Explore unknown areas of the environment - 'e'
10. Search for an object of a certain color in the environment (color specified by pixy settings) - 's'

## Required Hardware
1. Raspberry Pi 4
2. RP Lidar S2
3. VESC 6 MK V
4. RC car
",['Tyler-Hattori'],1,,0.78,0,,,,,,1,,,
357699068,MDEwOlJlcG9zaXRvcnkzNTc2OTkwNjg=,adrianstier,adrianstier/adrianstier,0,adrianstier,https://github.com/adrianstier/adrianstier,,0,2021-04-13 21:59:42+00:00,2021-04-14 16:48:51+00:00,2021-04-14 16:48:49+00:00,,1,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,main,1,,"## 👋 Hi there!

My name is Adrian and I'm an Associate Professor at the [University of California Santa Barbara](https://www.ucsb.edu/) in the [Ecology, Evolution, and Marine Biology Department](https://www.eemb.ucsb.edu/) 

I am an ecologist and conservation biologist interested in the recovery of degraded ocean ecosystems. You can learn more about me and my lab [here](https://www.oceanrecoveries.com/).
  

- 📫 You can find my contact info [here](https://www.oceanrecoveries.com/).

- 😄 Pronouns: He/Him/His
",['adrianstier'],1,,0.7,0,,,,,,1,,,
681355235,R_kgDOKJyn4w,PromotionskollegModule6800_2023,agpo-ilr-uni-bonn/PromotionskollegModule6800_2023,0,agpo-ilr-uni-bonn,https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023,,0,2023-08-21 20:43:31+00:00,2024-08-16 07:11:11+00:00,2024-08-16 07:11:07+00:00,,2464,1,1,Jupyter Notebook,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,master,1,1,"# PromotionskollegModule6800_2023
Course material and links for Promotionskolleg Module 6800: Machine learning in applied economic analysis.
September 4-8, 2023 (in presence in Bonn, Nussallee 19, seminar room)
[Note: Slides and videos related to an earlier online version of the course can be found under https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2021]

### Instructors 

Thomas Heckelei - University of Bonn, Germany

Hugo Storm - University of Bonn, Germany

[Kathy Baylis - University of California, Santa Barbara, USA]


### Research pitch 
Please prepare a 3 min pitch of your research project. The pitch should cover the following points:
1) What is your research question?
2) What type of data do you use (intent to use)?
3) What type of model do you use (intent to use)?
4) What is the major challenge you are currently facing?
5) Are you plan to use ML? If yes: Why and how? If no: What limitation do you see?

We are planning to do the pitches Wednesday/Thursday in the after the Q&A session, as well Friday morning. 

### Links to Intro material

- [Intro slides](https://docs.google.com/presentation/d/1GHHBYM8lXTJg5A9hhl9do5f5yCH6yC7fwGK3FBLcnxE/edit?usp=sharing)
- [Intro jupyter notebook](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/labIntro.ipynb)

### Links to Day 1 material 

- [Day 1 slides](https://docs.google.com/presentation/d/1NZQ_QTfO5KKz8MtXEjkoMIIl6OK09uHQkqwcMG9Pk4s/edit?usp=sharing)
- [Day 1 jupyter notebook for lecture and lab](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/6800_Day1.ipynb)


### Links to Day 2 material 

- [Day 2 slides](https://docs.google.com/presentation/d/1NF8WQrP9S5zoPddD45hZ0Wb0bjjbzBMzmDY-Mbt8Q7Y/edit?usp=sharing)
- [Day 2 jupyter notebook for lecture and lab](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/6800_Day2.ipynb)


### Links to Day 3 material 
- [Day 3a slides - Interpretation part II, Shapley values and other approaches](https://docs.google.com/presentation/d/1mCYuiOdMBvFpzIYgwokVAWc_UR46nqV6dA15rVBL7CQ/edit?usp=sharing)
- [Day 3b slides - Neural Networks (also include part of day 4 slides)](https://docs.google.com/presentation/d/12SLyH3bxYu0kySxFD61983cJjuOBW9vRcQ3T2tXpp2o/edit?usp=sharing)
- [Day 3-4 jupyter notebook for lecture and lab](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/6800_Day3-4.ipynb)


### Links to Day 4 material 
- [Day 4a slides - Neural Networks (same as day 3)](https://docs.google.com/presentation/d/12SLyH3bxYu0kySxFD61983cJjuOBW9vRcQ3T2tXpp2o/edit?usp=sharing)
- [Day 4b slides - ML and causal analysis (also include part of day 5 slides)](https://docs.google.com/presentation/d/1p7RcfS5FyqO3fwhNfUmSvP7RyfH2ebHcsejXDYhybmE/edit?usp=sharing)
- [Day 4-5 jupyter notebook for lecture and lab](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/6800_Day4-5.ipynb)
-[Example notebook of Lasso Double selection](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/Example_LassoDoubleSelection.ipynb)


### Links to Day 5 material 
- [Day 5 slides - ML and causal analysis (same as day 4b)](https://docs.google.com/presentation/d/1p7RcfS5FyqO3fwhNfUmSvP7RyfH2ebHcsejXDYhybmE/edit?usp=sharing)
- [Day 4-5 jupyter notebook for lecture and lab](https://github.com/agpo-ilr-uni-bonn/PromotionskollegModule6800_2023/blob/master/6800_Day4-5.ipynb)
","['hstorm', 'heckelei', 'bsrthyle']",1,,0.61,0,,,,,,1,,,
580519771,R_kgDOIpoHWw,nft-security-study,ucsb-seclab/nft-security-study,0,ucsb-seclab,https://github.com/ucsb-seclab/nft-security-study,"Code and data of the CCS '22 paper titled ""Understanding Security Issues in the NFT Ecosystem""",0,2022-12-20 19:08:49+00:00,2023-11-22 03:08:38+00:00,2022-12-20 20:18:41+00:00,,1,10,10,,1,1,1,1,0,0,1,0,0,0,,1,0,0,public,1,0,10,master,1,1,"# Understanding Security Issues in the NFT Ecosystem

In our ACM CCS 2022 paper titled ""[Understanding Security Issues in the NFT Ecosystem](https://arxiv.org/abs/2111.08893)"", we perform the first systematic study of the emerging, multi-billion dollar Non-Fungible Token (NFT) ecosystem on top 8 NFT marketplaces.
We systematize the NFT ecosystem by identifying three major participating actors—marketplaces, external entities, and users.
In order to have an in-depth understanding of the market dynamics, we perform a large-scale data collection involving various sources, such as, the Ethereum mainnet, marketplace APIs, web crawling.
We then identify security and privacy issues, and design weaknesses surrounding the identified actors.
Lastly, we quantified the extent of the those threats on the data collected, whenever possible.

## Data

- The asset (e.g., collection name, asset URI, metadata URI, etc.) and event (e.g., mint, buy, sell, auction creation, placing of a bid, acceptance of a bid, transfer, etc.) data collected from the top 8 NFT marketplaces (OpenSea, Axie, CryptoPunks, Rarible, Superrare, Sorare, Foundation, and Nifty) are stored in their respective databases.
Since the OpenSea dataset contains events for the same set of assets, crawled three times, with a three-month interval between two subsequent crawls: in June 2021, September 2021, and finally in December 2021, therefore respective asset tables are appropriately timestamped: [https://zenodo.org/record/6526192](https://zenodo.org/record/6526192)

- The `coins` database contains the Historical prices of the cryptocoins as provided by [CoinGecko](https://www.coingecko.com): [https://zenodo.org/record/6526192](https://zenodo.org/record/6526192)

- The `stats` database contains the availability of the source code of the token contracts in [Etherscan](https://etherscan.io): [https://zenodo.org/record/6526192](https://zenodo.org/record/6526192)

## Bibliography

```
@inproceedings{nft-study,
    author = {Dipanjan Das and Priyanka Bose and Nicola Ruaro and Christopher Kruegel and Giovanni Vigna},
    booktitle = {Proceedings of the ACM Conference on Computer and Communications Security (CCS)},
    title = {Understanding Security Issues in the NFT Ecosystem},
    year = {2022}
}
```
",['dipanjan'],1,,0.71,0,,,,,,10,,,
16779744,MDEwOlJlcG9zaXRvcnkxNjc3OTc0NA==,cs56-games-dealer,ucsb-cs56-projects/cs56-games-dealer,0,ucsb-cs56-projects,https://github.com/ucsb-cs56-projects/cs56-games-dealer,-,0,2014-02-12 19:53:10+00:00,2018-03-20 22:46:07+00:00,2018-03-20 22:46:05+00:00,,6488,0,0,Java,1,1,1,1,1,0,8,0,0,4,,1,0,0,public,8,4,0,master,1,1,"cs56-games-dealer
=================

project history
===============
```
 W14 | jcneally 4pm | acantor | Application to shuffle a deck of 52 playing cards and deal them to the use

 W16 | ttstarck kellybielaski 5pm | Added GUI and multiple hand functionality
 
 F16 | eric-xiao8 kpoon1 5 pm | Added main menu and Blackjack game
 
 F17 | JamesW121 KiwanSung 5pm | 

 W18 | adiltruong ernestosandoval 5pm | Added JaCoCo for code coverage 
```

What is this?
=============

This is an interface with classes such as card, deck, and hand that can be used to make card games. 
Dealer itself is an application to shuffle a deck of 52 playing cards and deal them to the user using command lines. 

JavaDoc: https://ucsb-cs56-projects.github.io/cs56-games-dealer/javadoc/

How To Run
==========

In the directory of where the build.xml is located 


    Type `ant run` - runs terminal
    Type 'ant runGUI' - runs GUI


 Other Ant Targets

 
    compile - compiles code
    linenumbers - creates file containing all source files with line numbers (doesn't work)
    clean - deletes javadoc, .jar, download, temp, and .class files
    javadoc - creates javadoc
    jar - creates a jar file
    download - old JWS target
    publish - old JWS target
    test - runs a JUnitTest
    
    
How does the application work?
==============================
Command Line:
The user is asked many hands the user wants to be dealt, then if the user wants the deck to be shuffled. The user is asked for a number to be dealt for each hand. The inputted numbers of cards are dealt to the player's hands and removed from the deck. The user is asked if they want to draw again until there are no more cards left in the deck. The user must input an integer from 0 to 52. Otherwise, the user will be dealt a default hand and the application will end. In the case of the deck being empty, the application will prompt the user to either reset with an empty hand and new deck or exit. The shuffle is done by using the shuffle function in the Collections class by using a RandomSecure seed.

GUI:
The user is prompted how many hands they want and if they don't want the deck to be shuffled, only shuffled once, or before each player draws. Then a panel is displayed that contains the textfields where the user can input how many cards they want for each hand. Then click the display cards button which replaces that panel with a new panel containing the textarea that displays the cards dealt for each hand and the remaining cards in the deck. The user can choose to continue drawing or reset the deck.

#### Running the Program ####
### If you run it by ""ant runGUI"" ###
![picture1](https://user-images.githubusercontent.com/25092924/32713886-1e02dfd0-c800-11e7-9c8f-c680334c1c7d.png)

You will be given two buttons, ""Blackjack"" and ""Dealer"". Each one will lead to corresponding game.

### Blackjack ###

-A player will be directed to play blackjack upon clicking on ""Blackjack"" button. Below is the next screen the user will see upon clicking the ""Blackjack"" button.

![picture2](https://user-images.githubusercontent.com/25092924/32713921-4c22919e-c800-11e7-8b0f-0fa4c2c6344b.png)


-Click on ""Play"" button to start playing blackjack.

![picture3](https://user-images.githubusercontent.com/25092924/32713940-5e3c05b8-c800-11e7-9a87-cc1cc4c7ec07.png)

-Initially the Player (user) and the Dealer will be each given two cards. Player will have all his/her cards faced up, Dealer's first card is faced down.

-Player will have to choose between the ""Hit"" button or the ""Stand"" button. Hit will draw another card to the Player; Stand will indicate that the Player does not wish to draw the card for this round.

![picture4](https://user-images.githubusercontent.com/25092924/32713955-734bba48-c800-11e7-91ad-76e28a5fedfa.png)

-Player will be able to select ""Hit"" button until the sum of cards reach 17 or above.

-Upon Stand, the Dealer will reveal the card faced down, and draw the additional random card(s) until the sum of its card reaches 17 or above.

-Player will win if the sum of his/her cards are greater than Dealer's (or if it busts), and equal or below to 21. (bust: Sum of the cards is greater than 21)

-The Dealer will win if the Player's card is bust, or the sum of its cards are less than that of Dealer's.

![picture5](https://user-images.githubusercontent.com/25092924/32713975-8a205db4-c800-11e7-9e07-37c3d153b6c1.png)

-Player will be given a result statement on the right of the screen and given a ""Continue"" button to play a new round. Player can always exit out of the system by clicking the ""X"" button of the GUI.

#### Dealer ####
-A player will be directed to play dealer upon clicking on ""Dealer"" button. Below is the next screen the user will see upon clicking the ""Dealer"" button.

![picture6](https://user-images.githubusercontent.com/25092924/32713992-9845c0f0-c800-11e7-947c-678cfa382b5b.png)

-The system will inqure how many hand(s) the user wants (between 1 and 10). Then the user is given a box to select shuffle frequencies. The user can choose between ""don't shuffle"", ""shuffle once before dealing"", and ""shuffle after every set of cards is dealt"". If ""don't shuffle"" is chosen, the deck will have the cards ordered from standard Diamond, Club, Heart, Spade in ascending order (2 -> 10 -> JQKA).

-The new line with box will be generated to inquire how many cards the User wants. The box will generate.

-Results of hands and cards will be printed, the system will inquire user to continue playing.

-Dealer API can be used and imported to other games that need a dealer such as various card games including Texas Hold Em and Go Fish. Since Dealer is universal in other card, mainly casino games, implementing the API will the save the game developers a great deal of time. For this project, we apply the concepts to BlackJack.

## If you run it by ""ant run"" ##
#### Blackjack ####
-You can run the program over the terminal (ant run). You can select to play Blackjack by inputting 2 on the first query. The system will then ask for the input of User's name to be featured throughout the rest of the game.

-The system will draw card for the dealer and the user and output accordingly (1st card of Dealer is hidden so denoted as ""X of X"").

-The system will query whether the User wants to hit or not (input either y for yes, and n for no).

-If yes, the system will draw the card, and the User will be given an option to hit or stand again. Should the sum of the cards exceed 21, the system will automatically announce user's loss without having to look at the Dealer's hand.

-If no, the system will move on to the Dealer's hands and Dealer will either hit or stand. Upon Dealer's stand, the system will compare the card sum of the Dealer and the User to determine the winner.

![picture7](https://user-images.githubusercontent.com/25092924/32714009-a83df4e6-c800-11e7-85b2-5a8c823b5211.png)

-After winner has been announced, the system will query whether to continue playing or not (y/n; y will immediately draw cards again, and n will exit the program).

#### Dealer ####
-You can run the program over the terminal (ant run). You can select to play Dealer by inputting 1 on the first query.

![picture8](https://user-images.githubusercontent.com/25092924/32714018-b86da424-c800-11e7-8626-5a877c895b26.png)

-The system will ask for input of number of hands to be used. (Any number between 1 and 10) The number n entered here will define n queries of cards wanted in each hand.

-The system will ask for whether for the cards to be shuffled. (Else standard sorted deck will be used)

-Each hand query, the deck will follow the shuffle frequencies that was determined in the beginning. 

-Upon the last hand, the system will ask whether if the user wishes to continue drawing hands. Upon yes, the system will start again with the leftover decks. Upon no, the system will print out rest of the cards remaining in the deck(s), print Goodbye.




F16 final remarks:
===================
The dealer interface has been updated to include card images and the game Blackjack has been created. Both console and GUI versions exist which can be run with 'ant run' and 'ant runGUI'. The code for the main menu is located in 'MainGui.java' and here additional games that are created can be added. One thing that can be improved for the Blackjack game is that when the player wins or loses, the continue button pushes the other GUI components to the left. This can be fixed so that they remain stationary instead. Also, the card class can be refactored. At the moment there are methods in the card class that are used specifically for Blackjack such as the rankValue method. These methods can be refactored into the Blackjack game so that Card remains generalized for other games. 

F17 final remarks:
===================
This project is now able to run with Gradle. Console could be run with 'gradle run' and GUI version could be run with 'gradle runGUI'. 

New features have been added:
1. A betting system is added to the Blackjack game for both console and GUI version. Players will be asked to bet points on each game, and game will end if player lose all points.
2. The program is now able to handle invalid inputs. For example, when player enters negative numbers, the program will ask for another input instead of crashing.
3. 'Hit' and 'Stand' buttons in Blackjack game are now being disabled after each game when result is showing.
4. Readme file has been updated with a more detailed instruction and screenshots.
5. Two redundant files has been removed. 'GamesDealerPanelcopy.java' and 'DealerPanelHelpercopy.java' as well as some dead code.
6. 'build.xml' has been updated; Errors and warnings have been fixed.

W18 final remarks:
===================
New features have been added:
1. The Card, Hand, and Deck classes have been refactored such that they can be used as a library for dealing cards to any card game. For example, BlackJackCard is a class that inherits from the Card class. It overrides the rankValue method because the game BlackJack uses rank values unique to this game. In this case, we also need to create a class BlackJackDeck that contains BlackJackCards, not the parent Cards.
2. The Card class has been updated to contain rank and value members of enumerated types, instead of strings. 
3. JaCoCo code coverage was added to check different cases within the code were checked with tests. Future case can be full test coverage.
4. Added home button to GUI as well as color background to Blackjack game. The GUI was made faster after hitting play but this introduced issue #59. 


","['kpoon1', 'acantor', 'kbielaski', 'SungKiwan', 'athielk', 'seemantasaha', 'ttstarck', 'YunSuk', 'kjorg50', 'adiltruong', 'ashedden', 'eric-xiao8', 'hannavigil', 'jcneally', 'mastergberry']",1,,0.83,0,,,,,,3,,,
172633469,MDEwOlJlcG9zaXRvcnkxNzI2MzM0Njk=,NVmain,SEAL-UCSB/NVmain,0,SEAL-UCSB,https://github.com/SEAL-UCSB/NVmain,NVMain - An Architectural Level Main Memory Simulator for Emerging Non-Volatile Memories,0,2019-02-26 03:46:36+00:00,2025-02-18 20:02:08+00:00,2019-07-23 10:55:31+00:00,,6856,80,80,C++,1,1,1,1,0,0,32,0,0,5,,1,0,0,public,32,5,80,master,1,1,"NVMain - An Architectural Level Main Memory Simulator
         for Emerging Non-Volatile Memories

======================================================

Sections

    1. Overview
    2. Building NVMain
       a. Trace Simulation
       b. Simulator-Connected Simulation
    3. Running NVMain
    4. Configuring NVMain
    5. Hacking NVMain
    6. README Changelog

------------------------------------------------------  

1. Overview

    NVMain is a cycle accurate main memory simulator
    designed to simulate emerging non-volatile
    memories at the architectural level. Since the 
    current status of non-volatile memory is unknown
    and this is a research tool, flexability is 
    provided to implement different variations of
    memory controllers, interconnects, organizations,
    etc. Detailed modification information is
    provided in section 5. Thanks for trying NVMain!


------------------------------------------------------

2. Building NVMain

    NVMain can be build as a standalone executable to
    run trace-based simulations, or it can be patched
    into a CPU simulator to provide closer to full
    system simulation. 

    2a. Trace Simulation

        The trace simulation can be build using scons:

        $ scons --build-type=[fast|debug|prof]

        Compiling with scons will automatically set 
        the compile flags needed for trace-based
        simulation. You can use --build-type=fast
        for -O3 optimization, --build-type=debug
        to add debugging symbol, or --build-type=prof
        to add support for profiling the simulator.

    2b. Simulator-Connected Simulation

        Running NVMain under a simulator depends on
        the simulator use. The 'patches' directory
        contains a directory for each of the supported
        simulators.

        gem5 (git);

           The gem5 patch is the most up-to-date patch
           in most cases. As of March 1st, 2017 gem5 uses
           a git repository as the master. The NVMain patch
           can be applied using the follwing command in the
           gem5 root directory:

           git apply /path/to/nvmain/patches/gem5/nvmain2-XYZ

           The patch can be removed using the following:

           git apply -R /path/to/nvmain/patches/gem5/nvmain2-XYZ

        gem5 (mercurial):

           If you are using a verison of gem5 cloned from
           the read-only mercurial mirror, mercurial queues
           can be used to apply the patch. To start, go to
           the gem5 root directory and import the patch

           $ hg qimport /path/to/nvmain/patches/gem5/nvmain2-XYZ

           Apply the path using qpush:

           $ hg qpush

           You can check that the patch was applied using
           qapplied:

           $ hg qapplied

           You can build gem5 normally at this point.
           You will need mercurial queues setup to do
           this. More information can be found at 
           http://mercurial.selenic.com/wiki/MqExtension/
           In general you should add the following to ~/.hgrc:

           [extensions]
           mq =

           and you should initialize queues in gem5 using:

           $ hg qinit


           To update the gem5 patch, first remove it and 
           delete it. It can then be imported again. In
           order to save your modifications, you can create
           your own patch before re-importing the nvmain 
           patch:

           $ hg qnew mychanges.patch
           $ hg qrefresh
              
           Now your changes are saved in the ""mychanges.patch""
           file. Feel free to rename this :). Next re-import
           NVmain:

           $ hg qpop -a
           $ hg qdel nvmain-XYZ
           $ hg qimport /path/to/nvmain/patches/gem5/nvmain-XYZ
           $ hg qpush -a

        zsim:

           There is a 3rd-party effort to integrate NVMain with
           zsim, a PIN-based x86-64 simulator. Details can be
           found here:

           https://github.com/AXLEproject/axle-zsim-nvmain


------------------------------------------------------

3. Running NVMain


    NVMain can be run on the command line with trace-based
    simulation via:

    ./nvmain CONFIG_FILE TRACE_FILE [Cycles [PARAM=value]]


    The CONFIG_FILE is the path to the configuration file
    for the memory system being simulated. The TRACE_FILE
    is the path to the trace file with the memory requests
    to simulate. Cycles is optional and specifies the max
    number of cycles to simulate. By default the entire
    trace file is simulated. This is equivalent to providing
    ""0"" as the value for Cycles. Additionally, CONFIG_FILE
    parameters can be overriden using PARAM=value, for
    example, adding ""MEM_CTL=FRFCFS"" to the command line
    will override the value for MEM_CTL in the configuration
    file.

    A various number of trace formats are supported, such
    as ""ProtocolTrace"" traces from gem5 or NVMain traces
    which contain the minimum amount of information needed
    to simulate a request. NVMain traces are recommended.
    Traces can be generated by running gem5 with the
    printtrace.config configuration file. The NVMain trace
    format prints the previous and new value of data being
    written to memory to allow for simulation of MLC NVMs
    and data encoding techniques which require knowing
    which data bits are changing.

    For gem5, simulation is setup using python scripts.
    NVMain only patches gem5 to recognize command line
    options for NVMain. The example scripts provided with
    gem5 can be used:

    configs/example/se.py - Run in SE mode
    configs/example/fs.py - Run in FS mode

    When running gem5, the parameter --mem-type=NVMainMemory
    must be used to enable NVMain. The option --nvmain-config
    must be used to specify the NVMain configuration file.
    Below is an example command line:

    $ gem5.fast config/example/se.py -c hello_world      \
                --mem-type=NVMainMemory --caches         \
                --l2cache --l1i_size 32kB                \
                --l1d_size 32kB --l2_size 2MB            \
                --cpu-type=detailed                      \
                --nvmain-config=/path/to/nvmain.config


------------------------------------------------------

4. Configuring NVMain


    NVMain can be configured using the configuration files.
    Several example configuration files can be found in
    the Config/ folder in the NVMain trunk. 

    A more detailed listing of configuration parameter 
    names and potential values are on the NVMain wiki page
    at http://wiki.nvmain.org/.


------------------------------------------------------

5. Hacking NVMain


    As mentioned in the overview, NVMain is meant to 
    be flexible. Writing your own interconnect, 
    memory controller, endurance model, address 
    translator, etc. Can be done by creating a new 
    C++ file with your new class.

    Each unit has a Factory class which selects 
    the class to used based on the configuration
    file input. You can create a class by looking
    at one of the example classes in each folder:

    MemControl - Custom Memory Controllers
    FaultModels - Custom hard-fault models
    Decoders - Custom address translators
    Endurance - Custom Endurance models
    Interconnect - Custom Interconnects
    Prefetchers - Custom prefetchers
    SimInterface - Simulator interface used to
                   gather useful statistics from
                   the CPU simulator such as
                   instructions executed, cache
                   miss rates, etc.
    traceReader - Custom trace file readers

    When adding a class, make sure to update
    the factory class to #include your class
    header and to initialize your class if 
    the configuration is set to your class'
    name.

    In some folders there is a ""GenerateSConscript.sh""
    This script should also be run when you
    create a new class so gem5 knows about it.


------------------------------------------------------


8/17/2012 - Created first README
2/8/2017 - Update README for cleanup branch



","['abmerop', 'tzhang0924', 'adriaarmejach', 'hktechn0']",1,,0.82,0,,,,,,4,,,
417619171,R_kgDOGORc4w,SnailProject,zoeisabellafung/SnailProject,0,zoeisabellafung,https://github.com/zoeisabellafung/SnailProject,,0,2021-10-15 19:55:36+00:00,2022-10-26 18:40:58+00:00,2022-02-07 20:51:11+00:00,,9035,1,1,R,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,1,main,1,,"# Hofmann Lab Snail Project Calibration Code
Here you will find the repository for code that can be used to calibrate pH and temperature data collected along the California coast. The repository is maintained by Zoë Fung (GitHub: [@zoeisabellafung](https://github.com/zoeisabellafung)) at the University of California, Santa Barbara.

![alt text](/media/teggy.jpg?raw=true)
###### photo by Amelia Ritger; *Tegula funebralis*, Black turban snail

![alt text](/media/bodega-sun.jpg?raw=true)
###### photo by Amelia Ritger; Sensor collecting pH and temperature data in Bodega Bay, CA

## Abstract
This code was written under the guidance of Amelia Ritger (GitHub: [@ameliaritger](https://github.com/ameliaritger)), in the scope of her research regarding large-scale patterns of intraspecific variation in the black turban snail (*Tegula funebralis*). Ritger's research uses temperature and pH data collected from various sensors within the California Current Large Marine Ecosystem to analyze the resiliency of the turban snail to environmental change. To use this script, upload a dataframe containing the values collected during calibration and a dataframe containing the values collected in the field. The script will generate a .csv file with the calibrated temperature and pH values as well as the date/time associated with each measurement.

## Code
file name | description 
---|-----------
Hofmann Lab Code.Rmd | customizable R script that converts raw temperature and pH values (*in the form of voltages*) to standard units and calibrates the values against known TRIS values

## How to use the script
##### Please follow the metadata guidelines below when loading your data into the R script.
1. Download the required packages, located at the top of the script (install.packages("" ""))
2. Enter the file name of your .csv sheet with values collected during calibration under ""tris"" (tris <- ""your_file_name.csv"")
3. Enter the file name of your .csv sheet with values collected in the field under ""raw"" (raw <- ""your_file_name_.csv"")
4. Name the file that the script will automatically add to your working directory after calibrating the values you collected in the field under ""filename"" (filename <- ""your_file_name"")

##### Note: do not add "".csv"" to the entry under ""filename""; it will be automatically added by the script
5. Run the script! The generated file will contain calibrated pH values and temperature values, and the corresponding date/time for each measurement

## Metadata 
### For the values collected during calibration
Each row represents one measurement taken        

variable | description
---|---
Date | Date corresponding measurement was taken
Time | Time corresponding measurement was taken
Voltage 1        | mV, corresponding to site pH
Voltage 2        | mV, corresponding to the batteries of the probe
Voltage 3 | mV, corresponding to the batteries of the probe
Voltage 4 | mV, corresponding to site temperature

### For the values collected in the field
Each row represents one measurement taken        

variable | description
---|---
Date | Date corresponding measurement was taken
Time | Time corresponding measurement was taken
Voltage 1        | mV, correponsding to site pH
Voltage 2        | mV, corresponding to the batteries of the probe
Voltage 3 | mV, corresponding to the batteries of the probe
Voltage 4 | mV, corresponding to site temperature

### For the final .csv file generated by the script
Each row represents one measurement taken        

variable | description
---|---
Date, Time |        Date and time corresponding raw measurement was taken
Temperature        | Calibrated temperature (ºC) of the environment
pH        | Calibrated pH of the environment

*Temperature and pH are calibrated against known TRIS values","['zoeisabellafung', 'ameliaritger']",1,,0.76,0,,,,,,1,,,
138116690,MDEwOlJlcG9zaXRvcnkxMzgxMTY2OTA=,seclab.cs.ucsb.edu,sguzman/seclab.cs.ucsb.edu,0,sguzman,https://github.com/sguzman/seclab.cs.ucsb.edu,Seclab bibtext,0,2018-06-21 03:52:24+00:00,2018-06-21 03:52:51+00:00,2018-06-21 03:52:50+00:00,,23,0,0,,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,"# seclab.cs.ucsb.edu
Seclab bibtext 
",['sguzman'],1,,0.8,0,,,,,,2,,,
148944492,MDEwOlJlcG9zaXRvcnkxNDg5NDQ0OTI=,Anthropology-Games,NigelBess/Anthropology-Games,0,NigelBess,https://github.com/NigelBess/Anthropology-Games,A collection of video games made for an experiment in the Department of Anthropology at the University of California Santa Barbara. The games were used to test and measure cognitive differences between sexes regarding hunting-related tasks.,0,2018-09-15 22:25:02+00:00,2024-04-12 17:38:57+00:00,2018-11-05 03:09:01+00:00,,145559,0,0,C#,1,1,1,1,0,0,0,0,0,0,,1,0,0,public,0,0,0,master,1,,,['NigelBess'],1,,0.68,0,,,,,,0,,,
257650621,MDEwOlJlcG9zaXRvcnkyNTc2NTA2MjE=,LogicNLG,wenhuchen/LogicNLG,0,wenhuchen,https://github.com/wenhuchen/LogicNLG,"The data and code for ACL2020 paper ""Logical Natural Language Generation from Open-Domain Tables""",0,2020-04-21 16:29:32+00:00,2025-02-11 06:08:10+00:00,2022-10-08 15:37:01+00:00,,21947,167,167,Python,1,1,1,1,0,0,22,0,0,2,mit,1,0,0,public,22,2,167,master,1,,"# LogicNLG
The data and code for ACL2020 paper [Logical Natural Language Generation from Open-Domain Tables](https://arxiv.org/abs/2004.10404), which aims to study the problem of natural language generation with logical inference in the intermediate steps. Going beyond simply surface-level copying, LogicNLG requires the model to deeply understand the content in the table and infer information implicitly expressed by the table.

<p align=""center"">
<img src=""examples.png"" width=""400"">
</p>

## Demo
You can explore the [visualization interface](https://wenhuchen.github.io/logicnlg.github.io/) to see the generation results of different models on LogNLG. Have fun!

## Requirements
- pytorch 1.4.0
- huggingface transformers 2.5.1
- tensorboardX
- tqdm
- apex [optional]

## Training/Evaluation Data
The data used for LogicNLG is provided in [data](https://github.com/wenhuchen/LogicNLG/blob/master/data) folder, the details are described in [README](https://github.com/wenhuchen/LogicNLG/blob/master/data/README.md)

## Preparation
### Unzip all the table files
```
unzip all_csv.zip
```

### Download the NLI scorer
```
wget https://logicnlg.s3-us-west-2.amazonaws.com/NLI_models.zip
unzip NLI_models.zip
```

### Download the Semantic Parser
```
wget https://logicnlg.s3-us-west-2.amazonaws.com/parser_models.zip
unzip parser_models.zip
```

## Reproducing Reported Results From Automatic Metric Models
The generated output from Field-Infusing-Transformer,GPT-2-based, Coarse-to-Fine models are stored in [outputs](https://github.com/wenhuchen/LogicNLG/blob/master/outputs). Their corresponding parsing results are stored in [program_outputs](https://github.com/wenhuchen/LogicNLG/blob/master/program_outputs). 

### You can verify their corpus-level BLEU score by: 
```
python evaluate.py --input outputs/field_infusing.json --refernce data/test_lm.json --option corpus
python evaluate.py --input outputs/GPT_gpt2_12.65.json --refernce data/test_lm.json --option corpus
python evaluate.py --input outputs/GPT_gpt2_C2F_13.35.json --refernce data/test_lm.json --option corpus
```
### You can verify their NLI-Acc by:
```
CUDA_VISIBLE_DEVICES=0 python NLI.py --model bert-base-multilingual-uncased --do_verify --encoding gnn --load_from NLI_models/model_ep4.pt --fp16 --verify_file outputs/GPT_gpt2_C2F_13.35.json --verify_linking data/test_lm.json
```
### You can verify their SP-Acc by:
```
CUDA_VISIBLE_DEVICES=0 python parse_programs.py --compute_score --load_from parser_models/model.pt --score_file program_outputs/GPT_gpt2_C2F_13.35.json
```

## Loading Our Trained Models
You are download and reload our trained models from Amazon S3 and decode results from them.
```
wget https://logicnlg.s3-us-west-2.amazonaws.com/models.zip
unzip models.zip
```
### For GPT-2.py model
You can either decode the sentences 
```
CUDA_VISIBLE_DEVICES=0 python GPT2.py --do_test --load_from models/GPT_ep8.pt
```
or evaluate the Adv-Acc
```
CUDA_VISIBLE_DEVICES=0 python GPT2.py --do_verify --load_from models/GPT_ep8.pt
```
### For Coarse-to-Fine model
You can either decode the sentences 
```
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_test --load_from models/GPT_stage2_C2F_ep13.pt
```
or evaluate the Adv-Acc
```
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_verify --load_from models/GPT_stage2_C2F_ep13.pt --stage 2
```
These commands will save the decoded sentences to outputs/ folder and print out the Adv-Acc scores reported in the paper.

## Retrain Your Own Model
### Train Field-Infusing Transformer
```
CUDA_VISIBLE_DEVICES=0 python Transformer.py --do_train
```
### Train GPT2-small Model
```
CUDA_VISIBLE_DEVICES=0 python GPT2.py --do_train --model gpt2
```
If you are running on a cluster of multiple nodes, you can also try our distributed training recipe:
```
CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node 4 GPT-distributed.py --do_train --model gpt2 --batch_size 4
```
### Train GPT2-Coarse-to-Fine Model
1. Warm-up the template generation model for 10 epochs
```
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_train --model gpt2 --stage 1
```
2. Load the last model and then train the fine-grained surface realization model for 15 epochs and smaller batch size.
```
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_train --model gpt2 --stage 2 --epochs 15 --batch_size 3 --load_from models/GPT_stage1_C2F_ep9.pt
```
The trained models are stored under models/ folder, you can reload them and evaluate.

## Evaluation Command
### Perform Verification
```
python GPT2.py --do_verify --load_from models/[Your_Model] --model gpt2
python GPT2-coarse-to-fine.py --do_verify --load_from models/[Your_Model] --model gpt2 --stage 2
```

### Perform Generation
```
CUDA_VISIBLE_DEVICES=0 python GPT2.py --do_test --load_from models/[Your_Model] --model gpt2
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_test --load_from models/[Your_Model] --model gpt2
```
After running do_test command, the decoded results on test split will be saved into outputs/ folder, which is required for the following NLI-Acc and SP-Acc score computation.

### Compute NLI-Acc score
```
CUDA_VISIBLE_DEVICES=0 python NLI.py --model bert-base-multilingual-uncased --do_verify --encoding gnn --load_from NLI_models/model_ep4.pt --fp16 --verify_file outputs/[Your_File] --verify_linking data/test_lm.json
```

### Compute SP-Acc score
1. Parsing your output file into programs (**warning**: this program uses breadth first search for potential programs, and could take a long time if you don't have many cpu cores. The experimented machine has 64 cores, and the parsing takes 30-60 minutes.):
```
python parse_programs.py --parse --score_file outputs/[Your_File]
```
2. Run the ranker model to predict the entailment relationship:
```
CUDA_VISIBLE_DEVICES=0 python parse_programs.py --compute_score --load_from parser_models/model.pt --score_file program_outputs/[Your_File]
```

### Parser and Entity Linker
We provide the details of our parser in [README](https://github.com/wenhuchen/LogicNLG/blob/master/LINKING.md).

## Codalab
We host challenge of LogicNLG in [CodaLab](https://competitions.codalab.org/competitions/24527). Please consider submit your results to the challenge site. 
```
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_verify_challenge --load_from models/GPT_stage2_C2F_ep13.pt --stage 2
CUDA_VISIBLE_DEVICES=0 python GPT2-coarse-to-fine.py --do_test_challenge --load_from models/GPT_stage2_C2F_ep13.pt --model gpt2
```
These two commands will output results ""verify_results.json"" and ""test_results.json"" in the challenge folder, please remember to zip your files before submission.
```
cd challenge
zip -r results.zip verify_results.json test_results.json
```

## Recent Papers


**Model**                                     |  **Organization**  |**Reference**                                                             | **BLUEU-1** | **BLEU-2** | **BLEU-3** | **SP-Acc** |   **SP-Acc** |
----------|---------------------------|-----------------------------------|---------------------------------------------------------------------------|---------|----------|------------------|------|
GPT-TabGen                 | UCSB          |    [Chen et al.](https://arxiv.org/abs/2004.10404)     | 48.8            |    27.1    |   12.6  |   42.1  | 68.7  |
GPT-Coarse-to-Fine         | UCSB          |   [Chen et al.](https://arxiv.org/abs/2004.10404)      |   46.6        |    26.8   |  13.3  |   42.7 |  72.2  |
DCVED     | Shanghai Jiao Tong University          |  [Chen & Jin et al.](https://aclanthology.org/2021.acl-long.430.pdf)  |    49.5                 |   28.6  |  15.3  |   43.9   |  76.9 |


## Miscellaneous
If you find any problem about the code, please leave an issue or shoot me an email.
",['wenhuchen'],1,,0.77,0,,,,,,5,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,163,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,33,,,,,,,,,,,,